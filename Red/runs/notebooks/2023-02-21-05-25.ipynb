{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "Este *notebook* incluye:\n",
    "- Pequeños ejemplos de uso de *pandas*.\n",
    "- Un *DataSet* (de *PyTorch*) que almacena información de los archivos de audio con los cantos de las aves. Este *DataSet*, al solicitársele el i-ésimo *item*, devuelve un cacho del i-ésimo audio, un cacho de un j-ésimo audio, y un 0 o 1 si `i != j` o `i == j` respectivamente.\n",
    "- Un *DataLoader* (de *PyTorch*) que envuelve al *DataSet* previamente descrito.\n",
    "- Una Red Neuronal (de *PyTorch*) que toma los espectrogramas de dos audios de longitud 1s cada uno, y devuelve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importaciones\n",
    "\n",
    "Importación de las bibliotecas a utilizar, y una pequeña descripción de cada una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alamina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/alamina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/alamina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/alamina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/alamina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/alamina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# pandas is an open source data analysis and manipulation tool.\n",
    "import pandas as pd\n",
    "\n",
    "# NumPy is for scientific computing with Python\n",
    "import numpy as np\n",
    "\n",
    "# TensorFlow is a free and open-source software library\n",
    "# for machine learning and artificial intelligence.\n",
    "import tensorflow as tf\n",
    "\n",
    "# PyTorch is an open source machine learning framework.\n",
    "import torch\n",
    "\n",
    "# PyTorch provides the torch.nn module to help us\n",
    "# in creating and training of the neural network.\n",
    "import torch.nn as nn\n",
    "\n",
    "# PyTorch has two primitives to work with data:\n",
    "# torch.utils.data.Dataset stores the samples and their corresponding labels.\n",
    "# torch.utils.data.DataLoader wraps an iterable around the Dataset.\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# \"The easiest way to use deep metric learning in your application\".\n",
    "# Written in PyTorch.\n",
    "# https://github.com/KevinMusgrave/pytorch-metric-learning\n",
    "from pytorch_metric_learning import losses\n",
    "\n",
    "# librosa is for music and audio analysis; it provides\n",
    "# the building blocks necessary to create music\n",
    "# information retrieval systems.\n",
    "import librosa\n",
    "\n",
    "# Displays a spectrogram/chromagram/cqt/etc.\n",
    "from librosa.display import specshow\n",
    "\n",
    "# matplotlib.pyplot is a collection of functions that make\n",
    "# matplotlib work like MATLAB. Each pyplot function makes\n",
    "# some change to a figure: e.g., creates a figure, creates\n",
    "# a plotting area in a figure, plots some lines in a plotting\n",
    "# area, decorates the plot with labels, etc.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TensorBoard is a visualization toolkit for machine learning\n",
    "# experimentation. TensorBoard allows tracking and visualizing\n",
    "# metrics such as loss and accuracy, visualizing the model graph,\n",
    "# viewing histograms, displaying images and much more.\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Para utilizar t-SNE.\n",
    "from tensorboard.plugins import projector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Para tomar el tiempo que toman ciertos procesos de la siguiente manera:\n",
    "# start = timer()\n",
    "# (algún proceso)\n",
    "# end = timer()\n",
    "# El tiempo en segundos es end-start.\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# CUDA-accelerated PyTorch implementation of the\n",
    "# T-Stochastic Neighbor Embedding algorithm.\n",
    "#from tsne_torch import TorchTSNE as TSNE\n",
    "\n",
    "# Manejo de guardado y cargado de objetos mediante archivos.\n",
    "import pickle\n",
    "\n",
    "# Manejo de pseudo-aleatoriedad.\n",
    "import random\n",
    "\n",
    "# Manejo de funciones matemáticas.\n",
    "import math\n",
    "\n",
    "# Manejo de fecha y tiempo.\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables generales\n",
    "\n",
    "Variables generales/globales que se utilizarán a lo largo del *notebook*. Conviene tener este apartado para consultarlas y modificarlas fácilmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizando cuda:0 para el procesamiento de datos.\n"
     ]
    }
   ],
   "source": [
    "# Uso del GPU, si está disponible.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Utilizando {device} para el procesamiento de datos.\")\n",
    "\n",
    "# Cadena con la ubicación del archivo CSV que contiene\n",
    "# el DataFrame con datos de los audios de aves.\n",
    "birds_csv = \"/media/birds/BirdsDataFrame.csv\"\n",
    "\n",
    "# Cadena con la ubicación de los archivos WAV y XML\n",
    "# correspondientes a los audios de aves a procesar.\n",
    "birds_path = \"/media/birds/data/\"\n",
    "\n",
    "# Otras ubicaciones útiles.\n",
    "DIR_runs = \"./runs/\"\n",
    "DIR_objects = DIR_runs+\"python_objects/\"\n",
    "DIR_tensorboard = DIR_runs+\"tensorboard/\"\n",
    "DIR_notebooks = DIR_runs+\"notebooks/\"\n",
    "DIR_models = DIR_runs+\"models/\"\n",
    "\n",
    "# Nombre de la columna, dentro del DataFrame,\n",
    "# que contiene el nombre de los archivos de audio.\n",
    "file_col_name = \"FileName\"\n",
    "\n",
    "# DataFrame (de 'pandas') del archivo CSV dado.\n",
    "birds_df = pd.read_csv(birds_csv)\n",
    "\n",
    "# Los audios de aves se cortarán en cachos cuya longitud\n",
    "# varíe entre len_min segundos y len_max segundos.\n",
    "len_min = 1\n",
    "len_max = 1\n",
    "\n",
    "# Ancho y alto de cada espectrograma.\n",
    "# TO-DO: ¿Es posible calcular esto mediante una fórmula? Resulta del size()/shape de aplicar \"stft\" al audio \"y\".\n",
    "ancho,alto = 1025,87\n",
    "\n",
    "# Número de canales que tendrá cada audio.\n",
    "# Hasta ahora, si un audio tiene 1 canal, y aquí se\n",
    "# especifican 2, se copia el primer canal en un\n",
    "# segundo canal. Si un audio tiene más de 2 canales,\n",
    "# la operación no está definida.\n",
    "audio_channels = 2\n",
    "\n",
    "# Frecuencia de muestreo a la cual TODOS los audios se\n",
    "# muestrearán. Esto es necesario para que los vectores\n",
    "# que representan a los audios tengan los mismos tamaños.\n",
    "sr = 44100\n",
    "\n",
    "# Probabilidad de que dos audios de aves (o\n",
    "# cachos de audios) compartan cierta propiedad.\n",
    "p_prop = 0.5\n",
    "\n",
    "# Variables asociadas a la Red Neuronal.\n",
    "batch_size = 64 # Número de muestras que se tomarán por lote/epoch.\n",
    "epochs = 150 # Veces que se recorrerá un DataSet entero.\n",
    "lr = 6e-04 # Learning Rate.\n",
    "#momentum = 0.5 # The SGD momentum (default: 0.5) is the moving average of our gradients (helps to keep direction).\n",
    "\n",
    "# Para TensorBoard, creamos un SummaryWriter.\n",
    "# Éste escribiría al directorio ./runs/ por defecto.\n",
    "dt_string = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "writer = SummaryWriter(log_dir=DIR_tensorboard+dt_string+\"_adbekunkus\")\n",
    "\n",
    "# Función a utilizar para procesar los audios de aves.\n",
    "def librosa_process(path, cut, cut_len=None):\n",
    "    \"\"\"\n",
    "    Función que carga un audio con Librosa y devuelve el vector\n",
    "    unidimensional que representa al audio, y su frecuencia de muestreo.\n",
    "    :param str path: Ruta donde se ubica el audio.\n",
    "    :param bool cut: ¿Se cortará (y devolverá) sólo un cacho aleatorio del audio?\n",
    "    :param float cut_len: Longitud del cacho de audio (si cut==True).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Longitud del audio completo en segundos.\n",
    "    audio_len = librosa.get_duration(filename=path)\n",
    "    \n",
    "    # Si se desea el audio completo, 'librosa' lo\n",
    "    # cargará desde el inicio hasta el final.\n",
    "    start = 0\n",
    "    duracion = audio_len\n",
    "        \n",
    "    # Si se desea sólo un cacho del audio...\n",
    "    if cut:\n",
    "        \n",
    "        # Determinamos la longitud del cacho\n",
    "        # aleatorio de audio en segundos.\n",
    "        duracion = cut_len if cut_len != None else random.uniform(len_min, len_max) # Rango [a,b].\n",
    "        \n",
    "        # Aseguramos que el audio completo es más\n",
    "        # grande que el tamaño del cacho que queremos.\n",
    "        assert audio_len > duracion\n",
    "        \n",
    "        # Definimos en dónde empezará\n",
    "        # (aleatoriamente) el cacho de audio.\n",
    "        start = random.uniform(0, audio_len-duracion) # Rango [a,b].\n",
    "    \n",
    "    # Obtenemos el audio-vector y su (nueva) frecuencia de muestreo.\n",
    "    y, sampling_rate = librosa.load(path, sr=sr, offset=start, duration=duracion, mono=False)\n",
    "    \n",
    "    # Algunos audios fueron grabados en dos canales (stereo), y otros en\n",
    "    # uno (mono). Convertimos los que fueron grabados en un canal en\n",
    "    # audios de dos canales (al duplicar el único canal que tienen).\n",
    "    if y.ndim == 1:\n",
    "        y = np.repeat(y[np.newaxis, :], 2, axis=0)\n",
    "    \n",
    "    # Función no definida para audios que tienen más de dos canales.\n",
    "    # Igual se lanza un error si los vectores no tienen la longitud adecuada (sr).\n",
    "    assert(y.shape == (2, sr))\n",
    "    \n",
    "    # Short-time Fourier transform (STFT).\n",
    "    # The STFT represents a signal in the time-frequency domain by computing\n",
    "    # discrete Fourier transforms (DFT) over short overlapping windows.\n",
    "    stft = librosa.stft(y)\n",
    "    \n",
    "    # This function (stft) returns a complex-valued matrix D such that\n",
    "    # np.abs(D[..., f, t]) is the magnitude of frequency bin f at frame t.\n",
    "    magnitude = np.abs(stft)\n",
    "    \n",
    "    # Converts an amplitude spectrogram to dB-scaled spectrogram.\n",
    "    spectogram = librosa.amplitude_to_db(magnitude)\n",
    "    \n",
    "    # Devolvemos el espectrograma y su frecuencia de muestreo.\n",
    "    return spectogram, sampling_rate\n",
    "\n",
    "# Comprobaciones sobre las variables aquí definidas.\n",
    "assert len_min <= len_max # Lógicamente, min<=max.\n",
    "assert p_prop >= 0 and p_prop <= 1 # Las probabilidades se encuentran en este rango."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _pandas_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el archivo `birds_csv` cuenta con *N* columnas `columna0,columna1,...,columnaN-1`, imprimimos a continuación el nombre de cada columna, enumerándolas desde cero.\n",
    "\n",
    "**NOTA**: La primera columna no tiene nombre, por lo que *pandas*, al convertir el archivo CSV en un *DataFrame* mediante la función `read_csv()`, le asigna el nombre `Unnamed: 0`. Esta columna sirve para indexar a las entradas dentro del archivo CSV (no confundir con la columna 'index' cuyo propósito es indexar a los archivos de audio de otra manera)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Por cada columna del DataFrame, imprimimos dicha columna.\n",
    "#for i,col in enumerate(birds_df.columns):\n",
    "#    print(f\"{i}:{col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplificamos con la primera entrada del archivo al imprimir qué valor tiene asociado a cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"iloc\" permite indexar por posiciones mediante el uso de enteros.\n",
    "# Por cada columna y valor en la primera línea, imprimimos ambos.\n",
    "#for col, val in birds_df.iloc[0].iteritems():\n",
    "#    print(f\"{col}:{val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay algunas columnas tal que todas las entradas del archivo comparten un mismo valor dentro de esa columna. A continuación imprimimos los nombres de las columnas que cumplen ésto, así como el valor que todas las entradas comparten en dicha columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Por cada columna del DataFrame...\n",
    "#for col in birds_df.columns:\n",
    "    \n",
    "    # Si todas las entradas tienen el mismo valor en dicha\n",
    "    # columna, imprimimos la columna y el valor correspondiente.\n",
    "    #if (birds_df[col] == birds_df[col][0]).all():\n",
    "        #print(f\"{col}:{birds_df[col][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del *DataSet*\n",
    "\n",
    "Creamos el *DataSet* de *PyTorch* que guarda y maneja los datos de los archivos de audio (que contienen los cantos de las aves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBirdDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset de audios de aves.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, process_func, audio_path, transform=None, target_transform=None):\n",
    "        \"\"\"\n",
    "        The __init__ function is run once when instantiating the Dataset object.\n",
    "        \"\"\"\n",
    "        \n",
    "        # 'df' es el DataFrame a almacenar.\n",
    "        self.df = df\n",
    "        \n",
    "        # 'process_func' toma la ruta de un audio a procesar, y lo procesa.\n",
    "        self.process_func = process_func\n",
    "        \n",
    "        # 'audio_path' es la ruta donde se ubican los archivos de audio.\n",
    "        self.audio_path = audio_path\n",
    "        \n",
    "        # 'transform' and 'target_transform' modify the samples and labels respectively.\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        The __len__ function returns the number of samples in our dataset.\n",
    "        \"\"\"\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx=None):\n",
    "        \"\"\"\n",
    "        The __getitem__ function loads and returns a sample from the dataset at the given index 'idx'.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Si no se especifica un índice, se toma una muestra aleatoria.\n",
    "        if idx == None:\n",
    "            idx = random.randrange(0, birds_ds.__len__()) # Rango [a,b).\n",
    "        \n",
    "        # Obtenemos la idx-ésima línea del DataFrame almacenado.\n",
    "        # Y el nombre del archivo de audio a procesar.\n",
    "        item = self.df.iloc[idx]\n",
    "        filename = item[file_col_name]\n",
    "        \n",
    "        # Procesamos el primer cacho de audio.\n",
    "        x,_ = self.process_func(self.audio_path+filename, True)\n",
    "        \n",
    "        # Si se desea que ambos cachos de audio compartan la propiedad,\n",
    "        # sólo dejamos la etiqueta como \"1\", y volvemos a procesar\n",
    "        # el mismo archivo de audio de manera aleatoria (más adelante).\n",
    "        if (random.random() < p_prop):\n",
    "            target = 1\n",
    "            \n",
    "        # Si, por otro lado, se desea que los cachos no compartan la\n",
    "        # propiedad, dejamos la etiqueta como \"-1\", y buscamos otro\n",
    "        # archivo de audio para procesar.\n",
    "        else:\n",
    "            target = -1\n",
    "            \n",
    "            # Guardamos la especie del ave del primer cacho de audio.\n",
    "            primera_especie = item[\"Species\"]\n",
    "            \n",
    "            # Quitamos el primer archivo de audio (que ya fue procesado) del\n",
    "            # DataFrame (temporalmente), obtenemos algún renglón aleatorio de\n",
    "            # este nuevo DataFrame (sample() devuelve un DataFrame, por lo que\n",
    "            # es necesario tomar el primer renglón con iloc[0]), y obtenemos\n",
    "            # el nombre del nuevo archivo de audio a procesar.\n",
    "            item = self.df.drop(idx).sample().iloc[0]\n",
    "            filename = item[file_col_name]\n",
    "                  \n",
    "            # Guardamos la especie del ave del segundo cacho de audio.\n",
    "            segunda_especie = item[\"Species\"]\n",
    "            \n",
    "            # TO-DO: Si son la misma especie, ¿sigo buscando otro segundo cacho\n",
    "            # de audio, o cambio el \"target\" a 1? Por ahora sólo lo cambio a 1.\n",
    "            #print(f\"El primer cacho de audio pertenece a un ave {primera_especie}, y el segundo pertenece a un ave {segunda_especie}.\")\n",
    "            if primera_especie == segunda_especie:\n",
    "                target = 1\n",
    "\n",
    "        # Procesamos el segundo cacho de audio.\n",
    "        y,_ = self.process_func(self.audio_path+filename, True)\n",
    "            \n",
    "        # NOTA:\n",
    "        # Aún no se define el uso para 'transform' y 'target_transform'.\n",
    "        # Una propuesta es que 'transform' sustituya a 'process_func'.\n",
    "        \n",
    "        # Devolvemos el primer cacho de audio, el segundo cacho de audio,\n",
    "        # y la etiqueta que indica si ambos comparten (1) o no (0) la propiedad.\n",
    "        return x, y, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el *DataSet* al pasarle:\n",
    "- El *DataFrame* creado previamente con *pandas*.\n",
    "- La función a utilizar para procesar los audios.\n",
    "- La ruta del directorio en el cual se encuentran los archivos de audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "birds_ds = CustomBirdDataset(birds_df, librosa_process, birds_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo del *DataSet*\n",
    "\n",
    "Y obtenemos una muestra aleatoria del *DataSet* mediante su función `__getitem__()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#birds_ds.__getitem__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del *DataLoader*\n",
    "\n",
    "Creamos dos *DataLoader* de *PyTorch* que envuelven el *DataSet* previamente definido. Uno está definido para el entrenamiento, mientras que otro está definido para el testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "birds_dl_train = [\n",
    "    DataLoader(birds_ds, batch_size=batch_size, shuffle=True, drop_last=True),\n",
    "    DataLoader(birds_ds, batch_size=batch_size, shuffle=False, drop_last=True),\n",
    "    #DataLoader(birds_ds, batch_size=batch_size, shuffle=True, drop_last=True),\n",
    "    #DataLoader(birds_ds, batch_size=batch_size, shuffle=False, drop_last=True),\n",
    "    #DataLoader(birds_ds, batch_size=batch_size, shuffle=True, drop_last=True),\n",
    "]\n",
    "\n",
    "birds_dl_test = DataLoader(birds_ds, batch_size=batch_size, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo del **DataLoader**\n",
    "\n",
    "El *DataLoader* contiene listas (que regresa la función `__getitem__()` correspondiente al *DataSet*). Estas listas contienen los lotes de tamaño `batch_size` y, para abarcar todos los datos, contiene aproximadamente `tamaño_de_todos_los_datos/batch_size` listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Tamaño del DataSet (de PyTorch) = 3277 = 3277 = Tamaño del DataFrame (de pandas)\n"
     ]
    }
   ],
   "source": [
    "print(f\"- Tamaño del DataSet (de PyTorch) = {len(birds_ds)} = {len(birds_df)} = Tamaño del DataFrame (de pandas)\")\n",
    "#print(f\"- Tamaño del DataLoader (de PyTorch): {len(birds_dl)}\")\n",
    "#iterador = iter(birds_dl)\n",
    "#primer_lote = next(iterador)\n",
    "#print(f\"- Tamaño de la primera lista del DataLoader: {len(primer_lote)}\")\n",
    "#print(f\"- Tamaño de los elementos de la primera lista: {len(primer_lote[0])} {len(primer_lote[1])} {len(primer_lote[2])}\")\n",
    "#print(f\"- Tamaño del DataLoader por el tamaño de cada lote: {len(birds_dl)*batch_size} ≈ {len(birds_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos datos sobre el primer lote para ejemplificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#primeros_cachos, segundos_cachos, labels = primer_lote\n",
    "#print(f\"- Los primeros cachos de audio del primer lote tienen tamaño: {primeros_cachos.size()}\")\n",
    "#print(f\"- Los segundos cachos de audio del primer lote tienen tamaño: {segundos_cachos.size()}\")\n",
    "#print(f\"- Las etiquetas del primer lote tienen tamaño: {labels.size()}\")\n",
    "#print(f\"- Etiquetas del primer lote: {labels}\")\n",
    "#print(f\"- Primeros cachos del primer lote: {primeros_cachos}\")\n",
    "#print(f\"- Segundos cachos del primer lote: {segundos_cachos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Module is the base class for all neural network modules.\n",
    "# Our models should also subclass this class.\n",
    "# Modules can also contain other Modules, allowing to nest them in a tree structure.\n",
    "class RN(nn.Module):\n",
    "    \"\"\"\n",
    "    Red Neuronal.\n",
    "    \"\"\"\n",
    "    \n",
    "    #This defines the structure of the NN.\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inicialización de la Red Neuronal.\n",
    "        Aquí se define su estructura.\n",
    "        \"\"\"\n",
    "        \n",
    "        #\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inicio de las capas convolucionales.\n",
    "        conv_layers = []\n",
    "        \n",
    "        # Primera capa convolucional.\n",
    "        self.conv1 = nn.Conv2d(in_channels=audio_channels, out_channels=batch_size, kernel_size=(10,10), stride=(2,1))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        conv_layers += [self.conv1, self.relu1, self.mp1]\n",
    "        \n",
    "        # Segunda capa convolucional.\n",
    "        self.conv2 = nn.Conv2d(in_channels=batch_size, out_channels=(batch_size//2), kernel_size=(7,7), stride=(2,1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        conv_layers += [self.conv2, self.relu2, self.mp2]\n",
    "        \n",
    "        # Tercera capa convolucional.\n",
    "        self.conv3 = nn.Conv2d(in_channels=(batch_size//2), out_channels=(batch_size//4), kernel_size=(4,4), stride=(2,1))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.mp3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        conv_layers += [self.conv3, self.relu3, self.mp3]\n",
    "        \n",
    "        # Fin de las capas convoluciones.\n",
    "        self.conv = nn.Sequential(*conv_layers)\n",
    "        \n",
    "        # Inicio de las capas lineales (fully-connected).\n",
    "        fc_layers = []\n",
    "        \n",
    "        # Primera capa lineal.\n",
    "        # TO-DO: Determinar entrada.\n",
    "        # TO-DO: Determinar salida.\n",
    "        self.fc1 = nn.Linear(int(22.5*batch_size),512)\n",
    "        fc_layers += [self.fc1]\n",
    "        \n",
    "        # Fin de las capas lineales.\n",
    "        self.fc = nn.Sequential(*fc_layers)\n",
    "        \n",
    "        # Segunda capa lineal.\n",
    "        # TO-DO: Determinar entrada.\n",
    "        # TO-DO: Determinar salida. ¿Es 1 valor para cada entrada?\n",
    "        self.fc2 = nn.Linear(4063232, 1)\n",
    "        # Ésta no se agrega a las demás,\n",
    "        # pues no se aplica individualmente a\n",
    "        # cada entrada; primero es necesario\n",
    "        # realizar la operación de distancia\n",
    "        # sobre éstas para después aplicar\n",
    "        # esta capa lineal.\n",
    "    \n",
    "    def invididual_process(self, z):\n",
    "        \n",
    "        start = timer()\n",
    "        z = self.conv(z)\n",
    "        end = timer()\n",
    "        #print(f\"\\t\\t[time] Capas convolucionales: time={end-start}s out_size={z.size()}\") # DEBUG\n",
    "        \n",
    "        # Para que 'z' tenga sólo una dimensión...\n",
    "        #print(f\"\\t\\tz antes de z.view: {z.size()}\") # DEBUG\n",
    "        z = z.view(batch_size, -1)\n",
    "        #print(f\"\\t\\tz después de z.view: {z.size()}\") # DEBUG\n",
    "        \n",
    "        start = timer()\n",
    "        z = self.fc(z)\n",
    "        end = timer()\n",
    "        #print(f\"\\t\\t[time] Capas lineales: time={end-start}s out_size={z.size()}\") # DEBUG\n",
    "        \n",
    "        return z\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \n",
    "        # TO-DO: Analizar las múltiples dimensiones en 2 o 3 dimensiones.\n",
    "        #TSNE(n_components=2, verbose=True).fit_transform(x)\n",
    "        \n",
    "        #print(f\"\\tProcesando x: {x.size()}\") # DEBUG\n",
    "        x = self.invididual_process(x)\n",
    "        #print(f\"\\tProcesando y: {y.size()}\") # DEBUG\n",
    "        y = self.invididual_process(y)\n",
    "        \n",
    "        # Para que 'x' y 'y' tengan sólo una dimensión...\n",
    "        x = x.view(batch_size, -1)\n",
    "        #print(f\"\\t\\tDespués de aplanar x: {x.size()}\") # DEBUG\n",
    "        y = y.view(batch_size, -1)\n",
    "        #print(f\"\\t\\tDespués de aplanar y: {y.size()}\") # DEBUG\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "# Definición del modelo.\n",
    "red = RN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.5296427011489868\n",
      "\tLoss: 0.4599570035934448\n",
      "\tLoss: 0.36031147837638855\n",
      "\tLoss: 0.31811395287513733\n",
      "\tLoss: 0.3614492416381836\n",
      "\tLoss: 0.3152157664299011\n",
      "\tLoss: 0.3609611392021179\n",
      "\tLoss: 0.2876925468444824\n",
      "\tLoss: 0.24107810854911804\n",
      "\tLoss: 0.3254508972167969\n",
      "\tLoss: 0.2999359369277954\n",
      "\tLoss: 0.29429206252098083\n",
      "\tLoss: 0.2810022532939911\n",
      "\tLoss: 0.19659604132175446\n",
      "\tLoss: 0.2971761226654053\n",
      "\tLoss: 0.2793503701686859\n",
      "\tLoss: 0.1710640788078308\n",
      "\tLoss: 0.2838774025440216\n",
      "\tLoss: 0.2647022604942322\n",
      "\tLoss: 0.2971755862236023\n",
      "\tLoss: 0.2493811845779419\n",
      "\tLoss: 0.2613627016544342\n",
      "\tLoss: 0.3018154203891754\n",
      "\tLoss: 0.2937178611755371\n",
      "\tLoss: 0.20070262253284454\n",
      "\tLoss: 0.2604760229587555\n",
      "\tLoss: 0.2247036099433899\n",
      "\tLoss: 0.17101478576660156\n",
      "\tLoss: 0.23657134175300598\n",
      "\tLoss: 0.21433192491531372\n",
      "\tLoss: 0.2737184762954712\n",
      "\tLoss: 0.22785648703575134\n",
      "\tLoss: 0.22293224930763245\n",
      "\tLoss: 0.2758403420448303\n",
      "\tLoss: 0.23622409999370575\n",
      "\tLoss: 0.24863559007644653\n",
      "\tLoss: 0.21235066652297974\n",
      "\tLoss: 0.21455498039722443\n",
      "\tLoss: 0.24651670455932617\n",
      "\tLoss: 0.25986379384994507\n",
      "\tLoss: 0.2203674465417862\n",
      "\tLoss: 0.2469935417175293\n",
      "\tLoss: 0.22589251399040222\n",
      "\tLoss: 0.21416696906089783\n",
      "\tLoss: 0.2673705816268921\n",
      "\tLoss: 0.23560717701911926\n",
      "\tLoss: 0.26563167572021484\n",
      "\tLoss: 0.14922936260700226\n",
      "\tLoss: 0.19164183735847473\n",
      "\tLoss: 0.22267736494541168\n",
      "\tLoss: 0.21613873541355133\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.26537835597991943\n",
      "\tLoss: 0.2224757969379425\n",
      "\tLoss: 0.20125487446784973\n",
      "\tLoss: 0.2058345377445221\n",
      "\tLoss: 0.19090235233306885\n",
      "\tLoss: 0.18465720117092133\n",
      "\tLoss: 0.18439844250679016\n",
      "\tLoss: 0.18667365610599518\n",
      "\tLoss: 0.17340892553329468\n",
      "\tLoss: 0.24465534090995789\n",
      "\tLoss: 0.22548454999923706\n",
      "\tLoss: 0.25587570667266846\n",
      "\tLoss: 0.18079188466072083\n",
      "\tLoss: 0.1905210316181183\n",
      "\tLoss: 0.2528607249259949\n",
      "\tLoss: 0.19070541858673096\n",
      "\tLoss: 0.22883351147174835\n",
      "\tLoss: 0.2953970730304718\n",
      "\tLoss: 0.19364295899868011\n",
      "\tLoss: 0.1702764332294464\n",
      "\tLoss: 0.2001301646232605\n",
      "\tLoss: 0.2514272928237915\n",
      "\tLoss: 0.22904232144355774\n",
      "\tLoss: 0.23941627144813538\n",
      "\tLoss: 0.2556009888648987\n",
      "\tLoss: 0.29355642199516296\n",
      "\tLoss: 0.25584542751312256\n",
      "\tLoss: 0.2014886736869812\n",
      "\tLoss: 0.25676000118255615\n",
      "\tLoss: 0.27670562267303467\n",
      "\tLoss: 0.24584831297397614\n",
      "\tLoss: 0.18729600310325623\n",
      "\tLoss: 0.17707833647727966\n",
      "\tLoss: 0.2156628668308258\n",
      "\tLoss: 0.23113563656806946\n",
      "\tLoss: 0.1992049366235733\n",
      "\tLoss: 0.17663957178592682\n",
      "\tLoss: 0.25889337062835693\n",
      "\tLoss: 0.18267911672592163\n",
      "\tLoss: 0.1862730085849762\n",
      "\tLoss: 0.20260770618915558\n",
      "\tLoss: 0.14989371597766876\n",
      "\tLoss: 0.18124184012413025\n",
      "\tLoss: 0.22485676407814026\n",
      "\tLoss: 0.19505424797534943\n",
      "\tLoss: 0.1650725156068802\n",
      "\tLoss: 0.1536342352628708\n",
      "\tLoss: 0.16954723000526428\n",
      "\tLoss: 0.2027963101863861\n",
      "\tLoss: 0.1869715005159378\n",
      "\tLoss: 0.18173842132091522\n",
      "[time] Epoch 1: 671.4983535199426s = 11.191639225332377m\n",
      "\n",
      "Epoch 2...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.18148872256278992\n",
      "\tLoss: 0.20007392764091492\n",
      "\tLoss: 0.19531044363975525\n",
      "\tLoss: 0.22888097167015076\n",
      "\tLoss: 0.18909835815429688\n",
      "\tLoss: 0.17995861172676086\n",
      "\tLoss: 0.22744406759738922\n",
      "\tLoss: 0.1335029900074005\n",
      "\tLoss: 0.1955662965774536\n",
      "\tLoss: 0.19034633040428162\n",
      "\tLoss: 0.16370737552642822\n",
      "\tLoss: 0.24263186752796173\n",
      "\tLoss: 0.17378102242946625\n",
      "\tLoss: 0.1852784901857376\n",
      "\tLoss: 0.21719759702682495\n",
      "\tLoss: 0.16393835842609406\n",
      "\tLoss: 0.22557827830314636\n",
      "\tLoss: 0.20462322235107422\n",
      "\tLoss: 0.172806978225708\n",
      "\tLoss: 0.1047259271144867\n",
      "\tLoss: 0.09468531608581543\n",
      "\tLoss: 0.09870107471942902\n",
      "\tLoss: 0.17069214582443237\n",
      "\tLoss: 0.1868939995765686\n",
      "\tLoss: 0.1736636459827423\n",
      "\tLoss: 0.1414746642112732\n",
      "\tLoss: 0.19346794486045837\n",
      "\tLoss: 0.23489589989185333\n",
      "\tLoss: 0.20354649424552917\n",
      "\tLoss: 0.16754695773124695\n",
      "\tLoss: 0.1589125245809555\n",
      "\tLoss: 0.2061561495065689\n",
      "\tLoss: 0.14398837089538574\n",
      "\tLoss: 0.16891920566558838\n",
      "\tLoss: 0.1400902420282364\n",
      "\tLoss: 0.17444109916687012\n",
      "\tLoss: 0.17291416227817535\n",
      "\tLoss: 0.19002968072891235\n",
      "\tLoss: 0.14136604964733124\n",
      "\tLoss: 0.2220870405435562\n",
      "\tLoss: 0.1420402079820633\n",
      "\tLoss: 0.1847415566444397\n",
      "\tLoss: 0.14310719072818756\n",
      "\tLoss: 0.16065093874931335\n",
      "\tLoss: 0.16943544149398804\n",
      "\tLoss: 0.17603473365306854\n",
      "\tLoss: 0.18936993181705475\n",
      "\tLoss: 0.1338358223438263\n",
      "\tLoss: 0.12257854640483856\n",
      "\tLoss: 0.13875478506088257\n",
      "\tLoss: 0.09999430179595947\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.18460212647914886\n",
      "\tLoss: 0.1446869671344757\n",
      "\tLoss: 0.14906790852546692\n",
      "\tLoss: 0.1650279462337494\n",
      "\tLoss: 0.18838390707969666\n",
      "\tLoss: 0.12712079286575317\n",
      "\tLoss: 0.17065851390361786\n",
      "\tLoss: 0.14224302768707275\n",
      "\tLoss: 0.13472703099250793\n",
      "\tLoss: 0.16528663039207458\n",
      "\tLoss: 0.13840742409229279\n",
      "\tLoss: 0.1774500608444214\n",
      "\tLoss: 0.15796828269958496\n",
      "\tLoss: 0.15440988540649414\n",
      "\tLoss: 0.15412703156471252\n",
      "\tLoss: 0.12256982177495956\n",
      "\tLoss: 0.15513354539871216\n",
      "\tLoss: 0.13959097862243652\n",
      "\tLoss: 0.18785250186920166\n",
      "\tLoss: 0.16941189765930176\n",
      "\tLoss: 0.19454741477966309\n",
      "\tLoss: 0.14831727743148804\n",
      "\tLoss: 0.19327154755592346\n",
      "\tLoss: 0.1641802042722702\n",
      "\tLoss: 0.15201935172080994\n",
      "\tLoss: 0.16021491587162018\n",
      "\tLoss: 0.1982455849647522\n",
      "\tLoss: 0.24424052238464355\n",
      "\tLoss: 0.2071635127067566\n",
      "\tLoss: 0.1429494321346283\n",
      "\tLoss: 0.179616317152977\n",
      "\tLoss: 0.15315043926239014\n",
      "\tLoss: 0.10212995111942291\n",
      "\tLoss: 0.10660435259342194\n",
      "\tLoss: 0.16464301943778992\n",
      "\tLoss: 0.16140666604042053\n",
      "\tLoss: 0.1649625301361084\n",
      "\tLoss: 0.11675220727920532\n",
      "\tLoss: 0.1937413364648819\n",
      "\tLoss: 0.1366395503282547\n",
      "\tLoss: 0.11237314343452454\n",
      "\tLoss: 0.18037466704845428\n",
      "\tLoss: 0.14195936918258667\n",
      "\tLoss: 0.14666947722434998\n",
      "\tLoss: 0.16497182846069336\n",
      "\tLoss: 0.1544257402420044\n",
      "\tLoss: 0.17589671909809113\n",
      "\tLoss: 0.16441552340984344\n",
      "\tLoss: 0.19725564122200012\n",
      "\tLoss: 0.24594435095787048\n",
      "\tLoss: 0.2110825926065445\n",
      "[time] Epoch 2: 565.700519267004s = 9.4283419877834m\n",
      "\n",
      "Epoch 3...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.2177189290523529\n",
      "\tLoss: 0.18240442872047424\n",
      "\tLoss: 0.09004150331020355\n",
      "\tLoss: 0.1406010091304779\n",
      "\tLoss: 0.16267822682857513\n",
      "\tLoss: 0.16365770995616913\n",
      "\tLoss: 0.12910430133342743\n",
      "\tLoss: 0.13928939402103424\n",
      "\tLoss: 0.16367998719215393\n",
      "\tLoss: 0.11026600003242493\n",
      "\tLoss: 0.12147679179906845\n",
      "\tLoss: 0.14118167757987976\n",
      "\tLoss: 0.1242905929684639\n",
      "\tLoss: 0.14324262738227844\n",
      "\tLoss: 0.1600777506828308\n",
      "\tLoss: 0.16618621349334717\n",
      "\tLoss: 0.15814410150051117\n",
      "\tLoss: 0.15980900824069977\n",
      "\tLoss: 0.15981081128120422\n",
      "\tLoss: 0.16291117668151855\n",
      "\tLoss: 0.10605622828006744\n",
      "\tLoss: 0.12230151891708374\n",
      "\tLoss: 0.14791524410247803\n",
      "\tLoss: 0.17617963254451752\n",
      "\tLoss: 0.13657492399215698\n",
      "\tLoss: 0.1392630934715271\n",
      "\tLoss: 0.1813252866268158\n",
      "\tLoss: 0.1543414294719696\n",
      "\tLoss: 0.17771568894386292\n",
      "\tLoss: 0.1556362509727478\n",
      "\tLoss: 0.20684418082237244\n",
      "\tLoss: 0.10427776724100113\n",
      "\tLoss: 0.15885518491268158\n",
      "\tLoss: 0.15336564183235168\n",
      "\tLoss: 0.11643165349960327\n",
      "\tLoss: 0.17631281912326813\n",
      "\tLoss: 0.1587943136692047\n",
      "\tLoss: 0.15923863649368286\n",
      "\tLoss: 0.15042051672935486\n",
      "\tLoss: 0.17180879414081573\n",
      "\tLoss: 0.20943626761436462\n",
      "\tLoss: 0.15577244758605957\n",
      "\tLoss: 0.15649640560150146\n",
      "\tLoss: 0.16634337604045868\n",
      "\tLoss: 0.15804919600486755\n",
      "\tLoss: 0.13146452605724335\n",
      "\tLoss: 0.15388664603233337\n",
      "\tLoss: 0.17867448925971985\n",
      "\tLoss: 0.11494354903697968\n",
      "\tLoss: 0.14932182431221008\n",
      "\tLoss: 0.18107189238071442\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.14231854677200317\n",
      "\tLoss: 0.15713246166706085\n",
      "\tLoss: 0.10699314624071121\n",
      "\tLoss: 0.13314926624298096\n",
      "\tLoss: 0.12151820957660675\n",
      "\tLoss: 0.1586170792579651\n",
      "\tLoss: 0.15634822845458984\n",
      "\tLoss: 0.10216952115297318\n",
      "\tLoss: 0.1502494513988495\n",
      "\tLoss: 0.1711130291223526\n",
      "\tLoss: 0.1623464673757553\n",
      "\tLoss: 0.15304309129714966\n",
      "\tLoss: 0.1013292744755745\n",
      "\tLoss: 0.12416255474090576\n",
      "\tLoss: 0.15965571999549866\n",
      "\tLoss: 0.152342289686203\n",
      "\tLoss: 0.15246854722499847\n",
      "\tLoss: 0.15092575550079346\n",
      "\tLoss: 0.15127716958522797\n",
      "\tLoss: 0.10526417195796967\n",
      "\tLoss: 0.14872018992900848\n",
      "\tLoss: 0.18152007460594177\n",
      "\tLoss: 0.13001024723052979\n",
      "\tLoss: 0.14391480386257172\n",
      "\tLoss: 0.11703266203403473\n",
      "\tLoss: 0.17124198377132416\n",
      "\tLoss: 0.12803539633750916\n",
      "\tLoss: 0.16260352730751038\n",
      "\tLoss: 0.16520094871520996\n",
      "\tLoss: 0.06463241577148438\n",
      "\tLoss: 0.11854273825883865\n",
      "\tLoss: 0.13376590609550476\n",
      "\tLoss: 0.10578799992799759\n",
      "\tLoss: 0.09054791182279587\n",
      "\tLoss: 0.1106639951467514\n",
      "\tLoss: 0.18261758983135223\n",
      "\tLoss: 0.13543570041656494\n",
      "\tLoss: 0.10824960470199585\n",
      "\tLoss: 0.12857402861118317\n",
      "\tLoss: 0.17045427858829498\n",
      "\tLoss: 0.14420783519744873\n",
      "\tLoss: 0.12703870236873627\n",
      "\tLoss: 0.12092453986406326\n",
      "\tLoss: 0.18314743041992188\n",
      "\tLoss: 0.1441698521375656\n",
      "\tLoss: 0.15735241770744324\n",
      "\tLoss: 0.12637293338775635\n",
      "\tLoss: 0.10906078666448593\n",
      "\tLoss: 0.08613719791173935\n",
      "\tLoss: 0.18174313008785248\n",
      "\tLoss: 0.12490394711494446\n",
      "[time] Epoch 3: 532.6281543280929s = 8.877135905468215m\n",
      "\n",
      "Epoch 4...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.14483684301376343\n",
      "\tLoss: 0.1775660514831543\n",
      "\tLoss: 0.10836724936962128\n",
      "\tLoss: 0.1714671403169632\n",
      "\tLoss: 0.1372462660074234\n",
      "\tLoss: 0.16802671551704407\n",
      "\tLoss: 0.1621183604001999\n",
      "\tLoss: 0.15514548122882843\n",
      "\tLoss: 0.13825474679470062\n",
      "\tLoss: 0.15864625573158264\n",
      "\tLoss: 0.1231812834739685\n",
      "\tLoss: 0.10611063241958618\n",
      "\tLoss: 0.08757525682449341\n",
      "\tLoss: 0.11861713975667953\n",
      "\tLoss: 0.13520869612693787\n",
      "\tLoss: 0.14389808475971222\n",
      "\tLoss: 0.11828351020812988\n",
      "\tLoss: 0.16125881671905518\n",
      "\tLoss: 0.11111918836832047\n",
      "\tLoss: 0.15644702315330505\n",
      "\tLoss: 0.16386520862579346\n",
      "\tLoss: 0.1359265148639679\n",
      "\tLoss: 0.08294090628623962\n",
      "\tLoss: 0.18172714114189148\n",
      "\tLoss: 0.1659860908985138\n",
      "\tLoss: 0.15065217018127441\n",
      "\tLoss: 0.15752919018268585\n",
      "\tLoss: 0.12857526540756226\n",
      "\tLoss: 0.16171130537986755\n",
      "\tLoss: 0.10636737942695618\n",
      "\tLoss: 0.14903464913368225\n",
      "\tLoss: 0.12913423776626587\n",
      "\tLoss: 0.14179986715316772\n",
      "\tLoss: 0.14703980088233948\n",
      "\tLoss: 0.16138309240341187\n",
      "\tLoss: 0.11955928802490234\n",
      "\tLoss: 0.17767351865768433\n",
      "\tLoss: 0.1411173939704895\n",
      "\tLoss: 0.1941327154636383\n",
      "\tLoss: 0.13600823283195496\n",
      "\tLoss: 0.1438223272562027\n",
      "\tLoss: 0.11862674355506897\n",
      "\tLoss: 0.16549919545650482\n",
      "\tLoss: 0.15011456608772278\n",
      "\tLoss: 0.1440185010433197\n",
      "\tLoss: 0.12353742867708206\n",
      "\tLoss: 0.15589508414268494\n",
      "\tLoss: 0.14369089901447296\n",
      "\tLoss: 0.15567073225975037\n",
      "\tLoss: 0.15540748834609985\n",
      "\tLoss: 0.1302892565727234\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.1468804031610489\n",
      "\tLoss: 0.10745637863874435\n",
      "\tLoss: 0.148840993642807\n",
      "\tLoss: 0.183328315615654\n",
      "\tLoss: 0.15510164201259613\n",
      "\tLoss: 0.17541436851024628\n",
      "\tLoss: 0.117031991481781\n",
      "\tLoss: 0.1752726137638092\n",
      "\tLoss: 0.1496700942516327\n",
      "\tLoss: 0.2044244259595871\n",
      "\tLoss: 0.1994655728340149\n",
      "\tLoss: 0.15858714282512665\n",
      "\tLoss: 0.1273534744977951\n",
      "\tLoss: 0.12960931658744812\n",
      "\tLoss: 0.15782839059829712\n",
      "\tLoss: 0.14039430022239685\n",
      "\tLoss: 0.13636431097984314\n",
      "\tLoss: 0.15653426945209503\n",
      "\tLoss: 0.1389993131160736\n",
      "\tLoss: 0.10085038095712662\n",
      "\tLoss: 0.10298231244087219\n",
      "\tLoss: 0.12471804022789001\n",
      "\tLoss: 0.13086865842342377\n",
      "\tLoss: 0.13044536113739014\n",
      "\tLoss: 0.17313693463802338\n",
      "\tLoss: 0.12847578525543213\n",
      "\tLoss: 0.13918384909629822\n",
      "\tLoss: 0.11065943539142609\n",
      "\tLoss: 0.09437670558691025\n",
      "\tLoss: 0.16897544264793396\n",
      "\tLoss: 0.1596449762582779\n",
      "\tLoss: 0.13252677023410797\n",
      "\tLoss: 0.0920514166355133\n",
      "\tLoss: 0.10322120040655136\n",
      "\tLoss: 0.13691101968288422\n",
      "\tLoss: 0.13464874029159546\n",
      "\tLoss: 0.12174137681722641\n",
      "\tLoss: 0.21956565976142883\n",
      "\tLoss: 0.16309049725532532\n",
      "\tLoss: 0.15827502310276031\n",
      "\tLoss: 0.16959163546562195\n",
      "\tLoss: 0.15432152152061462\n",
      "\tLoss: 0.1788802444934845\n",
      "\tLoss: 0.12302051484584808\n",
      "\tLoss: 0.1248432993888855\n",
      "\tLoss: 0.12559197843074799\n",
      "\tLoss: 0.1924716681241989\n",
      "\tLoss: 0.09842965751886368\n",
      "\tLoss: 0.1348647177219391\n",
      "\tLoss: 0.14230254292488098\n",
      "\tLoss: 0.158194899559021\n",
      "[time] Epoch 4: 511.2830377337523s = 8.521383962229205m\n",
      "\n",
      "Epoch 5...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.15872249007225037\n",
      "\tLoss: 0.16053366661071777\n",
      "\tLoss: 0.14399895071983337\n",
      "\tLoss: 0.13567186892032623\n",
      "\tLoss: 0.11138707399368286\n",
      "\tLoss: 0.19322042167186737\n",
      "\tLoss: 0.1125698909163475\n",
      "\tLoss: 0.10299105197191238\n",
      "\tLoss: 0.13737861812114716\n",
      "\tLoss: 0.14738395810127258\n",
      "\tLoss: 0.11420029401779175\n",
      "\tLoss: 0.14524981379508972\n",
      "\tLoss: 0.14879994094371796\n",
      "\tLoss: 0.12502877414226532\n",
      "\tLoss: 0.18749907612800598\n",
      "\tLoss: 0.15927471220493317\n",
      "\tLoss: 0.16257351636886597\n",
      "\tLoss: 0.1664448082447052\n",
      "\tLoss: 0.13850051164627075\n",
      "\tLoss: 0.11404480785131454\n",
      "\tLoss: 0.12690269947052002\n",
      "\tLoss: 0.10350216925144196\n",
      "\tLoss: 0.1339273750782013\n",
      "\tLoss: 0.15998224914073944\n",
      "\tLoss: 0.2232239842414856\n",
      "\tLoss: 0.1542530506849289\n",
      "\tLoss: 0.19656817615032196\n",
      "\tLoss: 0.22529277205467224\n",
      "\tLoss: 0.15109124779701233\n",
      "\tLoss: 0.18026922643184662\n",
      "\tLoss: 0.1750602424144745\n",
      "\tLoss: 0.10351762920618057\n",
      "\tLoss: 0.14049071073532104\n",
      "\tLoss: 0.15173842012882233\n",
      "\tLoss: 0.15900960564613342\n",
      "\tLoss: 0.15938979387283325\n",
      "\tLoss: 0.19123725593090057\n",
      "\tLoss: 0.16081902384757996\n",
      "\tLoss: 0.20334136486053467\n",
      "\tLoss: 0.14513464272022247\n",
      "\tLoss: 0.15267544984817505\n",
      "\tLoss: 0.19900020956993103\n",
      "\tLoss: 0.20148150622844696\n",
      "\tLoss: 0.2103722244501114\n",
      "\tLoss: 0.20141196250915527\n",
      "\tLoss: 0.20057664811611176\n",
      "\tLoss: 0.09961438179016113\n",
      "\tLoss: 0.1764117181301117\n",
      "\tLoss: 0.1783784180879593\n",
      "\tLoss: 0.13542258739471436\n",
      "\tLoss: 0.13979458808898926\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.15016447007656097\n",
      "\tLoss: 0.1264222413301468\n",
      "\tLoss: 0.15854758024215698\n",
      "\tLoss: 0.13298174738883972\n",
      "\tLoss: 0.1517779529094696\n",
      "\tLoss: 0.15354284644126892\n",
      "\tLoss: 0.1473744809627533\n",
      "\tLoss: 0.16333526372909546\n",
      "\tLoss: 0.11017904430627823\n",
      "\tLoss: 0.1018775999546051\n",
      "\tLoss: 0.1095251590013504\n",
      "\tLoss: 0.13551850616931915\n",
      "\tLoss: 0.14610669016838074\n",
      "\tLoss: 0.12258289754390717\n",
      "\tLoss: 0.16526272892951965\n",
      "\tLoss: 0.15732532739639282\n",
      "\tLoss: 0.1459597796201706\n",
      "\tLoss: 0.12699809670448303\n",
      "\tLoss: 0.1792508065700531\n",
      "\tLoss: 0.15979325771331787\n",
      "\tLoss: 0.13457021117210388\n",
      "\tLoss: 0.17060211300849915\n",
      "\tLoss: 0.12019914388656616\n",
      "\tLoss: 0.1327390968799591\n",
      "\tLoss: 0.12207885086536407\n",
      "\tLoss: 0.1143902987241745\n",
      "\tLoss: 0.1512334942817688\n",
      "\tLoss: 0.15080177783966064\n",
      "\tLoss: 0.12601736187934875\n",
      "\tLoss: 0.13532422482967377\n",
      "\tLoss: 0.10923153162002563\n",
      "\tLoss: 0.09916484355926514\n",
      "\tLoss: 0.1189938336610794\n",
      "\tLoss: 0.11797401309013367\n",
      "\tLoss: 0.15418003499507904\n",
      "\tLoss: 0.14042294025421143\n",
      "\tLoss: 0.11724616587162018\n",
      "\tLoss: 0.0873703807592392\n",
      "\tLoss: 0.12423371523618698\n",
      "\tLoss: 0.16820533573627472\n",
      "\tLoss: 0.10610413551330566\n",
      "\tLoss: 0.10599090158939362\n",
      "\tLoss: 0.14254094660282135\n",
      "\tLoss: 0.13084334135055542\n",
      "\tLoss: 0.16328155994415283\n",
      "\tLoss: 0.1519652009010315\n",
      "\tLoss: 0.14929905533790588\n",
      "\tLoss: 0.12950196862220764\n",
      "\tLoss: 0.1724318116903305\n",
      "\tLoss: 0.1318143904209137\n",
      "\tLoss: 0.12170863151550293\n",
      "[time] Epoch 5: 489.4768434120342s = 8.15794739020057m\n",
      "\n",
      "Epoch 6...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1573009341955185\n",
      "\tLoss: 0.1266629546880722\n",
      "\tLoss: 0.1546652615070343\n",
      "\tLoss: 0.11387966573238373\n",
      "\tLoss: 0.1335430145263672\n",
      "\tLoss: 0.1363714337348938\n",
      "\tLoss: 0.13787761330604553\n",
      "\tLoss: 0.12171377241611481\n",
      "\tLoss: 0.159953773021698\n",
      "\tLoss: 0.11572325974702835\n",
      "\tLoss: 0.13501513004302979\n",
      "\tLoss: 0.11933629214763641\n",
      "\tLoss: 0.10416799783706665\n",
      "\tLoss: 0.11540726572275162\n",
      "\tLoss: 0.10686633735895157\n",
      "\tLoss: 0.19988740980625153\n",
      "\tLoss: 0.1045961081981659\n",
      "\tLoss: 0.11533193290233612\n",
      "\tLoss: 0.14440187811851501\n",
      "\tLoss: 0.13900500535964966\n",
      "\tLoss: 0.13106560707092285\n",
      "\tLoss: 0.13639289140701294\n",
      "\tLoss: 0.10633166134357452\n",
      "\tLoss: 0.07736345380544662\n",
      "\tLoss: 0.14829348027706146\n",
      "\tLoss: 0.14219951629638672\n",
      "\tLoss: 0.17511200904846191\n",
      "\tLoss: 0.10911425948143005\n",
      "\tLoss: 0.15609294176101685\n",
      "\tLoss: 0.13675758242607117\n",
      "\tLoss: 0.132971853017807\n",
      "\tLoss: 0.13194060325622559\n",
      "\tLoss: 0.13915280997753143\n",
      "\tLoss: 0.0737101286649704\n",
      "\tLoss: 0.1340886354446411\n",
      "\tLoss: 0.16972897946834564\n",
      "\tLoss: 0.1145496517419815\n",
      "\tLoss: 0.1346975564956665\n",
      "\tLoss: 0.11666148900985718\n",
      "\tLoss: 0.15157322585582733\n",
      "\tLoss: 0.1413450539112091\n",
      "\tLoss: 0.10271957516670227\n",
      "\tLoss: 0.13069573044776917\n",
      "\tLoss: 0.14054477214813232\n",
      "\tLoss: 0.15040895342826843\n",
      "\tLoss: 0.14179973304271698\n",
      "\tLoss: 0.12945181131362915\n",
      "\tLoss: 0.12318487465381622\n",
      "\tLoss: 0.17706957459449768\n",
      "\tLoss: 0.14811372756958008\n",
      "\tLoss: 0.12293262034654617\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.10651224851608276\n",
      "\tLoss: 0.13027212023735046\n",
      "\tLoss: 0.12112884223461151\n",
      "\tLoss: 0.1357543170452118\n",
      "\tLoss: 0.14484229683876038\n",
      "\tLoss: 0.12934379279613495\n",
      "\tLoss: 0.1113412156701088\n",
      "\tLoss: 0.10655393451452255\n",
      "\tLoss: 0.14653408527374268\n",
      "\tLoss: 0.11853465437889099\n",
      "\tLoss: 0.16230535507202148\n",
      "\tLoss: 0.10959586501121521\n",
      "\tLoss: 0.10647264122962952\n",
      "\tLoss: 0.1574910581111908\n",
      "\tLoss: 0.12798558175563812\n",
      "\tLoss: 0.11328911781311035\n",
      "\tLoss: 0.1711568534374237\n",
      "\tLoss: 0.11995051801204681\n",
      "\tLoss: 0.12871864438056946\n",
      "\tLoss: 0.12202587723731995\n",
      "\tLoss: 0.15411019325256348\n",
      "\tLoss: 0.12248831242322922\n",
      "\tLoss: 0.17031922936439514\n",
      "\tLoss: 0.09188127517700195\n",
      "\tLoss: 0.13221311569213867\n",
      "\tLoss: 0.1438005268573761\n",
      "\tLoss: 0.15759171545505524\n",
      "\tLoss: 0.1412651240825653\n",
      "\tLoss: 0.1449393630027771\n",
      "\tLoss: 0.12490731477737427\n",
      "\tLoss: 0.13275139033794403\n",
      "\tLoss: 0.1354081630706787\n",
      "\tLoss: 0.12183374166488647\n",
      "\tLoss: 0.08959756791591644\n",
      "\tLoss: 0.10863827168941498\n",
      "\tLoss: 0.15045027434825897\n",
      "\tLoss: 0.16866092383861542\n",
      "\tLoss: 0.16340109705924988\n",
      "\tLoss: 0.14123839139938354\n",
      "\tLoss: 0.1781046986579895\n",
      "\tLoss: 0.09941388666629791\n",
      "\tLoss: 0.15147341787815094\n",
      "\tLoss: 0.14975066483020782\n",
      "\tLoss: 0.10806071013212204\n",
      "\tLoss: 0.12072315812110901\n",
      "\tLoss: 0.07595163583755493\n",
      "\tLoss: 0.09694202989339828\n",
      "\tLoss: 0.11576754599809647\n",
      "\tLoss: 0.09145988523960114\n",
      "\tLoss: 0.12134292721748352\n",
      "\tLoss: 0.1976318508386612\n",
      "[time] Epoch 6: 478.01242358097807s = 7.966873726349634m\n",
      "\n",
      "Epoch 7...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1205224096775055\n",
      "\tLoss: 0.135518878698349\n",
      "\tLoss: 0.15222379565238953\n",
      "\tLoss: 0.13904063403606415\n",
      "\tLoss: 0.13888558745384216\n",
      "\tLoss: 0.10034681856632233\n",
      "\tLoss: 0.18015125393867493\n",
      "\tLoss: 0.07760615646839142\n",
      "\tLoss: 0.12693986296653748\n",
      "\tLoss: 0.12204835563898087\n",
      "\tLoss: 0.15220917761325836\n",
      "\tLoss: 0.16460536420345306\n",
      "\tLoss: 0.1721479445695877\n",
      "\tLoss: 0.12673576176166534\n",
      "\tLoss: 0.1251755654811859\n",
      "\tLoss: 0.12348685413599014\n",
      "\tLoss: 0.14234411716461182\n",
      "\tLoss: 0.11198070645332336\n",
      "\tLoss: 0.1482401341199875\n",
      "\tLoss: 0.09972590208053589\n",
      "\tLoss: 0.1690431535243988\n",
      "\tLoss: 0.10039304941892624\n",
      "\tLoss: 0.12162138521671295\n",
      "\tLoss: 0.1733585000038147\n",
      "\tLoss: 0.14824709296226501\n",
      "\tLoss: 0.16416168212890625\n",
      "\tLoss: 0.162613183259964\n",
      "\tLoss: 0.13265898823738098\n",
      "\tLoss: 0.14077183604240417\n",
      "\tLoss: 0.11772878468036652\n",
      "\tLoss: 0.13063228130340576\n",
      "\tLoss: 0.09483252465724945\n",
      "\tLoss: 0.12232480198144913\n",
      "\tLoss: 0.12057466804981232\n",
      "\tLoss: 0.14284385740756989\n",
      "\tLoss: 0.11867670714855194\n",
      "\tLoss: 0.18685445189476013\n",
      "\tLoss: 0.1568143218755722\n",
      "\tLoss: 0.1371793895959854\n",
      "\tLoss: 0.1465838998556137\n",
      "\tLoss: 0.17571541666984558\n",
      "\tLoss: 0.09587227553129196\n",
      "\tLoss: 0.11799539625644684\n",
      "\tLoss: 0.1495235413312912\n",
      "\tLoss: 0.15281666815280914\n",
      "\tLoss: 0.09233005344867706\n",
      "\tLoss: 0.12226013839244843\n",
      "\tLoss: 0.12749379873275757\n",
      "\tLoss: 0.19226595759391785\n",
      "\tLoss: 0.16138122975826263\n",
      "\tLoss: 0.12345057725906372\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.12120833247900009\n",
      "\tLoss: 0.14076659083366394\n",
      "\tLoss: 0.10204842686653137\n",
      "\tLoss: 0.13522058725357056\n",
      "\tLoss: 0.11582151055335999\n",
      "\tLoss: 0.12252811342477798\n",
      "\tLoss: 0.10877303779125214\n",
      "\tLoss: 0.14577049016952515\n",
      "\tLoss: 0.11965341866016388\n",
      "\tLoss: 0.1403176486492157\n",
      "\tLoss: 0.16562722623348236\n",
      "\tLoss: 0.1381997913122177\n",
      "\tLoss: 0.15392982959747314\n",
      "\tLoss: 0.11488521844148636\n",
      "\tLoss: 0.11126478016376495\n",
      "\tLoss: 0.0918469950556755\n",
      "\tLoss: 0.12622931599617004\n",
      "\tLoss: 0.10395941883325577\n",
      "\tLoss: 0.18280068039894104\n",
      "\tLoss: 0.11732955276966095\n",
      "\tLoss: 0.12009502947330475\n",
      "\tLoss: 0.11349936574697495\n",
      "\tLoss: 0.10374361276626587\n",
      "\tLoss: 0.16557303071022034\n",
      "\tLoss: 0.11103390902280807\n",
      "\tLoss: 0.1317761093378067\n",
      "\tLoss: 0.14294227957725525\n",
      "\tLoss: 0.12028665840625763\n",
      "\tLoss: 0.1957995444536209\n",
      "\tLoss: 0.09804702550172806\n",
      "\tLoss: 0.10002313554286957\n",
      "\tLoss: 0.1641073226928711\n",
      "\tLoss: 0.11461657285690308\n",
      "\tLoss: 0.16618330776691437\n",
      "\tLoss: 0.1192103922367096\n",
      "\tLoss: 0.1001771092414856\n",
      "\tLoss: 0.15306690335273743\n",
      "\tLoss: 0.11122438311576843\n",
      "\tLoss: 0.13371025025844574\n",
      "\tLoss: 0.1491648256778717\n",
      "\tLoss: 0.11079112440347672\n",
      "\tLoss: 0.15206174552440643\n",
      "\tLoss: 0.14310789108276367\n",
      "\tLoss: 0.12101135402917862\n",
      "\tLoss: 0.14654165506362915\n",
      "\tLoss: 0.09033878892660141\n",
      "\tLoss: 0.10842777788639069\n",
      "\tLoss: 0.09209480881690979\n",
      "\tLoss: 0.1910521686077118\n",
      "\tLoss: 0.17664287984371185\n",
      "\tLoss: 0.15529482066631317\n",
      "[time] Epoch 7: 465.52793464483693s = 7.758798910747283m\n",
      "\n",
      "Epoch 8...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.18033677339553833\n",
      "\tLoss: 0.18484780192375183\n",
      "\tLoss: 0.1305561065673828\n",
      "\tLoss: 0.16083967685699463\n",
      "\tLoss: 0.12018655240535736\n",
      "\tLoss: 0.13396233320236206\n",
      "\tLoss: 0.16230006515979767\n",
      "\tLoss: 0.12252868711948395\n",
      "\tLoss: 0.1421658992767334\n",
      "\tLoss: 0.17874042689800262\n",
      "\tLoss: 0.1948639154434204\n",
      "\tLoss: 0.13973094522953033\n",
      "\tLoss: 0.15488308668136597\n",
      "\tLoss: 0.14209294319152832\n",
      "\tLoss: 0.1048184335231781\n",
      "\tLoss: 0.12574782967567444\n",
      "\tLoss: 0.12925691902637482\n",
      "\tLoss: 0.11106041073799133\n",
      "\tLoss: 0.12306860089302063\n",
      "\tLoss: 0.13646939396858215\n",
      "\tLoss: 0.1366739422082901\n",
      "\tLoss: 0.10559582710266113\n",
      "\tLoss: 0.16223062574863434\n",
      "\tLoss: 0.1592208594083786\n",
      "\tLoss: 0.16222955286502838\n",
      "\tLoss: 0.15032944083213806\n",
      "\tLoss: 0.17609667778015137\n",
      "\tLoss: 0.15325139462947845\n",
      "\tLoss: 0.20898552238941193\n",
      "\tLoss: 0.1387576013803482\n",
      "\tLoss: 0.15035691857337952\n",
      "\tLoss: 0.1347956657409668\n",
      "\tLoss: 0.16462242603302002\n",
      "\tLoss: 0.14700156450271606\n",
      "\tLoss: 0.07433879375457764\n",
      "\tLoss: 0.1708066314458847\n",
      "\tLoss: 0.15690095722675323\n",
      "\tLoss: 0.1708166003227234\n",
      "\tLoss: 0.1428866684436798\n",
      "\tLoss: 0.11292856186628342\n",
      "\tLoss: 0.18337813019752502\n",
      "\tLoss: 0.14719924330711365\n",
      "\tLoss: 0.13102976977825165\n",
      "\tLoss: 0.17666465044021606\n",
      "\tLoss: 0.12715819478034973\n",
      "\tLoss: 0.169219508767128\n",
      "\tLoss: 0.16095775365829468\n",
      "\tLoss: 0.11875080317258835\n",
      "\tLoss: 0.21269896626472473\n",
      "\tLoss: 0.12084797024726868\n",
      "\tLoss: 0.10229656100273132\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.12795662879943848\n",
      "\tLoss: 0.15656845271587372\n",
      "\tLoss: 0.12705501914024353\n",
      "\tLoss: 0.09142708033323288\n",
      "\tLoss: 0.1680600792169571\n",
      "\tLoss: 0.16176220774650574\n",
      "\tLoss: 0.1296021044254303\n",
      "\tLoss: 0.1601739227771759\n",
      "\tLoss: 0.11152670532464981\n",
      "\tLoss: 0.11779406666755676\n",
      "\tLoss: 0.09128972887992859\n",
      "\tLoss: 0.11181540042161942\n",
      "\tLoss: 0.09389838576316833\n",
      "\tLoss: 0.12280505895614624\n",
      "\tLoss: 0.12441090494394302\n",
      "\tLoss: 0.11053921282291412\n",
      "\tLoss: 0.12505729496479034\n",
      "\tLoss: 0.09335488080978394\n",
      "\tLoss: 0.1682250201702118\n",
      "\tLoss: 0.11626431345939636\n",
      "\tLoss: 0.09726257622241974\n",
      "\tLoss: 0.1080908328294754\n",
      "\tLoss: 0.11785224825143814\n",
      "\tLoss: 0.15244945883750916\n",
      "\tLoss: 0.13773852586746216\n",
      "\tLoss: 0.1147586852312088\n",
      "\tLoss: 0.13151516020298004\n",
      "\tLoss: 0.12474345415830612\n",
      "\tLoss: 0.18158842623233795\n",
      "\tLoss: 0.1485569179058075\n",
      "\tLoss: 0.15537497401237488\n",
      "\tLoss: 0.12578417360782623\n",
      "\tLoss: 0.12091884762048721\n",
      "\tLoss: 0.12107077240943909\n",
      "\tLoss: 0.11406944692134857\n",
      "\tLoss: 0.1287086009979248\n",
      "\tLoss: 0.12167347967624664\n",
      "\tLoss: 0.10045607388019562\n",
      "\tLoss: 0.17674866318702698\n",
      "\tLoss: 0.0941338911652565\n",
      "\tLoss: 0.11571559309959412\n",
      "\tLoss: 0.15135471522808075\n",
      "\tLoss: 0.144783616065979\n",
      "\tLoss: 0.11867066472768784\n",
      "\tLoss: 0.08692827820777893\n",
      "\tLoss: 0.12593336403369904\n",
      "\tLoss: 0.1655268371105194\n",
      "\tLoss: 0.1066865622997284\n",
      "\tLoss: 0.11844436079263687\n",
      "\tLoss: 0.10388756543397903\n",
      "\tLoss: 0.15081192553043365\n",
      "[time] Epoch 8: 456.60123409470543s = 7.6100205682450905m\n",
      "\n",
      "Epoch 9...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.10644124448299408\n",
      "\tLoss: 0.1721532642841339\n",
      "\tLoss: 0.10378465056419373\n",
      "\tLoss: 0.15319904685020447\n",
      "\tLoss: 0.10099314898252487\n",
      "\tLoss: 0.13883769512176514\n",
      "\tLoss: 0.12204362452030182\n",
      "\tLoss: 0.12221620231866837\n",
      "\tLoss: 0.1566053032875061\n",
      "\tLoss: 0.09099845588207245\n",
      "\tLoss: 0.1469995379447937\n",
      "\tLoss: 0.16450557112693787\n",
      "\tLoss: 0.11852395534515381\n",
      "\tLoss: 0.15142065286636353\n",
      "\tLoss: 0.13178640604019165\n",
      "\tLoss: 0.12946179509162903\n",
      "\tLoss: 0.17022135853767395\n",
      "\tLoss: 0.15778066217899323\n",
      "\tLoss: 0.1077054888010025\n",
      "\tLoss: 0.09823048114776611\n",
      "\tLoss: 0.09972456097602844\n",
      "\tLoss: 0.11665931344032288\n",
      "\tLoss: 0.13272464275360107\n",
      "\tLoss: 0.1568746417760849\n",
      "\tLoss: 0.10636844485998154\n",
      "\tLoss: 0.1351960152387619\n",
      "\tLoss: 0.1218767911195755\n",
      "\tLoss: 0.14139708876609802\n",
      "\tLoss: 0.10524441301822662\n",
      "\tLoss: 0.12310776114463806\n",
      "\tLoss: 0.15244191884994507\n",
      "\tLoss: 0.14150990545749664\n",
      "\tLoss: 0.11461448669433594\n",
      "\tLoss: 0.10915419459342957\n",
      "\tLoss: 0.14751854538917542\n",
      "\tLoss: 0.1758860945701599\n",
      "\tLoss: 0.1302369236946106\n",
      "\tLoss: 0.10071814060211182\n",
      "\tLoss: 0.09293430298566818\n",
      "\tLoss: 0.08380835503339767\n",
      "\tLoss: 0.09673863649368286\n",
      "\tLoss: 0.12645193934440613\n",
      "\tLoss: 0.09598231315612793\n",
      "\tLoss: 0.08737453818321228\n",
      "\tLoss: 0.13578128814697266\n",
      "\tLoss: 0.12034128606319427\n",
      "\tLoss: 0.14434580504894257\n",
      "\tLoss: 0.06702366471290588\n",
      "\tLoss: 0.15683430433273315\n",
      "\tLoss: 0.11432555317878723\n",
      "\tLoss: 0.12947508692741394\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.11627134680747986\n",
      "\tLoss: 0.1338491439819336\n",
      "\tLoss: 0.11049458384513855\n",
      "\tLoss: 0.11817337572574615\n",
      "\tLoss: 0.10809636116027832\n",
      "\tLoss: 0.08220845460891724\n",
      "\tLoss: 0.11025122553110123\n",
      "\tLoss: 0.17298763990402222\n",
      "\tLoss: 0.13402247428894043\n",
      "\tLoss: 0.15257495641708374\n",
      "\tLoss: 0.12492247670888901\n",
      "\tLoss: 0.13249266147613525\n",
      "\tLoss: 0.16421593725681305\n",
      "\tLoss: 0.10125469416379929\n",
      "\tLoss: 0.12622985243797302\n",
      "\tLoss: 0.09724923223257065\n",
      "\tLoss: 0.11226028203964233\n",
      "\tLoss: 0.11100848019123077\n",
      "\tLoss: 0.134383887052536\n",
      "\tLoss: 0.10679951310157776\n",
      "\tLoss: 0.10372183471918106\n",
      "\tLoss: 0.10072018206119537\n",
      "\tLoss: 0.11500438302755356\n",
      "\tLoss: 0.13337138295173645\n",
      "\tLoss: 0.09681989252567291\n",
      "\tLoss: 0.14919036626815796\n",
      "\tLoss: 0.13560634851455688\n",
      "\tLoss: 0.13719718158245087\n",
      "\tLoss: 0.14253011345863342\n",
      "\tLoss: 0.07367025315761566\n",
      "\tLoss: 0.11117260903120041\n",
      "\tLoss: 0.08966043591499329\n",
      "\tLoss: 0.1487761288881302\n",
      "\tLoss: 0.10209222137928009\n",
      "\tLoss: 0.11115486174821854\n",
      "\tLoss: 0.11911574006080627\n",
      "\tLoss: 0.14550688862800598\n",
      "\tLoss: 0.12456938624382019\n",
      "\tLoss: 0.13221579790115356\n",
      "\tLoss: 0.14962393045425415\n",
      "\tLoss: 0.13195081055164337\n",
      "\tLoss: 0.12076733261346817\n",
      "\tLoss: 0.15631206333637238\n",
      "\tLoss: 0.10839962959289551\n",
      "\tLoss: 0.1498228758573532\n",
      "\tLoss: 0.1147385910153389\n",
      "\tLoss: 0.1501922905445099\n",
      "\tLoss: 0.11018799245357513\n",
      "\tLoss: 0.102629154920578\n",
      "\tLoss: 0.1270095407962799\n",
      "\tLoss: 0.11698758602142334\n",
      "[time] Epoch 9: 470.7869482333772s = 7.846449137222953m\n",
      "\n",
      "Epoch 10...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.13030052185058594\n",
      "\tLoss: 0.1429709494113922\n",
      "\tLoss: 0.12264320254325867\n",
      "\tLoss: 0.1870931088924408\n",
      "\tLoss: 0.14555588364601135\n",
      "\tLoss: 0.13216614723205566\n",
      "\tLoss: 0.11083780229091644\n",
      "\tLoss: 0.1124616488814354\n",
      "\tLoss: 0.13361743092536926\n",
      "\tLoss: 0.11066680401563644\n",
      "\tLoss: 0.14909233152866364\n",
      "\tLoss: 0.12169215083122253\n",
      "\tLoss: 0.10943848639726639\n",
      "\tLoss: 0.1222255676984787\n",
      "\tLoss: 0.10558389127254486\n",
      "\tLoss: 0.09019863605499268\n",
      "\tLoss: 0.11291328072547913\n",
      "\tLoss: 0.1226142942905426\n",
      "\tLoss: 0.12427067756652832\n",
      "\tLoss: 0.0783596783876419\n",
      "\tLoss: 0.1032605767250061\n",
      "\tLoss: 0.12264540791511536\n",
      "\tLoss: 0.1155463233590126\n",
      "\tLoss: 0.16699081659317017\n",
      "\tLoss: 0.13516399264335632\n",
      "\tLoss: 0.14951366186141968\n",
      "\tLoss: 0.09756147861480713\n",
      "\tLoss: 0.17678189277648926\n",
      "\tLoss: 0.1415950059890747\n",
      "\tLoss: 0.1306503862142563\n",
      "\tLoss: 0.12836766242980957\n",
      "\tLoss: 0.15024620294570923\n",
      "\tLoss: 0.12441489845514297\n",
      "\tLoss: 0.10644177347421646\n",
      "\tLoss: 0.11334343254566193\n",
      "\tLoss: 0.16059055924415588\n",
      "\tLoss: 0.10221096128225327\n",
      "\tLoss: 0.1301383078098297\n",
      "\tLoss: 0.10062547028064728\n",
      "\tLoss: 0.1977161020040512\n",
      "\tLoss: 0.12504103779792786\n",
      "\tLoss: 0.130866140127182\n",
      "\tLoss: 0.15525224804878235\n",
      "\tLoss: 0.12834113836288452\n",
      "\tLoss: 0.13166843354701996\n",
      "\tLoss: 0.13315847516059875\n",
      "\tLoss: 0.14296427369117737\n",
      "\tLoss: 0.1183646097779274\n",
      "\tLoss: 0.10205648839473724\n",
      "\tLoss: 0.1637587696313858\n",
      "\tLoss: 0.10661523789167404\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.12673136591911316\n",
      "\tLoss: 0.14143416285514832\n",
      "\tLoss: 0.17715898156166077\n",
      "\tLoss: 0.13156327605247498\n",
      "\tLoss: 0.16387876868247986\n",
      "\tLoss: 0.11903233826160431\n",
      "\tLoss: 0.15282735228538513\n",
      "\tLoss: 0.11998523771762848\n",
      "\tLoss: 0.09753729403018951\n",
      "\tLoss: 0.15124346315860748\n",
      "\tLoss: 0.11007313430309296\n",
      "\tLoss: 0.1321258246898651\n",
      "\tLoss: 0.08443358540534973\n",
      "\tLoss: 0.12429382652044296\n",
      "\tLoss: 0.16032840311527252\n",
      "\tLoss: 0.1073855310678482\n",
      "\tLoss: 0.12298809736967087\n",
      "\tLoss: 0.14717379212379456\n",
      "\tLoss: 0.16325336694717407\n",
      "\tLoss: 0.1493370682001114\n",
      "\tLoss: 0.13888514041900635\n",
      "\tLoss: 0.15190346539020538\n",
      "\tLoss: 0.12412294745445251\n",
      "\tLoss: 0.155222088098526\n",
      "\tLoss: 0.10772331058979034\n",
      "\tLoss: 0.16362129151821136\n",
      "\tLoss: 0.12128356844186783\n",
      "\tLoss: 0.1183975487947464\n",
      "\tLoss: 0.14810559153556824\n",
      "\tLoss: 0.13661162555217743\n",
      "\tLoss: 0.1551150679588318\n",
      "\tLoss: 0.09940559417009354\n",
      "\tLoss: 0.10589989274740219\n",
      "\tLoss: 0.13417112827301025\n",
      "\tLoss: 0.10414664447307587\n",
      "\tLoss: 0.11450053751468658\n",
      "\tLoss: 0.11467728018760681\n",
      "\tLoss: 0.11007074266672134\n",
      "\tLoss: 0.1654747724533081\n",
      "\tLoss: 0.14487212896347046\n",
      "\tLoss: 0.12712737917900085\n",
      "\tLoss: 0.13510066270828247\n",
      "\tLoss: 0.12081891298294067\n",
      "\tLoss: 0.17295315861701965\n",
      "\tLoss: 0.1301470398902893\n",
      "\tLoss: 0.11653927713632584\n",
      "\tLoss: 0.1472231149673462\n",
      "\tLoss: 0.15545320510864258\n",
      "\tLoss: 0.05483134835958481\n",
      "\tLoss: 0.10293103009462357\n",
      "\tLoss: 0.11446475982666016\n",
      "[time] Epoch 10: 469.81196468230337s = 7.830199411371723m\n",
      "\n",
      "Epoch 11...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.10285089910030365\n",
      "\tLoss: 0.10313926637172699\n",
      "\tLoss: 0.14753445982933044\n",
      "\tLoss: 0.07541906833648682\n",
      "\tLoss: 0.10642653703689575\n",
      "\tLoss: 0.14829212427139282\n",
      "\tLoss: 0.11164268106222153\n",
      "\tLoss: 0.09322677552700043\n",
      "\tLoss: 0.10866932570934296\n",
      "\tLoss: 0.14034321904182434\n",
      "\tLoss: 0.09770755469799042\n",
      "\tLoss: 0.109397754073143\n",
      "\tLoss: 0.13519297540187836\n",
      "\tLoss: 0.1282045543193817\n",
      "\tLoss: 0.1529456377029419\n",
      "\tLoss: 0.11185982078313828\n",
      "\tLoss: 0.1229296401143074\n",
      "\tLoss: 0.08663617074489594\n",
      "\tLoss: 0.1282108724117279\n",
      "\tLoss: 0.11759325861930847\n",
      "\tLoss: 0.14084923267364502\n",
      "\tLoss: 0.12519226968288422\n",
      "\tLoss: 0.12379461526870728\n",
      "\tLoss: 0.14533290266990662\n",
      "\tLoss: 0.14418168365955353\n",
      "\tLoss: 0.13777975738048553\n",
      "\tLoss: 0.09767225384712219\n",
      "\tLoss: 0.12442079931497574\n",
      "\tLoss: 0.08097580075263977\n",
      "\tLoss: 0.059618208557367325\n",
      "\tLoss: 0.12825337052345276\n",
      "\tLoss: 0.12473709881305695\n",
      "\tLoss: 0.09071805328130722\n",
      "\tLoss: 0.11593347787857056\n",
      "\tLoss: 0.13955190777778625\n",
      "\tLoss: 0.1006065383553505\n",
      "\tLoss: 0.09098747372627258\n",
      "\tLoss: 0.09194200485944748\n",
      "\tLoss: 0.10695718973875046\n",
      "\tLoss: 0.1563735008239746\n",
      "\tLoss: 0.09656013548374176\n",
      "\tLoss: 0.15218794345855713\n",
      "\tLoss: 0.12518218159675598\n",
      "\tLoss: 0.1455710530281067\n",
      "\tLoss: 0.10968068242073059\n",
      "\tLoss: 0.11807870864868164\n",
      "\tLoss: 0.1025400459766388\n",
      "\tLoss: 0.12597540020942688\n",
      "\tLoss: 0.16461984813213348\n",
      "\tLoss: 0.13316138088703156\n",
      "\tLoss: 0.11131475865840912\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.12136350572109222\n",
      "\tLoss: 0.11596652865409851\n",
      "\tLoss: 0.1116727739572525\n",
      "\tLoss: 0.11390219628810883\n",
      "\tLoss: 0.15576478838920593\n",
      "\tLoss: 0.11237941682338715\n",
      "\tLoss: 0.08229964226484299\n",
      "\tLoss: 0.10259652137756348\n",
      "\tLoss: 0.1214979737997055\n",
      "\tLoss: 0.10188111662864685\n",
      "\tLoss: 0.1245289221405983\n",
      "\tLoss: 0.08227121829986572\n",
      "\tLoss: 0.14276722073554993\n",
      "\tLoss: 0.12075898051261902\n",
      "\tLoss: 0.07618340849876404\n",
      "\tLoss: 0.10765379667282104\n",
      "\tLoss: 0.10042252391576767\n",
      "\tLoss: 0.099119171500206\n",
      "\tLoss: 0.11470454931259155\n",
      "\tLoss: 0.11415478587150574\n",
      "\tLoss: 0.15996232628822327\n",
      "\tLoss: 0.1375880241394043\n",
      "\tLoss: 0.11122426390647888\n",
      "\tLoss: 0.14433586597442627\n",
      "\tLoss: 0.12975873053073883\n",
      "\tLoss: 0.11166274547576904\n",
      "\tLoss: 0.10559438169002533\n",
      "\tLoss: 0.07065828144550323\n",
      "\tLoss: 0.15667173266410828\n",
      "\tLoss: 0.11816947162151337\n",
      "\tLoss: 0.11867129802703857\n",
      "\tLoss: 0.09377170354127884\n",
      "\tLoss: 0.1470128744840622\n",
      "\tLoss: 0.10752256214618683\n",
      "\tLoss: 0.10963495820760727\n",
      "\tLoss: 0.0997110903263092\n",
      "\tLoss: 0.1342560052871704\n",
      "\tLoss: 0.13535001873970032\n",
      "\tLoss: 0.11846840381622314\n",
      "\tLoss: 0.10885544121265411\n",
      "\tLoss: 0.15670619904994965\n",
      "\tLoss: 0.14343826472759247\n",
      "\tLoss: 0.11127449572086334\n",
      "\tLoss: 0.1465487778186798\n",
      "\tLoss: 0.10565008223056793\n",
      "\tLoss: 0.11871663480997086\n",
      "\tLoss: 0.09752068668603897\n",
      "\tLoss: 0.09678566455841064\n",
      "\tLoss: 0.12382003664970398\n",
      "\tLoss: 0.1350165605545044\n",
      "\tLoss: 0.1932561844587326\n",
      "[time] Epoch 11: 471.84580411808565s = 7.864096735301428m\n",
      "\n",
      "Epoch 12...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.11072216928005219\n",
      "\tLoss: 0.1263170689344406\n",
      "\tLoss: 0.12065912038087845\n",
      "\tLoss: 0.08858687430620193\n",
      "\tLoss: 0.08598379045724869\n",
      "\tLoss: 0.13030308485031128\n",
      "\tLoss: 0.12443467229604721\n",
      "\tLoss: 0.1525459736585617\n",
      "\tLoss: 0.11293022334575653\n",
      "\tLoss: 0.1255584955215454\n",
      "\tLoss: 0.10707584023475647\n",
      "\tLoss: 0.1002250462770462\n",
      "\tLoss: 0.1268903613090515\n",
      "\tLoss: 0.10542846471071243\n",
      "\tLoss: 0.1674521267414093\n",
      "\tLoss: 0.11973098665475845\n",
      "\tLoss: 0.16770632565021515\n",
      "\tLoss: 0.13487523794174194\n",
      "\tLoss: 0.14614835381507874\n",
      "\tLoss: 0.1345466673374176\n",
      "\tLoss: 0.1241016760468483\n",
      "\tLoss: 0.14170749485492706\n",
      "\tLoss: 0.11086304485797882\n",
      "\tLoss: 0.10795088857412338\n",
      "\tLoss: 0.07195805013179779\n",
      "\tLoss: 0.12709961831569672\n",
      "\tLoss: 0.1453428566455841\n",
      "\tLoss: 0.09708450734615326\n",
      "\tLoss: 0.1550152599811554\n",
      "\tLoss: 0.1650795340538025\n",
      "\tLoss: 0.17201516032218933\n",
      "\tLoss: 0.12823417782783508\n",
      "\tLoss: 0.15594050288200378\n",
      "\tLoss: 0.18509915471076965\n",
      "\tLoss: 0.12135693430900574\n",
      "\tLoss: 0.09686852991580963\n",
      "\tLoss: 0.15085147321224213\n",
      "\tLoss: 0.16169002652168274\n",
      "\tLoss: 0.1391548216342926\n",
      "\tLoss: 0.11412666738033295\n",
      "\tLoss: 0.15888603031635284\n",
      "\tLoss: 0.1482735574245453\n",
      "\tLoss: 0.11213457584381104\n",
      "\tLoss: 0.1384323537349701\n",
      "\tLoss: 0.17184875905513763\n",
      "\tLoss: 0.16395030915737152\n",
      "\tLoss: 0.12763652205467224\n",
      "\tLoss: 0.11922603100538254\n",
      "\tLoss: 0.17215314507484436\n",
      "\tLoss: 0.18509997427463531\n",
      "\tLoss: 0.11180761456489563\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.08633394539356232\n",
      "\tLoss: 0.17491212487220764\n",
      "\tLoss: 0.11604136228561401\n",
      "\tLoss: 0.10758496820926666\n",
      "\tLoss: 0.12167465686798096\n",
      "\tLoss: 0.13497093319892883\n",
      "\tLoss: 0.10950158536434174\n",
      "\tLoss: 0.12866610288619995\n",
      "\tLoss: 0.10265378654003143\n",
      "\tLoss: 0.12911662459373474\n",
      "\tLoss: 0.11879390478134155\n",
      "\tLoss: 0.10598596930503845\n",
      "\tLoss: 0.1662498414516449\n",
      "\tLoss: 0.11720139533281326\n",
      "\tLoss: 0.14550018310546875\n",
      "\tLoss: 0.17923176288604736\n",
      "\tLoss: 0.10043688118457794\n",
      "\tLoss: 0.11053794622421265\n",
      "\tLoss: 0.13319027423858643\n",
      "\tLoss: 0.11820639669895172\n",
      "\tLoss: 0.12395493686199188\n",
      "\tLoss: 0.13230127096176147\n",
      "\tLoss: 0.09621778130531311\n",
      "\tLoss: 0.14589673280715942\n",
      "\tLoss: 0.11700809001922607\n",
      "\tLoss: 0.14249259233474731\n",
      "\tLoss: 0.08319596946239471\n",
      "\tLoss: 0.11268997192382812\n",
      "\tLoss: 0.15746721625328064\n",
      "\tLoss: 0.131063312292099\n",
      "\tLoss: 0.13846652209758759\n",
      "\tLoss: 0.13898193836212158\n",
      "\tLoss: 0.1489238291978836\n",
      "\tLoss: 0.1134093701839447\n",
      "\tLoss: 0.08702027797698975\n",
      "\tLoss: 0.15474356710910797\n",
      "\tLoss: 0.13964290916919708\n",
      "\tLoss: 0.11561214178800583\n",
      "\tLoss: 0.1005353182554245\n",
      "\tLoss: 0.11009794473648071\n",
      "\tLoss: 0.11264567822217941\n",
      "\tLoss: 0.14182034134864807\n",
      "\tLoss: 0.10285177826881409\n",
      "\tLoss: 0.11650292575359344\n",
      "\tLoss: 0.13034909963607788\n",
      "\tLoss: 0.12985284626483917\n",
      "\tLoss: 0.11564788222312927\n",
      "\tLoss: 0.1367460936307907\n",
      "\tLoss: 0.06952279061079025\n",
      "\tLoss: 0.1312369406223297\n",
      "\tLoss: 0.1019960343837738\n",
      "[time] Epoch 12: 473.6550646908581s = 7.894251078180969m\n",
      "\n",
      "Epoch 13...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.09559819102287292\n",
      "\tLoss: 0.1687476634979248\n",
      "\tLoss: 0.08792093396186829\n",
      "\tLoss: 0.09887470304965973\n",
      "\tLoss: 0.11219847202301025\n",
      "\tLoss: 0.09604813158512115\n",
      "\tLoss: 0.1196441650390625\n",
      "\tLoss: 0.11213946342468262\n",
      "\tLoss: 0.14780429005622864\n",
      "\tLoss: 0.09715326130390167\n",
      "\tLoss: 0.0879061222076416\n",
      "\tLoss: 0.10503405332565308\n",
      "\tLoss: 0.12841323018074036\n",
      "\tLoss: 0.11646682024002075\n",
      "\tLoss: 0.10405746847391129\n",
      "\tLoss: 0.1592935025691986\n",
      "\tLoss: 0.17090648412704468\n",
      "\tLoss: 0.10592013597488403\n",
      "\tLoss: 0.13242533802986145\n",
      "\tLoss: 0.09339088201522827\n",
      "\tLoss: 0.10078965872526169\n",
      "\tLoss: 0.13529711961746216\n",
      "\tLoss: 0.09742681682109833\n",
      "\tLoss: 0.1270170956850052\n",
      "\tLoss: 0.15451161563396454\n",
      "\tLoss: 0.11712431162595749\n",
      "\tLoss: 0.11752168834209442\n",
      "\tLoss: 0.14746931195259094\n",
      "\tLoss: 0.15538926422595978\n",
      "\tLoss: 0.14506661891937256\n",
      "\tLoss: 0.10813035070896149\n",
      "\tLoss: 0.07839587330818176\n",
      "\tLoss: 0.1258862167596817\n",
      "\tLoss: 0.11279991269111633\n",
      "\tLoss: 0.1246820017695427\n",
      "\tLoss: 0.10097962617874146\n",
      "\tLoss: 0.10978381335735321\n",
      "\tLoss: 0.08843955397605896\n",
      "\tLoss: 0.11499527096748352\n",
      "\tLoss: 0.14158952236175537\n",
      "\tLoss: 0.14484445750713348\n",
      "\tLoss: 0.1111319288611412\n",
      "\tLoss: 0.11923492699861526\n",
      "\tLoss: 0.08385545015335083\n",
      "\tLoss: 0.13348904252052307\n",
      "\tLoss: 0.06730210781097412\n",
      "\tLoss: 0.1296534538269043\n",
      "\tLoss: 0.11298705637454987\n",
      "\tLoss: 0.14302346110343933\n",
      "\tLoss: 0.13644598424434662\n",
      "\tLoss: 0.12051989883184433\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.1230965256690979\n",
      "\tLoss: 0.0802311897277832\n",
      "\tLoss: 0.1471465528011322\n",
      "\tLoss: 0.11253581196069717\n",
      "\tLoss: 0.09365524351596832\n",
      "\tLoss: 0.1496829092502594\n",
      "\tLoss: 0.07489195466041565\n",
      "\tLoss: 0.08316256105899811\n",
      "\tLoss: 0.11792535334825516\n",
      "\tLoss: 0.1631624400615692\n",
      "\tLoss: 0.09674929082393646\n",
      "\tLoss: 0.11842906475067139\n",
      "\tLoss: 0.13039763271808624\n",
      "\tLoss: 0.10506190359592438\n",
      "\tLoss: 0.1237260177731514\n",
      "\tLoss: 0.11618898063898087\n",
      "\tLoss: 0.08999079465866089\n",
      "\tLoss: 0.13121983408927917\n",
      "\tLoss: 0.12377059459686279\n",
      "\tLoss: 0.13872937858104706\n",
      "\tLoss: 0.11534681916236877\n",
      "\tLoss: 0.12483248114585876\n",
      "\tLoss: 0.08112699538469315\n",
      "\tLoss: 0.17191515862941742\n",
      "\tLoss: 0.08761754631996155\n",
      "\tLoss: 0.2097192108631134\n",
      "\tLoss: 0.1764659881591797\n",
      "\tLoss: 0.09753964096307755\n",
      "\tLoss: 0.168962299823761\n",
      "\tLoss: 0.13205361366271973\n",
      "\tLoss: 0.1389765590429306\n",
      "\tLoss: 0.12136141955852509\n",
      "\tLoss: 0.203351229429245\n",
      "\tLoss: 0.1502458155155182\n",
      "\tLoss: 0.1115642786026001\n",
      "\tLoss: 0.07742157578468323\n",
      "\tLoss: 0.15273073315620422\n",
      "\tLoss: 0.12550373375415802\n",
      "\tLoss: 0.13896800577640533\n",
      "\tLoss: 0.13939136266708374\n",
      "\tLoss: 0.14269278943538666\n",
      "\tLoss: 0.1437467336654663\n",
      "\tLoss: 0.07696201652288437\n",
      "\tLoss: 0.07858943194150925\n",
      "\tLoss: 0.09838975965976715\n",
      "\tLoss: 0.13544350862503052\n",
      "\tLoss: 0.08498337119817734\n",
      "\tLoss: 0.08901062607765198\n",
      "\tLoss: 0.1548922210931778\n",
      "\tLoss: 0.14432094991207123\n",
      "\tLoss: 0.1719272881746292\n",
      "[time] Epoch 13: 477.0757381627336s = 7.951262302712227m\n",
      "\n",
      "Epoch 14...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.13463985919952393\n",
      "\tLoss: 0.11555773764848709\n",
      "\tLoss: 0.09558158367872238\n",
      "\tLoss: 0.14425505697727203\n",
      "\tLoss: 0.12824563682079315\n",
      "\tLoss: 0.08518695831298828\n",
      "\tLoss: 0.09405841678380966\n",
      "\tLoss: 0.1380903422832489\n",
      "\tLoss: 0.1369384527206421\n",
      "\tLoss: 0.14943039417266846\n",
      "\tLoss: 0.11007038503885269\n",
      "\tLoss: 0.13561402261257172\n",
      "\tLoss: 0.1232038214802742\n",
      "\tLoss: 0.12409180402755737\n",
      "\tLoss: 0.10897659510374069\n",
      "\tLoss: 0.13953498005867004\n",
      "\tLoss: 0.11953295767307281\n",
      "\tLoss: 0.175587460398674\n",
      "\tLoss: 0.15427231788635254\n",
      "\tLoss: 0.15836676955223083\n",
      "\tLoss: 0.15935704112052917\n",
      "\tLoss: 0.13986974954605103\n",
      "\tLoss: 0.11817925423383713\n",
      "\tLoss: 0.12793537974357605\n",
      "\tLoss: 0.1577453315258026\n",
      "\tLoss: 0.09985058009624481\n",
      "\tLoss: 0.15105973184108734\n",
      "\tLoss: 0.14898507297039032\n",
      "\tLoss: 0.12529338896274567\n",
      "\tLoss: 0.12814851105213165\n",
      "\tLoss: 0.1881875991821289\n",
      "\tLoss: 0.14926229417324066\n",
      "\tLoss: 0.10230368375778198\n",
      "\tLoss: 0.1731402426958084\n",
      "\tLoss: 0.12151366472244263\n",
      "\tLoss: 0.13019604980945587\n",
      "\tLoss: 0.11182725429534912\n",
      "\tLoss: 0.10392877459526062\n",
      "\tLoss: 0.11521872133016586\n",
      "\tLoss: 0.1353483647108078\n",
      "\tLoss: 0.11850099265575409\n",
      "\tLoss: 0.1691768914461136\n",
      "\tLoss: 0.1373615711927414\n",
      "\tLoss: 0.08914540708065033\n",
      "\tLoss: 0.0733388140797615\n",
      "\tLoss: 0.13618336617946625\n",
      "\tLoss: 0.12652206420898438\n",
      "\tLoss: 0.1410595029592514\n",
      "\tLoss: 0.13936275243759155\n",
      "\tLoss: 0.14024707674980164\n",
      "\tLoss: 0.13862472772598267\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.10140422731637955\n",
      "\tLoss: 0.1122656986117363\n",
      "\tLoss: 0.15750914812088013\n",
      "\tLoss: 0.16021956503391266\n",
      "\tLoss: 0.13305875658988953\n",
      "\tLoss: 0.11023284494876862\n",
      "\tLoss: 0.11272579431533813\n",
      "\tLoss: 0.1325703114271164\n",
      "\tLoss: 0.12337872385978699\n",
      "\tLoss: 0.1876167356967926\n",
      "\tLoss: 0.11277306079864502\n",
      "\tLoss: 0.10700914263725281\n",
      "\tLoss: 0.10656729340553284\n",
      "\tLoss: 0.08042623102664948\n",
      "\tLoss: 0.149884894490242\n",
      "\tLoss: 0.11271430552005768\n",
      "\tLoss: 0.10609210282564163\n",
      "\tLoss: 0.1124473363161087\n",
      "\tLoss: 0.1070794016122818\n",
      "\tLoss: 0.12488707900047302\n",
      "\tLoss: 0.11732426285743713\n",
      "\tLoss: 0.14109188318252563\n",
      "\tLoss: 0.10872185975313187\n",
      "\tLoss: 0.142556831240654\n",
      "\tLoss: 0.1186395063996315\n",
      "\tLoss: 0.12785083055496216\n",
      "\tLoss: 0.1801568865776062\n",
      "\tLoss: 0.14195261895656586\n",
      "\tLoss: 0.16074489057064056\n",
      "\tLoss: 0.15935182571411133\n",
      "\tLoss: 0.11705905199050903\n",
      "\tLoss: 0.12472988665103912\n",
      "\tLoss: 0.1157594695687294\n",
      "\tLoss: 0.15032923221588135\n",
      "\tLoss: 0.1733819544315338\n",
      "\tLoss: 0.10768062621355057\n",
      "\tLoss: 0.10114963352680206\n",
      "\tLoss: 0.1549730896949768\n",
      "\tLoss: 0.13680189847946167\n",
      "\tLoss: 0.1285739541053772\n",
      "\tLoss: 0.14557942748069763\n",
      "\tLoss: 0.1094428300857544\n",
      "\tLoss: 0.10425548255443573\n",
      "\tLoss: 0.11504824459552765\n",
      "\tLoss: 0.09465688467025757\n",
      "\tLoss: 0.07675696909427643\n",
      "\tLoss: 0.10654444992542267\n",
      "\tLoss: 0.10029114037752151\n",
      "\tLoss: 0.14817260205745697\n",
      "\tLoss: 0.11910213530063629\n",
      "\tLoss: 0.11405488103628159\n",
      "[time] Epoch 14: 476.8237404199317s = 7.947062340332195m\n",
      "\n",
      "Epoch 15...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1344282329082489\n",
      "\tLoss: 0.08425752818584442\n",
      "\tLoss: 0.11510676145553589\n",
      "\tLoss: 0.10746119171380997\n",
      "\tLoss: 0.14491668343544006\n",
      "\tLoss: 0.09952511638402939\n",
      "\tLoss: 0.13313552737236023\n",
      "\tLoss: 0.11293461918830872\n",
      "\tLoss: 0.09387872368097305\n",
      "\tLoss: 0.11678709089756012\n",
      "\tLoss: 0.13838690519332886\n",
      "\tLoss: 0.1429498791694641\n",
      "\tLoss: 0.12586912512779236\n",
      "\tLoss: 0.13943418860435486\n",
      "\tLoss: 0.10126812011003494\n",
      "\tLoss: 0.13636226952075958\n",
      "\tLoss: 0.08325858414173126\n",
      "\tLoss: 0.15645188093185425\n",
      "\tLoss: 0.11687180399894714\n",
      "\tLoss: 0.12407156825065613\n",
      "\tLoss: 0.09940661489963531\n",
      "\tLoss: 0.10382242500782013\n",
      "\tLoss: 0.08772598206996918\n",
      "\tLoss: 0.11391349881887436\n",
      "\tLoss: 0.11666140705347061\n",
      "\tLoss: 0.11982788890600204\n",
      "\tLoss: 0.17164862155914307\n",
      "\tLoss: 0.1457843780517578\n",
      "\tLoss: 0.12041360139846802\n",
      "\tLoss: 0.08126215636730194\n",
      "\tLoss: 0.14277935028076172\n",
      "\tLoss: 0.18372809886932373\n",
      "\tLoss: 0.116141177713871\n",
      "\tLoss: 0.17992570996284485\n",
      "\tLoss: 0.1191616803407669\n",
      "\tLoss: 0.11876372247934341\n",
      "\tLoss: 0.10811127722263336\n",
      "\tLoss: 0.14271080493927002\n",
      "\tLoss: 0.1400623917579651\n",
      "\tLoss: 0.12004218995571136\n",
      "\tLoss: 0.13723933696746826\n",
      "\tLoss: 0.10478399693965912\n",
      "\tLoss: 0.12078678607940674\n",
      "\tLoss: 0.11540436744689941\n",
      "\tLoss: 0.09031476080417633\n",
      "\tLoss: 0.16123583912849426\n",
      "\tLoss: 0.12434926629066467\n",
      "\tLoss: 0.13972026109695435\n",
      "\tLoss: 0.11484527587890625\n",
      "\tLoss: 0.0925215482711792\n",
      "\tLoss: 0.17445388436317444\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.1302087903022766\n",
      "\tLoss: 0.12544003129005432\n",
      "\tLoss: 0.11462844163179398\n",
      "\tLoss: 0.12917549908161163\n",
      "\tLoss: 0.09562912583351135\n",
      "\tLoss: 0.11591000854969025\n",
      "\tLoss: 0.17853014171123505\n",
      "\tLoss: 0.09054774045944214\n",
      "\tLoss: 0.14745724201202393\n",
      "\tLoss: 0.1243254542350769\n",
      "\tLoss: 0.11044294387102127\n",
      "\tLoss: 0.09882836043834686\n",
      "\tLoss: 0.14509879052639008\n",
      "\tLoss: 0.1236138865351677\n",
      "\tLoss: 0.14687050879001617\n",
      "\tLoss: 0.10922307521104813\n",
      "\tLoss: 0.13619036972522736\n",
      "\tLoss: 0.13772052526474\n",
      "\tLoss: 0.11114446818828583\n",
      "\tLoss: 0.10336784273386002\n",
      "\tLoss: 0.11748576164245605\n",
      "\tLoss: 0.10638687014579773\n",
      "\tLoss: 0.07289391756057739\n",
      "\tLoss: 0.14290833473205566\n",
      "\tLoss: 0.12504839897155762\n",
      "\tLoss: 0.10766784846782684\n",
      "\tLoss: 0.1229027509689331\n",
      "\tLoss: 0.1280522644519806\n",
      "\tLoss: 0.0935777872800827\n",
      "\tLoss: 0.10158352553844452\n",
      "\tLoss: 0.1289755254983902\n",
      "\tLoss: 0.143113374710083\n",
      "\tLoss: 0.12511996924877167\n",
      "\tLoss: 0.09819620102643967\n",
      "\tLoss: 0.11314423382282257\n",
      "\tLoss: 0.14236533641815186\n",
      "\tLoss: 0.10117906332015991\n",
      "\tLoss: 0.1378997415304184\n",
      "\tLoss: 0.11871901154518127\n",
      "\tLoss: 0.10915456712245941\n",
      "\tLoss: 0.11747705936431885\n",
      "\tLoss: 0.11465218663215637\n",
      "\tLoss: 0.14223329722881317\n",
      "\tLoss: 0.10340552031993866\n",
      "\tLoss: 0.13288557529449463\n",
      "\tLoss: 0.13099642097949982\n",
      "\tLoss: 0.14757181704044342\n",
      "\tLoss: 0.13485337793827057\n",
      "\tLoss: 0.15401363372802734\n",
      "\tLoss: 0.1463838666677475\n",
      "\tLoss: 0.10513509064912796\n",
      "[time] Epoch 15: 478.63306250376627s = 7.977217708396105m\n",
      "\n",
      "Epoch 16...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.12208110839128494\n",
      "\tLoss: 0.14062240719795227\n",
      "\tLoss: 0.10591955482959747\n",
      "\tLoss: 0.12429697811603546\n",
      "\tLoss: 0.16442354023456573\n",
      "\tLoss: 0.1014428362250328\n",
      "\tLoss: 0.14024725556373596\n",
      "\tLoss: 0.12137298285961151\n",
      "\tLoss: 0.10897368937730789\n",
      "\tLoss: 0.15263155102729797\n",
      "\tLoss: 0.13139954209327698\n",
      "\tLoss: 0.13078996539115906\n",
      "\tLoss: 0.12108949571847916\n",
      "\tLoss: 0.1440020054578781\n",
      "\tLoss: 0.15561217069625854\n",
      "\tLoss: 0.15657642483711243\n",
      "\tLoss: 0.15443837642669678\n",
      "\tLoss: 0.15855365991592407\n",
      "\tLoss: 0.17028526961803436\n",
      "\tLoss: 0.12336166948080063\n",
      "\tLoss: 0.14364367723464966\n",
      "\tLoss: 0.16519832611083984\n",
      "\tLoss: 0.16949371993541718\n",
      "\tLoss: 0.12279822677373886\n",
      "\tLoss: 0.15740777552127838\n",
      "\tLoss: 0.1480102241039276\n",
      "\tLoss: 0.12532678246498108\n",
      "\tLoss: 0.13125842809677124\n",
      "\tLoss: 0.12676413357257843\n",
      "\tLoss: 0.1536344289779663\n",
      "\tLoss: 0.13504372537136078\n",
      "\tLoss: 0.0815158486366272\n",
      "\tLoss: 0.10674294829368591\n",
      "\tLoss: 0.14590826630592346\n",
      "\tLoss: 0.14600849151611328\n",
      "\tLoss: 0.11544039845466614\n",
      "\tLoss: 0.1465199887752533\n",
      "\tLoss: 0.13748377561569214\n",
      "\tLoss: 0.10610612481832504\n",
      "\tLoss: 0.09862680733203888\n",
      "\tLoss: 0.15110479295253754\n",
      "\tLoss: 0.15322844684123993\n",
      "\tLoss: 0.1335274875164032\n",
      "\tLoss: 0.1694793701171875\n",
      "\tLoss: 0.13082356750965118\n",
      "\tLoss: 0.10636243969202042\n",
      "\tLoss: 0.12434051185846329\n",
      "\tLoss: 0.10834139585494995\n",
      "\tLoss: 0.10785353928804398\n",
      "\tLoss: 0.14782656729221344\n",
      "\tLoss: 0.13172999024391174\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.16027629375457764\n",
      "\tLoss: 0.12926286458969116\n",
      "\tLoss: 0.13948668539524078\n",
      "\tLoss: 0.11498263478279114\n",
      "\tLoss: 0.14265477657318115\n",
      "\tLoss: 0.19522571563720703\n",
      "\tLoss: 0.1094074472784996\n",
      "\tLoss: 0.15719091892242432\n",
      "\tLoss: 0.10570409148931503\n",
      "\tLoss: 0.11040306091308594\n",
      "\tLoss: 0.1286751627922058\n",
      "\tLoss: 0.15546834468841553\n",
      "\tLoss: 0.11222288757562637\n",
      "\tLoss: 0.13815820217132568\n",
      "\tLoss: 0.1397920846939087\n",
      "\tLoss: 0.16580629348754883\n",
      "\tLoss: 0.14184895157814026\n",
      "\tLoss: 0.13194972276687622\n",
      "\tLoss: 0.09654369950294495\n",
      "\tLoss: 0.15659670531749725\n",
      "\tLoss: 0.1187799796462059\n",
      "\tLoss: 0.08316271007061005\n",
      "\tLoss: 0.14387378096580505\n",
      "\tLoss: 0.15504181385040283\n",
      "\tLoss: 0.12364926934242249\n",
      "\tLoss: 0.1137804239988327\n",
      "\tLoss: 0.1312146931886673\n",
      "\tLoss: 0.07445581257343292\n",
      "\tLoss: 0.13709767162799835\n",
      "\tLoss: 0.14968077838420868\n",
      "\tLoss: 0.08219334483146667\n",
      "\tLoss: 0.1027599349617958\n",
      "\tLoss: 0.12543049454689026\n",
      "\tLoss: 0.14396844804286957\n",
      "\tLoss: 0.10329438745975494\n",
      "\tLoss: 0.1518653929233551\n",
      "\tLoss: 0.1480005979537964\n",
      "\tLoss: 0.15173937380313873\n",
      "\tLoss: 0.14125068485736847\n",
      "\tLoss: 0.14752860367298126\n",
      "\tLoss: 0.14037036895751953\n",
      "\tLoss: 0.15785641968250275\n",
      "\tLoss: 0.10539096593856812\n",
      "\tLoss: 0.1217229962348938\n",
      "\tLoss: 0.08869309723377228\n",
      "\tLoss: 0.13526856899261475\n",
      "\tLoss: 0.106638103723526\n",
      "\tLoss: 0.07912231981754303\n",
      "\tLoss: 0.13214126229286194\n",
      "\tLoss: 0.12761782109737396\n",
      "\tLoss: 0.10024604946374893\n",
      "[time] Epoch 16: 473.8392151822336s = 7.897320253037226m\n",
      "\n",
      "Epoch 17...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.08873146772384644\n",
      "\tLoss: 0.11412401497364044\n",
      "\tLoss: 0.11230937391519547\n",
      "\tLoss: 0.13833415508270264\n",
      "\tLoss: 0.13750673830509186\n",
      "\tLoss: 0.1372557282447815\n",
      "\tLoss: 0.11994215101003647\n",
      "\tLoss: 0.10993283241987228\n",
      "\tLoss: 0.09788243472576141\n",
      "\tLoss: 0.10190887749195099\n",
      "\tLoss: 0.1316525638103485\n",
      "\tLoss: 0.1582832634449005\n",
      "\tLoss: 0.12884120643138885\n",
      "\tLoss: 0.12966489791870117\n",
      "\tLoss: 0.09968264400959015\n",
      "\tLoss: 0.10682574659585953\n",
      "\tLoss: 0.14344121515750885\n",
      "\tLoss: 0.1328878104686737\n",
      "\tLoss: 0.11919693648815155\n",
      "\tLoss: 0.13390085101127625\n",
      "\tLoss: 0.12909430265426636\n",
      "\tLoss: 0.15437668561935425\n",
      "\tLoss: 0.11068050563335419\n",
      "\tLoss: 0.15817619860172272\n",
      "\tLoss: 0.08848433196544647\n",
      "\tLoss: 0.14878025650978088\n",
      "\tLoss: 0.1259312629699707\n",
      "\tLoss: 0.10339826345443726\n",
      "\tLoss: 0.14541158080101013\n",
      "\tLoss: 0.16593220829963684\n",
      "\tLoss: 0.10800738632678986\n",
      "\tLoss: 0.09374585002660751\n",
      "\tLoss: 0.12007728219032288\n",
      "\tLoss: 0.10071305930614471\n",
      "\tLoss: 0.13281576335430145\n",
      "\tLoss: 0.09840060770511627\n",
      "\tLoss: 0.1533573567867279\n",
      "\tLoss: 0.15407654643058777\n",
      "\tLoss: 0.1373765468597412\n",
      "\tLoss: 0.11324914544820786\n",
      "\tLoss: 0.11116274446249008\n",
      "\tLoss: 0.09374242275953293\n",
      "\tLoss: 0.10730621963739395\n",
      "\tLoss: 0.12104001641273499\n",
      "\tLoss: 0.12436543405056\n",
      "\tLoss: 0.12147993594408035\n",
      "\tLoss: 0.10314182937145233\n",
      "\tLoss: 0.13222038745880127\n",
      "\tLoss: 0.1253899335861206\n",
      "\tLoss: 0.13815975189208984\n",
      "\tLoss: 0.10578162968158722\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.1211402639746666\n",
      "\tLoss: 0.09625844657421112\n",
      "\tLoss: 0.10566575825214386\n",
      "\tLoss: 0.10794781148433685\n",
      "\tLoss: 0.08566433936357498\n",
      "\tLoss: 0.13708354532718658\n",
      "\tLoss: 0.14100408554077148\n",
      "\tLoss: 0.10170112550258636\n",
      "\tLoss: 0.11943672597408295\n",
      "\tLoss: 0.13002395629882812\n",
      "\tLoss: 0.1522383689880371\n",
      "\tLoss: 0.15982909500598907\n",
      "\tLoss: 0.11597427725791931\n",
      "\tLoss: 0.1228812038898468\n",
      "\tLoss: 0.1863071471452713\n",
      "\tLoss: 0.12432533502578735\n",
      "\tLoss: 0.09607961773872375\n",
      "\tLoss: 0.13020551204681396\n",
      "\tLoss: 0.15007032454013824\n",
      "\tLoss: 0.10798794031143188\n",
      "\tLoss: 0.12846428155899048\n",
      "\tLoss: 0.1697131097316742\n",
      "\tLoss: 0.13097572326660156\n",
      "\tLoss: 0.11706501245498657\n",
      "\tLoss: 0.13911356031894684\n",
      "\tLoss: 0.10944351553916931\n",
      "\tLoss: 0.09161289781332016\n",
      "\tLoss: 0.11122274398803711\n",
      "\tLoss: 0.1462336778640747\n",
      "\tLoss: 0.12734387814998627\n",
      "\tLoss: 0.16882866621017456\n",
      "\tLoss: 0.12971444427967072\n",
      "\tLoss: 0.1237185001373291\n",
      "\tLoss: 0.0901079773902893\n",
      "\tLoss: 0.09765563905239105\n",
      "\tLoss: 0.11138257384300232\n",
      "\tLoss: 0.1046314388513565\n",
      "\tLoss: 0.11675841361284256\n",
      "\tLoss: 0.1389363408088684\n",
      "\tLoss: 0.16190001368522644\n",
      "\tLoss: 0.1197953000664711\n",
      "\tLoss: 0.13774597644805908\n",
      "\tLoss: 0.12247255444526672\n",
      "\tLoss: 0.09405116736888885\n",
      "\tLoss: 0.15297666192054749\n",
      "\tLoss: 0.13417808711528778\n",
      "\tLoss: 0.18760639429092407\n",
      "\tLoss: 0.12337946891784668\n",
      "\tLoss: 0.1376107931137085\n",
      "\tLoss: 0.11434706300497055\n",
      "\tLoss: 0.14846128225326538\n",
      "[time] Epoch 17: 468.4262465122156s = 7.807104108536927m\n",
      "\n",
      "Epoch 18...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1310020089149475\n",
      "\tLoss: 0.07158759981393814\n",
      "\tLoss: 0.16000515222549438\n",
      "\tLoss: 0.10197374224662781\n",
      "\tLoss: 0.09831835329532623\n",
      "\tLoss: 0.10239797830581665\n",
      "\tLoss: 0.11064939945936203\n",
      "\tLoss: 0.09634166210889816\n",
      "\tLoss: 0.10970649123191833\n",
      "\tLoss: 0.12341632694005966\n",
      "\tLoss: 0.12209522724151611\n",
      "\tLoss: 0.09573057293891907\n",
      "\tLoss: 0.1275864988565445\n",
      "\tLoss: 0.11523377895355225\n",
      "\tLoss: 0.13648775219917297\n",
      "\tLoss: 0.10832008719444275\n",
      "\tLoss: 0.09860120713710785\n",
      "\tLoss: 0.0981081873178482\n",
      "\tLoss: 0.11043525487184525\n",
      "\tLoss: 0.17410658299922943\n",
      "\tLoss: 0.1525227129459381\n",
      "\tLoss: 0.09214632213115692\n",
      "\tLoss: 0.07938991487026215\n",
      "\tLoss: 0.12584882974624634\n",
      "\tLoss: 0.11609556525945663\n",
      "\tLoss: 0.142172709107399\n",
      "\tLoss: 0.14763876795768738\n",
      "\tLoss: 0.12766772508621216\n",
      "\tLoss: 0.07445314526557922\n",
      "\tLoss: 0.12780295312404633\n",
      "\tLoss: 0.18322479724884033\n",
      "\tLoss: 0.11666093021631241\n",
      "\tLoss: 0.10400278866291046\n",
      "\tLoss: 0.13575038313865662\n",
      "\tLoss: 0.09416013956069946\n",
      "\tLoss: 0.09345157444477081\n",
      "\tLoss: 0.09813881665468216\n",
      "\tLoss: 0.12135854363441467\n",
      "\tLoss: 0.11806201934814453\n",
      "\tLoss: 0.14201101660728455\n",
      "\tLoss: 0.1000252366065979\n",
      "\tLoss: 0.12213325500488281\n",
      "\tLoss: 0.10100866854190826\n",
      "\tLoss: 0.1546488255262375\n",
      "\tLoss: 0.07307755202054977\n",
      "\tLoss: 0.11539377272129059\n",
      "\tLoss: 0.09529244899749756\n",
      "\tLoss: 0.10296036303043365\n",
      "\tLoss: 0.11084069311618805\n",
      "\tLoss: 0.15590985119342804\n",
      "\tLoss: 0.10711216926574707\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.14123043417930603\n",
      "\tLoss: 0.11519680172204971\n",
      "\tLoss: 0.08502186834812164\n",
      "\tLoss: 0.0898064374923706\n",
      "\tLoss: 0.10322766751050949\n",
      "\tLoss: 0.10744120180606842\n",
      "\tLoss: 0.10674495995044708\n",
      "\tLoss: 0.08787975460290909\n",
      "\tLoss: 0.11812090128660202\n",
      "\tLoss: 0.12436868995428085\n",
      "\tLoss: 0.07251246273517609\n",
      "\tLoss: 0.0769403874874115\n",
      "\tLoss: 0.13376538455486298\n",
      "\tLoss: 0.09605152904987335\n",
      "\tLoss: 0.12461382150650024\n",
      "\tLoss: 0.11638089269399643\n",
      "\tLoss: 0.11224588006734848\n",
      "\tLoss: 0.12078629434108734\n",
      "\tLoss: 0.109042689204216\n",
      "\tLoss: 0.10212074220180511\n",
      "\tLoss: 0.08984516561031342\n",
      "\tLoss: 0.12617911398410797\n",
      "\tLoss: 0.10108207166194916\n",
      "\tLoss: 0.09893929213285446\n",
      "\tLoss: 0.14664703607559204\n",
      "\tLoss: 0.13899706304073334\n",
      "\tLoss: 0.1334647238254547\n",
      "\tLoss: 0.10836197435855865\n",
      "\tLoss: 0.08928915113210678\n",
      "\tLoss: 0.07929491996765137\n",
      "\tLoss: 0.14926478266716003\n",
      "\tLoss: 0.09338398277759552\n",
      "\tLoss: 0.11566359549760818\n",
      "\tLoss: 0.07594319432973862\n",
      "\tLoss: 0.08135268092155457\n",
      "\tLoss: 0.123797208070755\n",
      "\tLoss: 0.11595839262008667\n",
      "\tLoss: 0.13389112055301666\n",
      "\tLoss: 0.10931306332349777\n",
      "\tLoss: 0.10825226455926895\n",
      "\tLoss: 0.13443373143672943\n",
      "\tLoss: 0.12571056187152863\n",
      "\tLoss: 0.14686906337738037\n",
      "\tLoss: 0.11861493438482285\n",
      "\tLoss: 0.13072621822357178\n",
      "\tLoss: 0.12733083963394165\n",
      "\tLoss: 0.13588771224021912\n",
      "\tLoss: 0.09630131721496582\n",
      "\tLoss: 0.090445876121521\n",
      "\tLoss: 0.1437431126832962\n",
      "\tLoss: 0.1034458726644516\n",
      "[time] Epoch 18: 468.8005795609206s = 7.81334299268201m\n",
      "\n",
      "Epoch 19...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.12059968709945679\n",
      "\tLoss: 0.13710163533687592\n",
      "\tLoss: 0.14386527240276337\n",
      "\tLoss: 0.12746387720108032\n",
      "\tLoss: 0.13012182712554932\n",
      "\tLoss: 0.16993051767349243\n",
      "\tLoss: 0.12737387418746948\n",
      "\tLoss: 0.11736517399549484\n",
      "\tLoss: 0.13870121538639069\n",
      "\tLoss: 0.13272497057914734\n",
      "\tLoss: 0.1004243940114975\n",
      "\tLoss: 0.08749565482139587\n",
      "\tLoss: 0.13007715344429016\n",
      "\tLoss: 0.1444224715232849\n",
      "\tLoss: 0.09360051155090332\n",
      "\tLoss: 0.12657412886619568\n",
      "\tLoss: 0.08979478478431702\n",
      "\tLoss: 0.11744891107082367\n",
      "\tLoss: 0.11440680921077728\n",
      "\tLoss: 0.05621098726987839\n",
      "\tLoss: 0.1224561333656311\n",
      "\tLoss: 0.11763901263475418\n",
      "\tLoss: 0.11289606988430023\n",
      "\tLoss: 0.1264389008283615\n",
      "\tLoss: 0.151502326130867\n",
      "\tLoss: 0.1158905029296875\n",
      "\tLoss: 0.12535929679870605\n",
      "\tLoss: 0.10188497602939606\n",
      "\tLoss: 0.11213772743940353\n",
      "\tLoss: 0.10466107726097107\n",
      "\tLoss: 0.12772908806800842\n",
      "\tLoss: 0.11561041325330734\n",
      "\tLoss: 0.08056724816560745\n",
      "\tLoss: 0.09067192673683167\n",
      "\tLoss: 0.08552977442741394\n",
      "\tLoss: 0.12006328999996185\n",
      "\tLoss: 0.1282890886068344\n",
      "\tLoss: 0.12946894764900208\n",
      "\tLoss: 0.19305896759033203\n",
      "\tLoss: 0.1083432212471962\n",
      "\tLoss: 0.08522699773311615\n",
      "\tLoss: 0.16123339533805847\n",
      "\tLoss: 0.1506207287311554\n",
      "\tLoss: 0.09960762411355972\n",
      "\tLoss: 0.10889864712953568\n",
      "\tLoss: 0.13312724232673645\n",
      "\tLoss: 0.11501649022102356\n",
      "\tLoss: 0.1087690219283104\n",
      "\tLoss: 0.12246376276016235\n",
      "\tLoss: 0.09431500732898712\n",
      "\tLoss: 0.09880461543798447\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.1357787847518921\n",
      "\tLoss: 0.1155865415930748\n",
      "\tLoss: 0.13180509209632874\n",
      "\tLoss: 0.16739779710769653\n",
      "\tLoss: 0.12445619702339172\n",
      "\tLoss: 0.05648558586835861\n",
      "\tLoss: 0.11572133004665375\n",
      "\tLoss: 0.11923681199550629\n",
      "\tLoss: 0.08498276770114899\n",
      "\tLoss: 0.13294312357902527\n",
      "\tLoss: 0.10824354737997055\n",
      "\tLoss: 0.10546042025089264\n",
      "\tLoss: 0.1410541534423828\n",
      "\tLoss: 0.07008631527423859\n",
      "\tLoss: 0.10730202496051788\n",
      "\tLoss: 0.0793747752904892\n",
      "\tLoss: 0.10528015345335007\n",
      "\tLoss: 0.11808164417743683\n",
      "\tLoss: 0.10297302901744843\n",
      "\tLoss: 0.10261499136686325\n",
      "\tLoss: 0.12320055067539215\n",
      "\tLoss: 0.10731817781925201\n",
      "\tLoss: 0.1720682978630066\n",
      "\tLoss: 0.17409871518611908\n",
      "\tLoss: 0.14043501019477844\n",
      "\tLoss: 0.12308134138584137\n",
      "\tLoss: 0.13361498713493347\n",
      "\tLoss: 0.12476324290037155\n",
      "\tLoss: 0.08514448255300522\n",
      "\tLoss: 0.11031626164913177\n",
      "\tLoss: 0.12019877135753632\n",
      "\tLoss: 0.1000254675745964\n",
      "\tLoss: 0.12803354859352112\n",
      "\tLoss: 0.13063865900039673\n",
      "\tLoss: 0.11024212092161179\n",
      "\tLoss: 0.18422311544418335\n",
      "\tLoss: 0.1117001622915268\n",
      "\tLoss: 0.10458265990018845\n",
      "\tLoss: 0.1352444440126419\n",
      "\tLoss: 0.12901273369789124\n",
      "\tLoss: 0.10105162113904953\n",
      "\tLoss: 0.13174541294574738\n",
      "\tLoss: 0.09495216608047485\n",
      "\tLoss: 0.07608435302972794\n",
      "\tLoss: 0.1554342359304428\n",
      "\tLoss: 0.1440161168575287\n",
      "\tLoss: 0.11123903095722198\n",
      "\tLoss: 0.10256786644458771\n",
      "\tLoss: 0.10132364928722382\n",
      "\tLoss: 0.11391980201005936\n",
      "\tLoss: 0.1397935450077057\n",
      "[time] Epoch 19: 466.6908795130439s = 7.778181325217399m\n",
      "\n",
      "Epoch 20...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.13007892668247223\n",
      "\tLoss: 0.1205943375825882\n",
      "\tLoss: 0.14455191791057587\n",
      "\tLoss: 0.18026462197303772\n",
      "\tLoss: 0.12308594584465027\n",
      "\tLoss: 0.11834288388490677\n",
      "\tLoss: 0.17511293292045593\n",
      "\tLoss: 0.1228213757276535\n",
      "\tLoss: 0.1041104793548584\n",
      "\tLoss: 0.13471706211566925\n",
      "\tLoss: 0.1090751513838768\n",
      "\tLoss: 0.08496727049350739\n",
      "\tLoss: 0.15297481417655945\n",
      "\tLoss: 0.1220117062330246\n",
      "\tLoss: 0.09007120132446289\n",
      "\tLoss: 0.12433669716119766\n",
      "\tLoss: 0.08985668420791626\n",
      "\tLoss: 0.12143243104219437\n",
      "\tLoss: 0.09349443018436432\n",
      "\tLoss: 0.1498730480670929\n",
      "\tLoss: 0.12764409184455872\n",
      "\tLoss: 0.09854301065206528\n",
      "\tLoss: 0.14407414197921753\n",
      "\tLoss: 0.11514565348625183\n",
      "\tLoss: 0.13462096452713013\n",
      "\tLoss: 0.11301161348819733\n",
      "\tLoss: 0.09678119421005249\n",
      "\tLoss: 0.1357901692390442\n",
      "\tLoss: 0.1401110291481018\n",
      "\tLoss: 0.09064090251922607\n",
      "\tLoss: 0.1085912212729454\n",
      "\tLoss: 0.09269614517688751\n",
      "\tLoss: 0.1329212337732315\n",
      "\tLoss: 0.08418095856904984\n",
      "\tLoss: 0.09247095882892609\n",
      "\tLoss: 0.1464262753725052\n",
      "\tLoss: 0.13661010563373566\n",
      "\tLoss: 0.08696907758712769\n",
      "\tLoss: 0.08750313520431519\n",
      "\tLoss: 0.11882281303405762\n",
      "\tLoss: 0.0915687084197998\n",
      "\tLoss: 0.1207161620259285\n",
      "\tLoss: 0.10221352428197861\n",
      "\tLoss: 0.1347726732492447\n",
      "\tLoss: 0.17133799195289612\n",
      "\tLoss: 0.11023871600627899\n",
      "\tLoss: 0.12533393502235413\n",
      "\tLoss: 0.12570039927959442\n",
      "\tLoss: 0.13833120465278625\n",
      "\tLoss: 0.11801183223724365\n",
      "\tLoss: 0.11642150580883026\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.07488708943128586\n",
      "\tLoss: 0.10732819139957428\n",
      "\tLoss: 0.13689455389976501\n",
      "\tLoss: 0.11344076693058014\n",
      "\tLoss: 0.10634704679250717\n",
      "\tLoss: 0.09292386472225189\n",
      "\tLoss: 0.10914115607738495\n",
      "\tLoss: 0.10373255610466003\n",
      "\tLoss: 0.09704184532165527\n",
      "\tLoss: 0.07971210777759552\n",
      "\tLoss: 0.11195330321788788\n",
      "\tLoss: 0.14705529808998108\n",
      "\tLoss: 0.10878895223140717\n",
      "\tLoss: 0.14601340889930725\n",
      "\tLoss: 0.1065407544374466\n",
      "\tLoss: 0.1772497147321701\n",
      "\tLoss: 0.13029849529266357\n",
      "\tLoss: 0.09093433618545532\n",
      "\tLoss: 0.13829825818538666\n",
      "\tLoss: 0.09542513638734818\n",
      "\tLoss: 0.14560571312904358\n",
      "\tLoss: 0.1221088096499443\n",
      "\tLoss: 0.08929894119501114\n",
      "\tLoss: 0.13158465921878815\n",
      "\tLoss: 0.12093409150838852\n",
      "\tLoss: 0.13956919312477112\n",
      "\tLoss: 0.1605404019355774\n",
      "\tLoss: 0.0975421816110611\n",
      "\tLoss: 0.14890357851982117\n",
      "\tLoss: 0.0775909498333931\n",
      "\tLoss: 0.17116089165210724\n",
      "\tLoss: 0.12715217471122742\n",
      "\tLoss: 0.13441768288612366\n",
      "\tLoss: 0.16062447428703308\n",
      "\tLoss: 0.1288459450006485\n",
      "\tLoss: 0.12414662539958954\n",
      "\tLoss: 0.11255388706922531\n",
      "\tLoss: 0.10870767384767532\n",
      "\tLoss: 0.07586212456226349\n",
      "\tLoss: 0.11271120607852936\n",
      "\tLoss: 0.11049839854240417\n",
      "\tLoss: 0.10302924364805222\n",
      "\tLoss: 0.11602125316858292\n",
      "\tLoss: 0.10814967006444931\n",
      "\tLoss: 0.16686266660690308\n",
      "\tLoss: 0.10271292179822922\n",
      "\tLoss: 0.1590847671031952\n",
      "\tLoss: 0.08137380331754684\n",
      "\tLoss: 0.1359025239944458\n",
      "\tLoss: 0.14106956124305725\n",
      "\tLoss: 0.11344432830810547\n",
      "[time] Epoch 20: 467.9875039393082s = 7.799791732321804m\n",
      "\n",
      "Epoch 21...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.09528731554746628\n",
      "\tLoss: 0.09088480472564697\n",
      "\tLoss: 0.15757416188716888\n",
      "\tLoss: 0.10270332545042038\n",
      "\tLoss: 0.12499534338712692\n",
      "\tLoss: 0.12605401873588562\n",
      "\tLoss: 0.12718303501605988\n",
      "\tLoss: 0.0921526700258255\n",
      "\tLoss: 0.11873741447925568\n",
      "\tLoss: 0.10011213272809982\n",
      "\tLoss: 0.11595617234706879\n",
      "\tLoss: 0.0980062186717987\n",
      "\tLoss: 0.13927747309207916\n",
      "\tLoss: 0.08450184762477875\n",
      "\tLoss: 0.12181340157985687\n",
      "\tLoss: 0.1520538032054901\n",
      "\tLoss: 0.1427309215068817\n",
      "\tLoss: 0.13446763157844543\n",
      "\tLoss: 0.1282522976398468\n",
      "\tLoss: 0.13194575905799866\n",
      "\tLoss: 0.11561833322048187\n",
      "\tLoss: 0.10747303068637848\n",
      "\tLoss: 0.12616263329982758\n",
      "\tLoss: 0.13974185287952423\n",
      "\tLoss: 0.11990693211555481\n",
      "\tLoss: 0.12445689737796783\n",
      "\tLoss: 0.12082436680793762\n",
      "\tLoss: 0.10934146493673325\n",
      "\tLoss: 0.10244260728359222\n",
      "\tLoss: 0.13144426047801971\n",
      "\tLoss: 0.10299944877624512\n",
      "\tLoss: 0.1387912929058075\n",
      "\tLoss: 0.14324739575386047\n",
      "\tLoss: 0.1246618777513504\n",
      "\tLoss: 0.1387980431318283\n",
      "\tLoss: 0.10740114748477936\n",
      "\tLoss: 0.18172994256019592\n",
      "\tLoss: 0.14003147184848785\n",
      "\tLoss: 0.13343915343284607\n",
      "\tLoss: 0.15155476331710815\n",
      "\tLoss: 0.07397542893886566\n",
      "\tLoss: 0.13879600167274475\n",
      "\tLoss: 0.14344529807567596\n",
      "\tLoss: 0.14704379439353943\n",
      "\tLoss: 0.11208809912204742\n",
      "\tLoss: 0.17407836019992828\n",
      "\tLoss: 0.1354820430278778\n",
      "\tLoss: 0.10044403374195099\n",
      "\tLoss: 0.13938680291175842\n",
      "\tLoss: 0.11103019118309021\n",
      "\tLoss: 0.12855149805545807\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.1501958668231964\n",
      "\tLoss: 0.20112070441246033\n",
      "\tLoss: 0.10768669843673706\n",
      "\tLoss: 0.10845951735973358\n",
      "\tLoss: 0.14231708645820618\n",
      "\tLoss: 0.1296318769454956\n",
      "\tLoss: 0.1321617066860199\n",
      "\tLoss: 0.09919684380292892\n",
      "\tLoss: 0.1532403975725174\n",
      "\tLoss: 0.1447417140007019\n",
      "\tLoss: 0.1242271214723587\n",
      "\tLoss: 0.13515566289424896\n",
      "\tLoss: 0.06470397114753723\n",
      "\tLoss: 0.09267269819974899\n",
      "\tLoss: 0.10474522411823273\n",
      "\tLoss: 0.14156457781791687\n",
      "\tLoss: 0.10244117677211761\n",
      "\tLoss: 0.06838874518871307\n",
      "\tLoss: 0.13973435759544373\n",
      "\tLoss: 0.10674969106912613\n",
      "\tLoss: 0.10069140791893005\n",
      "\tLoss: 0.15975549817085266\n",
      "\tLoss: 0.11487745493650436\n",
      "\tLoss: 0.15160657465457916\n",
      "\tLoss: 0.10970234870910645\n",
      "\tLoss: 0.0955563634634018\n",
      "\tLoss: 0.13821296393871307\n",
      "\tLoss: 0.1036425456404686\n",
      "\tLoss: 0.10770797729492188\n",
      "\tLoss: 0.12096862494945526\n",
      "\tLoss: 0.13903792202472687\n",
      "\tLoss: 0.10202191770076752\n",
      "\tLoss: 0.10761106759309769\n",
      "\tLoss: 0.10050130635499954\n",
      "\tLoss: 0.0873878076672554\n",
      "\tLoss: 0.12296363711357117\n",
      "\tLoss: 0.13982003927230835\n",
      "\tLoss: 0.11462391912937164\n",
      "\tLoss: 0.1098557710647583\n",
      "\tLoss: 0.10104046761989594\n",
      "\tLoss: 0.07649580389261246\n",
      "\tLoss: 0.16081121563911438\n",
      "\tLoss: 0.13661527633666992\n",
      "\tLoss: 0.09992598742246628\n",
      "\tLoss: 0.1355588734149933\n",
      "\tLoss: 0.12675651907920837\n",
      "\tLoss: 0.10821397602558136\n",
      "\tLoss: 0.11932973563671112\n",
      "\tLoss: 0.08618200570344925\n",
      "\tLoss: 0.08476502448320389\n",
      "\tLoss: 0.13335371017456055\n",
      "[time] Epoch 21: 461.8054542122409s = 7.6967575702040145m\n",
      "\n",
      "Epoch 22...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.13084088265895844\n",
      "\tLoss: 0.09229616820812225\n",
      "\tLoss: 0.14176657795906067\n",
      "\tLoss: 0.1298331767320633\n",
      "\tLoss: 0.130354106426239\n",
      "\tLoss: 0.10231763124465942\n",
      "\tLoss: 0.12375719100236893\n",
      "\tLoss: 0.11295413225889206\n",
      "\tLoss: 0.10383729636669159\n",
      "\tLoss: 0.12023630738258362\n",
      "\tLoss: 0.12122096866369247\n",
      "\tLoss: 0.1402444839477539\n",
      "\tLoss: 0.11489436030387878\n",
      "\tLoss: 0.1179804876446724\n",
      "\tLoss: 0.1585898995399475\n",
      "\tLoss: 0.09564726799726486\n",
      "\tLoss: 0.08721677958965302\n",
      "\tLoss: 0.08187907934188843\n",
      "\tLoss: 0.1225944310426712\n",
      "\tLoss: 0.10909517854452133\n",
      "\tLoss: 0.09731300175189972\n",
      "\tLoss: 0.11671493202447891\n",
      "\tLoss: 0.07011108100414276\n",
      "\tLoss: 0.14504198729991913\n",
      "\tLoss: 0.08757951855659485\n",
      "\tLoss: 0.1164771318435669\n",
      "\tLoss: 0.10724668204784393\n",
      "\tLoss: 0.1359121948480606\n",
      "\tLoss: 0.10148242115974426\n",
      "\tLoss: 0.14864866435527802\n",
      "\tLoss: 0.1157623752951622\n",
      "\tLoss: 0.12988555431365967\n",
      "\tLoss: 0.1495705544948578\n",
      "\tLoss: 0.12769082188606262\n",
      "\tLoss: 0.10314567387104034\n",
      "\tLoss: 0.1539006531238556\n",
      "\tLoss: 0.16953688859939575\n",
      "\tLoss: 0.11936098337173462\n",
      "\tLoss: 0.08983641862869263\n",
      "\tLoss: 0.09074212610721588\n",
      "\tLoss: 0.12260235100984573\n",
      "\tLoss: 0.1276361048221588\n",
      "\tLoss: 0.11573139578104019\n",
      "\tLoss: 0.09065210819244385\n",
      "\tLoss: 0.10799865424633026\n",
      "\tLoss: 0.08756408095359802\n",
      "\tLoss: 0.09607616066932678\n",
      "\tLoss: 0.14179164171218872\n",
      "\tLoss: 0.13685747981071472\n",
      "\tLoss: 0.1364157497882843\n",
      "\tLoss: 0.11340750753879547\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.13896755874156952\n",
      "\tLoss: 0.10207017511129379\n",
      "\tLoss: 0.11430598795413971\n",
      "\tLoss: 0.18035194277763367\n",
      "\tLoss: 0.10497185587882996\n",
      "\tLoss: 0.11759847402572632\n",
      "\tLoss: 0.1001688688993454\n",
      "\tLoss: 0.13181141018867493\n",
      "\tLoss: 0.11582288891077042\n",
      "\tLoss: 0.15043970942497253\n",
      "\tLoss: 0.12863314151763916\n",
      "\tLoss: 0.11602054536342621\n",
      "\tLoss: 0.11624184250831604\n",
      "\tLoss: 0.0853101834654808\n",
      "\tLoss: 0.13643622398376465\n",
      "\tLoss: 0.12077268958091736\n",
      "\tLoss: 0.07438445091247559\n",
      "\tLoss: 0.09469206631183624\n",
      "\tLoss: 0.10037263482809067\n",
      "\tLoss: 0.1461852788925171\n",
      "\tLoss: 0.14004822075366974\n",
      "\tLoss: 0.11979270726442337\n",
      "\tLoss: 0.1258365362882614\n",
      "\tLoss: 0.09896703064441681\n",
      "\tLoss: 0.15181699395179749\n",
      "\tLoss: 0.08862794190645218\n",
      "\tLoss: 0.11764207482337952\n",
      "\tLoss: 0.08803942054510117\n",
      "\tLoss: 0.11100402474403381\n",
      "\tLoss: 0.12108959257602692\n",
      "\tLoss: 0.0859580934047699\n",
      "\tLoss: 0.12880432605743408\n",
      "\tLoss: 0.09502679109573364\n",
      "\tLoss: 0.1433643102645874\n",
      "\tLoss: 0.13820399343967438\n",
      "\tLoss: 0.14536483585834503\n",
      "\tLoss: 0.1166197806596756\n",
      "\tLoss: 0.07110144942998886\n",
      "\tLoss: 0.151341512799263\n",
      "\tLoss: 0.11958269774913788\n",
      "\tLoss: 0.15694580972194672\n",
      "\tLoss: 0.1174549013376236\n",
      "\tLoss: 0.08827289193868637\n",
      "\tLoss: 0.14704471826553345\n",
      "\tLoss: 0.10236559808254242\n",
      "\tLoss: 0.16711843013763428\n",
      "\tLoss: 0.13348887860774994\n",
      "\tLoss: 0.10612080991268158\n",
      "\tLoss: 0.11006476730108261\n",
      "\tLoss: 0.13405561447143555\n",
      "\tLoss: 0.1097588837146759\n",
      "[time] Epoch 22: 464.1915400689468s = 7.73652566781578m\n",
      "\n",
      "Epoch 23...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.18155774474143982\n",
      "\tLoss: 0.1477455198764801\n",
      "\tLoss: 0.1121850311756134\n",
      "\tLoss: 0.159084752202034\n",
      "\tLoss: 0.11664538085460663\n",
      "\tLoss: 0.13487622141838074\n",
      "\tLoss: 0.14997082948684692\n",
      "\tLoss: 0.10357391834259033\n",
      "\tLoss: 0.08499105274677277\n",
      "\tLoss: 0.07248029112815857\n",
      "\tLoss: 0.09635849297046661\n",
      "\tLoss: 0.1312764286994934\n",
      "\tLoss: 0.11579915881156921\n",
      "\tLoss: 0.1219443827867508\n",
      "\tLoss: 0.11825688928365707\n",
      "\tLoss: 0.11776772886514664\n",
      "\tLoss: 0.08481721580028534\n",
      "\tLoss: 0.07975372672080994\n",
      "\tLoss: 0.11569881439208984\n",
      "\tLoss: 0.14021167159080505\n",
      "\tLoss: 0.12533044815063477\n",
      "\tLoss: 0.09912225604057312\n",
      "\tLoss: 0.16425076127052307\n",
      "\tLoss: 0.11748260259628296\n",
      "\tLoss: 0.1296563595533371\n",
      "\tLoss: 0.14424265921115875\n",
      "\tLoss: 0.09053593873977661\n",
      "\tLoss: 0.1315576732158661\n",
      "\tLoss: 0.09302613139152527\n",
      "\tLoss: 0.08612649142742157\n",
      "\tLoss: 0.11136247217655182\n",
      "\tLoss: 0.15660350024700165\n",
      "\tLoss: 0.14072337746620178\n",
      "\tLoss: 0.16607587039470673\n",
      "\tLoss: 0.07979267090559006\n",
      "\tLoss: 0.11397390812635422\n",
      "\tLoss: 0.15363866090774536\n",
      "\tLoss: 0.07189466804265976\n",
      "\tLoss: 0.14610055088996887\n",
      "\tLoss: 0.12218043208122253\n",
      "\tLoss: 0.10252190381288528\n",
      "\tLoss: 0.09415711462497711\n",
      "\tLoss: 0.1380118429660797\n",
      "\tLoss: 0.14256416261196136\n",
      "\tLoss: 0.09553267806768417\n",
      "\tLoss: 0.1311284601688385\n",
      "\tLoss: 0.1116153672337532\n",
      "\tLoss: 0.12914155423641205\n",
      "\tLoss: 0.1095857322216034\n",
      "\tLoss: 0.14220616221427917\n",
      "\tLoss: 0.142566978931427\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.12552687525749207\n",
      "\tLoss: 0.13007612526416779\n",
      "\tLoss: 0.140039324760437\n",
      "\tLoss: 0.16885024309158325\n",
      "\tLoss: 0.11421789228916168\n",
      "\tLoss: 0.11958673596382141\n",
      "\tLoss: 0.1453712284564972\n",
      "\tLoss: 0.11468511819839478\n",
      "\tLoss: 0.10587836802005768\n",
      "\tLoss: 0.09306462109088898\n",
      "\tLoss: 0.12482504546642303\n",
      "\tLoss: 0.13129201531410217\n",
      "\tLoss: 0.12852035462856293\n",
      "\tLoss: 0.13930189609527588\n",
      "\tLoss: 0.14425000548362732\n",
      "\tLoss: 0.11569845676422119\n",
      "\tLoss: 0.12602603435516357\n",
      "\tLoss: 0.16628782451152802\n",
      "\tLoss: 0.11873485147953033\n",
      "\tLoss: 0.17555713653564453\n",
      "\tLoss: 0.1220264583826065\n",
      "\tLoss: 0.1558954119682312\n",
      "\tLoss: 0.12485191226005554\n",
      "\tLoss: 0.1364273726940155\n",
      "\tLoss: 0.17480167746543884\n",
      "\tLoss: 0.14058145880699158\n",
      "\tLoss: 0.1360771656036377\n",
      "\tLoss: 0.11369950324296951\n",
      "\tLoss: 0.13354240357875824\n",
      "\tLoss: 0.07046478986740112\n",
      "\tLoss: 0.12466239184141159\n",
      "\tLoss: 0.1259440779685974\n",
      "\tLoss: 0.11914423108100891\n",
      "\tLoss: 0.1081000417470932\n",
      "\tLoss: 0.1353665292263031\n",
      "\tLoss: 0.1124165877699852\n",
      "\tLoss: 0.13859373331069946\n",
      "\tLoss: 0.123526431620121\n",
      "\tLoss: 0.12023600190877914\n",
      "\tLoss: 0.1552453339099884\n",
      "\tLoss: 0.14034795761108398\n",
      "\tLoss: 0.12031969428062439\n",
      "\tLoss: 0.1065250039100647\n",
      "\tLoss: 0.10507801920175552\n",
      "\tLoss: 0.11943429708480835\n",
      "\tLoss: 0.1077868789434433\n",
      "\tLoss: 0.11616671830415726\n",
      "\tLoss: 0.0871444121003151\n",
      "\tLoss: 0.1168476790189743\n",
      "\tLoss: 0.09252266585826874\n",
      "\tLoss: 0.13152779638767242\n",
      "[time] Epoch 23: 460.49268727377057s = 7.67487812122951m\n",
      "\n",
      "Epoch 24...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.11559705436229706\n",
      "\tLoss: 0.0995422825217247\n",
      "\tLoss: 0.14313584566116333\n",
      "\tLoss: 0.1404985934495926\n",
      "\tLoss: 0.15868251025676727\n",
      "\tLoss: 0.09255556762218475\n",
      "\tLoss: 0.1324632316827774\n",
      "\tLoss: 0.1509382724761963\n",
      "\tLoss: 0.13020476698875427\n",
      "\tLoss: 0.09636743366718292\n",
      "\tLoss: 0.14524035155773163\n",
      "\tLoss: 0.11092273890972137\n",
      "\tLoss: 0.061285629868507385\n",
      "\tLoss: 0.15663443505764008\n",
      "\tLoss: 0.12758079171180725\n",
      "\tLoss: 0.14926372468471527\n",
      "\tLoss: 0.1574365496635437\n",
      "\tLoss: 0.16387532651424408\n",
      "\tLoss: 0.09493836760520935\n",
      "\tLoss: 0.07488484680652618\n",
      "\tLoss: 0.08199983090162277\n",
      "\tLoss: 0.11866581439971924\n",
      "\tLoss: 0.10460185259580612\n",
      "\tLoss: 0.10902722179889679\n",
      "\tLoss: 0.1198907345533371\n",
      "\tLoss: 0.13552460074424744\n",
      "\tLoss: 0.06811359524726868\n",
      "\tLoss: 0.10012909024953842\n",
      "\tLoss: 0.14590516686439514\n",
      "\tLoss: 0.14371098577976227\n",
      "\tLoss: 0.11438276618719101\n",
      "\tLoss: 0.11026574671268463\n",
      "\tLoss: 0.17447338998317719\n",
      "\tLoss: 0.12656888365745544\n",
      "\tLoss: 0.12982545793056488\n",
      "\tLoss: 0.13151396811008453\n",
      "\tLoss: 0.12555034458637238\n",
      "\tLoss: 0.07110916823148727\n",
      "\tLoss: 0.13537240028381348\n",
      "\tLoss: 0.1386421024799347\n",
      "\tLoss: 0.1354963779449463\n",
      "\tLoss: 0.07764270156621933\n",
      "\tLoss: 0.13417375087738037\n",
      "\tLoss: 0.11622604727745056\n",
      "\tLoss: 0.10962886363267899\n",
      "\tLoss: 0.06557720899581909\n",
      "\tLoss: 0.13176070153713226\n",
      "\tLoss: 0.14312843978405\n",
      "\tLoss: 0.08061598986387253\n",
      "\tLoss: 0.13309313356876373\n",
      "\tLoss: 0.07842376083135605\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.07619696855545044\n",
      "\tLoss: 0.08093683421611786\n",
      "\tLoss: 0.1377430558204651\n",
      "\tLoss: 0.0802469253540039\n",
      "\tLoss: 0.07868914306163788\n",
      "\tLoss: 0.09812511503696442\n",
      "\tLoss: 0.0884288027882576\n",
      "\tLoss: 0.09425126016139984\n",
      "\tLoss: 0.09421462565660477\n",
      "\tLoss: 0.12037943303585052\n",
      "\tLoss: 0.1061243936419487\n",
      "\tLoss: 0.09179966151714325\n",
      "\tLoss: 0.09344837069511414\n",
      "\tLoss: 0.1451588273048401\n",
      "\tLoss: 0.12846148014068604\n",
      "\tLoss: 0.12295398116111755\n",
      "\tLoss: 0.11711104214191437\n",
      "\tLoss: 0.09685498476028442\n",
      "\tLoss: 0.09881233423948288\n",
      "\tLoss: 0.11375047266483307\n",
      "\tLoss: 0.14000263810157776\n",
      "\tLoss: 0.1305643767118454\n",
      "\tLoss: 0.10886046290397644\n",
      "\tLoss: 0.09993178397417068\n",
      "\tLoss: 0.09874726831912994\n",
      "\tLoss: 0.13005752861499786\n",
      "\tLoss: 0.11818255484104156\n",
      "\tLoss: 0.11513178050518036\n",
      "\tLoss: 0.12096816301345825\n",
      "\tLoss: 0.1214013546705246\n",
      "\tLoss: 0.14073461294174194\n",
      "\tLoss: 0.0960702896118164\n",
      "\tLoss: 0.08449088037014008\n",
      "\tLoss: 0.1571633368730545\n",
      "\tLoss: 0.06555718183517456\n",
      "\tLoss: 0.16248229146003723\n",
      "\tLoss: 0.12635748088359833\n",
      "\tLoss: 0.12459971755743027\n",
      "\tLoss: 0.09369020909070969\n",
      "\tLoss: 0.12159620225429535\n",
      "\tLoss: 0.0928548201918602\n",
      "\tLoss: 0.10888746380805969\n",
      "\tLoss: 0.11401799321174622\n",
      "\tLoss: 0.08908028155565262\n",
      "\tLoss: 0.14152102172374725\n",
      "\tLoss: 0.1262391209602356\n",
      "\tLoss: 0.12043897062540054\n",
      "\tLoss: 0.09145810455083847\n",
      "\tLoss: 0.11165948212146759\n",
      "\tLoss: 0.09240686893463135\n",
      "\tLoss: 0.13697263598442078\n",
      "[time] Epoch 24: 457.1333204759285s = 7.618888674598808m\n",
      "\n",
      "Epoch 25...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1372579038143158\n",
      "\tLoss: 0.09456625580787659\n",
      "\tLoss: 0.08604899793863297\n",
      "\tLoss: 0.07745923101902008\n",
      "\tLoss: 0.09256438910961151\n",
      "\tLoss: 0.0888446569442749\n",
      "\tLoss: 0.08016984909772873\n",
      "\tLoss: 0.13020582497119904\n",
      "\tLoss: 0.13114839792251587\n",
      "\tLoss: 0.14756125211715698\n",
      "\tLoss: 0.12018639594316483\n",
      "\tLoss: 0.13002684712409973\n",
      "\tLoss: 0.10874561965465546\n",
      "\tLoss: 0.08235497772693634\n",
      "\tLoss: 0.09028982371091843\n",
      "\tLoss: 0.10554809868335724\n",
      "\tLoss: 0.1297704428434372\n",
      "\tLoss: 0.07885324954986572\n",
      "\tLoss: 0.12248556315898895\n",
      "\tLoss: 0.11568479239940643\n",
      "\tLoss: 0.08745071291923523\n",
      "\tLoss: 0.13373982906341553\n",
      "\tLoss: 0.12345777451992035\n",
      "\tLoss: 0.0776815414428711\n",
      "\tLoss: 0.09984428435564041\n",
      "\tLoss: 0.09615364670753479\n",
      "\tLoss: 0.08181896805763245\n",
      "\tLoss: 0.11474186182022095\n",
      "\tLoss: 0.07693812251091003\n",
      "\tLoss: 0.14749407768249512\n",
      "\tLoss: 0.10322855412960052\n",
      "\tLoss: 0.0991629809141159\n",
      "\tLoss: 0.13064903020858765\n",
      "\tLoss: 0.09865707159042358\n",
      "\tLoss: 0.11047586798667908\n",
      "\tLoss: 0.15210825204849243\n",
      "\tLoss: 0.10707832872867584\n",
      "\tLoss: 0.1151251494884491\n",
      "\tLoss: 0.13468822836875916\n",
      "\tLoss: 0.163588747382164\n",
      "\tLoss: 0.15985578298568726\n",
      "\tLoss: 0.13304848968982697\n",
      "\tLoss: 0.16189968585968018\n",
      "\tLoss: 0.06909273564815521\n",
      "\tLoss: 0.15172716975212097\n",
      "\tLoss: 0.11259691417217255\n",
      "\tLoss: 0.1271894872188568\n",
      "\tLoss: 0.128127321600914\n",
      "\tLoss: 0.16130678355693817\n",
      "\tLoss: 0.07701371610164642\n",
      "\tLoss: 0.12335383892059326\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.1161169707775116\n",
      "\tLoss: 0.09247361868619919\n",
      "\tLoss: 0.1302718222141266\n",
      "\tLoss: 0.12022297084331512\n",
      "\tLoss: 0.1150834858417511\n",
      "\tLoss: 0.1205323114991188\n",
      "\tLoss: 0.10232947766780853\n",
      "\tLoss: 0.11009639501571655\n",
      "\tLoss: 0.09242569655179977\n",
      "\tLoss: 0.14419449865818024\n",
      "\tLoss: 0.11390356719493866\n",
      "\tLoss: 0.11670418083667755\n",
      "\tLoss: 0.12117764353752136\n",
      "\tLoss: 0.10426412522792816\n",
      "\tLoss: 0.1177448257803917\n",
      "\tLoss: 0.12081403285264969\n",
      "\tLoss: 0.09711885452270508\n",
      "\tLoss: 0.11768637597560883\n",
      "\tLoss: 0.11726488173007965\n",
      "\tLoss: 0.11022496223449707\n",
      "\tLoss: 0.09629455953836441\n",
      "\tLoss: 0.08469004184007645\n",
      "\tLoss: 0.10367877036333084\n",
      "\tLoss: 0.12275069952011108\n",
      "\tLoss: 0.10458540916442871\n",
      "\tLoss: 0.08657369762659073\n",
      "\tLoss: 0.14579987525939941\n",
      "\tLoss: 0.10649365931749344\n",
      "\tLoss: 0.128420889377594\n",
      "\tLoss: 0.0904204472899437\n",
      "\tLoss: 0.08370396494865417\n",
      "\tLoss: 0.11725988239049911\n",
      "\tLoss: 0.10017932951450348\n",
      "\tLoss: 0.0977126732468605\n",
      "\tLoss: 0.12050032615661621\n",
      "\tLoss: 0.139748677611351\n",
      "\tLoss: 0.10532020032405853\n",
      "\tLoss: 0.09973318874835968\n",
      "\tLoss: 0.18240611255168915\n",
      "\tLoss: 0.119329072535038\n",
      "\tLoss: 0.12151368707418442\n",
      "\tLoss: 0.11032940447330475\n",
      "\tLoss: 0.09235505014657974\n",
      "\tLoss: 0.07299523055553436\n",
      "\tLoss: 0.13570675253868103\n",
      "\tLoss: 0.0917118489742279\n",
      "\tLoss: 0.14270946383476257\n",
      "\tLoss: 0.16069944202899933\n",
      "\tLoss: 0.16740715503692627\n",
      "\tLoss: 0.170196071267128\n",
      "\tLoss: 0.13764385879039764\n",
      "[time] Epoch 25: 455.8760360199958s = 7.597933933666597m\n",
      "\n",
      "Epoch 26...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.11323373019695282\n",
      "\tLoss: 0.09372299909591675\n",
      "\tLoss: 0.08054695278406143\n",
      "\tLoss: 0.11593440175056458\n",
      "\tLoss: 0.10643208026885986\n",
      "\tLoss: 0.10622658580541611\n",
      "\tLoss: 0.11429218202829361\n",
      "\tLoss: 0.13000275194644928\n",
      "\tLoss: 0.0908161923289299\n",
      "\tLoss: 0.14871683716773987\n",
      "\tLoss: 0.12387494742870331\n",
      "\tLoss: 0.11606477200984955\n",
      "\tLoss: 0.17217525839805603\n",
      "\tLoss: 0.13445161283016205\n",
      "\tLoss: 0.1257927417755127\n",
      "\tLoss: 0.13543564081192017\n",
      "\tLoss: 0.08492772281169891\n",
      "\tLoss: 0.1378745436668396\n",
      "\tLoss: 0.11945942789316177\n",
      "\tLoss: 0.10663467645645142\n",
      "\tLoss: 0.1309422105550766\n",
      "\tLoss: 0.11530010402202606\n",
      "\tLoss: 0.11414536833763123\n",
      "\tLoss: 0.09394249320030212\n",
      "\tLoss: 0.11021065711975098\n",
      "\tLoss: 0.07020388543605804\n",
      "\tLoss: 0.09187942743301392\n",
      "\tLoss: 0.13448219001293182\n",
      "\tLoss: 0.1427392214536667\n",
      "\tLoss: 0.176007479429245\n",
      "\tLoss: 0.11668729037046432\n",
      "\tLoss: 0.06387057900428772\n",
      "\tLoss: 0.12284545600414276\n",
      "\tLoss: 0.09485422074794769\n",
      "\tLoss: 0.07882039248943329\n",
      "\tLoss: 0.12234816700220108\n",
      "\tLoss: 0.07280508428812027\n",
      "\tLoss: 0.10145387053489685\n",
      "\tLoss: 0.0917237401008606\n",
      "\tLoss: 0.09011629968881607\n",
      "\tLoss: 0.11888878792524338\n",
      "\tLoss: 0.1724225878715515\n",
      "\tLoss: 0.12539303302764893\n",
      "\tLoss: 0.09985766559839249\n",
      "\tLoss: 0.09978514909744263\n",
      "\tLoss: 0.08192747831344604\n",
      "\tLoss: 0.10364338010549545\n",
      "\tLoss: 0.07052382826805115\n",
      "\tLoss: 0.0982205793261528\n",
      "\tLoss: 0.12458884716033936\n",
      "\tLoss: 0.11629827320575714\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.07697966694831848\n",
      "\tLoss: 0.09812799096107483\n",
      "\tLoss: 0.12296436727046967\n",
      "\tLoss: 0.11450902372598648\n",
      "\tLoss: 0.0988134890794754\n",
      "\tLoss: 0.09763310849666595\n",
      "\tLoss: 0.0873945951461792\n",
      "\tLoss: 0.11330607533454895\n",
      "\tLoss: 0.1364181935787201\n",
      "\tLoss: 0.12908107042312622\n",
      "\tLoss: 0.1129908561706543\n",
      "\tLoss: 0.11039841920137405\n",
      "\tLoss: 0.10114049166440964\n",
      "\tLoss: 0.10023351013660431\n",
      "\tLoss: 0.15366730093955994\n",
      "\tLoss: 0.1211681216955185\n",
      "\tLoss: 0.13530385494232178\n",
      "\tLoss: 0.140695720911026\n",
      "\tLoss: 0.08432382345199585\n",
      "\tLoss: 0.10953640937805176\n",
      "\tLoss: 0.11134364455938339\n",
      "\tLoss: 0.08576993644237518\n",
      "\tLoss: 0.10680605471134186\n",
      "\tLoss: 0.08478271961212158\n",
      "\tLoss: 0.08263058960437775\n",
      "\tLoss: 0.10846307873725891\n",
      "\tLoss: 0.11385393142700195\n",
      "\tLoss: 0.1315070241689682\n",
      "\tLoss: 0.10133957862854004\n",
      "\tLoss: 0.09673909097909927\n",
      "\tLoss: 0.10771595686674118\n",
      "\tLoss: 0.1490766853094101\n",
      "\tLoss: 0.08662553131580353\n",
      "\tLoss: 0.08746515959501266\n",
      "\tLoss: 0.08172324299812317\n",
      "\tLoss: 0.12609532475471497\n",
      "\tLoss: 0.133575439453125\n",
      "\tLoss: 0.06802099943161011\n",
      "\tLoss: 0.1031925305724144\n",
      "\tLoss: 0.09152650833129883\n",
      "\tLoss: 0.0744614452123642\n",
      "\tLoss: 0.13559451699256897\n",
      "\tLoss: 0.1398220658302307\n",
      "\tLoss: 0.12365669012069702\n",
      "\tLoss: 0.15221288800239563\n",
      "\tLoss: 0.09846236556768417\n",
      "\tLoss: 0.11020583659410477\n",
      "\tLoss: 0.13851550221443176\n",
      "\tLoss: 0.12911388278007507\n",
      "\tLoss: 0.14684122800827026\n",
      "\tLoss: 0.12523016333580017\n",
      "[time] Epoch 26: 456.47512023104355s = 7.6079186705173925m\n",
      "\n",
      "Epoch 27...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.08056063205003738\n",
      "\tLoss: 0.10505540668964386\n",
      "\tLoss: 0.08035910874605179\n",
      "\tLoss: 0.1512409746646881\n",
      "\tLoss: 0.10923533886671066\n",
      "\tLoss: 0.1101672574877739\n",
      "\tLoss: 0.09472586214542389\n",
      "\tLoss: 0.14340715110301971\n",
      "\tLoss: 0.09799153357744217\n",
      "\tLoss: 0.100399449467659\n",
      "\tLoss: 0.1464916467666626\n",
      "\tLoss: 0.10010495036840439\n",
      "\tLoss: 0.1396327018737793\n",
      "\tLoss: 0.12390923500061035\n",
      "\tLoss: 0.11489477753639221\n",
      "\tLoss: 0.11109872162342072\n",
      "\tLoss: 0.07365541160106659\n",
      "\tLoss: 0.1277332305908203\n",
      "\tLoss: 0.15681283175945282\n",
      "\tLoss: 0.09792090952396393\n",
      "\tLoss: 0.12071321904659271\n",
      "\tLoss: 0.13337424397468567\n",
      "\tLoss: 0.0905018076300621\n",
      "\tLoss: 0.08509843796491623\n",
      "\tLoss: 0.06267216801643372\n",
      "\tLoss: 0.11528338491916656\n",
      "\tLoss: 0.11581850051879883\n",
      "\tLoss: 0.13938415050506592\n",
      "\tLoss: 0.05735579505562782\n",
      "\tLoss: 0.1299821436405182\n",
      "\tLoss: 0.12696127593517303\n",
      "\tLoss: 0.13655096292495728\n",
      "\tLoss: 0.13218021392822266\n",
      "\tLoss: 0.12901851534843445\n",
      "\tLoss: 0.1799294650554657\n",
      "\tLoss: 0.07345302402973175\n",
      "\tLoss: 0.11855799704790115\n",
      "\tLoss: 0.08803398907184601\n",
      "\tLoss: 0.1344299614429474\n",
      "\tLoss: 0.09885820746421814\n",
      "\tLoss: 0.1179259791970253\n",
      "\tLoss: 0.09959234297275543\n",
      "\tLoss: 0.1483515501022339\n",
      "\tLoss: 0.10930334031581879\n",
      "\tLoss: 0.1148739829659462\n",
      "\tLoss: 0.11430861055850983\n",
      "\tLoss: 0.11600793898105621\n",
      "\tLoss: 0.11643718183040619\n",
      "\tLoss: 0.10000365227460861\n",
      "\tLoss: 0.06757165491580963\n",
      "\tLoss: 0.10406588017940521\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.11296489834785461\n",
      "\tLoss: 0.09912371635437012\n",
      "\tLoss: 0.13252860307693481\n",
      "\tLoss: 0.08468817919492722\n",
      "\tLoss: 0.10027742385864258\n",
      "\tLoss: 0.09816031903028488\n",
      "\tLoss: 0.07708767801523209\n",
      "\tLoss: 0.15370246767997742\n",
      "\tLoss: 0.11425168812274933\n",
      "\tLoss: 0.16518744826316833\n",
      "\tLoss: 0.12337519228458405\n",
      "\tLoss: 0.1755923628807068\n",
      "\tLoss: 0.1518583595752716\n",
      "\tLoss: 0.1132621094584465\n",
      "\tLoss: 0.13227733969688416\n",
      "\tLoss: 0.09828044474124908\n",
      "\tLoss: 0.06761816143989563\n",
      "\tLoss: 0.1674421727657318\n",
      "\tLoss: 0.11299056559801102\n",
      "\tLoss: 0.12460380792617798\n",
      "\tLoss: 0.09074755758047104\n",
      "\tLoss: 0.10380487889051437\n",
      "\tLoss: 0.11672957241535187\n",
      "\tLoss: 0.12802572548389435\n",
      "\tLoss: 0.13374358415603638\n",
      "\tLoss: 0.137895405292511\n",
      "\tLoss: 0.10166594386100769\n",
      "\tLoss: 0.08831696957349777\n",
      "\tLoss: 0.10491052269935608\n",
      "\tLoss: 0.10332117974758148\n",
      "\tLoss: 0.12442749738693237\n",
      "\tLoss: 0.12369491159915924\n",
      "\tLoss: 0.11334982514381409\n",
      "\tLoss: 0.06975919008255005\n",
      "\tLoss: 0.09308309853076935\n",
      "\tLoss: 0.09802557528018951\n",
      "\tLoss: 0.07244634628295898\n",
      "\tLoss: 0.08895514905452728\n",
      "\tLoss: 0.16001564264297485\n",
      "\tLoss: 0.09453654289245605\n",
      "\tLoss: 0.09494921565055847\n",
      "\tLoss: 0.09079599380493164\n",
      "\tLoss: 0.10637149214744568\n",
      "\tLoss: 0.07845201343297958\n",
      "\tLoss: 0.10260031372308731\n",
      "\tLoss: 0.08159156888723373\n",
      "\tLoss: 0.11087336391210556\n",
      "\tLoss: 0.11846461892127991\n",
      "\tLoss: 0.08530062437057495\n",
      "\tLoss: 0.09486794471740723\n",
      "\tLoss: 0.11727078258991241\n",
      "[time] Epoch 27: 452.05082525499165s = 7.5341804209165275m\n",
      "\n",
      "Epoch 28...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.14137515425682068\n",
      "\tLoss: 0.11789847165346146\n",
      "\tLoss: 0.10858897864818573\n",
      "\tLoss: 0.10159865021705627\n",
      "\tLoss: 0.08651749044656754\n",
      "\tLoss: 0.059859294444322586\n",
      "\tLoss: 0.11112599074840546\n",
      "\tLoss: 0.07507312297821045\n",
      "\tLoss: 0.11620866507291794\n",
      "\tLoss: 0.11036879569292068\n",
      "\tLoss: 0.08729913830757141\n",
      "\tLoss: 0.13630753755569458\n",
      "\tLoss: 0.10181666910648346\n",
      "\tLoss: 0.17166167497634888\n",
      "\tLoss: 0.12135981023311615\n",
      "\tLoss: 0.10636076331138611\n",
      "\tLoss: 0.14208775758743286\n",
      "\tLoss: 0.10492002964019775\n",
      "\tLoss: 0.11414948850870132\n",
      "\tLoss: 0.12251248210668564\n",
      "\tLoss: 0.08876043558120728\n",
      "\tLoss: 0.11882656812667847\n",
      "\tLoss: 0.09623371064662933\n",
      "\tLoss: 0.10295233130455017\n",
      "\tLoss: 0.10043299943208694\n",
      "\tLoss: 0.12837092578411102\n",
      "\tLoss: 0.13402961194515228\n",
      "\tLoss: 0.1252896636724472\n",
      "\tLoss: 0.09059621393680573\n",
      "\tLoss: 0.13057929277420044\n",
      "\tLoss: 0.10627807676792145\n",
      "\tLoss: 0.12037281692028046\n",
      "\tLoss: 0.11579334735870361\n",
      "\tLoss: 0.13287769258022308\n",
      "\tLoss: 0.13664184510707855\n",
      "\tLoss: 0.10402541607618332\n",
      "\tLoss: 0.1358567327260971\n",
      "\tLoss: 0.12444913387298584\n",
      "\tLoss: 0.10298999398946762\n",
      "\tLoss: 0.12915536761283875\n",
      "\tLoss: 0.10946100950241089\n",
      "\tLoss: 0.12468418478965759\n",
      "\tLoss: 0.13096877932548523\n",
      "\tLoss: 0.12066066265106201\n",
      "\tLoss: 0.12128174304962158\n",
      "\tLoss: 0.1104305237531662\n",
      "\tLoss: 0.10304054617881775\n",
      "\tLoss: 0.13342921435832977\n",
      "\tLoss: 0.12661750614643097\n",
      "\tLoss: 0.15240079164505005\n",
      "\tLoss: 0.11959200352430344\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.08606968820095062\n",
      "\tLoss: 0.14248350262641907\n",
      "\tLoss: 0.07485941052436829\n",
      "\tLoss: 0.14072278141975403\n",
      "\tLoss: 0.1145211011171341\n",
      "\tLoss: 0.15327879786491394\n",
      "\tLoss: 0.09475426375865936\n",
      "\tLoss: 0.07352904975414276\n",
      "\tLoss: 0.10021640360355377\n",
      "\tLoss: 0.13576053082942963\n",
      "\tLoss: 0.1087748110294342\n",
      "\tLoss: 0.11569351702928543\n",
      "\tLoss: 0.15932130813598633\n",
      "\tLoss: 0.056387558579444885\n",
      "\tLoss: 0.08492197096347809\n",
      "\tLoss: 0.10986223816871643\n",
      "\tLoss: 0.09024839103221893\n",
      "\tLoss: 0.08627808094024658\n",
      "\tLoss: 0.15772147476673126\n",
      "\tLoss: 0.07733414322137833\n",
      "\tLoss: 0.13932982087135315\n",
      "\tLoss: 0.11860372126102448\n",
      "\tLoss: 0.10044023394584656\n",
      "\tLoss: 0.1333940178155899\n",
      "\tLoss: 0.08823440968990326\n",
      "\tLoss: 0.07161006331443787\n",
      "\tLoss: 0.16123415529727936\n",
      "\tLoss: 0.11230073869228363\n",
      "\tLoss: 0.10160842537879944\n",
      "\tLoss: 0.12751537561416626\n",
      "\tLoss: 0.12844397127628326\n",
      "\tLoss: 0.1473970264196396\n",
      "\tLoss: 0.10213342308998108\n",
      "\tLoss: 0.08496326208114624\n",
      "\tLoss: 0.105710968375206\n",
      "\tLoss: 0.09106683731079102\n",
      "\tLoss: 0.14399681985378265\n",
      "\tLoss: 0.13914495706558228\n",
      "\tLoss: 0.08988982439041138\n",
      "\tLoss: 0.11605577170848846\n",
      "\tLoss: 0.16380664706230164\n",
      "\tLoss: 0.12376408278942108\n",
      "\tLoss: 0.11564204841852188\n",
      "\tLoss: 0.10895596444606781\n",
      "\tLoss: 0.10300702601671219\n",
      "\tLoss: 0.1355818808078766\n",
      "\tLoss: 0.08528013527393341\n",
      "\tLoss: 0.11497839540243149\n",
      "\tLoss: 0.11282511800527573\n",
      "\tLoss: 0.13056185841560364\n",
      "\tLoss: 0.11664135754108429\n",
      "[time] Epoch 28: 449.81574445590377s = 7.496929074265063m\n",
      "\n",
      "Epoch 29...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.12233458459377289\n",
      "\tLoss: 0.10026806592941284\n",
      "\tLoss: 0.11412698030471802\n",
      "\tLoss: 0.13848274946212769\n",
      "\tLoss: 0.14024701714515686\n",
      "\tLoss: 0.10807265341281891\n",
      "\tLoss: 0.08029709756374359\n",
      "\tLoss: 0.11004358530044556\n",
      "\tLoss: 0.19929367303848267\n",
      "\tLoss: 0.12012697756290436\n",
      "\tLoss: 0.09484539926052094\n",
      "\tLoss: 0.11529666185379028\n",
      "\tLoss: 0.09886359423398972\n",
      "\tLoss: 0.11288083344697952\n",
      "\tLoss: 0.09178043901920319\n",
      "\tLoss: 0.1133836954832077\n",
      "\tLoss: 0.0593218095600605\n",
      "\tLoss: 0.12367144227027893\n",
      "\tLoss: 0.0962279811501503\n",
      "\tLoss: 0.08590508997440338\n",
      "\tLoss: 0.09342412650585175\n",
      "\tLoss: 0.10291305184364319\n",
      "\tLoss: 0.11769626289606094\n",
      "\tLoss: 0.13780173659324646\n",
      "\tLoss: 0.09880024194717407\n",
      "\tLoss: 0.1029992327094078\n",
      "\tLoss: 0.11339374631643295\n",
      "\tLoss: 0.11032441258430481\n",
      "\tLoss: 0.09853124618530273\n",
      "\tLoss: 0.10150347650051117\n",
      "\tLoss: 0.12164722383022308\n",
      "\tLoss: 0.14756780862808228\n",
      "\tLoss: 0.10353265702724457\n",
      "\tLoss: 0.11057901382446289\n",
      "\tLoss: 0.10856371372938156\n",
      "\tLoss: 0.09908854961395264\n",
      "\tLoss: 0.10693368315696716\n",
      "\tLoss: 0.11638525873422623\n",
      "\tLoss: 0.11175672709941864\n",
      "\tLoss: 0.10980886220932007\n",
      "\tLoss: 0.12636686861515045\n",
      "\tLoss: 0.09285500645637512\n",
      "\tLoss: 0.14132225513458252\n",
      "\tLoss: 0.14735785126686096\n",
      "\tLoss: 0.12208312749862671\n",
      "\tLoss: 0.11481930315494537\n",
      "\tLoss: 0.10353190451860428\n",
      "\tLoss: 0.10499966144561768\n",
      "\tLoss: 0.09173081815242767\n",
      "\tLoss: 0.10775350779294968\n",
      "\tLoss: 0.14787355065345764\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.07982730865478516\n",
      "\tLoss: 0.127580925822258\n",
      "\tLoss: 0.1058645248413086\n",
      "\tLoss: 0.13722744584083557\n",
      "\tLoss: 0.14304614067077637\n",
      "\tLoss: 0.12266416847705841\n",
      "\tLoss: 0.08656908571720123\n",
      "\tLoss: 0.13102635741233826\n",
      "\tLoss: 0.10985169559717178\n",
      "\tLoss: 0.08083417266607285\n",
      "\tLoss: 0.0918748676776886\n",
      "\tLoss: 0.15771600604057312\n",
      "\tLoss: 0.1210157722234726\n",
      "\tLoss: 0.08044983446598053\n",
      "\tLoss: 0.14757868647575378\n",
      "\tLoss: 0.1526586413383484\n",
      "\tLoss: 0.10815472155809402\n",
      "\tLoss: 0.10350373387336731\n",
      "\tLoss: 0.07428330183029175\n",
      "\tLoss: 0.08928883075714111\n",
      "\tLoss: 0.16710731387138367\n",
      "\tLoss: 0.10122011601924896\n",
      "\tLoss: 0.12711937725543976\n",
      "\tLoss: 0.11740541458129883\n",
      "\tLoss: 0.07832412421703339\n",
      "\tLoss: 0.14132295548915863\n",
      "\tLoss: 0.11003632843494415\n",
      "\tLoss: 0.12426194548606873\n",
      "\tLoss: 0.10496640205383301\n",
      "\tLoss: 0.12352854013442993\n",
      "\tLoss: 0.10410118848085403\n",
      "\tLoss: 0.09250490367412567\n",
      "\tLoss: 0.13449332118034363\n",
      "\tLoss: 0.12064198404550552\n",
      "\tLoss: 0.11234986782073975\n",
      "\tLoss: 0.07787471264600754\n",
      "\tLoss: 0.12182784080505371\n",
      "\tLoss: 0.09979718923568726\n",
      "\tLoss: 0.1259317696094513\n",
      "\tLoss: 0.14756259322166443\n",
      "\tLoss: 0.0723176971077919\n",
      "\tLoss: 0.10164010524749756\n",
      "\tLoss: 0.10479159653186798\n",
      "\tLoss: 0.12714236974716187\n",
      "\tLoss: 0.16137781739234924\n",
      "\tLoss: 0.08447454124689102\n",
      "\tLoss: 0.12733900547027588\n",
      "\tLoss: 0.12125864624977112\n",
      "\tLoss: 0.12156378477811813\n",
      "\tLoss: 0.11203844845294952\n",
      "\tLoss: 0.16276279091835022\n",
      "[time] Epoch 29: 452.637031220831s = 7.543950520347183m\n",
      "\n",
      "Epoch 30...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.13429179787635803\n",
      "\tLoss: 0.11562535166740417\n",
      "\tLoss: 0.1080024242401123\n",
      "\tLoss: 0.11265809834003448\n",
      "\tLoss: 0.11077192425727844\n",
      "\tLoss: 0.12797170877456665\n",
      "\tLoss: 0.11173789203166962\n",
      "\tLoss: 0.12668627500534058\n",
      "\tLoss: 0.13662317395210266\n",
      "\tLoss: 0.11505727469921112\n",
      "\tLoss: 0.14582793414592743\n",
      "\tLoss: 0.1301545351743698\n",
      "\tLoss: 0.11727005988359451\n",
      "\tLoss: 0.1330600082874298\n",
      "\tLoss: 0.14669382572174072\n",
      "\tLoss: 0.11563782393932343\n",
      "\tLoss: 0.1372106373310089\n",
      "\tLoss: 0.1291867345571518\n",
      "\tLoss: 0.12072727084159851\n",
      "\tLoss: 0.09744080156087875\n",
      "\tLoss: 0.14394792914390564\n",
      "\tLoss: 0.09370473027229309\n",
      "\tLoss: 0.0975760668516159\n",
      "\tLoss: 0.10066699236631393\n",
      "\tLoss: 0.11937753856182098\n",
      "\tLoss: 0.09279195219278336\n",
      "\tLoss: 0.11946737766265869\n",
      "\tLoss: 0.07845258712768555\n",
      "\tLoss: 0.13369813561439514\n",
      "\tLoss: 0.12904131412506104\n",
      "\tLoss: 0.14797629415988922\n",
      "\tLoss: 0.08579714596271515\n",
      "\tLoss: 0.11738615483045578\n",
      "\tLoss: 0.09438486397266388\n",
      "\tLoss: 0.13263759016990662\n",
      "\tLoss: 0.18015725910663605\n",
      "\tLoss: 0.14251559972763062\n",
      "\tLoss: 0.13454966247081757\n",
      "\tLoss: 0.11207745969295502\n",
      "\tLoss: 0.1524708867073059\n",
      "\tLoss: 0.11728522181510925\n",
      "\tLoss: 0.11182743310928345\n",
      "\tLoss: 0.10680276155471802\n",
      "\tLoss: 0.05834643542766571\n",
      "\tLoss: 0.1522907018661499\n",
      "\tLoss: 0.06452642381191254\n",
      "\tLoss: 0.08196135610342026\n",
      "\tLoss: 0.11580784618854523\n",
      "\tLoss: 0.1148669421672821\n",
      "\tLoss: 0.08416561782360077\n",
      "\tLoss: 0.11920839548110962\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.13467997312545776\n",
      "\tLoss: 0.11470712721347809\n",
      "\tLoss: 0.1086038202047348\n",
      "\tLoss: 0.10950329899787903\n",
      "\tLoss: 0.1269439309835434\n",
      "\tLoss: 0.10996872186660767\n",
      "\tLoss: 0.07683488726615906\n",
      "\tLoss: 0.12074017524719238\n",
      "\tLoss: 0.09003257751464844\n",
      "\tLoss: 0.09548991918563843\n",
      "\tLoss: 0.1201411709189415\n",
      "\tLoss: 0.12638553977012634\n",
      "\tLoss: 0.130738765001297\n",
      "\tLoss: 0.12749962508678436\n",
      "\tLoss: 0.09588596224784851\n",
      "\tLoss: 0.09995806217193604\n",
      "\tLoss: 0.09032534807920456\n",
      "\tLoss: 0.10215270519256592\n",
      "\tLoss: 0.07976244390010834\n",
      "\tLoss: 0.13383695483207703\n",
      "\tLoss: 0.08193732798099518\n",
      "\tLoss: 0.11398003250360489\n",
      "\tLoss: 0.06684558838605881\n",
      "\tLoss: 0.1140851229429245\n",
      "\tLoss: 0.0876556783914566\n",
      "\tLoss: 0.12873238325119019\n",
      "\tLoss: 0.11716482788324356\n",
      "\tLoss: 0.0716957300901413\n",
      "\tLoss: 0.09068231284618378\n",
      "\tLoss: 0.13344459235668182\n",
      "\tLoss: 0.12989403307437897\n",
      "\tLoss: 0.08236095309257507\n",
      "\tLoss: 0.12077342718839645\n",
      "\tLoss: 0.12410417944192886\n",
      "\tLoss: 0.08646085113286972\n",
      "\tLoss: 0.15420600771903992\n",
      "\tLoss: 0.08531233668327332\n",
      "\tLoss: 0.10666975378990173\n",
      "\tLoss: 0.10723806917667389\n",
      "\tLoss: 0.1300508677959442\n",
      "\tLoss: 0.10325432568788528\n",
      "\tLoss: 0.11608996987342834\n",
      "\tLoss: 0.11052124947309494\n",
      "\tLoss: 0.1214773878455162\n",
      "\tLoss: 0.14223942160606384\n",
      "\tLoss: 0.12690645456314087\n",
      "\tLoss: 0.1390223205089569\n",
      "\tLoss: 0.12163712829351425\n",
      "\tLoss: 0.11425710469484329\n",
      "\tLoss: 0.08716676384210587\n",
      "\tLoss: 0.13956314325332642\n",
      "[time] Epoch 30: 452.5068558230996s = 7.541780930384993m\n",
      "\n",
      "Epoch 31...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.0949903130531311\n",
      "\tLoss: 0.12064613401889801\n",
      "\tLoss: 0.10895873606204987\n",
      "\tLoss: 0.15001937747001648\n",
      "\tLoss: 0.06502410769462585\n",
      "\tLoss: 0.11932944506406784\n",
      "\tLoss: 0.10213233530521393\n",
      "\tLoss: 0.11904926598072052\n",
      "\tLoss: 0.16990530490875244\n",
      "\tLoss: 0.1415674239397049\n",
      "\tLoss: 0.12142634391784668\n",
      "\tLoss: 0.11307114362716675\n",
      "\tLoss: 0.12833523750305176\n",
      "\tLoss: 0.10487164556980133\n",
      "\tLoss: 0.10367103666067123\n",
      "\tLoss: 0.11963795125484467\n",
      "\tLoss: 0.1059601679444313\n",
      "\tLoss: 0.0844729095697403\n",
      "\tLoss: 0.14286348223686218\n",
      "\tLoss: 0.11102277785539627\n",
      "\tLoss: 0.1277262568473816\n",
      "\tLoss: 0.06172254681587219\n",
      "\tLoss: 0.10074733197689056\n",
      "\tLoss: 0.10055208206176758\n",
      "\tLoss: 0.0650859922170639\n",
      "\tLoss: 0.13035926222801208\n",
      "\tLoss: 0.14884892106056213\n",
      "\tLoss: 0.10047444701194763\n",
      "\tLoss: 0.10432912409305573\n",
      "\tLoss: 0.13069714605808258\n",
      "\tLoss: 0.12850844860076904\n",
      "\tLoss: 0.10094687342643738\n",
      "\tLoss: 0.12795791029930115\n",
      "\tLoss: 0.11313697695732117\n",
      "\tLoss: 0.1496325135231018\n",
      "\tLoss: 0.12937134504318237\n",
      "\tLoss: 0.15853431820869446\n",
      "\tLoss: 0.08856260031461716\n",
      "\tLoss: 0.1433291882276535\n",
      "\tLoss: 0.123776376247406\n",
      "\tLoss: 0.10377804934978485\n",
      "\tLoss: 0.0807819813489914\n",
      "\tLoss: 0.11847305297851562\n",
      "\tLoss: 0.07461380958557129\n",
      "\tLoss: 0.12562638521194458\n",
      "\tLoss: 0.11033789068460464\n",
      "\tLoss: 0.10978463292121887\n",
      "\tLoss: 0.09107546508312225\n",
      "\tLoss: 0.1739727407693863\n",
      "\tLoss: 0.0907718762755394\n",
      "\tLoss: 0.108754463493824\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.1377565860748291\n",
      "\tLoss: 0.13109585642814636\n",
      "\tLoss: 0.10103067010641098\n",
      "\tLoss: 0.10976067185401917\n",
      "\tLoss: 0.13932913541793823\n",
      "\tLoss: 0.11427287012338638\n",
      "\tLoss: 0.07448869943618774\n",
      "\tLoss: 0.1344131976366043\n",
      "\tLoss: 0.09459763765335083\n",
      "\tLoss: 0.09360140562057495\n",
      "\tLoss: 0.15958470106124878\n",
      "\tLoss: 0.13830208778381348\n",
      "\tLoss: 0.11182473599910736\n",
      "\tLoss: 0.08633729815483093\n",
      "\tLoss: 0.10227366536855698\n",
      "\tLoss: 0.09899754822254181\n",
      "\tLoss: 0.15028958022594452\n",
      "\tLoss: 0.16256757080554962\n",
      "\tLoss: 0.11976437270641327\n",
      "\tLoss: 0.12194006145000458\n",
      "\tLoss: 0.07894492149353027\n",
      "\tLoss: 0.1228947564959526\n",
      "\tLoss: 0.12203750759363174\n",
      "\tLoss: 0.10892385244369507\n",
      "\tLoss: 0.11413155496120453\n",
      "\tLoss: 0.1282268613576889\n",
      "\tLoss: 0.0744762122631073\n",
      "\tLoss: 0.0924542248249054\n",
      "\tLoss: 0.08802026510238647\n",
      "\tLoss: 0.11007477343082428\n",
      "\tLoss: 0.0912504568696022\n",
      "\tLoss: 0.11599226295948029\n",
      "\tLoss: 0.1319715678691864\n",
      "\tLoss: 0.15784241259098053\n",
      "\tLoss: 0.14601898193359375\n",
      "\tLoss: 0.08894940465688705\n",
      "\tLoss: 0.1282929629087448\n",
      "\tLoss: 0.11580643057823181\n",
      "\tLoss: 0.05703809857368469\n",
      "\tLoss: 0.1137034147977829\n",
      "\tLoss: 0.1361614465713501\n",
      "\tLoss: 0.08193597197532654\n",
      "\tLoss: 0.11152421683073044\n",
      "\tLoss: 0.1447983831167221\n",
      "\tLoss: 0.16758409142494202\n",
      "\tLoss: 0.09236331284046173\n",
      "\tLoss: 0.10132354497909546\n",
      "\tLoss: 0.06315973401069641\n",
      "\tLoss: 0.1229153573513031\n",
      "\tLoss: 0.13693606853485107\n",
      "\tLoss: 0.1279437392950058\n",
      "[time] Epoch 31: 452.60498556727543s = 7.543416426121257m\n",
      "\n",
      "Epoch 32...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.08648230135440826\n",
      "\tLoss: 0.10161564499139786\n",
      "\tLoss: 0.12512193620204926\n",
      "\tLoss: 0.10135743767023087\n",
      "\tLoss: 0.12839165329933167\n",
      "\tLoss: 0.10745848715305328\n",
      "\tLoss: 0.11592554301023483\n",
      "\tLoss: 0.13982218503952026\n",
      "\tLoss: 0.08971496671438217\n",
      "\tLoss: 0.1561836302280426\n",
      "\tLoss: 0.09906749427318573\n",
      "\tLoss: 0.13939166069030762\n",
      "\tLoss: 0.15631258487701416\n",
      "\tLoss: 0.153862863779068\n",
      "\tLoss: 0.12543661892414093\n",
      "\tLoss: 0.11464783549308777\n",
      "\tLoss: 0.11657232791185379\n",
      "\tLoss: 0.0801355391740799\n",
      "\tLoss: 0.13022388517856598\n",
      "\tLoss: 0.14881989359855652\n",
      "\tLoss: 0.12774953246116638\n",
      "\tLoss: 0.14832298457622528\n",
      "\tLoss: 0.12017412483692169\n",
      "\tLoss: 0.12439364194869995\n",
      "\tLoss: 0.11253044009208679\n",
      "\tLoss: 0.08785448968410492\n",
      "\tLoss: 0.1446332037448883\n",
      "\tLoss: 0.120494544506073\n",
      "\tLoss: 0.14715692400932312\n",
      "\tLoss: 0.13750143349170685\n",
      "\tLoss: 0.11553272604942322\n",
      "\tLoss: 0.09412631392478943\n",
      "\tLoss: 0.11606297641992569\n",
      "\tLoss: 0.13602876663208008\n",
      "\tLoss: 0.11357317864894867\n",
      "\tLoss: 0.14291363954544067\n",
      "\tLoss: 0.15367159247398376\n",
      "\tLoss: 0.11476555466651917\n",
      "\tLoss: 0.09715881198644638\n",
      "\tLoss: 0.11951183527708054\n",
      "\tLoss: 0.08040543645620346\n",
      "\tLoss: 0.12864884734153748\n",
      "\tLoss: 0.0929732471704483\n",
      "\tLoss: 0.13843053579330444\n",
      "\tLoss: 0.1413198560476303\n",
      "\tLoss: 0.11896802484989166\n",
      "\tLoss: 0.10529128462076187\n",
      "\tLoss: 0.11180797219276428\n",
      "\tLoss: 0.14820590615272522\n",
      "\tLoss: 0.12057161331176758\n",
      "\tLoss: 0.09730599820613861\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.09422333538532257\n",
      "\tLoss: 0.13767248392105103\n",
      "\tLoss: 0.1346275806427002\n",
      "\tLoss: 0.08187219500541687\n",
      "\tLoss: 0.10976271331310272\n",
      "\tLoss: 0.14965683221817017\n",
      "\tLoss: 0.1273612678050995\n",
      "\tLoss: 0.09709812700748444\n",
      "\tLoss: 0.10003440827131271\n",
      "\tLoss: 0.13534925878047943\n",
      "\tLoss: 0.10426639020442963\n",
      "\tLoss: 0.11361891776323318\n",
      "\tLoss: 0.11672979593276978\n",
      "\tLoss: 0.10152629762887955\n",
      "\tLoss: 0.10083484649658203\n",
      "\tLoss: 0.13004110753536224\n",
      "\tLoss: 0.08274757117033005\n",
      "\tLoss: 0.10586445033550262\n",
      "\tLoss: 0.13870912790298462\n",
      "\tLoss: 0.12820649147033691\n",
      "\tLoss: 0.10446207225322723\n",
      "\tLoss: 0.09685559570789337\n",
      "\tLoss: 0.1286170780658722\n",
      "\tLoss: 0.10022946447134018\n",
      "\tLoss: 0.0929846242070198\n",
      "\tLoss: 0.09735816717147827\n",
      "\tLoss: 0.1527564823627472\n",
      "\tLoss: 0.07571902871131897\n",
      "\tLoss: 0.10567504912614822\n",
      "\tLoss: 0.11712244153022766\n",
      "\tLoss: 0.12320544570684433\n",
      "\tLoss: 0.10452230274677277\n",
      "\tLoss: 0.11076033860445023\n",
      "\tLoss: 0.08076182007789612\n",
      "\tLoss: 0.09759339690208435\n",
      "\tLoss: 0.09929710626602173\n",
      "\tLoss: 0.08937062323093414\n",
      "\tLoss: 0.11018680036067963\n",
      "\tLoss: 0.09257163852453232\n",
      "\tLoss: 0.11849725246429443\n",
      "\tLoss: 0.09892940521240234\n",
      "\tLoss: 0.10820748656988144\n",
      "\tLoss: 0.0956023782491684\n",
      "\tLoss: 0.11959539353847504\n",
      "\tLoss: 0.09091976284980774\n",
      "\tLoss: 0.06854066252708435\n",
      "\tLoss: 0.12960246205329895\n",
      "\tLoss: 0.11173410713672638\n",
      "\tLoss: 0.10237876325845718\n",
      "\tLoss: 0.10415903478860855\n",
      "\tLoss: 0.1336449235677719\n",
      "[time] Epoch 32: 444.6127806631848s = 7.41021301105308m\n",
      "\n",
      "Epoch 33...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.10746888816356659\n",
      "\tLoss: 0.10745418071746826\n",
      "\tLoss: 0.10714021325111389\n",
      "\tLoss: 0.09326504170894623\n",
      "\tLoss: 0.13364790380001068\n",
      "\tLoss: 0.10193821787834167\n",
      "\tLoss: 0.15434503555297852\n",
      "\tLoss: 0.07140914350748062\n",
      "\tLoss: 0.1223071813583374\n",
      "\tLoss: 0.11583736538887024\n",
      "\tLoss: 0.1060396283864975\n",
      "\tLoss: 0.14567455649375916\n",
      "\tLoss: 0.08881193399429321\n",
      "\tLoss: 0.08601991832256317\n",
      "\tLoss: 0.12662725150585175\n",
      "\tLoss: 0.15122303366661072\n",
      "\tLoss: 0.11312238872051239\n",
      "\tLoss: 0.09596972167491913\n",
      "\tLoss: 0.1017850786447525\n",
      "\tLoss: 0.10410071909427643\n",
      "\tLoss: 0.1367809772491455\n",
      "\tLoss: 0.10534977912902832\n",
      "\tLoss: 0.11009031534194946\n",
      "\tLoss: 0.12934213876724243\n",
      "\tLoss: 0.04676283895969391\n",
      "\tLoss: 0.11253751814365387\n",
      "\tLoss: 0.11132001131772995\n",
      "\tLoss: 0.11015652120113373\n",
      "\tLoss: 0.12228120863437653\n",
      "\tLoss: 0.08827202767133713\n",
      "\tLoss: 0.1160506159067154\n",
      "\tLoss: 0.10621366649866104\n",
      "\tLoss: 0.10699214786291122\n",
      "\tLoss: 0.0875837579369545\n",
      "\tLoss: 0.12213268131017685\n",
      "\tLoss: 0.07923954725265503\n",
      "\tLoss: 0.12985780835151672\n",
      "\tLoss: 0.13574916124343872\n",
      "\tLoss: 0.11391730606555939\n",
      "\tLoss: 0.10314682126045227\n",
      "\tLoss: 0.10383681952953339\n",
      "\tLoss: 0.08833888173103333\n",
      "\tLoss: 0.07833018898963928\n",
      "\tLoss: 0.1339477002620697\n",
      "\tLoss: 0.10778073966503143\n",
      "\tLoss: 0.10815028846263885\n",
      "\tLoss: 0.10777319967746735\n",
      "\tLoss: 0.14527320861816406\n",
      "\tLoss: 0.10150264948606491\n",
      "\tLoss: 0.08595480024814606\n",
      "\tLoss: 0.13200706243515015\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.07929104566574097\n",
      "\tLoss: 0.09523564577102661\n",
      "\tLoss: 0.11275139451026917\n",
      "\tLoss: 0.09902684390544891\n",
      "\tLoss: 0.08313487470149994\n",
      "\tLoss: 0.07373999059200287\n",
      "\tLoss: 0.11117478460073471\n",
      "\tLoss: 0.09768661856651306\n",
      "\tLoss: 0.08084365725517273\n",
      "\tLoss: 0.14509078860282898\n",
      "\tLoss: 0.07734842598438263\n",
      "\tLoss: 0.10274538397789001\n",
      "\tLoss: 0.11296747624874115\n",
      "\tLoss: 0.14723387360572815\n",
      "\tLoss: 0.09996796399354935\n",
      "\tLoss: 0.1390790343284607\n",
      "\tLoss: 0.14749541878700256\n",
      "\tLoss: 0.09048448503017426\n",
      "\tLoss: 0.11380961537361145\n",
      "\tLoss: 0.11477304995059967\n",
      "\tLoss: 0.08009299635887146\n",
      "\tLoss: 0.10335291922092438\n",
      "\tLoss: 0.09561722725629807\n",
      "\tLoss: 0.07825033366680145\n",
      "\tLoss: 0.0928674191236496\n",
      "\tLoss: 0.11085167527198792\n",
      "\tLoss: 0.13675077259540558\n",
      "\tLoss: 0.10244111716747284\n",
      "\tLoss: 0.1375652551651001\n",
      "\tLoss: 0.11160153895616531\n",
      "\tLoss: 0.14509883522987366\n",
      "\tLoss: 0.14428424835205078\n",
      "\tLoss: 0.10514514148235321\n",
      "\tLoss: 0.12084537744522095\n",
      "\tLoss: 0.10285934060811996\n",
      "\tLoss: 0.10197271406650543\n",
      "\tLoss: 0.09861733764410019\n",
      "\tLoss: 0.1707417368888855\n",
      "\tLoss: 0.10262017697095871\n",
      "\tLoss: 0.09424558281898499\n",
      "\tLoss: 0.11820614337921143\n",
      "\tLoss: 0.09172674268484116\n",
      "\tLoss: 0.14427775144577026\n",
      "\tLoss: 0.1017385944724083\n",
      "\tLoss: 0.10243076086044312\n",
      "\tLoss: 0.08810891956090927\n",
      "\tLoss: 0.1326419711112976\n",
      "\tLoss: 0.10461901128292084\n",
      "\tLoss: 0.0979464128613472\n",
      "\tLoss: 0.09821784496307373\n",
      "\tLoss: 0.12587366998195648\n",
      "[time] Epoch 33: 432.4122068500146s = 7.20687011416691m\n",
      "\n",
      "Epoch 34...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.09245093166828156\n",
      "\tLoss: 0.10187117755413055\n",
      "\tLoss: 0.13575175404548645\n",
      "\tLoss: 0.13838225603103638\n",
      "\tLoss: 0.09257195889949799\n",
      "\tLoss: 0.12475676834583282\n",
      "\tLoss: 0.0854705274105072\n",
      "\tLoss: 0.07495293021202087\n",
      "\tLoss: 0.09212440252304077\n",
      "\tLoss: 0.13793328404426575\n",
      "\tLoss: 0.08019854128360748\n",
      "\tLoss: 0.17358900606632233\n",
      "\tLoss: 0.1285533607006073\n",
      "\tLoss: 0.1127362847328186\n",
      "\tLoss: 0.09801992774009705\n",
      "\tLoss: 0.1278807520866394\n",
      "\tLoss: 0.1143665611743927\n",
      "\tLoss: 0.14003446698188782\n",
      "\tLoss: 0.08009754121303558\n",
      "\tLoss: 0.15905332565307617\n",
      "\tLoss: 0.10300649702548981\n",
      "\tLoss: 0.09813015162944794\n",
      "\tLoss: 0.12047898024320602\n",
      "\tLoss: 0.15338276326656342\n",
      "\tLoss: 0.11598469316959381\n",
      "\tLoss: 0.07201923429965973\n",
      "\tLoss: 0.11780115962028503\n",
      "\tLoss: 0.10160299390554428\n",
      "\tLoss: 0.1238698810338974\n",
      "\tLoss: 0.13314491510391235\n",
      "\tLoss: 0.12379655987024307\n",
      "\tLoss: 0.09653735160827637\n",
      "\tLoss: 0.09788292646408081\n",
      "\tLoss: 0.07934006303548813\n",
      "\tLoss: 0.0961284190416336\n",
      "\tLoss: 0.11749359220266342\n",
      "\tLoss: 0.10715450346469879\n",
      "\tLoss: 0.0894029438495636\n",
      "\tLoss: 0.1356600821018219\n",
      "\tLoss: 0.14632263779640198\n",
      "\tLoss: 0.10511351376771927\n",
      "\tLoss: 0.07472831010818481\n",
      "\tLoss: 0.13234631717205048\n",
      "\tLoss: 0.09197589755058289\n",
      "\tLoss: 0.08043606579303741\n",
      "\tLoss: 0.1278141736984253\n",
      "\tLoss: 0.1324101835489273\n",
      "\tLoss: 0.12972581386566162\n",
      "\tLoss: 0.10386842489242554\n",
      "\tLoss: 0.10177518427371979\n",
      "\tLoss: 0.07795513421297073\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.10062021762132645\n",
      "\tLoss: 0.14351734519004822\n",
      "\tLoss: 0.06516703963279724\n",
      "\tLoss: 0.14682509005069733\n",
      "\tLoss: 0.0547482855618\n",
      "\tLoss: 0.12134771794080734\n",
      "\tLoss: 0.09639886021614075\n",
      "\tLoss: 0.09070427715778351\n",
      "\tLoss: 0.09033027291297913\n",
      "\tLoss: 0.0994858592748642\n",
      "\tLoss: 0.0843157023191452\n",
      "\tLoss: 0.09364546090364456\n",
      "\tLoss: 0.12068559974431992\n",
      "\tLoss: 0.09012442827224731\n",
      "\tLoss: 0.14593616127967834\n",
      "\tLoss: 0.10300414264202118\n",
      "\tLoss: 0.11113689839839935\n",
      "\tLoss: 0.10925470292568207\n",
      "\tLoss: 0.13734158873558044\n",
      "\tLoss: 0.11865903437137604\n",
      "\tLoss: 0.11417201161384583\n",
      "\tLoss: 0.10377883911132812\n",
      "\tLoss: 0.13235095143318176\n",
      "\tLoss: 0.16260875761508942\n",
      "\tLoss: 0.13775303959846497\n",
      "\tLoss: 0.11974378675222397\n",
      "\tLoss: 0.16063490509986877\n",
      "\tLoss: 0.13701753318309784\n",
      "\tLoss: 0.13257336616516113\n",
      "\tLoss: 0.0734592005610466\n",
      "\tLoss: 0.12515631318092346\n",
      "\tLoss: 0.09848818182945251\n",
      "\tLoss: 0.1322711557149887\n",
      "\tLoss: 0.10433833301067352\n",
      "\tLoss: 0.08562908321619034\n",
      "\tLoss: 0.12883040308952332\n",
      "\tLoss: 0.08896255493164062\n",
      "\tLoss: 0.13471859693527222\n",
      "\tLoss: 0.14786940813064575\n",
      "\tLoss: 0.12699642777442932\n",
      "\tLoss: 0.1497957408428192\n",
      "\tLoss: 0.11298081278800964\n",
      "\tLoss: 0.09203536808490753\n",
      "\tLoss: 0.09507035464048386\n",
      "\tLoss: 0.15394946932792664\n",
      "\tLoss: 0.10431750118732452\n",
      "\tLoss: 0.11630455404520035\n",
      "\tLoss: 0.10978260636329651\n",
      "\tLoss: 0.09705264121294022\n",
      "\tLoss: 0.16947242617607117\n",
      "\tLoss: 0.09570924937725067\n",
      "[time] Epoch 34: 426.4085936611518s = 7.106809894352531m\n",
      "\n",
      "Epoch 35...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.09963154792785645\n",
      "\tLoss: 0.08047090470790863\n",
      "\tLoss: 0.07269994169473648\n",
      "\tLoss: 0.10232347249984741\n",
      "\tLoss: 0.15800505876541138\n",
      "\tLoss: 0.14170172810554504\n",
      "\tLoss: 0.11119174212217331\n",
      "\tLoss: 0.1204720288515091\n",
      "\tLoss: 0.10663572698831558\n",
      "\tLoss: 0.12138548493385315\n",
      "\tLoss: 0.1237185075879097\n",
      "\tLoss: 0.14926500618457794\n",
      "\tLoss: 0.1337212324142456\n",
      "\tLoss: 0.09818504750728607\n",
      "\tLoss: 0.1436910778284073\n",
      "\tLoss: 0.1444142609834671\n",
      "\tLoss: 0.10931396484375\n",
      "\tLoss: 0.17152976989746094\n",
      "\tLoss: 0.09094160795211792\n",
      "\tLoss: 0.08751507103443146\n",
      "\tLoss: 0.11290338635444641\n",
      "\tLoss: 0.13049864768981934\n",
      "\tLoss: 0.12198396027088165\n",
      "\tLoss: 0.11014743149280548\n",
      "\tLoss: 0.13865219056606293\n",
      "\tLoss: 0.11280395090579987\n",
      "\tLoss: 0.15642419457435608\n",
      "\tLoss: 0.09651938080787659\n",
      "\tLoss: 0.13331745564937592\n",
      "\tLoss: 0.07669360935688019\n",
      "\tLoss: 0.0978919118642807\n",
      "\tLoss: 0.13923540711402893\n",
      "\tLoss: 0.0887833759188652\n",
      "\tLoss: 0.11202353239059448\n",
      "\tLoss: 0.0989350825548172\n",
      "\tLoss: 0.11426045000553131\n",
      "\tLoss: 0.10833554714918137\n",
      "\tLoss: 0.12090516835451126\n",
      "\tLoss: 0.1249980702996254\n",
      "\tLoss: 0.11268627643585205\n",
      "\tLoss: 0.08408711850643158\n",
      "\tLoss: 0.13710324466228485\n",
      "\tLoss: 0.1418243944644928\n",
      "\tLoss: 0.1617794930934906\n",
      "\tLoss: 0.14681605994701385\n",
      "\tLoss: 0.1016635149717331\n",
      "\tLoss: 0.10044613480567932\n",
      "\tLoss: 0.10169726610183716\n",
      "\tLoss: 0.09395389258861542\n",
      "\tLoss: 0.11633146554231644\n",
      "\tLoss: 0.14749383926391602\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.0886535495519638\n",
      "\tLoss: 0.10851557552814484\n",
      "\tLoss: 0.07179474830627441\n",
      "\tLoss: 0.07439576089382172\n",
      "\tLoss: 0.10023881494998932\n",
      "\tLoss: 0.08365093916654587\n",
      "\tLoss: 0.10467542707920074\n",
      "\tLoss: 0.09757214784622192\n",
      "\tLoss: 0.09414777159690857\n",
      "\tLoss: 0.11235672235488892\n",
      "\tLoss: 0.12102814763784409\n",
      "\tLoss: 0.14908072352409363\n",
      "\tLoss: 0.12203126400709152\n",
      "\tLoss: 0.1176174134016037\n",
      "\tLoss: 0.14262548089027405\n",
      "\tLoss: 0.09935276210308075\n",
      "\tLoss: 0.1175762489438057\n",
      "\tLoss: 0.11708243191242218\n",
      "\tLoss: 0.13326168060302734\n",
      "\tLoss: 0.10284373164176941\n",
      "\tLoss: 0.11243360489606857\n",
      "\tLoss: 0.14598123729228973\n",
      "\tLoss: 0.10396407544612885\n",
      "\tLoss: 0.11211702227592468\n",
      "\tLoss: 0.1034538671374321\n",
      "\tLoss: 0.09868833422660828\n",
      "\tLoss: 0.1310536414384842\n",
      "\tLoss: 0.12461750209331512\n",
      "\tLoss: 0.09734520316123962\n",
      "\tLoss: 0.06964446604251862\n",
      "\tLoss: 0.08355546742677689\n",
      "\tLoss: 0.0945933386683464\n",
      "\tLoss: 0.07539846003055573\n",
      "\tLoss: 0.11737862974405289\n",
      "\tLoss: 0.07135190069675446\n",
      "\tLoss: 0.0932656079530716\n",
      "\tLoss: 0.10327915102243423\n",
      "\tLoss: 0.13213986158370972\n",
      "\tLoss: 0.10146155953407288\n",
      "\tLoss: 0.11655406653881073\n",
      "\tLoss: 0.10510669648647308\n",
      "\tLoss: 0.08603081107139587\n",
      "\tLoss: 0.09872477501630783\n",
      "\tLoss: 0.07652891427278519\n",
      "\tLoss: 0.09762829542160034\n",
      "\tLoss: 0.10662755370140076\n",
      "\tLoss: 0.11143233627080917\n",
      "\tLoss: 0.10464262962341309\n",
      "\tLoss: 0.08837144821882248\n",
      "\tLoss: 0.11634542047977448\n",
      "\tLoss: 0.08148548007011414\n",
      "[time] Epoch 35: 425.99460346996784s = 7.099910057832798m\n",
      "\n",
      "Epoch 36...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.13766849040985107\n",
      "\tLoss: 0.12153130024671555\n",
      "\tLoss: 0.09972690045833588\n",
      "\tLoss: 0.0964946523308754\n",
      "\tLoss: 0.12921808660030365\n",
      "\tLoss: 0.0849529430270195\n",
      "\tLoss: 0.0876036137342453\n",
      "\tLoss: 0.11528745293617249\n",
      "\tLoss: 0.12365558743476868\n",
      "\tLoss: 0.10384144634008408\n",
      "\tLoss: 0.13561566174030304\n",
      "\tLoss: 0.08596944063901901\n",
      "\tLoss: 0.08856150507926941\n",
      "\tLoss: 0.08845588564872742\n",
      "\tLoss: 0.10612312704324722\n",
      "\tLoss: 0.14322444796562195\n",
      "\tLoss: 0.11908550560474396\n",
      "\tLoss: 0.12047307193279266\n",
      "\tLoss: 0.13616330921649933\n",
      "\tLoss: 0.0827464833855629\n",
      "\tLoss: 0.12874796986579895\n",
      "\tLoss: 0.12721210718154907\n",
      "\tLoss: 0.10766004025936127\n",
      "\tLoss: 0.09247399121522903\n",
      "\tLoss: 0.12283745408058167\n",
      "\tLoss: 0.12413030862808228\n",
      "\tLoss: 0.114564910531044\n",
      "\tLoss: 0.11604899168014526\n",
      "\tLoss: 0.1020653173327446\n",
      "\tLoss: 0.09099124372005463\n",
      "\tLoss: 0.10155479609966278\n",
      "\tLoss: 0.10518749058246613\n",
      "\tLoss: 0.13237300515174866\n",
      "\tLoss: 0.09052693843841553\n",
      "\tLoss: 0.14573270082473755\n",
      "\tLoss: 0.0849369466304779\n",
      "\tLoss: 0.10459670424461365\n",
      "\tLoss: 0.10254901647567749\n",
      "\tLoss: 0.12407591193914413\n",
      "\tLoss: 0.08970168977975845\n",
      "\tLoss: 0.11619982123374939\n",
      "\tLoss: 0.138692706823349\n",
      "\tLoss: 0.1105208694934845\n",
      "\tLoss: 0.12226469814777374\n",
      "\tLoss: 0.09344711154699326\n",
      "\tLoss: 0.0997122973203659\n",
      "\tLoss: 0.1402958631515503\n",
      "\tLoss: 0.11100003123283386\n",
      "\tLoss: 0.13557305932044983\n",
      "\tLoss: 0.14712581038475037\n",
      "\tLoss: 0.13146746158599854\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.11662343889474869\n",
      "\tLoss: 0.07995956391096115\n",
      "\tLoss: 0.08695343136787415\n",
      "\tLoss: 0.12263378500938416\n",
      "\tLoss: 0.12193075567483902\n",
      "\tLoss: 0.1165793314576149\n",
      "\tLoss: 0.12111036479473114\n",
      "\tLoss: 0.13346952199935913\n",
      "\tLoss: 0.09909483790397644\n",
      "\tLoss: 0.08632393181324005\n",
      "\tLoss: 0.06355026364326477\n",
      "\tLoss: 0.12753579020500183\n",
      "\tLoss: 0.09711278229951859\n",
      "\tLoss: 0.08756393939256668\n",
      "\tLoss: 0.11319732666015625\n",
      "\tLoss: 0.16400113701820374\n",
      "\tLoss: 0.09218840301036835\n",
      "\tLoss: 0.1027442216873169\n",
      "\tLoss: 0.06381603330373764\n",
      "\tLoss: 0.07281649112701416\n",
      "\tLoss: 0.11262176185846329\n",
      "\tLoss: 0.11141356080770493\n",
      "\tLoss: 0.09703363478183746\n",
      "\tLoss: 0.08689917623996735\n",
      "\tLoss: 0.12992703914642334\n",
      "\tLoss: 0.10502518713474274\n",
      "\tLoss: 0.10557545721530914\n",
      "\tLoss: 0.08799609541893005\n",
      "\tLoss: 0.09186083823442459\n",
      "\tLoss: 0.15578065812587738\n",
      "\tLoss: 0.17209339141845703\n",
      "\tLoss: 0.12600523233413696\n",
      "\tLoss: 0.07139701396226883\n",
      "\tLoss: 0.17008864879608154\n",
      "\tLoss: 0.10745099186897278\n",
      "\tLoss: 0.11635927855968475\n",
      "\tLoss: 0.11402629315853119\n",
      "\tLoss: 0.11039576679468155\n",
      "\tLoss: 0.18517343699932098\n",
      "\tLoss: 0.1496182084083557\n",
      "\tLoss: 0.17566873133182526\n",
      "\tLoss: 0.13916727900505066\n",
      "\tLoss: 0.14086389541625977\n",
      "\tLoss: 0.1081899106502533\n",
      "\tLoss: 0.10699386149644852\n",
      "\tLoss: 0.13946110010147095\n",
      "\tLoss: 0.10882473737001419\n",
      "\tLoss: 0.10268022865056992\n",
      "\tLoss: 0.14696282148361206\n",
      "\tLoss: 0.13206134736537933\n",
      "\tLoss: 0.1746269315481186\n",
      "[time] Epoch 36: 423.1461117360741s = 7.052435195601235m\n",
      "\n",
      "Epoch 37...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.12889166176319122\n",
      "\tLoss: 0.11554983258247375\n",
      "\tLoss: 0.11371240019798279\n",
      "\tLoss: 0.1332252025604248\n",
      "\tLoss: 0.1376953125\n",
      "\tLoss: 0.09137773513793945\n",
      "\tLoss: 0.12366960197687149\n",
      "\tLoss: 0.10855833441019058\n",
      "\tLoss: 0.08207590132951736\n",
      "\tLoss: 0.11235614866018295\n",
      "\tLoss: 0.13176554441452026\n",
      "\tLoss: 0.16679492592811584\n",
      "\tLoss: 0.12184257805347443\n",
      "\tLoss: 0.11069568991661072\n",
      "\tLoss: 0.13866114616394043\n",
      "\tLoss: 0.11752703785896301\n",
      "\tLoss: 0.1654222160577774\n",
      "\tLoss: 0.08914162963628769\n",
      "\tLoss: 0.11543969810009003\n",
      "\tLoss: 0.10503330826759338\n",
      "\tLoss: 0.10562416166067123\n",
      "\tLoss: 0.1375843733549118\n",
      "\tLoss: 0.12448816746473312\n",
      "\tLoss: 0.1050560474395752\n",
      "\tLoss: 0.08978277444839478\n",
      "\tLoss: 0.10123865306377411\n",
      "\tLoss: 0.14674726128578186\n",
      "\tLoss: 0.11685237288475037\n",
      "\tLoss: 0.11647583544254303\n",
      "\tLoss: 0.09999393671751022\n",
      "\tLoss: 0.14452701807022095\n",
      "\tLoss: 0.12247887253761292\n",
      "\tLoss: 0.09864049404859543\n",
      "\tLoss: 0.10379543900489807\n",
      "\tLoss: 0.08965308964252472\n",
      "\tLoss: 0.07784153521060944\n",
      "\tLoss: 0.08176136016845703\n",
      "\tLoss: 0.12686315178871155\n",
      "\tLoss: 0.09045307338237762\n",
      "\tLoss: 0.0968540757894516\n",
      "\tLoss: 0.08025224506855011\n",
      "\tLoss: 0.09935890883207321\n",
      "\tLoss: 0.14780348539352417\n",
      "\tLoss: 0.11569121479988098\n",
      "\tLoss: 0.11774100363254547\n",
      "\tLoss: 0.13657379150390625\n",
      "\tLoss: 0.10744564235210419\n",
      "\tLoss: 0.09112341701984406\n",
      "\tLoss: 0.0723341628909111\n",
      "\tLoss: 0.07855167239904404\n",
      "\tLoss: 0.07962672412395477\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.08199495822191238\n",
      "\tLoss: 0.13912099599838257\n",
      "\tLoss: 0.11496159434318542\n",
      "\tLoss: 0.11198599636554718\n",
      "\tLoss: 0.0746542438864708\n",
      "\tLoss: 0.08361834287643433\n",
      "\tLoss: 0.10763853788375854\n",
      "\tLoss: 0.10290278494358063\n",
      "\tLoss: 0.08173754811286926\n",
      "\tLoss: 0.11050701141357422\n",
      "\tLoss: 0.11928436160087585\n",
      "\tLoss: 0.08371522277593613\n",
      "\tLoss: 0.12563776969909668\n",
      "\tLoss: 0.08118922263383865\n",
      "\tLoss: 0.13757483661174774\n",
      "\tLoss: 0.10702892392873764\n",
      "\tLoss: 0.09689413011074066\n",
      "\tLoss: 0.09906706213951111\n",
      "\tLoss: 0.12031476944684982\n",
      "\tLoss: 0.0940672755241394\n",
      "\tLoss: 0.1073966845870018\n",
      "\tLoss: 0.10346674919128418\n",
      "\tLoss: 0.15031149983406067\n",
      "\tLoss: 0.11385670304298401\n",
      "\tLoss: 0.08209367841482162\n",
      "\tLoss: 0.10671985149383545\n",
      "\tLoss: 0.11712224781513214\n",
      "\tLoss: 0.10152672231197357\n",
      "\tLoss: 0.0818205177783966\n",
      "\tLoss: 0.09620820730924606\n",
      "\tLoss: 0.14527446031570435\n",
      "\tLoss: 0.07331784069538116\n",
      "\tLoss: 0.09323425590991974\n",
      "\tLoss: 0.12854477763175964\n",
      "\tLoss: 0.12999200820922852\n",
      "\tLoss: 0.08812446892261505\n",
      "\tLoss: 0.1282438188791275\n",
      "\tLoss: 0.08980165421962738\n",
      "\tLoss: 0.11758293956518173\n",
      "\tLoss: 0.09868822246789932\n",
      "\tLoss: 0.16494372487068176\n",
      "\tLoss: 0.11599960178136826\n",
      "\tLoss: 0.11716678738594055\n",
      "\tLoss: 0.11850813031196594\n",
      "\tLoss: 0.09005646407604218\n",
      "\tLoss: 0.11815720796585083\n",
      "\tLoss: 0.15863795578479767\n",
      "\tLoss: 0.1045415997505188\n",
      "\tLoss: 0.14578253030776978\n",
      "\tLoss: 0.10640381276607513\n",
      "\tLoss: 0.11121781170368195\n",
      "[time] Epoch 37: 420.2788940668106s = 7.004648234446844m\n",
      "\n",
      "Epoch 38...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.09093225002288818\n",
      "\tLoss: 0.14708879590034485\n",
      "\tLoss: 0.12325689196586609\n",
      "\tLoss: 0.11654940247535706\n",
      "\tLoss: 0.13129772245883942\n",
      "\tLoss: 0.1351393312215805\n",
      "\tLoss: 0.1558687686920166\n",
      "\tLoss: 0.15426291525363922\n",
      "\tLoss: 0.10772639513015747\n",
      "\tLoss: 0.1280032843351364\n",
      "\tLoss: 0.18175968527793884\n",
      "\tLoss: 0.1277264952659607\n",
      "\tLoss: 0.16846375167369843\n",
      "\tLoss: 0.07987690716981888\n",
      "\tLoss: 0.09145208448171616\n",
      "\tLoss: 0.11880598217248917\n",
      "\tLoss: 0.11119912564754486\n",
      "\tLoss: 0.08690136671066284\n",
      "\tLoss: 0.12641094624996185\n",
      "\tLoss: 0.1172359436750412\n",
      "\tLoss: 0.08795055747032166\n",
      "\tLoss: 0.09812703728675842\n",
      "\tLoss: 0.1330558955669403\n",
      "\tLoss: 0.1330558955669403\n",
      "\tLoss: 0.07249265909194946\n",
      "\tLoss: 0.1228296086192131\n",
      "\tLoss: 0.1122608631849289\n",
      "\tLoss: 0.1411975771188736\n",
      "\tLoss: 0.08751241862773895\n",
      "\tLoss: 0.09280315041542053\n",
      "\tLoss: 0.13438957929611206\n",
      "\tLoss: 0.12249769270420074\n",
      "\tLoss: 0.09818514436483383\n",
      "\tLoss: 0.14230512082576752\n",
      "\tLoss: 0.11757633090019226\n",
      "\tLoss: 0.11156248301267624\n",
      "\tLoss: 0.1385459303855896\n",
      "\tLoss: 0.0674140453338623\n",
      "\tLoss: 0.128410205245018\n",
      "\tLoss: 0.11590283364057541\n",
      "\tLoss: 0.13853704929351807\n",
      "\tLoss: 0.15834152698516846\n",
      "\tLoss: 0.11245753616094589\n",
      "\tLoss: 0.13621416687965393\n",
      "\tLoss: 0.10560287535190582\n",
      "\tLoss: 0.12601788341999054\n",
      "\tLoss: 0.09879286587238312\n",
      "\tLoss: 0.1328050047159195\n",
      "\tLoss: 0.1269209086894989\n",
      "\tLoss: 0.1010713055729866\n",
      "\tLoss: 0.13883844017982483\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.16767090559005737\n",
      "\tLoss: 0.12097064405679703\n",
      "\tLoss: 0.10396716743707657\n",
      "\tLoss: 0.16147330403327942\n",
      "\tLoss: 0.16551090776920319\n",
      "\tLoss: 0.109635129570961\n",
      "\tLoss: 0.13964933156967163\n",
      "\tLoss: 0.1222473680973053\n",
      "\tLoss: 0.1107456237077713\n",
      "\tLoss: 0.11628369987010956\n",
      "\tLoss: 0.1345202773809433\n",
      "\tLoss: 0.15057021379470825\n",
      "\tLoss: 0.09177297353744507\n",
      "\tLoss: 0.07768566161394119\n",
      "\tLoss: 0.13465309143066406\n",
      "\tLoss: 0.14111796021461487\n",
      "\tLoss: 0.10359668731689453\n",
      "\tLoss: 0.11325369030237198\n",
      "\tLoss: 0.11589370667934418\n",
      "\tLoss: 0.12613347172737122\n",
      "\tLoss: 0.13999351859092712\n",
      "\tLoss: 0.11149901151657104\n",
      "\tLoss: 0.15248610079288483\n",
      "\tLoss: 0.12001203000545502\n",
      "\tLoss: 0.09142906218767166\n",
      "\tLoss: 0.1059245839715004\n",
      "\tLoss: 0.1046769767999649\n",
      "\tLoss: 0.06595273315906525\n",
      "\tLoss: 0.14425265789031982\n",
      "\tLoss: 0.1027207225561142\n",
      "\tLoss: 0.1497536301612854\n",
      "\tLoss: 0.11296723783016205\n",
      "\tLoss: 0.11210974305868149\n",
      "\tLoss: 0.09350144863128662\n",
      "\tLoss: 0.1229221448302269\n",
      "\tLoss: 0.11538490653038025\n",
      "\tLoss: 0.14118599891662598\n",
      "\tLoss: 0.11770196259021759\n",
      "\tLoss: 0.08560825139284134\n",
      "\tLoss: 0.11850821226835251\n",
      "\tLoss: 0.11001218855381012\n",
      "\tLoss: 0.16574235260486603\n",
      "\tLoss: 0.13062523305416107\n",
      "\tLoss: 0.12894177436828613\n",
      "\tLoss: 0.08548158407211304\n",
      "\tLoss: 0.11123024672269821\n",
      "\tLoss: 0.0954848974943161\n",
      "\tLoss: 0.156012624502182\n",
      "\tLoss: 0.09977635741233826\n",
      "\tLoss: 0.1314813792705536\n",
      "\tLoss: 0.09188192337751389\n",
      "[time] Epoch 38: 419.12371379788965s = 6.985395229964827m\n",
      "\n",
      "Epoch 39...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.0986769050359726\n",
      "\tLoss: 0.0950741395354271\n",
      "\tLoss: 0.11271704733371735\n",
      "\tLoss: 0.1131708174943924\n",
      "\tLoss: 0.1252773106098175\n",
      "\tLoss: 0.08593864738941193\n",
      "\tLoss: 0.10758005082607269\n",
      "\tLoss: 0.08960554748773575\n",
      "\tLoss: 0.13648799061775208\n",
      "\tLoss: 0.13489007949829102\n",
      "\tLoss: 0.09462736546993256\n",
      "\tLoss: 0.09967704117298126\n",
      "\tLoss: 0.1254425048828125\n",
      "\tLoss: 0.12463092803955078\n",
      "\tLoss: 0.12207582592964172\n",
      "\tLoss: 0.09953402727842331\n",
      "\tLoss: 0.09691943228244781\n",
      "\tLoss: 0.1146891713142395\n",
      "\tLoss: 0.10329343378543854\n",
      "\tLoss: 0.1014915332198143\n",
      "\tLoss: 0.1049480140209198\n",
      "\tLoss: 0.09749738872051239\n",
      "\tLoss: 0.1557520627975464\n",
      "\tLoss: 0.11938431113958359\n",
      "\tLoss: 0.08853407204151154\n",
      "\tLoss: 0.15252742171287537\n",
      "\tLoss: 0.14039941132068634\n",
      "\tLoss: 0.1291913539171219\n",
      "\tLoss: 0.16464580595493317\n",
      "\tLoss: 0.10423275828361511\n",
      "\tLoss: 0.1038348525762558\n",
      "\tLoss: 0.11475539207458496\n",
      "\tLoss: 0.12331002205610275\n",
      "\tLoss: 0.10417237877845764\n",
      "\tLoss: 0.09875130653381348\n",
      "\tLoss: 0.10669082403182983\n",
      "\tLoss: 0.08301632106304169\n",
      "\tLoss: 0.1369849443435669\n",
      "\tLoss: 0.1061626747250557\n",
      "\tLoss: 0.08719080686569214\n",
      "\tLoss: 0.1512913852930069\n",
      "\tLoss: 0.1103893369436264\n",
      "\tLoss: 0.143597811460495\n",
      "\tLoss: 0.11526721715927124\n",
      "\tLoss: 0.11158931255340576\n",
      "\tLoss: 0.08680838346481323\n",
      "\tLoss: 0.1322687268257141\n",
      "\tLoss: 0.11962983012199402\n",
      "\tLoss: 0.08487287908792496\n",
      "\tLoss: 0.10049427300691605\n",
      "\tLoss: 0.11438027769327164\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.11433524638414383\n",
      "\tLoss: 0.10165800899267197\n",
      "\tLoss: 0.1303393840789795\n",
      "\tLoss: 0.11896931380033493\n",
      "\tLoss: 0.08686665445566177\n",
      "\tLoss: 0.08520960062742233\n",
      "\tLoss: 0.06472068279981613\n",
      "\tLoss: 0.13571986556053162\n",
      "\tLoss: 0.11894305795431137\n",
      "\tLoss: 0.09485915303230286\n",
      "\tLoss: 0.05579576641321182\n",
      "\tLoss: 0.11739577353000641\n",
      "\tLoss: 0.12158973515033722\n",
      "\tLoss: 0.11634550988674164\n",
      "\tLoss: 0.11336176097393036\n",
      "\tLoss: 0.11197242885828018\n",
      "\tLoss: 0.09734265506267548\n",
      "\tLoss: 0.1503714919090271\n",
      "\tLoss: 0.10259212553501129\n",
      "\tLoss: 0.05918222665786743\n",
      "\tLoss: 0.1766691356897354\n",
      "\tLoss: 0.09211339056491852\n",
      "\tLoss: 0.11288253962993622\n",
      "\tLoss: 0.14276926219463348\n",
      "\tLoss: 0.08887806534767151\n",
      "\tLoss: 0.13363927602767944\n",
      "\tLoss: 0.15671075880527496\n",
      "\tLoss: 0.09890342503786087\n",
      "\tLoss: 0.07796955108642578\n",
      "\tLoss: 0.1098649799823761\n",
      "\tLoss: 0.13009560108184814\n",
      "\tLoss: 0.09133152663707733\n",
      "\tLoss: 0.0532388761639595\n",
      "\tLoss: 0.12708690762519836\n",
      "\tLoss: 0.07786157727241516\n",
      "\tLoss: 0.12287172675132751\n",
      "\tLoss: 0.11911845952272415\n",
      "\tLoss: 0.1208728775382042\n",
      "\tLoss: 0.11383548378944397\n",
      "\tLoss: 0.1175224632024765\n",
      "\tLoss: 0.12620320916175842\n",
      "\tLoss: 0.11147573590278625\n",
      "\tLoss: 0.06590209901332855\n",
      "\tLoss: 0.10704903304576874\n",
      "\tLoss: 0.16389252245426178\n",
      "\tLoss: 0.10995209217071533\n",
      "\tLoss: 0.13700923323631287\n",
      "\tLoss: 0.12085689604282379\n",
      "\tLoss: 0.11732349544763565\n",
      "\tLoss: 0.13662394881248474\n",
      "\tLoss: 0.08872538059949875\n",
      "[time] Epoch 39: 417.3348683929071s = 6.955581139881785m\n",
      "\n",
      "Epoch 40...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.08736169338226318\n",
      "\tLoss: 0.11776258051395416\n",
      "\tLoss: 0.12045364081859589\n",
      "\tLoss: 0.10294966399669647\n",
      "\tLoss: 0.09786579012870789\n",
      "\tLoss: 0.10016927123069763\n",
      "\tLoss: 0.09322209656238556\n",
      "\tLoss: 0.08839157223701477\n",
      "\tLoss: 0.1225661188364029\n",
      "\tLoss: 0.1013147383928299\n",
      "\tLoss: 0.13516849279403687\n",
      "\tLoss: 0.11076825857162476\n",
      "\tLoss: 0.09634478390216827\n",
      "\tLoss: 0.11244510114192963\n",
      "\tLoss: 0.09692583233118057\n",
      "\tLoss: 0.12113862484693527\n",
      "\tLoss: 0.1137399822473526\n",
      "\tLoss: 0.14269959926605225\n",
      "\tLoss: 0.1257636398077011\n",
      "\tLoss: 0.10363674908876419\n",
      "\tLoss: 0.1297537237405777\n",
      "\tLoss: 0.14012062549591064\n",
      "\tLoss: 0.09262281656265259\n",
      "\tLoss: 0.0862300843000412\n",
      "\tLoss: 0.09029748290777206\n",
      "\tLoss: 0.09952689707279205\n",
      "\tLoss: 0.12175565958023071\n",
      "\tLoss: 0.09279021620750427\n",
      "\tLoss: 0.08636468648910522\n",
      "\tLoss: 0.11845780909061432\n",
      "\tLoss: 0.12030471861362457\n",
      "\tLoss: 0.0835060179233551\n",
      "\tLoss: 0.09611031413078308\n",
      "\tLoss: 0.10717469453811646\n",
      "\tLoss: 0.10824000835418701\n",
      "\tLoss: 0.10203597694635391\n",
      "\tLoss: 0.1066703051328659\n",
      "\tLoss: 0.11746656894683838\n",
      "\tLoss: 0.12099167704582214\n",
      "\tLoss: 0.07219403982162476\n",
      "\tLoss: 0.13105928897857666\n",
      "\tLoss: 0.10089622437953949\n",
      "\tLoss: 0.11783698201179504\n",
      "\tLoss: 0.115327388048172\n",
      "\tLoss: 0.13108868896961212\n",
      "\tLoss: 0.0957738608121872\n",
      "\tLoss: 0.1132623702287674\n",
      "\tLoss: 0.15459637343883514\n",
      "\tLoss: 0.09294165670871735\n",
      "\tLoss: 0.15232343971729279\n",
      "\tLoss: 0.14540255069732666\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.1026889830827713\n",
      "\tLoss: 0.12832427024841309\n",
      "\tLoss: 0.10382306575775146\n",
      "\tLoss: 0.09176851063966751\n",
      "\tLoss: 0.1502634882926941\n",
      "\tLoss: 0.10238683968782425\n",
      "\tLoss: 0.11888472735881805\n",
      "\tLoss: 0.08960382640361786\n",
      "\tLoss: 0.06769698858261108\n",
      "\tLoss: 0.11199021339416504\n",
      "\tLoss: 0.10251384228467941\n",
      "\tLoss: 0.08129695057868958\n",
      "\tLoss: 0.10492300242185593\n",
      "\tLoss: 0.10793758183717728\n",
      "\tLoss: 0.10350995510816574\n",
      "\tLoss: 0.09702401608228683\n",
      "\tLoss: 0.11318588256835938\n",
      "\tLoss: 0.09615441411733627\n",
      "\tLoss: 0.0841493010520935\n",
      "\tLoss: 0.12738391757011414\n",
      "\tLoss: 0.14619562029838562\n",
      "\tLoss: 0.11184369772672653\n",
      "\tLoss: 0.0803225189447403\n",
      "\tLoss: 0.14266881346702576\n",
      "\tLoss: 0.11518207937479019\n",
      "\tLoss: 0.09230291843414307\n",
      "\tLoss: 0.07866200804710388\n",
      "\tLoss: 0.08781284838914871\n",
      "\tLoss: 0.10497500002384186\n",
      "\tLoss: 0.07637465000152588\n",
      "\tLoss: 0.12542326748371124\n",
      "\tLoss: 0.13962861895561218\n",
      "\tLoss: 0.10525470972061157\n",
      "\tLoss: 0.10601125657558441\n",
      "\tLoss: 0.1139514222741127\n",
      "\tLoss: 0.0795682817697525\n",
      "\tLoss: 0.1289554089307785\n",
      "\tLoss: 0.09289594739675522\n",
      "\tLoss: 0.11895884573459625\n",
      "\tLoss: 0.11013814061880112\n",
      "\tLoss: 0.08990586549043655\n",
      "\tLoss: 0.13286641240119934\n",
      "\tLoss: 0.11817682534456253\n",
      "\tLoss: 0.1550973653793335\n",
      "\tLoss: 0.08817306160926819\n",
      "\tLoss: 0.10745535790920258\n",
      "\tLoss: 0.1210019588470459\n",
      "\tLoss: 0.09839767217636108\n",
      "\tLoss: 0.07753148674964905\n",
      "\tLoss: 0.1290486603975296\n",
      "\tLoss: 0.15093722939491272\n",
      "[time] Epoch 40: 420.40123563678935s = 7.006687260613156m\n",
      "\n",
      "Epoch 41...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.09900324046611786\n",
      "\tLoss: 0.13537484407424927\n",
      "\tLoss: 0.13527613878250122\n",
      "\tLoss: 0.09976512938737869\n",
      "\tLoss: 0.14703355729579926\n",
      "\tLoss: 0.10564135015010834\n",
      "\tLoss: 0.12172726541757584\n",
      "\tLoss: 0.07435546815395355\n",
      "\tLoss: 0.10876686871051788\n",
      "\tLoss: 0.13441678881645203\n",
      "\tLoss: 0.08632852137088776\n",
      "\tLoss: 0.1111757829785347\n",
      "\tLoss: 0.07258717715740204\n",
      "\tLoss: 0.0776970386505127\n",
      "\tLoss: 0.09781759977340698\n",
      "\tLoss: 0.15413811802864075\n",
      "\tLoss: 0.12615150213241577\n",
      "\tLoss: 0.12089431285858154\n",
      "\tLoss: 0.1298820674419403\n",
      "\tLoss: 0.08275749534368515\n",
      "\tLoss: 0.0801125168800354\n",
      "\tLoss: 0.11537811160087585\n",
      "\tLoss: 0.08384707570075989\n",
      "\tLoss: 0.13744576275348663\n",
      "\tLoss: 0.1259917914867401\n",
      "\tLoss: 0.0829949826002121\n",
      "\tLoss: 0.11917801201343536\n",
      "\tLoss: 0.08945932984352112\n",
      "\tLoss: 0.09122218191623688\n",
      "\tLoss: 0.07950245589017868\n",
      "\tLoss: 0.10934717208147049\n",
      "\tLoss: 0.16599509119987488\n",
      "\tLoss: 0.10883885622024536\n",
      "\tLoss: 0.09914709627628326\n",
      "\tLoss: 0.11257851868867874\n",
      "\tLoss: 0.0851445272564888\n",
      "\tLoss: 0.11543308198451996\n",
      "\tLoss: 0.11238762736320496\n",
      "\tLoss: 0.09123660624027252\n",
      "\tLoss: 0.08675326406955719\n",
      "\tLoss: 0.13303790986537933\n",
      "\tLoss: 0.08768857270479202\n",
      "\tLoss: 0.09686978906393051\n",
      "\tLoss: 0.1369561105966568\n",
      "\tLoss: 0.11833476275205612\n",
      "\tLoss: 0.10602442920207977\n",
      "\tLoss: 0.07960934937000275\n",
      "\tLoss: 0.12479446828365326\n",
      "\tLoss: 0.12003985047340393\n",
      "\tLoss: 0.05908587574958801\n",
      "\tLoss: 0.12541024386882782\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.08763520419597626\n",
      "\tLoss: 0.12191607058048248\n",
      "\tLoss: 0.07915322482585907\n",
      "\tLoss: 0.1118137389421463\n",
      "\tLoss: 0.08998502790927887\n",
      "\tLoss: 0.12182728946208954\n",
      "\tLoss: 0.10359007120132446\n",
      "\tLoss: 0.11565353721380234\n",
      "\tLoss: 0.08563967049121857\n",
      "\tLoss: 0.14552615582942963\n",
      "\tLoss: 0.07486803084611893\n",
      "\tLoss: 0.13696305453777313\n",
      "\tLoss: 0.07762791216373444\n",
      "\tLoss: 0.10602578520774841\n",
      "\tLoss: 0.08764651417732239\n",
      "\tLoss: 0.10501469671726227\n",
      "\tLoss: 0.08106173574924469\n",
      "\tLoss: 0.11477508395910263\n",
      "\tLoss: 0.0728839859366417\n",
      "\tLoss: 0.10047461092472076\n",
      "\tLoss: 0.10534249991178513\n",
      "\tLoss: 0.12118040770292282\n",
      "\tLoss: 0.07863569259643555\n",
      "\tLoss: 0.1334741860628128\n",
      "\tLoss: 0.08927582204341888\n",
      "\tLoss: 0.12284919619560242\n",
      "\tLoss: 0.08340738713741302\n",
      "\tLoss: 0.11518394201993942\n",
      "\tLoss: 0.07951078563928604\n",
      "\tLoss: 0.12471563369035721\n",
      "\tLoss: 0.12346918135881424\n",
      "\tLoss: 0.07289696484804153\n",
      "\tLoss: 0.09457136690616608\n",
      "\tLoss: 0.12492671608924866\n",
      "\tLoss: 0.11251284182071686\n",
      "\tLoss: 0.1355808675289154\n",
      "\tLoss: 0.07386904954910278\n",
      "\tLoss: 0.11529579758644104\n",
      "\tLoss: 0.13991940021514893\n",
      "\tLoss: 0.13066667318344116\n",
      "\tLoss: 0.13423830270767212\n",
      "\tLoss: 0.07165370881557465\n",
      "\tLoss: 0.0910000205039978\n",
      "\tLoss: 0.12278210371732712\n",
      "\tLoss: 0.0899440348148346\n",
      "\tLoss: 0.06325902044773102\n",
      "\tLoss: 0.16042670607566833\n",
      "\tLoss: 0.1200932189822197\n",
      "\tLoss: 0.06801918894052505\n",
      "\tLoss: 0.10870242118835449\n",
      "\tLoss: 0.1204625591635704\n",
      "[time] Epoch 41: 416.4679284892045s = 6.941132141486742m\n",
      "\n",
      "Epoch 42...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.13473142683506012\n",
      "\tLoss: 0.06507200002670288\n",
      "\tLoss: 0.1061239019036293\n",
      "\tLoss: 0.10731714963912964\n",
      "\tLoss: 0.09090694785118103\n",
      "\tLoss: 0.14770105481147766\n",
      "\tLoss: 0.10976916551589966\n",
      "\tLoss: 0.08820224553346634\n",
      "\tLoss: 0.08754642307758331\n",
      "\tLoss: 0.09302979707717896\n",
      "\tLoss: 0.12047085165977478\n",
      "\tLoss: 0.1257341355085373\n",
      "\tLoss: 0.13030892610549927\n",
      "\tLoss: 0.12627382576465607\n",
      "\tLoss: 0.13627776503562927\n",
      "\tLoss: 0.09475868195295334\n",
      "\tLoss: 0.08522728830575943\n",
      "\tLoss: 0.08189455419778824\n",
      "\tLoss: 0.10607985407114029\n",
      "\tLoss: 0.12301167100667953\n",
      "\tLoss: 0.14098218083381653\n",
      "\tLoss: 0.09405970573425293\n",
      "\tLoss: 0.08122804760932922\n",
      "\tLoss: 0.11151540279388428\n",
      "\tLoss: 0.07098351418972015\n",
      "\tLoss: 0.10597073286771774\n",
      "\tLoss: 0.11921814829111099\n",
      "\tLoss: 0.09600073099136353\n",
      "\tLoss: 0.11998745799064636\n",
      "\tLoss: 0.1105869710445404\n",
      "\tLoss: 0.09746395796537399\n",
      "\tLoss: 0.1089095026254654\n",
      "\tLoss: 0.09221906214952469\n",
      "\tLoss: 0.14161831140518188\n",
      "\tLoss: 0.09846934676170349\n",
      "\tLoss: 0.10482706129550934\n",
      "\tLoss: 0.06999543309211731\n",
      "\tLoss: 0.13155971467494965\n",
      "\tLoss: 0.07084465026855469\n",
      "\tLoss: 0.11694613099098206\n",
      "\tLoss: 0.12280480563640594\n",
      "\tLoss: 0.09248872846364975\n",
      "\tLoss: 0.08111155033111572\n",
      "\tLoss: 0.11185495555400848\n",
      "\tLoss: 0.12482807040214539\n",
      "\tLoss: 0.062464646995067596\n",
      "\tLoss: 0.10237766802310944\n",
      "\tLoss: 0.11536052823066711\n",
      "\tLoss: 0.07039765268564224\n",
      "\tLoss: 0.09661564230918884\n",
      "\tLoss: 0.14428934454917908\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.15495818853378296\n",
      "\tLoss: 0.12038769572973251\n",
      "\tLoss: 0.10462900996208191\n",
      "\tLoss: 0.09969937056303024\n",
      "\tLoss: 0.10953188687562943\n",
      "\tLoss: 0.10833300650119781\n",
      "\tLoss: 0.09315057098865509\n",
      "\tLoss: 0.1340366005897522\n",
      "\tLoss: 0.0986856147646904\n",
      "\tLoss: 0.090823233127594\n",
      "\tLoss: 0.1339331567287445\n",
      "\tLoss: 0.12223410606384277\n",
      "\tLoss: 0.12032590806484222\n",
      "\tLoss: 0.11466824263334274\n",
      "\tLoss: 0.13756400346755981\n",
      "\tLoss: 0.11662764847278595\n",
      "\tLoss: 0.07902738451957703\n",
      "\tLoss: 0.08352574706077576\n",
      "\tLoss: 0.10148658603429794\n",
      "\tLoss: 0.1158219650387764\n",
      "\tLoss: 0.10737401247024536\n",
      "\tLoss: 0.11000889539718628\n",
      "\tLoss: 0.12210866808891296\n",
      "\tLoss: 0.09822508692741394\n",
      "\tLoss: 0.07360994070768356\n",
      "\tLoss: 0.08182211220264435\n",
      "\tLoss: 0.11239008605480194\n",
      "\tLoss: 0.10613665729761124\n",
      "\tLoss: 0.10804840177297592\n",
      "\tLoss: 0.09802903980016708\n",
      "\tLoss: 0.1408700793981552\n",
      "\tLoss: 0.09455780684947968\n",
      "\tLoss: 0.1215725913643837\n",
      "\tLoss: 0.1521407961845398\n",
      "\tLoss: 0.08458208292722702\n",
      "\tLoss: 0.12232886254787445\n",
      "\tLoss: 0.07447090744972229\n",
      "\tLoss: 0.0742403194308281\n",
      "\tLoss: 0.11094741523265839\n",
      "\tLoss: 0.11842066049575806\n",
      "\tLoss: 0.1237831860780716\n",
      "\tLoss: 0.09103338420391083\n",
      "\tLoss: 0.14003238081932068\n",
      "\tLoss: 0.1232469230890274\n",
      "\tLoss: 0.12052375078201294\n",
      "\tLoss: 0.12970606982707977\n",
      "\tLoss: 0.07454239577054977\n",
      "\tLoss: 0.11148391664028168\n",
      "\tLoss: 0.11218729615211487\n",
      "\tLoss: 0.11442530155181885\n",
      "\tLoss: 0.1010291576385498\n",
      "[time] Epoch 42: 422.2473029727116s = 7.037455049545193m\n",
      "\n",
      "Epoch 43...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.15538537502288818\n",
      "\tLoss: 0.14088734984397888\n",
      "\tLoss: 0.1128697469830513\n",
      "\tLoss: 0.09446080029010773\n",
      "\tLoss: 0.11100217700004578\n",
      "\tLoss: 0.10544890910387039\n",
      "\tLoss: 0.13626500964164734\n",
      "\tLoss: 0.1266624927520752\n",
      "\tLoss: 0.07942640781402588\n",
      "\tLoss: 0.15315893292427063\n",
      "\tLoss: 0.08732283860445023\n",
      "\tLoss: 0.05983272194862366\n",
      "\tLoss: 0.10967765748500824\n",
      "\tLoss: 0.1803746223449707\n",
      "\tLoss: 0.13192623853683472\n",
      "\tLoss: 0.12317434698343277\n",
      "\tLoss: 0.1254102885723114\n",
      "\tLoss: 0.13705377280712128\n",
      "\tLoss: 0.11828687787055969\n",
      "\tLoss: 0.09205836057662964\n",
      "\tLoss: 0.09897701442241669\n",
      "\tLoss: 0.08963663876056671\n",
      "\tLoss: 0.09600269794464111\n",
      "\tLoss: 0.1037570983171463\n",
      "\tLoss: 0.11667011678218842\n",
      "\tLoss: 0.09422231465578079\n",
      "\tLoss: 0.1060875952243805\n",
      "\tLoss: 0.13458764553070068\n",
      "\tLoss: 0.17120271921157837\n",
      "\tLoss: 0.09723534435033798\n",
      "\tLoss: 0.12975384294986725\n",
      "\tLoss: 0.08643724024295807\n",
      "\tLoss: 0.10254473984241486\n",
      "\tLoss: 0.061647798866033554\n",
      "\tLoss: 0.06592272222042084\n",
      "\tLoss: 0.10261993855237961\n",
      "\tLoss: 0.11946187913417816\n",
      "\tLoss: 0.08713538199663162\n",
      "\tLoss: 0.06401457637548447\n",
      "\tLoss: 0.10512484610080719\n",
      "\tLoss: 0.13524389266967773\n",
      "\tLoss: 0.09051115810871124\n",
      "\tLoss: 0.09793828427791595\n",
      "\tLoss: 0.100692518055439\n",
      "\tLoss: 0.08770093321800232\n",
      "\tLoss: 0.1435241997241974\n",
      "\tLoss: 0.11542730778455734\n",
      "\tLoss: 0.10450983047485352\n",
      "\tLoss: 0.0970696359872818\n",
      "\tLoss: 0.10493205487728119\n",
      "\tLoss: 0.12253246456384659\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.0978766530752182\n",
      "\tLoss: 0.13417018949985504\n",
      "\tLoss: 0.11177276819944382\n",
      "\tLoss: 0.08108052611351013\n",
      "\tLoss: 0.12440675497055054\n",
      "\tLoss: 0.0970529317855835\n",
      "\tLoss: 0.08651243150234222\n",
      "\tLoss: 0.10217572748661041\n",
      "\tLoss: 0.08979876339435577\n",
      "\tLoss: 0.12391147017478943\n",
      "\tLoss: 0.15571679174900055\n",
      "\tLoss: 0.09738761186599731\n",
      "\tLoss: 0.09600265324115753\n",
      "\tLoss: 0.08123183250427246\n",
      "\tLoss: 0.1356254518032074\n",
      "\tLoss: 0.10703988373279572\n",
      "\tLoss: 0.08724119514226913\n",
      "\tLoss: 0.09542044997215271\n",
      "\tLoss: 0.14322611689567566\n",
      "\tLoss: 0.11595581471920013\n",
      "\tLoss: 0.1209019124507904\n",
      "\tLoss: 0.09292852878570557\n",
      "\tLoss: 0.11995614320039749\n",
      "\tLoss: 0.11741235852241516\n",
      "\tLoss: 0.0829417034983635\n",
      "\tLoss: 0.07731124013662338\n",
      "\tLoss: 0.10361252725124359\n",
      "\tLoss: 0.12339987605810165\n",
      "\tLoss: 0.09657019376754761\n",
      "\tLoss: 0.11770007014274597\n",
      "\tLoss: 0.10698608309030533\n",
      "\tLoss: 0.08746083080768585\n",
      "\tLoss: 0.09145088493824005\n",
      "\tLoss: 0.08455093204975128\n",
      "\tLoss: 0.09274262189865112\n",
      "\tLoss: 0.09088262915611267\n",
      "\tLoss: 0.13297873735427856\n",
      "\tLoss: 0.13176904618740082\n",
      "\tLoss: 0.13444015383720398\n",
      "\tLoss: 0.09859156608581543\n",
      "\tLoss: 0.13049188256263733\n",
      "\tLoss: 0.14933541417121887\n",
      "\tLoss: 0.09558038413524628\n",
      "\tLoss: 0.11795340478420258\n",
      "\tLoss: 0.10050152987241745\n",
      "\tLoss: 0.07204071432352066\n",
      "\tLoss: 0.12608306109905243\n",
      "\tLoss: 0.0848260223865509\n",
      "\tLoss: 0.10384158790111542\n",
      "\tLoss: 0.15358151495456696\n",
      "\tLoss: 0.1356334090232849\n",
      "[time] Epoch 43: 421.73547083325684s = 7.028924513887614m\n",
      "\n",
      "Epoch 44...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1252269744873047\n",
      "\tLoss: 0.13514366745948792\n",
      "\tLoss: 0.09953999519348145\n",
      "\tLoss: 0.12755164504051208\n",
      "\tLoss: 0.11781753599643707\n",
      "\tLoss: 0.06586163491010666\n",
      "\tLoss: 0.09483947604894638\n",
      "\tLoss: 0.09381382167339325\n",
      "\tLoss: 0.09912309050559998\n",
      "\tLoss: 0.11161285638809204\n",
      "\tLoss: 0.10456918925046921\n",
      "\tLoss: 0.10300998389720917\n",
      "\tLoss: 0.10880552977323532\n",
      "\tLoss: 0.07484494894742966\n",
      "\tLoss: 0.10149939358234406\n",
      "\tLoss: 0.12195215374231339\n",
      "\tLoss: 0.10044799745082855\n",
      "\tLoss: 0.09055858850479126\n",
      "\tLoss: 0.08818703144788742\n",
      "\tLoss: 0.1030493974685669\n",
      "\tLoss: 0.1187906563282013\n",
      "\tLoss: 0.11777578294277191\n",
      "\tLoss: 0.06116398051381111\n",
      "\tLoss: 0.10268829017877579\n",
      "\tLoss: 0.09535934031009674\n",
      "\tLoss: 0.09957364201545715\n",
      "\tLoss: 0.11947198212146759\n",
      "\tLoss: 0.1089543029665947\n",
      "\tLoss: 0.1352633237838745\n",
      "\tLoss: 0.14908519387245178\n",
      "\tLoss: 0.14260005950927734\n",
      "\tLoss: 0.09588256478309631\n",
      "\tLoss: 0.12318725883960724\n",
      "\tLoss: 0.13650120794773102\n",
      "\tLoss: 0.08449260145425797\n",
      "\tLoss: 0.16035300493240356\n",
      "\tLoss: 0.1162862777709961\n",
      "\tLoss: 0.11519122868776321\n",
      "\tLoss: 0.12755431234836578\n",
      "\tLoss: 0.11096985638141632\n",
      "\tLoss: 0.1631532609462738\n",
      "\tLoss: 0.15875867009162903\n",
      "\tLoss: 0.14803564548492432\n",
      "\tLoss: 0.0817328616976738\n",
      "\tLoss: 0.07277580350637436\n",
      "\tLoss: 0.10157527029514313\n",
      "\tLoss: 0.09955339878797531\n",
      "\tLoss: 0.1165570542216301\n",
      "\tLoss: 0.07126473635435104\n",
      "\tLoss: 0.09523797780275345\n",
      "\tLoss: 0.0812448039650917\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.12733793258666992\n",
      "\tLoss: 0.10869697481393814\n",
      "\tLoss: 0.13320283591747284\n",
      "\tLoss: 0.10208815336227417\n",
      "\tLoss: 0.15955257415771484\n",
      "\tLoss: 0.08979681879281998\n",
      "\tLoss: 0.12134853005409241\n",
      "\tLoss: 0.1004662960767746\n",
      "\tLoss: 0.10563641786575317\n",
      "\tLoss: 0.07458600401878357\n",
      "\tLoss: 0.10671121627092361\n",
      "\tLoss: 0.1014794111251831\n",
      "\tLoss: 0.09515086561441422\n",
      "\tLoss: 0.10177581012248993\n",
      "\tLoss: 0.0895954817533493\n",
      "\tLoss: 0.05710413306951523\n",
      "\tLoss: 0.08214236795902252\n",
      "\tLoss: 0.09853700548410416\n",
      "\tLoss: 0.1160084530711174\n",
      "\tLoss: 0.10489655286073685\n",
      "\tLoss: 0.11916325986385345\n",
      "\tLoss: 0.10923495888710022\n",
      "\tLoss: 0.08530046045780182\n",
      "\tLoss: 0.11465632915496826\n",
      "\tLoss: 0.12085384130477905\n",
      "\tLoss: 0.10372649878263474\n",
      "\tLoss: 0.09542232751846313\n",
      "\tLoss: 0.08914020657539368\n",
      "\tLoss: 0.07504516839981079\n",
      "\tLoss: 0.11568547785282135\n",
      "\tLoss: 0.09198150038719177\n",
      "\tLoss: 0.10211862623691559\n",
      "\tLoss: 0.10313985496759415\n",
      "\tLoss: 0.056866806000471115\n",
      "\tLoss: 0.07266424596309662\n",
      "\tLoss: 0.06602361798286438\n",
      "\tLoss: 0.09608101844787598\n",
      "\tLoss: 0.1029975563287735\n",
      "\tLoss: 0.1157759502530098\n",
      "\tLoss: 0.1187858134508133\n",
      "\tLoss: 0.1021861881017685\n",
      "\tLoss: 0.14601010084152222\n",
      "\tLoss: 0.09569120407104492\n",
      "\tLoss: 0.11274486780166626\n",
      "\tLoss: 0.08967671543359756\n",
      "\tLoss: 0.10108387470245361\n",
      "\tLoss: 0.10870218276977539\n",
      "\tLoss: 0.08543480187654495\n",
      "\tLoss: 0.14505353569984436\n",
      "\tLoss: 0.12292960286140442\n",
      "\tLoss: 0.1109202653169632\n",
      "[time] Epoch 44: 419.53364494489506s = 6.992227415748251m\n",
      "\n",
      "Epoch 45...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.10539107769727707\n",
      "\tLoss: 0.08906327188014984\n",
      "\tLoss: 0.1230943575501442\n",
      "\tLoss: 0.11944118142127991\n",
      "\tLoss: 0.09447278082370758\n",
      "\tLoss: 0.09688937664031982\n",
      "\tLoss: 0.08906763792037964\n",
      "\tLoss: 0.07196060568094254\n",
      "\tLoss: 0.08223368227481842\n",
      "\tLoss: 0.10063697397708893\n",
      "\tLoss: 0.09692205488681793\n",
      "\tLoss: 0.13357846438884735\n",
      "\tLoss: 0.10600951313972473\n",
      "\tLoss: 0.07423685491085052\n",
      "\tLoss: 0.09203873574733734\n",
      "\tLoss: 0.07917013764381409\n",
      "\tLoss: 0.12665389478206635\n",
      "\tLoss: 0.09915333241224289\n",
      "\tLoss: 0.08726294338703156\n",
      "\tLoss: 0.07273735851049423\n",
      "\tLoss: 0.08193270862102509\n",
      "\tLoss: 0.09234163910150528\n",
      "\tLoss: 0.16223827004432678\n",
      "\tLoss: 0.09151323139667511\n",
      "\tLoss: 0.1291384994983673\n",
      "\tLoss: 0.12228289246559143\n",
      "\tLoss: 0.14403560757637024\n",
      "\tLoss: 0.10521901398897171\n",
      "\tLoss: 0.1086912676692009\n",
      "\tLoss: 0.10039548575878143\n",
      "\tLoss: 0.09820518642663956\n",
      "\tLoss: 0.09475985169410706\n",
      "\tLoss: 0.12962839007377625\n",
      "\tLoss: 0.14124447107315063\n",
      "\tLoss: 0.10411810874938965\n",
      "\tLoss: 0.13339127600193024\n",
      "\tLoss: 0.12733329832553864\n",
      "\tLoss: 0.11810901015996933\n",
      "\tLoss: 0.07339201867580414\n",
      "\tLoss: 0.0999876856803894\n",
      "\tLoss: 0.11717670410871506\n",
      "\tLoss: 0.09942834824323654\n",
      "\tLoss: 0.08682984858751297\n",
      "\tLoss: 0.13656085729599\n",
      "\tLoss: 0.14018790423870087\n",
      "\tLoss: 0.12374161183834076\n",
      "\tLoss: 0.08942078799009323\n",
      "\tLoss: 0.0543731264770031\n",
      "\tLoss: 0.1362900733947754\n",
      "\tLoss: 0.106364406645298\n",
      "\tLoss: 0.06955726444721222\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.17581596970558167\n",
      "\tLoss: 0.0818406492471695\n",
      "\tLoss: 0.09296128153800964\n",
      "\tLoss: 0.10916294902563095\n",
      "\tLoss: 0.09237071871757507\n",
      "\tLoss: 0.13789671659469604\n",
      "\tLoss: 0.10729210823774338\n",
      "\tLoss: 0.07000412046909332\n",
      "\tLoss: 0.08803984522819519\n",
      "\tLoss: 0.1440320611000061\n",
      "\tLoss: 0.1437506526708603\n",
      "\tLoss: 0.07948443293571472\n",
      "\tLoss: 0.11691820621490479\n",
      "\tLoss: 0.08743153512477875\n",
      "\tLoss: 0.08791817724704742\n",
      "\tLoss: 0.10434133559465408\n",
      "\tLoss: 0.11140237748622894\n",
      "\tLoss: 0.08265352249145508\n",
      "\tLoss: 0.1126926988363266\n",
      "\tLoss: 0.0953737422823906\n",
      "\tLoss: 0.11146356165409088\n",
      "\tLoss: 0.1083819568157196\n",
      "\tLoss: 0.1311960220336914\n",
      "\tLoss: 0.08838477730751038\n",
      "\tLoss: 0.15718302130699158\n",
      "\tLoss: 0.09771960973739624\n",
      "\tLoss: 0.10785914957523346\n",
      "\tLoss: 0.11870930343866348\n",
      "\tLoss: 0.09903584420681\n",
      "\tLoss: 0.06435467302799225\n",
      "\tLoss: 0.11060236394405365\n",
      "\tLoss: 0.08542585372924805\n",
      "\tLoss: 0.11581988632678986\n",
      "\tLoss: 0.14492923021316528\n",
      "\tLoss: 0.0693419873714447\n",
      "\tLoss: 0.15091556310653687\n",
      "\tLoss: 0.08361423015594482\n",
      "\tLoss: 0.07826577126979828\n",
      "\tLoss: 0.09439373016357422\n",
      "\tLoss: 0.13559789955615997\n",
      "\tLoss: 0.08549913763999939\n",
      "\tLoss: 0.1366802155971527\n",
      "\tLoss: 0.12471529096364975\n",
      "\tLoss: 0.0904575064778328\n",
      "\tLoss: 0.06787864863872528\n",
      "\tLoss: 0.1670455038547516\n",
      "\tLoss: 0.12392671406269073\n",
      "\tLoss: 0.10342314839363098\n",
      "\tLoss: 0.09538008272647858\n",
      "\tLoss: 0.14489375054836273\n",
      "\tLoss: 0.08969226479530334\n",
      "[time] Epoch 45: 418.88649939000607s = 6.981441656500101m\n",
      "\n",
      "Epoch 46...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.09638532996177673\n",
      "\tLoss: 0.08466599881649017\n",
      "\tLoss: 0.12403554469347\n",
      "\tLoss: 0.10032561421394348\n",
      "\tLoss: 0.15555626153945923\n",
      "\tLoss: 0.07260163128376007\n",
      "\tLoss: 0.10037648677825928\n",
      "\tLoss: 0.13730382919311523\n",
      "\tLoss: 0.09037783741950989\n",
      "\tLoss: 0.09640486538410187\n",
      "\tLoss: 0.11438828706741333\n",
      "\tLoss: 0.10262034088373184\n",
      "\tLoss: 0.09603828936815262\n",
      "\tLoss: 0.10370713472366333\n",
      "\tLoss: 0.10909886658191681\n",
      "\tLoss: 0.07152403891086578\n",
      "\tLoss: 0.1060982197523117\n",
      "\tLoss: 0.11270658671855927\n",
      "\tLoss: 0.12749448418617249\n",
      "\tLoss: 0.11601428687572479\n",
      "\tLoss: 0.07969522476196289\n",
      "\tLoss: 0.09103849530220032\n",
      "\tLoss: 0.09308436512947083\n",
      "\tLoss: 0.11432316154241562\n",
      "\tLoss: 0.11369836330413818\n",
      "\tLoss: 0.11335157603025436\n",
      "\tLoss: 0.12931180000305176\n",
      "\tLoss: 0.11791159212589264\n",
      "\tLoss: 0.06800878047943115\n",
      "\tLoss: 0.12453246861696243\n",
      "\tLoss: 0.059497322887182236\n",
      "\tLoss: 0.13168957829475403\n",
      "\tLoss: 0.09080573916435242\n",
      "\tLoss: 0.09468486905097961\n",
      "\tLoss: 0.10203765332698822\n",
      "\tLoss: 0.1438317447900772\n",
      "\tLoss: 0.1185070127248764\n",
      "\tLoss: 0.11705254763364792\n",
      "\tLoss: 0.15202808380126953\n",
      "\tLoss: 0.07216233015060425\n",
      "\tLoss: 0.09746567159891129\n",
      "\tLoss: 0.0872829332947731\n",
      "\tLoss: 0.12811970710754395\n",
      "\tLoss: 0.12072835862636566\n",
      "\tLoss: 0.1154470443725586\n",
      "\tLoss: 0.08691681921482086\n",
      "\tLoss: 0.0981183648109436\n",
      "\tLoss: 0.07388832420110703\n",
      "\tLoss: 0.12210683524608612\n",
      "\tLoss: 0.06033385172486305\n",
      "\tLoss: 0.11165180802345276\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.12923625111579895\n",
      "\tLoss: 0.13952142000198364\n",
      "\tLoss: 0.06312555819749832\n",
      "\tLoss: 0.14652429521083832\n",
      "\tLoss: 0.12847140431404114\n",
      "\tLoss: 0.10126683115959167\n",
      "\tLoss: 0.1081039160490036\n",
      "\tLoss: 0.1005818247795105\n",
      "\tLoss: 0.10158967971801758\n",
      "\tLoss: 0.11777907609939575\n",
      "\tLoss: 0.11252865195274353\n",
      "\tLoss: 0.10974577069282532\n",
      "\tLoss: 0.11851396411657333\n",
      "\tLoss: 0.0896817222237587\n",
      "\tLoss: 0.08796374499797821\n",
      "\tLoss: 0.11058540642261505\n",
      "\tLoss: 0.08985123783349991\n",
      "\tLoss: 0.07524651288986206\n",
      "\tLoss: 0.08795709908008575\n",
      "\tLoss: 0.09118860214948654\n",
      "\tLoss: 0.08911178261041641\n",
      "\tLoss: 0.1373964548110962\n",
      "\tLoss: 0.10655135661363602\n",
      "\tLoss: 0.10636796057224274\n",
      "\tLoss: 0.09197880327701569\n",
      "\tLoss: 0.07556227594614029\n",
      "\tLoss: 0.12658129632472992\n",
      "\tLoss: 0.10250318050384521\n",
      "\tLoss: 0.12721550464630127\n",
      "\tLoss: 0.07282453775405884\n",
      "\tLoss: 0.09402108192443848\n",
      "\tLoss: 0.09497140347957611\n",
      "\tLoss: 0.09196193516254425\n",
      "\tLoss: 0.10915903002023697\n",
      "\tLoss: 0.09379822015762329\n",
      "\tLoss: 0.10616548359394073\n",
      "\tLoss: 0.08320551365613937\n",
      "\tLoss: 0.10743942856788635\n",
      "\tLoss: 0.08394096791744232\n",
      "\tLoss: 0.10369738936424255\n",
      "\tLoss: 0.11922119557857513\n",
      "\tLoss: 0.11967764794826508\n",
      "\tLoss: 0.14388340711593628\n",
      "\tLoss: 0.061831213533878326\n",
      "\tLoss: 0.12101708352565765\n",
      "\tLoss: 0.12006618082523346\n",
      "\tLoss: 0.13524214923381805\n",
      "\tLoss: 0.14951187372207642\n",
      "\tLoss: 0.08272019773721695\n",
      "\tLoss: 0.11011208593845367\n",
      "\tLoss: 0.06819979846477509\n",
      "[time] Epoch 46: 423.00349336490035s = 7.050058222748339m\n",
      "\n",
      "Epoch 47...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.13114973902702332\n",
      "\tLoss: 0.12436740100383759\n",
      "\tLoss: 0.1173655092716217\n",
      "\tLoss: 0.10516110062599182\n",
      "\tLoss: 0.08599348366260529\n",
      "\tLoss: 0.10020656138658524\n",
      "\tLoss: 0.11156140267848969\n",
      "\tLoss: 0.13713406026363373\n",
      "\tLoss: 0.134844571352005\n",
      "\tLoss: 0.0940292477607727\n",
      "\tLoss: 0.10490088909864426\n",
      "\tLoss: 0.1134008839726448\n",
      "\tLoss: 0.07799806445837021\n",
      "\tLoss: 0.11499734222888947\n",
      "\tLoss: 0.07738594710826874\n",
      "\tLoss: 0.10143274068832397\n",
      "\tLoss: 0.09348127245903015\n",
      "\tLoss: 0.10816875100135803\n",
      "\tLoss: 0.08299994468688965\n",
      "\tLoss: 0.08378241211175919\n",
      "\tLoss: 0.07853490859270096\n",
      "\tLoss: 0.07754699885845184\n",
      "\tLoss: 0.08687402307987213\n",
      "\tLoss: 0.13117223978042603\n",
      "\tLoss: 0.13252580165863037\n",
      "\tLoss: 0.06629271805286407\n",
      "\tLoss: 0.14225387573242188\n",
      "\tLoss: 0.09934606403112411\n",
      "\tLoss: 0.106864333152771\n",
      "\tLoss: 0.12493301182985306\n",
      "\tLoss: 0.0853835865855217\n",
      "\tLoss: 0.1394989788532257\n",
      "\tLoss: 0.10715881735086441\n",
      "\tLoss: 0.07860016822814941\n",
      "\tLoss: 0.07245206832885742\n",
      "\tLoss: 0.1010546088218689\n",
      "\tLoss: 0.10308511555194855\n",
      "\tLoss: 0.13535474240779877\n",
      "\tLoss: 0.1120823323726654\n",
      "\tLoss: 0.08428682386875153\n",
      "\tLoss: 0.07953311502933502\n",
      "\tLoss: 0.08892077207565308\n",
      "\tLoss: 0.087023064494133\n",
      "\tLoss: 0.09028024226427078\n",
      "\tLoss: 0.10906431078910828\n",
      "\tLoss: 0.12908819317817688\n",
      "\tLoss: 0.11251989006996155\n",
      "\tLoss: 0.12281538546085358\n",
      "\tLoss: 0.10078158229589462\n",
      "\tLoss: 0.08755020797252655\n",
      "\tLoss: 0.11402510851621628\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.09427947551012039\n",
      "\tLoss: 0.08694444596767426\n",
      "\tLoss: 0.06660425662994385\n",
      "\tLoss: 0.10649217665195465\n",
      "\tLoss: 0.07857191562652588\n",
      "\tLoss: 0.10120901465415955\n",
      "\tLoss: 0.10574851930141449\n",
      "\tLoss: 0.09396687150001526\n",
      "\tLoss: 0.09611300379037857\n",
      "\tLoss: 0.1277538537979126\n",
      "\tLoss: 0.09277345985174179\n",
      "\tLoss: 0.125594824552536\n",
      "\tLoss: 0.07886749505996704\n",
      "\tLoss: 0.09919548034667969\n",
      "\tLoss: 0.10554252564907074\n",
      "\tLoss: 0.1238337904214859\n",
      "\tLoss: 0.09185713529586792\n",
      "\tLoss: 0.10710810124874115\n",
      "\tLoss: 0.09626705944538116\n",
      "\tLoss: 0.10718531161546707\n",
      "\tLoss: 0.079985111951828\n",
      "\tLoss: 0.13071471452713013\n",
      "\tLoss: 0.1300487220287323\n",
      "\tLoss: 0.0893111526966095\n",
      "\tLoss: 0.09520073235034943\n",
      "\tLoss: 0.11036549508571625\n",
      "\tLoss: 0.10957563668489456\n",
      "\tLoss: 0.11224795877933502\n",
      "\tLoss: 0.145199254155159\n",
      "\tLoss: 0.07993058860301971\n",
      "\tLoss: 0.1290052980184555\n",
      "\tLoss: 0.13173288106918335\n",
      "\tLoss: 0.06657925248146057\n",
      "\tLoss: 0.1314047873020172\n",
      "\tLoss: 0.07051540911197662\n",
      "\tLoss: 0.10955825448036194\n",
      "\tLoss: 0.10857757925987244\n",
      "\tLoss: 0.11543077230453491\n",
      "\tLoss: 0.12647582590579987\n",
      "\tLoss: 0.11009290814399719\n",
      "\tLoss: 0.12034891545772552\n",
      "\tLoss: 0.12316285073757172\n",
      "\tLoss: 0.09237175434827805\n",
      "\tLoss: 0.10769058763980865\n",
      "\tLoss: 0.1589868813753128\n",
      "\tLoss: 0.07991037517786026\n",
      "\tLoss: 0.14329220354557037\n",
      "\tLoss: 0.0835699588060379\n",
      "\tLoss: 0.07816606760025024\n",
      "\tLoss: 0.14591704308986664\n",
      "\tLoss: 0.07940469682216644\n",
      "[time] Epoch 47: 420.25634416518733s = 7.004272402753122m\n",
      "\n",
      "Epoch 48...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.10978206247091293\n",
      "\tLoss: 0.11865553259849548\n",
      "\tLoss: 0.1282806396484375\n",
      "\tLoss: 0.1090216189622879\n",
      "\tLoss: 0.11858247220516205\n",
      "\tLoss: 0.04734991863369942\n",
      "\tLoss: 0.06721656024456024\n",
      "\tLoss: 0.07741566002368927\n",
      "\tLoss: 0.09378476440906525\n",
      "\tLoss: 0.08083470165729523\n",
      "\tLoss: 0.0974702537059784\n",
      "\tLoss: 0.08819320052862167\n",
      "\tLoss: 0.1154332160949707\n",
      "\tLoss: 0.08921483904123306\n",
      "\tLoss: 0.10007132589817047\n",
      "\tLoss: 0.12103185802698135\n",
      "\tLoss: 0.09062502533197403\n",
      "\tLoss: 0.11627212166786194\n",
      "\tLoss: 0.08632053434848785\n",
      "\tLoss: 0.15733516216278076\n",
      "\tLoss: 0.11547283828258514\n",
      "\tLoss: 0.10102207213640213\n",
      "\tLoss: 0.14034783840179443\n",
      "\tLoss: 0.08845376968383789\n",
      "\tLoss: 0.14286628365516663\n",
      "\tLoss: 0.08564490079879761\n",
      "\tLoss: 0.11359329521656036\n",
      "\tLoss: 0.09019599854946136\n",
      "\tLoss: 0.1302756667137146\n",
      "\tLoss: 0.09069100767374039\n",
      "\tLoss: 0.1267269253730774\n",
      "\tLoss: 0.1554042100906372\n",
      "\tLoss: 0.08931657671928406\n",
      "\tLoss: 0.13133473694324493\n",
      "\tLoss: 0.1274591088294983\n",
      "\tLoss: 0.13607348501682281\n",
      "\tLoss: 0.08314277231693268\n",
      "\tLoss: 0.11299367994070053\n",
      "\tLoss: 0.11415153741836548\n",
      "\tLoss: 0.08837266266345978\n",
      "\tLoss: 0.06801055371761322\n",
      "\tLoss: 0.09532390534877777\n",
      "\tLoss: 0.16895988583564758\n",
      "\tLoss: 0.07832692563533783\n",
      "\tLoss: 0.09357336163520813\n",
      "\tLoss: 0.09397122263908386\n",
      "\tLoss: 0.11731396615505219\n",
      "\tLoss: 0.09371845424175262\n",
      "\tLoss: 0.10783542692661285\n",
      "\tLoss: 0.07939716428518295\n",
      "\tLoss: 0.11887191981077194\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.11878973245620728\n",
      "\tLoss: 0.09677697718143463\n",
      "\tLoss: 0.09228339046239853\n",
      "\tLoss: 0.13893216848373413\n",
      "\tLoss: 0.11338608711957932\n",
      "\tLoss: 0.09621889889240265\n",
      "\tLoss: 0.08128738403320312\n",
      "\tLoss: 0.12493618577718735\n",
      "\tLoss: 0.09321441501379013\n",
      "\tLoss: 0.14367328584194183\n",
      "\tLoss: 0.0749523788690567\n",
      "\tLoss: 0.10316900908946991\n",
      "\tLoss: 0.08161750435829163\n",
      "\tLoss: 0.14545685052871704\n",
      "\tLoss: 0.08724647760391235\n",
      "\tLoss: 0.08960996568202972\n",
      "\tLoss: 0.10138830542564392\n",
      "\tLoss: 0.11659608036279678\n",
      "\tLoss: 0.1077476292848587\n",
      "\tLoss: 0.09263627231121063\n",
      "\tLoss: 0.10858523100614548\n",
      "\tLoss: 0.09965828061103821\n",
      "\tLoss: 0.12157456576824188\n",
      "\tLoss: 0.15520483255386353\n",
      "\tLoss: 0.06846634298563004\n",
      "\tLoss: 0.10850538313388824\n",
      "\tLoss: 0.11236776411533356\n",
      "\tLoss: 0.09027127176523209\n",
      "\tLoss: 0.11172322928905487\n",
      "\tLoss: 0.10430146008729935\n",
      "\tLoss: 0.05696798861026764\n",
      "\tLoss: 0.11502014845609665\n",
      "\tLoss: 0.135736882686615\n",
      "\tLoss: 0.12598586082458496\n",
      "\tLoss: 0.12201081216335297\n",
      "\tLoss: 0.12045039236545563\n",
      "\tLoss: 0.10254958271980286\n",
      "\tLoss: 0.08235155045986176\n",
      "\tLoss: 0.09484550356864929\n",
      "\tLoss: 0.12157405912876129\n",
      "\tLoss: 0.086711585521698\n",
      "\tLoss: 0.12179770320653915\n",
      "\tLoss: 0.10326449573040009\n",
      "\tLoss: 0.08214157819747925\n",
      "\tLoss: 0.09784264117479324\n",
      "\tLoss: 0.10331911593675613\n",
      "\tLoss: 0.11687171459197998\n",
      "\tLoss: 0.10164819657802582\n",
      "\tLoss: 0.08056913316249847\n",
      "\tLoss: 0.10022374987602234\n",
      "\tLoss: 0.1313380002975464\n",
      "[time] Epoch 48: 418.4345647301525s = 6.973909412169208m\n",
      "\n",
      "Epoch 49...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.11934715509414673\n",
      "\tLoss: 0.13587825000286102\n",
      "\tLoss: 0.11823538690805435\n",
      "\tLoss: 0.13348348438739777\n",
      "\tLoss: 0.11959842592477798\n",
      "\tLoss: 0.11855991184711456\n",
      "\tLoss: 0.11751121282577515\n",
      "\tLoss: 0.09803852438926697\n",
      "\tLoss: 0.07790377736091614\n",
      "\tLoss: 0.11713813990354538\n",
      "\tLoss: 0.10692882537841797\n",
      "\tLoss: 0.10520586371421814\n",
      "\tLoss: 0.08368438482284546\n",
      "\tLoss: 0.11146499216556549\n",
      "\tLoss: 0.09016142785549164\n",
      "\tLoss: 0.11772873997688293\n",
      "\tLoss: 0.09512466192245483\n",
      "\tLoss: 0.0932328924536705\n",
      "\tLoss: 0.11435965448617935\n",
      "\tLoss: 0.09495274722576141\n",
      "\tLoss: 0.1339671015739441\n",
      "\tLoss: 0.07513902336359024\n",
      "\tLoss: 0.0733928382396698\n",
      "\tLoss: 0.11644443869590759\n",
      "\tLoss: 0.11378220468759537\n",
      "\tLoss: 0.12977927923202515\n",
      "\tLoss: 0.0921839028596878\n",
      "\tLoss: 0.10899093747138977\n",
      "\tLoss: 0.11959831416606903\n",
      "\tLoss: 0.11913217604160309\n",
      "\tLoss: 0.09362627565860748\n",
      "\tLoss: 0.08842146396636963\n",
      "\tLoss: 0.15493978559970856\n",
      "\tLoss: 0.09839217364788055\n",
      "\tLoss: 0.12606599926948547\n",
      "\tLoss: 0.1024196594953537\n",
      "\tLoss: 0.11508346349000931\n",
      "\tLoss: 0.09412859380245209\n",
      "\tLoss: 0.10226255655288696\n",
      "\tLoss: 0.1480814814567566\n",
      "\tLoss: 0.0730406865477562\n",
      "\tLoss: 0.1152028739452362\n",
      "\tLoss: 0.10911774635314941\n",
      "\tLoss: 0.09070554375648499\n",
      "\tLoss: 0.12858815491199493\n",
      "\tLoss: 0.1559806764125824\n",
      "\tLoss: 0.145542174577713\n",
      "\tLoss: 0.15156203508377075\n",
      "\tLoss: 0.09041197597980499\n",
      "\tLoss: 0.11925213038921356\n",
      "\tLoss: 0.06941504776477814\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.11480061709880829\n",
      "\tLoss: 0.09690731763839722\n",
      "\tLoss: 0.10163547843694687\n",
      "\tLoss: 0.09361833333969116\n",
      "\tLoss: 0.07757056504487991\n",
      "\tLoss: 0.09209287166595459\n",
      "\tLoss: 0.08831629902124405\n",
      "\tLoss: 0.1044267937541008\n",
      "\tLoss: 0.1138129010796547\n",
      "\tLoss: 0.077696792781353\n",
      "\tLoss: 0.10195726156234741\n",
      "\tLoss: 0.09952719509601593\n",
      "\tLoss: 0.09896789491176605\n",
      "\tLoss: 0.07384970039129257\n",
      "\tLoss: 0.08661777526140213\n",
      "\tLoss: 0.07833931595087051\n",
      "\tLoss: 0.10931459069252014\n",
      "\tLoss: 0.07200577855110168\n",
      "\tLoss: 0.09525707364082336\n",
      "\tLoss: 0.07364001870155334\n",
      "\tLoss: 0.11877511441707611\n",
      "\tLoss: 0.09886419028043747\n",
      "\tLoss: 0.10268298536539078\n",
      "\tLoss: 0.1148008331656456\n",
      "\tLoss: 0.10720349848270416\n",
      "\tLoss: 0.09039705991744995\n",
      "\tLoss: 0.085014209151268\n",
      "\tLoss: 0.09046196937561035\n",
      "\tLoss: 0.09320862591266632\n",
      "\tLoss: 0.12818053364753723\n",
      "\tLoss: 0.12770043313503265\n",
      "\tLoss: 0.1414356380701065\n",
      "\tLoss: 0.09081366658210754\n",
      "\tLoss: 0.13662469387054443\n",
      "\tLoss: 0.13970789313316345\n",
      "\tLoss: 0.105305515229702\n",
      "\tLoss: 0.11342322826385498\n",
      "\tLoss: 0.0862947553396225\n",
      "\tLoss: 0.07554644346237183\n",
      "\tLoss: 0.09696904569864273\n",
      "\tLoss: 0.118338942527771\n",
      "\tLoss: 0.14147233963012695\n",
      "\tLoss: 0.10547913610935211\n",
      "\tLoss: 0.1002458930015564\n",
      "\tLoss: 0.13554328680038452\n",
      "\tLoss: 0.07245702296495438\n",
      "\tLoss: 0.12466748058795929\n",
      "\tLoss: 0.1171766147017479\n",
      "\tLoss: 0.09125777333974838\n",
      "\tLoss: 0.13919447362422943\n",
      "\tLoss: 0.12349477410316467\n",
      "[time] Epoch 49: 420.26983822509646s = 7.004497303751608m\n",
      "\n",
      "Epoch 50...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1478191316127777\n",
      "\tLoss: 0.14046260714530945\n",
      "\tLoss: 0.10327816754579544\n",
      "\tLoss: 0.11882615089416504\n",
      "\tLoss: 0.07470060884952545\n",
      "\tLoss: 0.11341937631368637\n",
      "\tLoss: 0.05330362170934677\n",
      "\tLoss: 0.10268443077802658\n",
      "\tLoss: 0.0693851038813591\n",
      "\tLoss: 0.08102744817733765\n",
      "\tLoss: 0.13886681199073792\n",
      "\tLoss: 0.0659770667552948\n",
      "\tLoss: 0.1258368343114853\n",
      "\tLoss: 0.09285741299390793\n",
      "\tLoss: 0.10427993535995483\n",
      "\tLoss: 0.13724398612976074\n",
      "\tLoss: 0.052599091082811356\n",
      "\tLoss: 0.1271621733903885\n",
      "\tLoss: 0.0881756842136383\n",
      "\tLoss: 0.1822936087846756\n",
      "\tLoss: 0.12666581571102142\n",
      "\tLoss: 0.0988679751753807\n",
      "\tLoss: 0.08000357449054718\n",
      "\tLoss: 0.10153311491012573\n",
      "\tLoss: 0.10128654539585114\n",
      "\tLoss: 0.130945086479187\n",
      "\tLoss: 0.08705679327249527\n",
      "\tLoss: 0.1645977795124054\n",
      "\tLoss: 0.0786307081580162\n",
      "\tLoss: 0.09995507448911667\n",
      "\tLoss: 0.10596093535423279\n",
      "\tLoss: 0.0961490347981453\n",
      "\tLoss: 0.07217059284448624\n",
      "\tLoss: 0.1053842157125473\n",
      "\tLoss: 0.12474654614925385\n",
      "\tLoss: 0.1250494122505188\n",
      "\tLoss: 0.09036996215581894\n",
      "\tLoss: 0.10404972732067108\n",
      "\tLoss: 0.0847245529294014\n",
      "\tLoss: 0.14504340291023254\n",
      "\tLoss: 0.12363910675048828\n",
      "\tLoss: 0.13094311952590942\n",
      "\tLoss: 0.12072177976369858\n",
      "\tLoss: 0.1293995976448059\n",
      "\tLoss: 0.11476996541023254\n",
      "\tLoss: 0.09059563279151917\n",
      "\tLoss: 0.1155058890581131\n",
      "\tLoss: 0.15226662158966064\n",
      "\tLoss: 0.08142845332622528\n",
      "\tLoss: 0.09129142016172409\n",
      "\tLoss: 0.13588474690914154\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.10213285684585571\n",
      "\tLoss: 0.06096748262643814\n",
      "\tLoss: 0.062195129692554474\n",
      "\tLoss: 0.09560462087392807\n",
      "\tLoss: 0.07330215722322464\n",
      "\tLoss: 0.0818721354007721\n",
      "\tLoss: 0.13278192281723022\n",
      "\tLoss: 0.12220840901136398\n",
      "\tLoss: 0.09370169788599014\n",
      "\tLoss: 0.11580944061279297\n",
      "\tLoss: 0.08995555341243744\n",
      "\tLoss: 0.10551612079143524\n",
      "\tLoss: 0.0803864449262619\n",
      "\tLoss: 0.10024018585681915\n",
      "\tLoss: 0.11262150853872299\n",
      "\tLoss: 0.08543144911527634\n",
      "\tLoss: 0.08890248090028763\n",
      "\tLoss: 0.06978777796030045\n",
      "\tLoss: 0.12351389974355698\n",
      "\tLoss: 0.08597727119922638\n",
      "\tLoss: 0.12658298015594482\n",
      "\tLoss: 0.12588690221309662\n",
      "\tLoss: 0.11850351095199585\n",
      "\tLoss: 0.132643461227417\n",
      "\tLoss: 0.06652238965034485\n",
      "\tLoss: 0.0984514057636261\n",
      "\tLoss: 0.08646045625209808\n",
      "\tLoss: 0.10152383148670197\n",
      "\tLoss: 0.11243890970945358\n",
      "\tLoss: 0.07332946360111237\n",
      "\tLoss: 0.08609628677368164\n",
      "\tLoss: 0.10892076790332794\n",
      "\tLoss: 0.15696078538894653\n",
      "\tLoss: 0.09684720635414124\n",
      "\tLoss: 0.07076007127761841\n",
      "\tLoss: 0.11815182119607925\n",
      "\tLoss: 0.16724103689193726\n",
      "\tLoss: 0.07307195663452148\n",
      "\tLoss: 0.11281538009643555\n",
      "\tLoss: 0.1256953477859497\n",
      "\tLoss: 0.1025029867887497\n",
      "\tLoss: 0.1411108672618866\n",
      "\tLoss: 0.13090816140174866\n",
      "\tLoss: 0.09314602613449097\n",
      "\tLoss: 0.10525785386562347\n",
      "\tLoss: 0.07612274587154388\n",
      "\tLoss: 0.12728002667427063\n",
      "\tLoss: 0.10995204001665115\n",
      "\tLoss: 0.09494038671255112\n",
      "\tLoss: 0.08064278960227966\n",
      "\tLoss: 0.13911083340644836\n",
      "[time] Epoch 50: 418.3295395737514s = 6.9721589928958565m\n",
      "\n",
      "Epoch 51...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.12046203017234802\n",
      "\tLoss: 0.10253612697124481\n",
      "\tLoss: 0.14931875467300415\n",
      "\tLoss: 0.1345377266407013\n",
      "\tLoss: 0.10702382028102875\n",
      "\tLoss: 0.06503162533044815\n",
      "\tLoss: 0.10057444870471954\n",
      "\tLoss: 0.10176776349544525\n",
      "\tLoss: 0.10238102078437805\n",
      "\tLoss: 0.0739845409989357\n",
      "\tLoss: 0.11591815948486328\n",
      "\tLoss: 0.10601158440113068\n",
      "\tLoss: 0.1243768036365509\n",
      "\tLoss: 0.07137581706047058\n",
      "\tLoss: 0.08257748931646347\n",
      "\tLoss: 0.09996043145656586\n",
      "\tLoss: 0.1359955072402954\n",
      "\tLoss: 0.09723794460296631\n",
      "\tLoss: 0.09899831563234329\n",
      "\tLoss: 0.11473831534385681\n",
      "\tLoss: 0.14592498540878296\n",
      "\tLoss: 0.14756280183792114\n",
      "\tLoss: 0.11973755806684494\n",
      "\tLoss: 0.09029106795787811\n",
      "\tLoss: 0.08706025779247284\n",
      "\tLoss: 0.11145184934139252\n",
      "\tLoss: 0.08285652101039886\n",
      "\tLoss: 0.1330888420343399\n",
      "\tLoss: 0.12174344062805176\n",
      "\tLoss: 0.10874082893133163\n",
      "\tLoss: 0.10504758358001709\n",
      "\tLoss: 0.11162339895963669\n",
      "\tLoss: 0.12728208303451538\n",
      "\tLoss: 0.1249440461397171\n",
      "\tLoss: 0.08415670692920685\n",
      "\tLoss: 0.08106925338506699\n",
      "\tLoss: 0.12101753056049347\n",
      "\tLoss: 0.1323220580816269\n",
      "\tLoss: 0.12102346122264862\n",
      "\tLoss: 0.08841092884540558\n",
      "\tLoss: 0.12019778788089752\n",
      "\tLoss: 0.07981698215007782\n",
      "\tLoss: 0.12142477184534073\n",
      "\tLoss: 0.13250663876533508\n",
      "\tLoss: 0.114559605717659\n",
      "\tLoss: 0.13171601295471191\n",
      "\tLoss: 0.09815840423107147\n",
      "\tLoss: 0.1394881308078766\n",
      "\tLoss: 0.07710625231266022\n",
      "\tLoss: 0.08159788697957993\n",
      "\tLoss: 0.11702631413936615\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.10060351341962814\n",
      "\tLoss: 0.13236317038536072\n",
      "\tLoss: 0.09692254662513733\n",
      "\tLoss: 0.08476749062538147\n",
      "\tLoss: 0.057931967079639435\n",
      "\tLoss: 0.08613508939743042\n",
      "\tLoss: 0.11618603020906448\n",
      "\tLoss: 0.08876534551382065\n",
      "\tLoss: 0.09017379581928253\n",
      "\tLoss: 0.10631342232227325\n",
      "\tLoss: 0.1201307475566864\n",
      "\tLoss: 0.09607890993356705\n",
      "\tLoss: 0.12085133790969849\n",
      "\tLoss: 0.078548863530159\n",
      "\tLoss: 0.1418483853340149\n",
      "\tLoss: 0.09477937966585159\n",
      "\tLoss: 0.11629581451416016\n",
      "\tLoss: 0.0796787366271019\n",
      "\tLoss: 0.13158541917800903\n",
      "\tLoss: 0.09274420887231827\n",
      "\tLoss: 0.07423824816942215\n",
      "\tLoss: 0.11065138876438141\n",
      "\tLoss: 0.11023008823394775\n",
      "\tLoss: 0.09996187686920166\n",
      "\tLoss: 0.07780721783638\n",
      "\tLoss: 0.06937766820192337\n",
      "\tLoss: 0.11819294840097427\n",
      "\tLoss: 0.058538857847452164\n",
      "\tLoss: 0.08684662729501724\n",
      "\tLoss: 0.09443557262420654\n",
      "\tLoss: 0.09645010530948639\n",
      "\tLoss: 0.06146655231714249\n",
      "\tLoss: 0.08600829541683197\n",
      "\tLoss: 0.11126016825437546\n",
      "\tLoss: 0.10378210991621017\n",
      "\tLoss: 0.10244395583868027\n",
      "\tLoss: 0.11150495707988739\n",
      "\tLoss: 0.06864814460277557\n",
      "\tLoss: 0.08182024955749512\n",
      "\tLoss: 0.11377155780792236\n",
      "\tLoss: 0.10008686035871506\n",
      "\tLoss: 0.1480552703142166\n",
      "\tLoss: 0.14426729083061218\n",
      "\tLoss: 0.11398523300886154\n",
      "\tLoss: 0.09762858599424362\n",
      "\tLoss: 0.12065675854682922\n",
      "\tLoss: 0.1392882913351059\n",
      "\tLoss: 0.12092235684394836\n",
      "\tLoss: 0.07966578751802444\n",
      "\tLoss: 0.1465086042881012\n",
      "\tLoss: 0.12129474431276321\n",
      "[time] Epoch 51: 420.92096335301176s = 7.015349389216863m\n",
      "\n",
      "Epoch 52...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.09711141884326935\n",
      "\tLoss: 0.09405191242694855\n",
      "\tLoss: 0.12951403856277466\n",
      "\tLoss: 0.08870330452919006\n",
      "\tLoss: 0.11120831966400146\n",
      "\tLoss: 0.10064809769392014\n",
      "\tLoss: 0.11701507121324539\n",
      "\tLoss: 0.09345987439155579\n",
      "\tLoss: 0.10788104683160782\n",
      "\tLoss: 0.09957291185855865\n",
      "\tLoss: 0.09535323828458786\n",
      "\tLoss: 0.06284168362617493\n",
      "\tLoss: 0.08393571525812149\n",
      "\tLoss: 0.08232356607913971\n",
      "\tLoss: 0.09760764241218567\n",
      "\tLoss: 0.10571981966495514\n",
      "\tLoss: 0.11058200150728226\n",
      "\tLoss: 0.11573663353919983\n",
      "\tLoss: 0.146323561668396\n",
      "\tLoss: 0.10548555850982666\n",
      "\tLoss: 0.11077024042606354\n",
      "\tLoss: 0.04892636835575104\n",
      "\tLoss: 0.10098062455654144\n",
      "\tLoss: 0.08351485431194305\n",
      "\tLoss: 0.11123138666152954\n",
      "\tLoss: 0.09111665189266205\n",
      "\tLoss: 0.07753750681877136\n",
      "\tLoss: 0.08568858355283737\n",
      "\tLoss: 0.10631751269102097\n",
      "\tLoss: 0.1368686854839325\n",
      "\tLoss: 0.11813411116600037\n",
      "\tLoss: 0.10524474084377289\n",
      "\tLoss: 0.08922836184501648\n",
      "\tLoss: 0.09836739301681519\n",
      "\tLoss: 0.102446049451828\n",
      "\tLoss: 0.12733012437820435\n",
      "\tLoss: 0.09019890427589417\n",
      "\tLoss: 0.10684478282928467\n",
      "\tLoss: 0.08034509420394897\n",
      "\tLoss: 0.0785929411649704\n",
      "\tLoss: 0.08144070208072662\n",
      "\tLoss: 0.1269562691450119\n",
      "\tLoss: 0.1643993854522705\n",
      "\tLoss: 0.08082693070173264\n",
      "\tLoss: 0.11390839517116547\n",
      "\tLoss: 0.11779157817363739\n",
      "\tLoss: 0.12430180609226227\n",
      "\tLoss: 0.10044631361961365\n",
      "\tLoss: 0.12279276549816132\n",
      "\tLoss: 0.1145632266998291\n",
      "\tLoss: 0.10253216326236725\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.07313436269760132\n",
      "\tLoss: 0.14199325442314148\n",
      "\tLoss: 0.09389951825141907\n",
      "\tLoss: 0.08441545814275742\n",
      "\tLoss: 0.060946449637413025\n",
      "\tLoss: 0.10984580963850021\n",
      "\tLoss: 0.08836062252521515\n",
      "\tLoss: 0.0914783626794815\n",
      "\tLoss: 0.09045983850955963\n",
      "\tLoss: 0.08466805517673492\n",
      "\tLoss: 0.15913236141204834\n",
      "\tLoss: 0.16054248809814453\n",
      "\tLoss: 0.08555246889591217\n",
      "\tLoss: 0.09885567426681519\n",
      "\tLoss: 0.11697588860988617\n",
      "\tLoss: 0.10740229487419128\n",
      "\tLoss: 0.062095027416944504\n",
      "\tLoss: 0.14126843214035034\n",
      "\tLoss: 0.0873359963297844\n",
      "\tLoss: 0.0986245721578598\n",
      "\tLoss: 0.08823400735855103\n",
      "\tLoss: 0.12690240144729614\n",
      "\tLoss: 0.13190427422523499\n",
      "\tLoss: 0.1584162414073944\n",
      "\tLoss: 0.07357342541217804\n",
      "\tLoss: 0.07425346970558167\n",
      "\tLoss: 0.09074275195598602\n",
      "\tLoss: 0.1188005805015564\n",
      "\tLoss: 0.1255895495414734\n",
      "\tLoss: 0.09386005997657776\n",
      "\tLoss: 0.11047030985355377\n",
      "\tLoss: 0.07127084583044052\n",
      "\tLoss: 0.06891487538814545\n",
      "\tLoss: 0.10675455629825592\n",
      "\tLoss: 0.06594275683164597\n",
      "\tLoss: 0.07801562547683716\n",
      "\tLoss: 0.10721775144338608\n",
      "\tLoss: 0.10485215485095978\n",
      "\tLoss: 0.10262459516525269\n",
      "\tLoss: 0.10692232847213745\n",
      "\tLoss: 0.10091331601142883\n",
      "\tLoss: 0.14201757311820984\n",
      "\tLoss: 0.08183977007865906\n",
      "\tLoss: 0.10097070038318634\n",
      "\tLoss: 0.12570908665657043\n",
      "\tLoss: 0.10318148136138916\n",
      "\tLoss: 0.11730106920003891\n",
      "\tLoss: 0.11538802087306976\n",
      "\tLoss: 0.06552842259407043\n",
      "\tLoss: 0.11391241103410721\n",
      "\tLoss: 0.1040993183851242\n",
      "[time] Epoch 52: 420.26483581308275s = 7.004413930218046m\n",
      "\n",
      "Epoch 53...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.10713598132133484\n",
      "\tLoss: 0.07980649173259735\n",
      "\tLoss: 0.09932804107666016\n",
      "\tLoss: 0.07248111069202423\n",
      "\tLoss: 0.12312754988670349\n",
      "\tLoss: 0.13127629458904266\n",
      "\tLoss: 0.09556816518306732\n",
      "\tLoss: 0.09620673954486847\n",
      "\tLoss: 0.12278001010417938\n",
      "\tLoss: 0.12803472578525543\n",
      "\tLoss: 0.0744524747133255\n",
      "\tLoss: 0.10571092367172241\n",
      "\tLoss: 0.11050564050674438\n",
      "\tLoss: 0.10276313126087189\n",
      "\tLoss: 0.087190181016922\n",
      "\tLoss: 0.0761011466383934\n",
      "\tLoss: 0.11056187748908997\n",
      "\tLoss: 0.09961004555225372\n",
      "\tLoss: 0.0788990706205368\n",
      "\tLoss: 0.0910896360874176\n",
      "\tLoss: 0.10959373414516449\n",
      "\tLoss: 0.09673923254013062\n",
      "\tLoss: 0.09848198294639587\n",
      "\tLoss: 0.109921894967556\n",
      "\tLoss: 0.09593021869659424\n",
      "\tLoss: 0.10837174952030182\n",
      "\tLoss: 0.10478899627923965\n",
      "\tLoss: 0.10023477673530579\n",
      "\tLoss: 0.11713504046201706\n",
      "\tLoss: 0.09531193226575851\n",
      "\tLoss: 0.1025247871875763\n",
      "\tLoss: 0.11540752649307251\n",
      "\tLoss: 0.13153308629989624\n",
      "\tLoss: 0.12878140807151794\n",
      "\tLoss: 0.09415923804044724\n",
      "\tLoss: 0.08381198346614838\n",
      "\tLoss: 0.12660828232765198\n",
      "\tLoss: 0.09392817318439484\n",
      "\tLoss: 0.12287254631519318\n",
      "\tLoss: 0.10906846076250076\n",
      "\tLoss: 0.12815232574939728\n",
      "\tLoss: 0.14100544154644012\n",
      "\tLoss: 0.11731512099504471\n",
      "\tLoss: 0.13913697004318237\n",
      "\tLoss: 0.13490135967731476\n",
      "\tLoss: 0.1173543632030487\n",
      "\tLoss: 0.10792722553014755\n",
      "\tLoss: 0.17063266038894653\n",
      "\tLoss: 0.11618632078170776\n",
      "\tLoss: 0.10012244433164597\n",
      "\tLoss: 0.11975973099470139\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.15325678884983063\n",
      "\tLoss: 0.13034480810165405\n",
      "\tLoss: 0.08395963907241821\n",
      "\tLoss: 0.12933292984962463\n",
      "\tLoss: 0.07849287241697311\n",
      "\tLoss: 0.10731840133666992\n",
      "\tLoss: 0.13802556693553925\n",
      "\tLoss: 0.1710486114025116\n",
      "\tLoss: 0.1187058538198471\n",
      "\tLoss: 0.09533478319644928\n",
      "\tLoss: 0.07821604609489441\n",
      "\tLoss: 0.13571128249168396\n",
      "\tLoss: 0.07345733791589737\n",
      "\tLoss: 0.11569631099700928\n",
      "\tLoss: 0.11308494210243225\n",
      "\tLoss: 0.07433690130710602\n",
      "\tLoss: 0.08417557924985886\n",
      "\tLoss: 0.0895712673664093\n",
      "\tLoss: 0.10118530690670013\n",
      "\tLoss: 0.0912570208311081\n",
      "\tLoss: 0.16100847721099854\n",
      "\tLoss: 0.08786126971244812\n",
      "\tLoss: 0.11201649904251099\n",
      "\tLoss: 0.12797753512859344\n",
      "\tLoss: 0.08607076108455658\n",
      "\tLoss: 0.11289961636066437\n",
      "\tLoss: 0.07885649800300598\n",
      "\tLoss: 0.10457247495651245\n",
      "\tLoss: 0.0951993465423584\n",
      "\tLoss: 0.09625811874866486\n",
      "\tLoss: 0.11465274542570114\n",
      "\tLoss: 0.0819944441318512\n",
      "\tLoss: 0.12381807714700699\n",
      "\tLoss: 0.10660980641841888\n",
      "\tLoss: 0.1122794821858406\n",
      "\tLoss: 0.1110432967543602\n",
      "\tLoss: 0.08783546090126038\n",
      "\tLoss: 0.10924991220235825\n",
      "\tLoss: 0.13326942920684814\n",
      "\tLoss: 0.16186851263046265\n",
      "\tLoss: 0.10962103307247162\n",
      "\tLoss: 0.12845054268836975\n",
      "\tLoss: 0.16830694675445557\n",
      "\tLoss: 0.1068502813577652\n",
      "\tLoss: 0.12373124063014984\n",
      "\tLoss: 0.10726878046989441\n",
      "\tLoss: 0.11111640930175781\n",
      "\tLoss: 0.06492935866117477\n",
      "\tLoss: 0.11275410652160645\n",
      "\tLoss: 0.0985908955335617\n",
      "\tLoss: 0.13544689118862152\n",
      "[time] Epoch 53: 417.1000183559954s = 6.951666972599924m\n",
      "\n",
      "Epoch 54...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.12461473047733307\n",
      "\tLoss: 0.09429360926151276\n",
      "\tLoss: 0.07303941249847412\n",
      "\tLoss: 0.09599582105875015\n",
      "\tLoss: 0.08406778424978256\n",
      "\tLoss: 0.10110319405794144\n",
      "\tLoss: 0.09635084867477417\n",
      "\tLoss: 0.07565397769212723\n",
      "\tLoss: 0.09896870702505112\n",
      "\tLoss: 0.11931091547012329\n",
      "\tLoss: 0.15673014521598816\n",
      "\tLoss: 0.09450821578502655\n",
      "\tLoss: 0.07129506021738052\n",
      "\tLoss: 0.09202287346124649\n",
      "\tLoss: 0.11529403924942017\n",
      "\tLoss: 0.0950726568698883\n",
      "\tLoss: 0.12166787683963776\n",
      "\tLoss: 0.13532012701034546\n",
      "\tLoss: 0.12765944004058838\n",
      "\tLoss: 0.08885695040225983\n",
      "\tLoss: 0.09123904258012772\n",
      "\tLoss: 0.15719863772392273\n",
      "\tLoss: 0.09576986730098724\n",
      "\tLoss: 0.08354903012514114\n",
      "\tLoss: 0.11172273755073547\n",
      "\tLoss: 0.10963784158229828\n",
      "\tLoss: 0.09509466588497162\n",
      "\tLoss: 0.11137457937002182\n",
      "\tLoss: 0.08308034390211105\n",
      "\tLoss: 0.13509346544742584\n",
      "\tLoss: 0.12134245038032532\n",
      "\tLoss: 0.1164047122001648\n",
      "\tLoss: 0.1275012344121933\n",
      "\tLoss: 0.08906520903110504\n",
      "\tLoss: 0.09805586189031601\n",
      "\tLoss: 0.11046472936868668\n",
      "\tLoss: 0.09857477992773056\n",
      "\tLoss: 0.08536754548549652\n",
      "\tLoss: 0.1288989782333374\n",
      "\tLoss: 0.12547612190246582\n",
      "\tLoss: 0.10294652730226517\n",
      "\tLoss: 0.11136114597320557\n",
      "\tLoss: 0.07641170918941498\n",
      "\tLoss: 0.06936942785978317\n",
      "\tLoss: 0.10331656038761139\n",
      "\tLoss: 0.13699692487716675\n",
      "\tLoss: 0.10377630591392517\n",
      "\tLoss: 0.11312355101108551\n",
      "\tLoss: 0.09750865399837494\n",
      "\tLoss: 0.13262242078781128\n",
      "\tLoss: 0.07907404005527496\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.12739843130111694\n",
      "\tLoss: 0.1182810589671135\n",
      "\tLoss: 0.07541366666555405\n",
      "\tLoss: 0.09433344751596451\n",
      "\tLoss: 0.09465054422616959\n",
      "\tLoss: 0.07575692981481552\n",
      "\tLoss: 0.07140129804611206\n",
      "\tLoss: 0.08208604902029037\n",
      "\tLoss: 0.12317012250423431\n",
      "\tLoss: 0.12623360753059387\n",
      "\tLoss: 0.09336686134338379\n",
      "\tLoss: 0.08368565887212753\n",
      "\tLoss: 0.0917142778635025\n",
      "\tLoss: 0.15146058797836304\n",
      "\tLoss: 0.14729264378547668\n",
      "\tLoss: 0.0885249674320221\n",
      "\tLoss: 0.11212944239377975\n",
      "\tLoss: 0.10282453149557114\n",
      "\tLoss: 0.1252644658088684\n",
      "\tLoss: 0.10424991697072983\n",
      "\tLoss: 0.09333255141973495\n",
      "\tLoss: 0.13489028811454773\n",
      "\tLoss: 0.11742906272411346\n",
      "\tLoss: 0.1134355366230011\n",
      "\tLoss: 0.09088731557130814\n",
      "\tLoss: 0.09890414774417877\n",
      "\tLoss: 0.11014483869075775\n",
      "\tLoss: 0.10492187738418579\n",
      "\tLoss: 0.09463482350111008\n",
      "\tLoss: 0.10912325978279114\n",
      "\tLoss: 0.12472493946552277\n",
      "\tLoss: 0.04551219195127487\n",
      "\tLoss: 0.060956619679927826\n",
      "\tLoss: 0.10912329703569412\n",
      "\tLoss: 0.11514797806739807\n",
      "\tLoss: 0.09089120477437973\n",
      "\tLoss: 0.10919211804866791\n",
      "\tLoss: 0.093526691198349\n",
      "\tLoss: 0.12567557394504547\n",
      "\tLoss: 0.10964314639568329\n",
      "\tLoss: 0.08497893810272217\n",
      "\tLoss: 0.1900288462638855\n",
      "\tLoss: 0.11586730182170868\n",
      "\tLoss: 0.1216026097536087\n",
      "\tLoss: 0.09974797815084457\n",
      "\tLoss: 0.13056886196136475\n",
      "\tLoss: 0.12102337181568146\n",
      "\tLoss: 0.08919130265712738\n",
      "\tLoss: 0.08431819826364517\n",
      "\tLoss: 0.1502852737903595\n",
      "\tLoss: 0.1368807852268219\n",
      "[time] Epoch 54: 411.7682134960778s = 6.862803558267964m\n",
      "\n",
      "Epoch 55...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.13743191957473755\n",
      "\tLoss: 0.11283864825963974\n",
      "\tLoss: 0.13196125626564026\n",
      "\tLoss: 0.0933656096458435\n",
      "\tLoss: 0.1144166812300682\n",
      "\tLoss: 0.10005254298448563\n",
      "\tLoss: 0.15444934368133545\n",
      "\tLoss: 0.0889086052775383\n",
      "\tLoss: 0.12088204175233841\n",
      "\tLoss: 0.08070976287126541\n",
      "\tLoss: 0.11921820789575577\n",
      "\tLoss: 0.11378144472837448\n",
      "\tLoss: 0.13435909152030945\n",
      "\tLoss: 0.0978132113814354\n",
      "\tLoss: 0.09938753396272659\n",
      "\tLoss: 0.11610148847103119\n",
      "\tLoss: 0.11149981617927551\n",
      "\tLoss: 0.10170480608940125\n",
      "\tLoss: 0.08363796025514603\n",
      "\tLoss: 0.06927931308746338\n",
      "\tLoss: 0.1482243537902832\n",
      "\tLoss: 0.11965885013341904\n",
      "\tLoss: 0.1103893518447876\n",
      "\tLoss: 0.14053049683570862\n",
      "\tLoss: 0.1146935299038887\n",
      "\tLoss: 0.1113235205411911\n",
      "\tLoss: 0.14622998237609863\n",
      "\tLoss: 0.10288719832897186\n",
      "\tLoss: 0.09947770088911057\n",
      "\tLoss: 0.10166580975055695\n",
      "\tLoss: 0.10209701955318451\n",
      "\tLoss: 0.12745696306228638\n",
      "\tLoss: 0.10252445936203003\n",
      "\tLoss: 0.09930652379989624\n",
      "\tLoss: 0.10680229961872101\n",
      "\tLoss: 0.1101195365190506\n",
      "\tLoss: 0.10262928158044815\n",
      "\tLoss: 0.09685969352722168\n",
      "\tLoss: 0.0762028843164444\n",
      "\tLoss: 0.11666741967201233\n",
      "\tLoss: 0.08042239397764206\n",
      "\tLoss: 0.15780524909496307\n",
      "\tLoss: 0.07807982712984085\n",
      "\tLoss: 0.12832799553871155\n",
      "\tLoss: 0.10773498564958572\n",
      "\tLoss: 0.10690002143383026\n",
      "\tLoss: 0.14023461937904358\n",
      "\tLoss: 0.10537789016962051\n",
      "\tLoss: 0.10319842398166656\n",
      "\tLoss: 0.13509011268615723\n",
      "\tLoss: 0.10159488022327423\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.09797115623950958\n",
      "\tLoss: 0.1803135871887207\n",
      "\tLoss: 0.16957709193229675\n",
      "\tLoss: 0.07865118235349655\n",
      "\tLoss: 0.10116863995790482\n",
      "\tLoss: 0.11379193514585495\n",
      "\tLoss: 0.10497714579105377\n",
      "\tLoss: 0.07471312582492828\n",
      "\tLoss: 0.12438987195491791\n",
      "\tLoss: 0.15794239938259125\n",
      "\tLoss: 0.11234571784734726\n",
      "\tLoss: 0.08175180852413177\n",
      "\tLoss: 0.10612688213586807\n",
      "\tLoss: 0.12263964861631393\n",
      "\tLoss: 0.13121232390403748\n",
      "\tLoss: 0.12297359108924866\n",
      "\tLoss: 0.07927702367305756\n",
      "\tLoss: 0.08093112707138062\n",
      "\tLoss: 0.093354232609272\n",
      "\tLoss: 0.07185622304677963\n",
      "\tLoss: 0.07996223121881485\n",
      "\tLoss: 0.10096900165081024\n",
      "\tLoss: 0.14257338643074036\n",
      "\tLoss: 0.12420884519815445\n",
      "\tLoss: 0.0873822271823883\n",
      "\tLoss: 0.10683688521385193\n",
      "\tLoss: 0.0927697941660881\n",
      "\tLoss: 0.11169391870498657\n",
      "\tLoss: 0.09356076270341873\n",
      "\tLoss: 0.08293559402227402\n",
      "\tLoss: 0.1399337351322174\n",
      "\tLoss: 0.0818796157836914\n",
      "\tLoss: 0.12084388732910156\n",
      "\tLoss: 0.10165154933929443\n",
      "\tLoss: 0.11009114980697632\n",
      "\tLoss: 0.10639497637748718\n",
      "\tLoss: 0.06714645773172379\n",
      "\tLoss: 0.1053256243467331\n",
      "\tLoss: 0.08412504196166992\n",
      "\tLoss: 0.11955922842025757\n",
      "\tLoss: 0.11571024358272552\n",
      "\tLoss: 0.12641218304634094\n",
      "\tLoss: 0.115775465965271\n",
      "\tLoss: 0.11661604046821594\n",
      "\tLoss: 0.11336122453212738\n",
      "\tLoss: 0.08515551686286926\n",
      "\tLoss: 0.11611252278089523\n",
      "\tLoss: 0.08102715015411377\n",
      "\tLoss: 0.10196202993392944\n",
      "\tLoss: 0.11385510861873627\n",
      "\tLoss: 0.12657395005226135\n",
      "[time] Epoch 55: 413.24916754104197s = 6.887486125684033m\n",
      "\n",
      "Epoch 56...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.0900212824344635\n",
      "\tLoss: 0.10125862807035446\n",
      "\tLoss: 0.12975719571113586\n",
      "\tLoss: 0.10000942647457123\n",
      "\tLoss: 0.10903115570545197\n",
      "\tLoss: 0.13393376767635345\n",
      "\tLoss: 0.07040032744407654\n",
      "\tLoss: 0.09956100583076477\n",
      "\tLoss: 0.10183694958686829\n",
      "\tLoss: 0.11089767515659332\n",
      "\tLoss: 0.11033767461776733\n",
      "\tLoss: 0.08318585157394409\n",
      "\tLoss: 0.06296190619468689\n",
      "\tLoss: 0.08455754816532135\n",
      "\tLoss: 0.12201651930809021\n",
      "\tLoss: 0.0892850011587143\n",
      "\tLoss: 0.11347027122974396\n",
      "\tLoss: 0.08378330618143082\n",
      "\tLoss: 0.07198663055896759\n",
      "\tLoss: 0.12723790109157562\n",
      "\tLoss: 0.09043395519256592\n",
      "\tLoss: 0.06619125604629517\n",
      "\tLoss: 0.11991830170154572\n",
      "\tLoss: 0.1511552631855011\n",
      "\tLoss: 0.09258478879928589\n",
      "\tLoss: 0.11332396417856216\n",
      "\tLoss: 0.10900893807411194\n",
      "\tLoss: 0.12829972803592682\n",
      "\tLoss: 0.07431407272815704\n",
      "\tLoss: 0.11304795742034912\n",
      "\tLoss: 0.06790062040090561\n",
      "\tLoss: 0.16465160250663757\n",
      "\tLoss: 0.10220618546009064\n",
      "\tLoss: 0.13455228507518768\n",
      "\tLoss: 0.07633298635482788\n",
      "\tLoss: 0.09424173831939697\n",
      "\tLoss: 0.11369054764509201\n",
      "\tLoss: 0.11225460469722748\n",
      "\tLoss: 0.08917400240898132\n",
      "\tLoss: 0.12354180216789246\n",
      "\tLoss: 0.1277489960193634\n",
      "\tLoss: 0.08375802636146545\n",
      "\tLoss: 0.07678297162055969\n",
      "\tLoss: 0.1208091676235199\n",
      "\tLoss: 0.08037984371185303\n",
      "\tLoss: 0.1255612075328827\n",
      "\tLoss: 0.07998088002204895\n",
      "\tLoss: 0.08296529948711395\n",
      "\tLoss: 0.11465251445770264\n",
      "\tLoss: 0.12130341678857803\n",
      "\tLoss: 0.11609382927417755\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.0815427303314209\n",
      "\tLoss: 0.11396908760070801\n",
      "\tLoss: 0.10140326619148254\n",
      "\tLoss: 0.11274170875549316\n",
      "\tLoss: 0.07508143782615662\n",
      "\tLoss: 0.09332966804504395\n",
      "\tLoss: 0.09568971395492554\n",
      "\tLoss: 0.1312858611345291\n",
      "\tLoss: 0.12873990833759308\n",
      "\tLoss: 0.12468359619379044\n",
      "\tLoss: 0.14987146854400635\n",
      "\tLoss: 0.1096416562795639\n",
      "\tLoss: 0.13722142577171326\n",
      "\tLoss: 0.10389643907546997\n",
      "\tLoss: 0.13502976298332214\n",
      "\tLoss: 0.10526134073734283\n",
      "\tLoss: 0.1455853432416916\n",
      "\tLoss: 0.12401255965232849\n",
      "\tLoss: 0.1166817843914032\n",
      "\tLoss: 0.11559988558292389\n",
      "\tLoss: 0.0987875908613205\n",
      "\tLoss: 0.11921042203903198\n",
      "\tLoss: 0.10706322640180588\n",
      "\tLoss: 0.1484639048576355\n",
      "\tLoss: 0.10988183319568634\n",
      "\tLoss: 0.11601664125919342\n",
      "\tLoss: 0.08400997519493103\n",
      "\tLoss: 0.10617541521787643\n",
      "\tLoss: 0.07672814279794693\n",
      "\tLoss: 0.11032366752624512\n",
      "\tLoss: 0.10357321798801422\n",
      "\tLoss: 0.12288981676101685\n",
      "\tLoss: 0.07874339818954468\n",
      "\tLoss: 0.10769500583410263\n",
      "\tLoss: 0.10760190337896347\n",
      "\tLoss: 0.06526628881692886\n",
      "\tLoss: 0.08226897567510605\n",
      "\tLoss: 0.14418883621692657\n",
      "\tLoss: 0.13218970596790314\n",
      "\tLoss: 0.08717798441648483\n",
      "\tLoss: 0.11132682859897614\n",
      "\tLoss: 0.12356185913085938\n",
      "\tLoss: 0.10361885279417038\n",
      "\tLoss: 0.12421166151762009\n",
      "\tLoss: 0.061086300760507584\n",
      "\tLoss: 0.09284535050392151\n",
      "\tLoss: 0.14284375309944153\n",
      "\tLoss: 0.10694093257188797\n",
      "\tLoss: 0.08433137089014053\n",
      "\tLoss: 0.09946447610855103\n",
      "\tLoss: 0.1370510756969452\n",
      "[time] Epoch 56: 409.42173217004165s = 6.823695536167361m\n",
      "\n",
      "Epoch 57...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.13690420985221863\n",
      "\tLoss: 0.09329250454902649\n",
      "\tLoss: 0.07402074337005615\n",
      "\tLoss: 0.11940456181764603\n",
      "\tLoss: 0.09956696629524231\n",
      "\tLoss: 0.12614798545837402\n",
      "\tLoss: 0.11586830019950867\n",
      "\tLoss: 0.11239699274301529\n",
      "\tLoss: 0.10946045815944672\n",
      "\tLoss: 0.07807368785142899\n",
      "\tLoss: 0.09589731693267822\n",
      "\tLoss: 0.09458567202091217\n",
      "\tLoss: 0.10962226241827011\n",
      "\tLoss: 0.13750812411308289\n",
      "\tLoss: 0.11948815733194351\n",
      "\tLoss: 0.10796691477298737\n",
      "\tLoss: 0.086467444896698\n",
      "\tLoss: 0.0912414938211441\n",
      "\tLoss: 0.1070854663848877\n",
      "\tLoss: 0.12283340096473694\n",
      "\tLoss: 0.12021373212337494\n",
      "\tLoss: 0.10052774846553802\n",
      "\tLoss: 0.08609124273061752\n",
      "\tLoss: 0.11022955179214478\n",
      "\tLoss: 0.10520227253437042\n",
      "\tLoss: 0.09944692254066467\n",
      "\tLoss: 0.10209431499242783\n",
      "\tLoss: 0.12193404138088226\n",
      "\tLoss: 0.12187609076499939\n",
      "\tLoss: 0.12716849148273468\n",
      "\tLoss: 0.12132547050714493\n",
      "\tLoss: 0.0984455943107605\n",
      "\tLoss: 0.1268870234489441\n",
      "\tLoss: 0.1014297604560852\n",
      "\tLoss: 0.11998599767684937\n",
      "\tLoss: 0.09676797688007355\n",
      "\tLoss: 0.10615228116512299\n",
      "\tLoss: 0.11010058224201202\n",
      "\tLoss: 0.13935384154319763\n",
      "\tLoss: 0.11450520157814026\n",
      "\tLoss: 0.20397743582725525\n",
      "\tLoss: 0.09061073511838913\n",
      "\tLoss: 0.1257162094116211\n",
      "\tLoss: 0.09656243026256561\n",
      "\tLoss: 0.13140222430229187\n",
      "\tLoss: 0.10842660069465637\n",
      "\tLoss: 0.0834045484662056\n",
      "\tLoss: 0.09314854443073273\n",
      "\tLoss: 0.10520251095294952\n",
      "\tLoss: 0.09194430708885193\n",
      "\tLoss: 0.10003994405269623\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.10166938602924347\n",
      "\tLoss: 0.12475395202636719\n",
      "\tLoss: 0.13253247737884521\n",
      "\tLoss: 0.14721015095710754\n",
      "\tLoss: 0.06582705676555634\n",
      "\tLoss: 0.11196282505989075\n",
      "\tLoss: 0.09812384843826294\n",
      "\tLoss: 0.06298267841339111\n",
      "\tLoss: 0.0846819281578064\n",
      "\tLoss: 0.11648625880479813\n",
      "\tLoss: 0.09844768047332764\n",
      "\tLoss: 0.1082627922296524\n",
      "\tLoss: 0.05980386584997177\n",
      "\tLoss: 0.12575700879096985\n",
      "\tLoss: 0.0983676016330719\n",
      "\tLoss: 0.1128641813993454\n",
      "\tLoss: 0.09568549692630768\n",
      "\tLoss: 0.12444561719894409\n",
      "\tLoss: 0.0821007639169693\n",
      "\tLoss: 0.0983770489692688\n",
      "\tLoss: 0.1477356255054474\n",
      "\tLoss: 0.136062890291214\n",
      "\tLoss: 0.1255096197128296\n",
      "\tLoss: 0.08176912367343903\n",
      "\tLoss: 0.11082307994365692\n",
      "\tLoss: 0.11423039436340332\n",
      "\tLoss: 0.12106730043888092\n",
      "\tLoss: 0.057138264179229736\n",
      "\tLoss: 0.10169681906700134\n",
      "\tLoss: 0.06596757471561432\n",
      "\tLoss: 0.11504081636667252\n",
      "\tLoss: 0.07501063495874405\n",
      "\tLoss: 0.0841156467795372\n",
      "\tLoss: 0.14605498313903809\n",
      "\tLoss: 0.10441305488348007\n",
      "\tLoss: 0.11168411374092102\n",
      "\tLoss: 0.10619242489337921\n",
      "\tLoss: 0.096860870718956\n",
      "\tLoss: 0.08533128350973129\n",
      "\tLoss: 0.07623272389173508\n",
      "\tLoss: 0.09331052005290985\n",
      "\tLoss: 0.08409999310970306\n",
      "\tLoss: 0.13496868312358856\n",
      "\tLoss: 0.11350538581609726\n",
      "\tLoss: 0.06920598447322845\n",
      "\tLoss: 0.08279010653495789\n",
      "\tLoss: 0.08525650948286057\n",
      "\tLoss: 0.13938429951667786\n",
      "\tLoss: 0.09260044246912003\n",
      "\tLoss: 0.10922697186470032\n",
      "\tLoss: 0.10243668407201767\n",
      "[time] Epoch 57: 411.5021511670202s = 6.858369186117003m\n",
      "\n",
      "Epoch 58...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.08063270151615143\n",
      "\tLoss: 0.12504564225673676\n",
      "\tLoss: 0.08585318922996521\n",
      "\tLoss: 0.10711877048015594\n",
      "\tLoss: 0.11122682690620422\n",
      "\tLoss: 0.12510891258716583\n",
      "\tLoss: 0.0864827036857605\n",
      "\tLoss: 0.12897735834121704\n",
      "\tLoss: 0.12445413321256638\n",
      "\tLoss: 0.12924759089946747\n",
      "\tLoss: 0.12083858251571655\n",
      "\tLoss: 0.11998312175273895\n",
      "\tLoss: 0.0869096890091896\n",
      "\tLoss: 0.0912582129240036\n",
      "\tLoss: 0.08704632520675659\n",
      "\tLoss: 0.1287066489458084\n",
      "\tLoss: 0.09809036552906036\n",
      "\tLoss: 0.09832711517810822\n",
      "\tLoss: 0.07127043604850769\n",
      "\tLoss: 0.10274982452392578\n",
      "\tLoss: 0.06878237426280975\n",
      "\tLoss: 0.12845423817634583\n",
      "\tLoss: 0.06986746191978455\n",
      "\tLoss: 0.11606862396001816\n",
      "\tLoss: 0.09815612435340881\n",
      "\tLoss: 0.07875262945890427\n",
      "\tLoss: 0.10420069098472595\n",
      "\tLoss: 0.12833817303180695\n",
      "\tLoss: 0.12800532579421997\n",
      "\tLoss: 0.0936688482761383\n",
      "\tLoss: 0.06510724127292633\n",
      "\tLoss: 0.09223447740077972\n",
      "\tLoss: 0.14068740606307983\n",
      "\tLoss: 0.1310296207666397\n",
      "\tLoss: 0.0837922915816307\n",
      "\tLoss: 0.13458405435085297\n",
      "\tLoss: 0.10271190851926804\n",
      "\tLoss: 0.08521267771720886\n",
      "\tLoss: 0.10273914039134979\n",
      "\tLoss: 0.12207338213920593\n",
      "\tLoss: 0.08553017675876617\n",
      "\tLoss: 0.12520074844360352\n",
      "\tLoss: 0.1144610345363617\n",
      "\tLoss: 0.11697402596473694\n",
      "\tLoss: 0.1201135516166687\n",
      "\tLoss: 0.09855152666568756\n",
      "\tLoss: 0.10468626022338867\n",
      "\tLoss: 0.11348851770162582\n",
      "\tLoss: 0.07721412181854248\n",
      "\tLoss: 0.05654731020331383\n",
      "\tLoss: 0.11251364648342133\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.08841313421726227\n",
      "\tLoss: 0.07523772865533829\n",
      "\tLoss: 0.07577252388000488\n",
      "\tLoss: 0.09273616969585419\n",
      "\tLoss: 0.0808526873588562\n",
      "\tLoss: 0.10721056163311005\n",
      "\tLoss: 0.1254625767469406\n",
      "\tLoss: 0.12217886745929718\n",
      "\tLoss: 0.08722522109746933\n",
      "\tLoss: 0.12739884853363037\n",
      "\tLoss: 0.06868227571249008\n",
      "\tLoss: 0.13945791125297546\n",
      "\tLoss: 0.09969305247068405\n",
      "\tLoss: 0.1139732152223587\n",
      "\tLoss: 0.10978280007839203\n",
      "\tLoss: 0.10694275051355362\n",
      "\tLoss: 0.1098165512084961\n",
      "\tLoss: 0.13862578570842743\n",
      "\tLoss: 0.08089391887187958\n",
      "\tLoss: 0.10570546984672546\n",
      "\tLoss: 0.09646118432283401\n",
      "\tLoss: 0.08990901708602905\n",
      "\tLoss: 0.09486661851406097\n",
      "\tLoss: 0.097627654671669\n",
      "\tLoss: 0.0761200487613678\n",
      "\tLoss: 0.1425810605287552\n",
      "\tLoss: 0.12617036700248718\n",
      "\tLoss: 0.11946241557598114\n",
      "\tLoss: 0.15991400182247162\n",
      "\tLoss: 0.08987534791231155\n",
      "\tLoss: 0.12803199887275696\n",
      "\tLoss: 0.11544033139944077\n",
      "\tLoss: 0.06718414276838303\n",
      "\tLoss: 0.11115863174200058\n",
      "\tLoss: 0.09755869209766388\n",
      "\tLoss: 0.08228626847267151\n",
      "\tLoss: 0.08168290555477142\n",
      "\tLoss: 0.09129226207733154\n",
      "\tLoss: 0.07858225703239441\n",
      "\tLoss: 0.12259755283594131\n",
      "\tLoss: 0.07220645248889923\n",
      "\tLoss: 0.10535696148872375\n",
      "\tLoss: 0.12380511313676834\n",
      "\tLoss: 0.13359515368938446\n",
      "\tLoss: 0.12379910796880722\n",
      "\tLoss: 0.10620193928480148\n",
      "\tLoss: 0.12411415576934814\n",
      "\tLoss: 0.08124110102653503\n",
      "\tLoss: 0.06772774457931519\n",
      "\tLoss: 0.11625564098358154\n",
      "\tLoss: 0.10682948678731918\n",
      "[time] Epoch 58: 408.9701784076169s = 6.816169640126948m\n",
      "\n",
      "Epoch 59...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.12566927075386047\n",
      "\tLoss: 0.090802863240242\n",
      "\tLoss: 0.10301849246025085\n",
      "\tLoss: 0.10992573946714401\n",
      "\tLoss: 0.10563990473747253\n",
      "\tLoss: 0.06205196678638458\n",
      "\tLoss: 0.15576985478401184\n",
      "\tLoss: 0.09217247366905212\n",
      "\tLoss: 0.12441004812717438\n",
      "\tLoss: 0.09259840846061707\n",
      "\tLoss: 0.12227293848991394\n",
      "\tLoss: 0.18026050925254822\n",
      "\tLoss: 0.11582853645086288\n",
      "\tLoss: 0.09915874898433685\n",
      "\tLoss: 0.07293710112571716\n",
      "\tLoss: 0.10636107623577118\n",
      "\tLoss: 0.08741484582424164\n",
      "\tLoss: 0.12203595042228699\n",
      "\tLoss: 0.13917958736419678\n",
      "\tLoss: 0.0858832374215126\n",
      "\tLoss: 0.11079486459493637\n",
      "\tLoss: 0.13640426099300385\n",
      "\tLoss: 0.13055849075317383\n",
      "\tLoss: 0.11422798782587051\n",
      "\tLoss: 0.10511822998523712\n",
      "\tLoss: 0.10359269380569458\n",
      "\tLoss: 0.11248528957366943\n",
      "\tLoss: 0.07344210147857666\n",
      "\tLoss: 0.08889410644769669\n",
      "\tLoss: 0.12075702100992203\n",
      "\tLoss: 0.12454883009195328\n",
      "\tLoss: 0.09283553063869476\n",
      "\tLoss: 0.06188580393791199\n",
      "\tLoss: 0.08141214400529861\n",
      "\tLoss: 0.0830179750919342\n",
      "\tLoss: 0.09096147119998932\n",
      "\tLoss: 0.12537238001823425\n",
      "\tLoss: 0.11483228206634521\n",
      "\tLoss: 0.1326124221086502\n",
      "\tLoss: 0.06447628140449524\n",
      "\tLoss: 0.18025188148021698\n",
      "\tLoss: 0.10993631184101105\n",
      "\tLoss: 0.14369064569473267\n",
      "\tLoss: 0.13722743093967438\n",
      "\tLoss: 0.09441018104553223\n",
      "\tLoss: 0.15892846882343292\n",
      "\tLoss: 0.14126256108283997\n",
      "\tLoss: 0.14962521195411682\n",
      "\tLoss: 0.1306813508272171\n",
      "\tLoss: 0.10780735313892365\n",
      "\tLoss: 0.12015625834465027\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.1235269159078598\n",
      "\tLoss: 0.1341407746076584\n",
      "\tLoss: 0.13778746128082275\n",
      "\tLoss: 0.15057975053787231\n",
      "\tLoss: 0.10357487946748734\n",
      "\tLoss: 0.1260903924703598\n",
      "\tLoss: 0.106532022356987\n",
      "\tLoss: 0.11702297627925873\n",
      "\tLoss: 0.11018437147140503\n",
      "\tLoss: 0.18038220703601837\n",
      "\tLoss: 0.12888848781585693\n",
      "\tLoss: 0.13060486316680908\n",
      "\tLoss: 0.11631117761135101\n",
      "\tLoss: 0.11479417979717255\n",
      "\tLoss: 0.11093254387378693\n",
      "\tLoss: 0.09595851600170135\n",
      "\tLoss: 0.07270563393831253\n",
      "\tLoss: 0.09220976382493973\n",
      "\tLoss: 0.171250581741333\n",
      "\tLoss: 0.09213252365589142\n",
      "\tLoss: 0.10696811228990555\n",
      "\tLoss: 0.1404440551996231\n",
      "\tLoss: 0.12809887528419495\n",
      "\tLoss: 0.11549340188503265\n",
      "\tLoss: 0.09605623781681061\n",
      "\tLoss: 0.13690391182899475\n",
      "\tLoss: 0.10120789706707001\n",
      "\tLoss: 0.10418400168418884\n",
      "\tLoss: 0.10788043588399887\n",
      "\tLoss: 0.09438786655664444\n",
      "\tLoss: 0.12357915937900543\n",
      "\tLoss: 0.14877313375473022\n",
      "\tLoss: 0.09729845821857452\n",
      "\tLoss: 0.15343895554542542\n",
      "\tLoss: 0.14044323563575745\n",
      "\tLoss: 0.0847182348370552\n",
      "\tLoss: 0.08397386968135834\n",
      "\tLoss: 0.08937302976846695\n",
      "\tLoss: 0.14874598383903503\n",
      "\tLoss: 0.15519452095031738\n",
      "\tLoss: 0.10961496829986572\n",
      "\tLoss: 0.10772264003753662\n",
      "\tLoss: 0.14530326426029205\n",
      "\tLoss: 0.08658814430236816\n",
      "\tLoss: 0.13050425052642822\n",
      "\tLoss: 0.11423008143901825\n",
      "\tLoss: 0.1305651217699051\n",
      "\tLoss: 0.07054119557142258\n",
      "\tLoss: 0.11110825836658478\n",
      "\tLoss: 0.11436361074447632\n",
      "\tLoss: 0.08798564970493317\n",
      "[time] Epoch 59: 408.58724651904777s = 6.809787441984129m\n",
      "\n",
      "Epoch 60...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.06898656487464905\n",
      "\tLoss: 0.10626933723688126\n",
      "\tLoss: 0.10933901369571686\n",
      "\tLoss: 0.10654740780591965\n",
      "\tLoss: 0.14062294363975525\n",
      "\tLoss: 0.11067059636116028\n",
      "\tLoss: 0.08288029581308365\n",
      "\tLoss: 0.09437558799982071\n",
      "\tLoss: 0.129513680934906\n",
      "\tLoss: 0.12041248381137848\n",
      "\tLoss: 0.08449845761060715\n",
      "\tLoss: 0.1129249706864357\n",
      "\tLoss: 0.09107492864131927\n",
      "\tLoss: 0.10290604829788208\n",
      "\tLoss: 0.11632279306650162\n",
      "\tLoss: 0.1007760688662529\n",
      "\tLoss: 0.13210277259349823\n",
      "\tLoss: 0.14609216153621674\n",
      "\tLoss: 0.13678961992263794\n",
      "\tLoss: 0.11061941832304001\n",
      "\tLoss: 0.09322571009397507\n",
      "\tLoss: 0.0840979814529419\n",
      "\tLoss: 0.10226519405841827\n",
      "\tLoss: 0.0976174846291542\n",
      "\tLoss: 0.10809671878814697\n",
      "\tLoss: 0.12086129933595657\n",
      "\tLoss: 0.07011833786964417\n",
      "\tLoss: 0.05688531696796417\n",
      "\tLoss: 0.10215839743614197\n",
      "\tLoss: 0.1086353287100792\n",
      "\tLoss: 0.11280226707458496\n",
      "\tLoss: 0.09560074657201767\n",
      "\tLoss: 0.12322674691677094\n",
      "\tLoss: 0.10426285862922668\n",
      "\tLoss: 0.09935764968395233\n",
      "\tLoss: 0.1013869196176529\n",
      "\tLoss: 0.09723196178674698\n",
      "\tLoss: 0.13794773817062378\n",
      "\tLoss: 0.06676027923822403\n",
      "\tLoss: 0.05268030986189842\n",
      "\tLoss: 0.09550543129444122\n",
      "\tLoss: 0.14279544353485107\n",
      "\tLoss: 0.20818038284778595\n",
      "\tLoss: 0.12575234472751617\n",
      "\tLoss: 0.13247132301330566\n",
      "\tLoss: 0.12983685731887817\n",
      "\tLoss: 0.08598340302705765\n",
      "\tLoss: 0.10851308703422546\n",
      "\tLoss: 0.1313931941986084\n",
      "\tLoss: 0.16484197974205017\n",
      "\tLoss: 0.09472078084945679\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.10212153941392899\n",
      "\tLoss: 0.1321876347064972\n",
      "\tLoss: 0.12009412050247192\n",
      "\tLoss: 0.05908158794045448\n",
      "\tLoss: 0.10247072577476501\n",
      "\tLoss: 0.14125996828079224\n",
      "\tLoss: 0.060024697333574295\n",
      "\tLoss: 0.07227324694395065\n",
      "\tLoss: 0.09967787563800812\n",
      "\tLoss: 0.14080794155597687\n",
      "\tLoss: 0.07417234778404236\n",
      "\tLoss: 0.0833868756890297\n",
      "\tLoss: 0.09097877144813538\n",
      "\tLoss: 0.13120517134666443\n",
      "\tLoss: 0.15110236406326294\n",
      "\tLoss: 0.10494552552700043\n",
      "\tLoss: 0.08898910135030746\n",
      "\tLoss: 0.1482950896024704\n",
      "\tLoss: 0.1087152436375618\n",
      "\tLoss: 0.11546176671981812\n",
      "\tLoss: 0.12020167708396912\n",
      "\tLoss: 0.09716297686100006\n",
      "\tLoss: 0.11579404771327972\n",
      "\tLoss: 0.13590243458747864\n",
      "\tLoss: 0.14733049273490906\n",
      "\tLoss: 0.0995420515537262\n",
      "\tLoss: 0.12272104620933533\n",
      "\tLoss: 0.06446097791194916\n",
      "\tLoss: 0.06837393343448639\n",
      "\tLoss: 0.16391511261463165\n",
      "\tLoss: 0.11477142572402954\n",
      "\tLoss: 0.09303180128335953\n",
      "\tLoss: 0.13421748578548431\n",
      "\tLoss: 0.09177275747060776\n",
      "\tLoss: 0.11874087154865265\n",
      "\tLoss: 0.1496773064136505\n",
      "\tLoss: 0.1286771595478058\n",
      "\tLoss: 0.14068160951137543\n",
      "\tLoss: 0.12827250361442566\n",
      "\tLoss: 0.15031862258911133\n",
      "\tLoss: 0.08643887937068939\n",
      "\tLoss: 0.16273583471775055\n",
      "\tLoss: 0.10480652004480362\n",
      "\tLoss: 0.11311420798301697\n",
      "\tLoss: 0.09701943397521973\n",
      "\tLoss: 0.08157236874103546\n",
      "\tLoss: 0.12450629472732544\n",
      "\tLoss: 0.08765605837106705\n",
      "\tLoss: 0.12115973234176636\n",
      "\tLoss: 0.1376117616891861\n",
      "\tLoss: 0.08260494470596313\n",
      "[time] Epoch 60: 408.4436676208861s = 6.807394460348102m\n",
      "\n",
      "Epoch 61...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1266184151172638\n",
      "\tLoss: 0.09049656242132187\n",
      "\tLoss: 0.1135186031460762\n",
      "\tLoss: 0.07676258683204651\n",
      "\tLoss: 0.10088739544153214\n",
      "\tLoss: 0.11500079929828644\n",
      "\tLoss: 0.12493953853845596\n",
      "\tLoss: 0.07988962531089783\n",
      "\tLoss: 0.1004914790391922\n",
      "\tLoss: 0.09600305557250977\n",
      "\tLoss: 0.09930562973022461\n",
      "\tLoss: 0.09876496344804764\n",
      "\tLoss: 0.12690852582454681\n",
      "\tLoss: 0.09181798249483109\n",
      "\tLoss: 0.115227110683918\n",
      "\tLoss: 0.08298030495643616\n",
      "\tLoss: 0.17409838736057281\n",
      "\tLoss: 0.08856043219566345\n",
      "\tLoss: 0.0996338501572609\n",
      "\tLoss: 0.08333048969507217\n",
      "\tLoss: 0.15058784186840057\n",
      "\tLoss: 0.11121918261051178\n",
      "\tLoss: 0.10073888301849365\n",
      "\tLoss: 0.11034882813692093\n",
      "\tLoss: 0.09031476080417633\n",
      "\tLoss: 0.13896989822387695\n",
      "\tLoss: 0.1132415160536766\n",
      "\tLoss: 0.08703826367855072\n",
      "\tLoss: 0.12917523086071014\n",
      "\tLoss: 0.0773584395647049\n",
      "\tLoss: 0.09938676655292511\n",
      "\tLoss: 0.12082941830158234\n",
      "\tLoss: 0.08820141106843948\n",
      "\tLoss: 0.10265632718801498\n",
      "\tLoss: 0.10928517580032349\n",
      "\tLoss: 0.07474163174629211\n",
      "\tLoss: 0.12429990619421005\n",
      "\tLoss: 0.11809452623128891\n",
      "\tLoss: 0.11183154582977295\n",
      "\tLoss: 0.10150649398565292\n",
      "\tLoss: 0.12398121505975723\n",
      "\tLoss: 0.1069198027253151\n",
      "\tLoss: 0.12154217064380646\n",
      "\tLoss: 0.1335756480693817\n",
      "\tLoss: 0.10182046890258789\n",
      "\tLoss: 0.10260026156902313\n",
      "\tLoss: 0.13902881741523743\n",
      "\tLoss: 0.12234889715909958\n",
      "\tLoss: 0.1582070291042328\n",
      "\tLoss: 0.09779807925224304\n",
      "\tLoss: 0.07189557701349258\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.11497905850410461\n",
      "\tLoss: 0.10209585726261139\n",
      "\tLoss: 0.10580600798130035\n",
      "\tLoss: 0.10855767130851746\n",
      "\tLoss: 0.08672238141298294\n",
      "\tLoss: 0.07750241458415985\n",
      "\tLoss: 0.06776412576436996\n",
      "\tLoss: 0.09002810716629028\n",
      "\tLoss: 0.07765234261751175\n",
      "\tLoss: 0.12056927382946014\n",
      "\tLoss: 0.12379954010248184\n",
      "\tLoss: 0.13378094136714935\n",
      "\tLoss: 0.10203295946121216\n",
      "\tLoss: 0.09401699900627136\n",
      "\tLoss: 0.13134367763996124\n",
      "\tLoss: 0.11147083342075348\n",
      "\tLoss: 0.0825323760509491\n",
      "\tLoss: 0.08960258215665817\n",
      "\tLoss: 0.13136348128318787\n",
      "\tLoss: 0.09061910212039948\n",
      "\tLoss: 0.12725552916526794\n",
      "\tLoss: 0.1014925017952919\n",
      "\tLoss: 0.12787239253520966\n",
      "\tLoss: 0.12446112185716629\n",
      "\tLoss: 0.08944915235042572\n",
      "\tLoss: 0.08814708888530731\n",
      "\tLoss: 0.11592812836170197\n",
      "\tLoss: 0.10395033657550812\n",
      "\tLoss: 0.11610695719718933\n",
      "\tLoss: 0.11589952558279037\n",
      "\tLoss: 0.0694366991519928\n",
      "\tLoss: 0.08323988318443298\n",
      "\tLoss: 0.10403352975845337\n",
      "\tLoss: 0.07870496809482574\n",
      "\tLoss: 0.1250988245010376\n",
      "\tLoss: 0.12307151407003403\n",
      "\tLoss: 0.11071311682462692\n",
      "\tLoss: 0.07941645383834839\n",
      "\tLoss: 0.10300539433956146\n",
      "\tLoss: 0.11754626035690308\n",
      "\tLoss: 0.09012634307146072\n",
      "\tLoss: 0.13903303444385529\n",
      "\tLoss: 0.12280794978141785\n",
      "\tLoss: 0.09798053652048111\n",
      "\tLoss: 0.12288442254066467\n",
      "\tLoss: 0.16656503081321716\n",
      "\tLoss: 0.1549559235572815\n",
      "\tLoss: 0.09379202127456665\n",
      "\tLoss: 0.11696518212556839\n",
      "\tLoss: 0.1217804104089737\n",
      "\tLoss: 0.09401342272758484\n",
      "[time] Epoch 61: 408.1835459829308s = 6.803059099715513m\n",
      "\n",
      "Epoch 62...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.09087661653757095\n",
      "\tLoss: 0.08250176906585693\n",
      "\tLoss: 0.07064055651426315\n",
      "\tLoss: 0.06973183155059814\n",
      "\tLoss: 0.09808340668678284\n",
      "\tLoss: 0.10405545681715012\n",
      "\tLoss: 0.12390854954719543\n",
      "\tLoss: 0.11313679814338684\n",
      "\tLoss: 0.1338026225566864\n",
      "\tLoss: 0.11510196328163147\n",
      "\tLoss: 0.08774226158857346\n",
      "\tLoss: 0.06719408929347992\n",
      "\tLoss: 0.12222306430339813\n",
      "\tLoss: 0.11855743825435638\n",
      "\tLoss: 0.14430730044841766\n",
      "\tLoss: 0.07524469494819641\n",
      "\tLoss: 0.07413068413734436\n",
      "\tLoss: 0.10435651242733002\n",
      "\tLoss: 0.08063536137342453\n",
      "\tLoss: 0.08432315289974213\n",
      "\tLoss: 0.0995931476354599\n",
      "\tLoss: 0.08370315283536911\n",
      "\tLoss: 0.0807155892252922\n",
      "\tLoss: 0.07150828838348389\n",
      "\tLoss: 0.13856513798236847\n",
      "\tLoss: 0.09558866918087006\n",
      "\tLoss: 0.13657976686954498\n",
      "\tLoss: 0.09919943660497665\n",
      "\tLoss: 0.09513159096240997\n",
      "\tLoss: 0.11393433809280396\n",
      "\tLoss: 0.10762623697519302\n",
      "\tLoss: 0.11069737374782562\n",
      "\tLoss: 0.10650072991847992\n",
      "\tLoss: 0.1277945637702942\n",
      "\tLoss: 0.12224239110946655\n",
      "\tLoss: 0.08372648060321808\n",
      "\tLoss: 0.0982506200671196\n",
      "\tLoss: 0.1231834888458252\n",
      "\tLoss: 0.09775709360837936\n",
      "\tLoss: 0.11150206625461578\n",
      "\tLoss: 0.1394076943397522\n",
      "\tLoss: 0.1230086088180542\n",
      "\tLoss: 0.09187181293964386\n",
      "\tLoss: 0.11906860023736954\n",
      "\tLoss: 0.13610446453094482\n",
      "\tLoss: 0.09668730944395065\n",
      "\tLoss: 0.10082526504993439\n",
      "\tLoss: 0.07249894738197327\n",
      "\tLoss: 0.08256544172763824\n",
      "\tLoss: 0.10205185413360596\n",
      "\tLoss: 0.10878854244947433\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.10484436899423599\n",
      "\tLoss: 0.07153952866792679\n",
      "\tLoss: 0.09557005763053894\n",
      "\tLoss: 0.1542131006717682\n",
      "\tLoss: 0.129221111536026\n",
      "\tLoss: 0.16091451048851013\n",
      "\tLoss: 0.12849146127700806\n",
      "\tLoss: 0.13253743946552277\n",
      "\tLoss: 0.0869707316160202\n",
      "\tLoss: 0.12188135087490082\n",
      "\tLoss: 0.11990833282470703\n",
      "\tLoss: 0.08922235667705536\n",
      "\tLoss: 0.09690127521753311\n",
      "\tLoss: 0.1154203861951828\n",
      "\tLoss: 0.19164243340492249\n",
      "\tLoss: 0.11389005184173584\n",
      "\tLoss: 0.11191152036190033\n",
      "\tLoss: 0.08007225394248962\n",
      "\tLoss: 0.13849136233329773\n",
      "\tLoss: 0.09925375878810883\n",
      "\tLoss: 0.10629142820835114\n",
      "\tLoss: 0.10640770196914673\n",
      "\tLoss: 0.10871972888708115\n",
      "\tLoss: 0.11521265655755997\n",
      "\tLoss: 0.10019529610872269\n",
      "\tLoss: 0.0978769063949585\n",
      "\tLoss: 0.11006729304790497\n",
      "\tLoss: 0.10188773274421692\n",
      "\tLoss: 0.10975748300552368\n",
      "\tLoss: 0.13261203467845917\n",
      "\tLoss: 0.12770438194274902\n",
      "\tLoss: 0.12124329805374146\n",
      "\tLoss: 0.1224168911576271\n",
      "\tLoss: 0.11938146501779556\n",
      "\tLoss: 0.10810030251741409\n",
      "\tLoss: 0.08988732099533081\n",
      "\tLoss: 0.13310909271240234\n",
      "\tLoss: 0.06456996500492096\n",
      "\tLoss: 0.10527929663658142\n",
      "\tLoss: 0.16112467646598816\n",
      "\tLoss: 0.09950508922338486\n",
      "\tLoss: 0.10823535919189453\n",
      "\tLoss: 0.11767354607582092\n",
      "\tLoss: 0.08865394443273544\n",
      "\tLoss: 0.119296595454216\n",
      "\tLoss: 0.11888973414897919\n",
      "\tLoss: 0.12159745395183563\n",
      "\tLoss: 0.13061338663101196\n",
      "\tLoss: 0.07308869063854218\n",
      "\tLoss: 0.09502905607223511\n",
      "\tLoss: 0.09549926221370697\n",
      "[time] Epoch 62: 403.5718391770497s = 6.726197319617495m\n",
      "\n",
      "Epoch 63...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.09165526926517487\n",
      "\tLoss: 0.11317809671163559\n",
      "\tLoss: 0.09869827330112457\n",
      "\tLoss: 0.11823059618473053\n",
      "\tLoss: 0.08468226343393326\n",
      "\tLoss: 0.06339424848556519\n",
      "\tLoss: 0.14325398206710815\n",
      "\tLoss: 0.0807081013917923\n",
      "\tLoss: 0.12311264872550964\n",
      "\tLoss: 0.11360323429107666\n",
      "\tLoss: 0.11140584945678711\n",
      "\tLoss: 0.09768392145633698\n",
      "\tLoss: 0.11936276406049728\n",
      "\tLoss: 0.11792594194412231\n",
      "\tLoss: 0.11103901267051697\n",
      "\tLoss: 0.1487576961517334\n",
      "\tLoss: 0.11927225440740585\n",
      "\tLoss: 0.08350890874862671\n",
      "\tLoss: 0.09819614142179489\n",
      "\tLoss: 0.1357082575559616\n",
      "\tLoss: 0.14080630242824554\n",
      "\tLoss: 0.10261017084121704\n",
      "\tLoss: 0.0995468944311142\n",
      "\tLoss: 0.12431928515434265\n",
      "\tLoss: 0.09771406650543213\n",
      "\tLoss: 0.11237788200378418\n",
      "\tLoss: 0.1213698461651802\n",
      "\tLoss: 0.12548230588436127\n",
      "\tLoss: 0.09827052056789398\n",
      "\tLoss: 0.0610586516559124\n",
      "\tLoss: 0.1426633894443512\n",
      "\tLoss: 0.10895556211471558\n",
      "\tLoss: 0.079447902739048\n",
      "\tLoss: 0.11460241675376892\n",
      "\tLoss: 0.08691886067390442\n",
      "\tLoss: 0.14183346927165985\n",
      "\tLoss: 0.12234322726726532\n",
      "\tLoss: 0.12753388285636902\n",
      "\tLoss: 0.0824287012219429\n",
      "\tLoss: 0.11328448355197906\n",
      "\tLoss: 0.11828331649303436\n",
      "\tLoss: 0.11038124561309814\n",
      "\tLoss: 0.12262268364429474\n",
      "\tLoss: 0.12233874201774597\n",
      "\tLoss: 0.0917835533618927\n",
      "\tLoss: 0.13187646865844727\n",
      "\tLoss: 0.1065017431974411\n",
      "\tLoss: 0.14091625809669495\n",
      "\tLoss: 0.10622663795948029\n",
      "\tLoss: 0.11928551644086838\n",
      "\tLoss: 0.12074431777000427\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.08259589970111847\n",
      "\tLoss: 0.12887106835842133\n",
      "\tLoss: 0.08509847521781921\n",
      "\tLoss: 0.1028977558016777\n",
      "\tLoss: 0.1057598739862442\n",
      "\tLoss: 0.09823600947856903\n",
      "\tLoss: 0.03062264248728752\n",
      "\tLoss: 0.11016782373189926\n",
      "\tLoss: 0.07838630676269531\n",
      "\tLoss: 0.1374979317188263\n",
      "\tLoss: 0.1075119897723198\n",
      "\tLoss: 0.09218517690896988\n",
      "\tLoss: 0.10409943014383316\n",
      "\tLoss: 0.09529826790094376\n",
      "\tLoss: 0.12699875235557556\n",
      "\tLoss: 0.1123514324426651\n",
      "\tLoss: 0.12461934238672256\n",
      "\tLoss: 0.14527863264083862\n",
      "\tLoss: 0.1482871174812317\n",
      "\tLoss: 0.1306588500738144\n",
      "\tLoss: 0.11083129048347473\n",
      "\tLoss: 0.0840773731470108\n",
      "\tLoss: 0.16425907611846924\n",
      "\tLoss: 0.08401590585708618\n",
      "\tLoss: 0.09585599601268768\n",
      "\tLoss: 0.09326109290122986\n",
      "\tLoss: 0.08384288102388382\n",
      "\tLoss: 0.09244635701179504\n",
      "\tLoss: 0.11181104183197021\n",
      "\tLoss: 0.09341355413198471\n",
      "\tLoss: 0.11234183609485626\n",
      "\tLoss: 0.12822723388671875\n",
      "\tLoss: 0.1522076427936554\n",
      "\tLoss: 0.08890945464372635\n",
      "\tLoss: 0.11468632519245148\n",
      "\tLoss: 0.11632582545280457\n",
      "\tLoss: 0.12312956899404526\n",
      "\tLoss: 0.12563571333885193\n",
      "\tLoss: 0.1477266550064087\n",
      "\tLoss: 0.10072685778141022\n",
      "\tLoss: 0.0761822983622551\n",
      "\tLoss: 0.13054874539375305\n",
      "\tLoss: 0.13945704698562622\n",
      "\tLoss: 0.13305515050888062\n",
      "\tLoss: 0.0869264006614685\n",
      "\tLoss: 0.08764508366584778\n",
      "\tLoss: 0.1030074805021286\n",
      "\tLoss: 0.09922805428504944\n",
      "\tLoss: 0.09383391588926315\n",
      "\tLoss: 0.07284953445196152\n",
      "\tLoss: 0.08290992677211761\n",
      "[time] Epoch 63: 409.650984223932s = 6.827516403732201m\n",
      "\n",
      "Epoch 64...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.09637504070997238\n",
      "\tLoss: 0.09267892688512802\n",
      "\tLoss: 0.09188681840896606\n",
      "\tLoss: 0.08325842022895813\n",
      "\tLoss: 0.0901719406247139\n",
      "\tLoss: 0.08366382867097855\n",
      "\tLoss: 0.09496257454156876\n",
      "\tLoss: 0.11327854543924332\n",
      "\tLoss: 0.10988268256187439\n",
      "\tLoss: 0.1136883795261383\n",
      "\tLoss: 0.12134309113025665\n",
      "\tLoss: 0.0940067395567894\n",
      "\tLoss: 0.1066872775554657\n",
      "\tLoss: 0.09710044413805008\n",
      "\tLoss: 0.11650080978870392\n",
      "\tLoss: 0.14212827384471893\n",
      "\tLoss: 0.08181522786617279\n",
      "\tLoss: 0.11489745229482651\n",
      "\tLoss: 0.1503305435180664\n",
      "\tLoss: 0.09550568461418152\n",
      "\tLoss: 0.11768758296966553\n",
      "\tLoss: 0.12040688842535019\n",
      "\tLoss: 0.17553025484085083\n",
      "\tLoss: 0.1278325617313385\n",
      "\tLoss: 0.12870372831821442\n",
      "\tLoss: 0.12660866975784302\n",
      "\tLoss: 0.09096777439117432\n",
      "\tLoss: 0.08903518319129944\n",
      "\tLoss: 0.1372261941432953\n",
      "\tLoss: 0.10035903006792068\n",
      "\tLoss: 0.13016358017921448\n",
      "\tLoss: 0.0970243513584137\n"
     ]
    }
   ],
   "source": [
    "# The loss function is the quantity that will be\n",
    "# minimized during training.\n",
    "# TO-DO: Escoger 'loss' adecuado.\n",
    "#loss_func = losses.ContrastiveLoss().to(device)\n",
    "loss_func = nn.CosineEmbeddingLoss().to(device)\n",
    "\n",
    "# The optimizer determines how the network will be\n",
    "# updated based on the loss function.\n",
    "# TO-DO: Escoger 'optimizer' adecuado.\n",
    "#optimizer = torch.optim.SGD(red.parameters(), lr=lr, momentum=momentum) # Usado por MNIST Colab.\n",
    "optimizer = torch.optim.Adam(red.parameters(), lr = lr) # Usado por AlexNet (TMLoss y MSELoss).\n",
    "\n",
    "# Para obtener estadísticas del entrenamiento.\n",
    "loss_history = []\n",
    "epoch_timing = []\n",
    "\n",
    "def train(epoch):\n",
    "    \"\"\"\n",
    "    Entrenamiento de la RN.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inicio, en segundos, del epoch.\n",
    "    epoch_start = timer()\n",
    "    \n",
    "    # Imprimimos el número de epoch.\n",
    "    print(f\"Epoch {epoch}...\")\n",
    "    \n",
    "    # Recorremos cada DataLoader.\n",
    "    for dl_idx, dl in enumerate(birds_dl_train):\n",
    "        \n",
    "        # DEBUG.\n",
    "        print(f\"\\tTrabajando con el {dl_idx}-ésimo DataLoader:\")\n",
    "        \n",
    "        for batch_idx, data in enumerate(dl):\n",
    "\n",
    "            # DEBUG.\n",
    "            relative_batch_str = f\"{batch_idx+1}/{len(dl)}\"\n",
    "            #print(f\"\\tProcesando lote {relative_batch_str}...\")\n",
    "        \n",
    "            # Completando lotes que no tienen tamaño batch_size.\n",
    "            incremento = 0\n",
    "            tam_original = len(data[2])\n",
    "            while len(data[2]) < batch_size:\n",
    "                x,y,l = birds_ds.__getitem__()\n",
    "                x = torch.tensor(x)[None, :]\n",
    "                y = torch.tensor(y)[None, :]\n",
    "                l = torch.unsqueeze(torch.tensor(l), 0)\n",
    "                data[0] = torch.cat((data[0], x), 0)\n",
    "                data[1] = torch.cat((data[1], y), 0)\n",
    "                data[2] = torch.cat((data[2], l), 0)\n",
    "                incremento += 1\n",
    "            if incremento != 0:\n",
    "                print(f\"\\tLote {relative_batch_str} de tamaño {tam_original} incrementado en {incremento}.\")\n",
    "            assert len(data[0]) == len(data[1])\n",
    "            assert len(data[0]) == len(data[2])\n",
    "\n",
    "            # 'data' es una lista que representa un lote:\n",
    "            # data[0] contiene los primeros cachos de audio.\n",
    "            # data[1] contiene los segundos cachos de audio.\n",
    "            # data[2] contiene las etiquetas.\n",
    "            for i,d in enumerate(data):\n",
    "                data[i] = d.to(device)\n",
    "\n",
    "            # Convertimos las etiquetas a tipo flotante.\n",
    "            # Necesario para la función de pérdida BCE.\n",
    "            #data[2] = data[2].to(torch.float32)\n",
    "            # TO-DO: ¿Ya no se usará BCE?\n",
    "\n",
    "            # Vaciamos los gradientes para este lote.\n",
    "            optimizer.zero_grad()\n",
    "            # In PyTorch, for every mini-batch during the training phase,\n",
    "            # we typically want to explicitly set the gradients to zero\n",
    "            # before starting to do backpropragation (i.e., updating the\n",
    "            # Weights and biases) because PyTorch accumulates the gradients\n",
    "            # on subsequent backward passes.\n",
    "\n",
    "            # Metemos los datos a la red neuronal.\n",
    "            output_x, output_y = red(data[0], data[1])\n",
    "\n",
    "            # TO-DO: Describir.\n",
    "\n",
    "            start = timer()\n",
    "            loss = loss_func(output_x, output_y, data[2])\n",
    "            end = timer()\n",
    "            #print(f\"\\t[time] Loss function: {end-start}s\") # DEBUG\n",
    "\n",
    "            start = timer()\n",
    "            loss.backward() #dloss/dx for every variable\n",
    "            end = timer()\n",
    "            #print(f\"\\t[time] Loss backward: {end-start}s\") # DEBUG\n",
    "\n",
    "            # TensorBoard.\n",
    "            writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "\n",
    "            start = timer()\n",
    "            optimizer.step() #to do a one-step update on our parameter.\n",
    "            end = timer()\n",
    "            #print(f\"\\t[time] Optimizer step: {end-start}s\") # DEBUG\n",
    "\n",
    "            # Guardamos estadísticas del entrenamiento.\n",
    "            loss_history.append(loss.item())\n",
    "\n",
    "\n",
    "            # DEBUG:\n",
    "            print(f\"\\tLoss: {loss}\")\n",
    "            #print(f\"\\tEtiquetas: {data[2]}\")\n",
    "            #print(f\"\\tOutput: {output}\")\n",
    "            #print()\n",
    "\n",
    "            #break # DEBUG: Permite el entrenamiento de sólo un lote.\n",
    "    \n",
    "    # Fin, en segundos, del epoch.\n",
    "    epoch_end = timer()\n",
    "    \n",
    "    # Tiempo total, en segundos, del epoch.\n",
    "    epoch_time_seconds = epoch_end-epoch_start\n",
    "    epoch_timing.append(epoch_time_seconds)\n",
    "    \n",
    "    # DEBUG:\n",
    "    print(f\"[time] Epoch {epoch}: {epoch_time_seconds}s = {epoch_time_seconds/(60)}m\")\n",
    "    print()\n",
    "    \n",
    "# red.train() le indica al modelo que está siendo entrenado.\n",
    "# Esto ayuda con capas como Dropout y BatchNorm, que están\n",
    "# diseñadas para comporsarse distinto durante entrenamiento\n",
    "# y evaluación.\n",
    "red.train()\n",
    "    \n",
    "# Ejecutamos el entrenamiento definido, \"epochs\" veces.\n",
    "train_start = timer()\n",
    "for epoch in range(1, epochs+1): # Rango [a, b)\n",
    "    train(epoch)\n",
    "    #break # DEBUG: Permite la ejecución de sólo un epoch.\n",
    "train_end = timer()\n",
    "\n",
    "# Call flush() method to make sure that all pending events have been written to disk.\n",
    "# If you do not need the summary writer anymore, call close() method.\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadísticas del entrenamiendo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (20, 10))\n",
    "plt.plot(range(0,len(loss_history)), loss_history, 'r')\n",
    "plt.title('loss_history')\n",
    "plt.xlabel('Lote')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[time] Total training time: 62956.031s = 17.488h\n",
      "[time] Time for each epoch:\n",
      "\t1     671.498s\n",
      "\t2     565.701s\n",
      "\t3     532.628s\n",
      "\t4     511.283s\n",
      "\t5     489.477s\n",
      "\t6     478.012s\n",
      "\t7     465.528s\n",
      "\t8     456.601s\n",
      "\t9     470.787s\n",
      "\t10    469.812s\n",
      "\t11    471.846s\n",
      "\t12    473.655s\n",
      "\t13    477.076s\n",
      "\t14    476.824s\n",
      "\t15    478.633s\n",
      "\t16    473.839s\n",
      "\t17    468.426s\n",
      "\t18    468.801s\n",
      "\t19    466.691s\n",
      "\t20    467.988s\n",
      "\t21    461.805s\n",
      "\t22    464.192s\n",
      "\t23    460.493s\n",
      "\t24    457.133s\n",
      "\t25    455.876s\n",
      "\t26    456.475s\n",
      "\t27    452.051s\n",
      "\t28    449.816s\n",
      "\t29    452.637s\n",
      "\t30    452.507s\n",
      "\t31    452.605s\n",
      "\t32    444.613s\n",
      "\t33    432.412s\n",
      "\t34    426.409s\n",
      "\t35    425.995s\n",
      "\t36    423.146s\n",
      "\t37    420.279s\n",
      "\t38    419.124s\n",
      "\t39    417.335s\n",
      "\t40    420.401s\n",
      "\t41    416.468s\n",
      "\t42    422.247s\n",
      "\t43    421.735s\n",
      "\t44    419.534s\n",
      "\t45    418.886s\n",
      "\t46    423.003s\n",
      "\t47    420.256s\n",
      "\t48    418.435s\n",
      "\t49    420.270s\n",
      "\t50    418.330s\n",
      "\t51    420.921s\n",
      "\t52    420.265s\n",
      "\t53    417.100s\n",
      "\t54    411.768s\n",
      "\t55    413.249s\n",
      "\t56    409.422s\n",
      "\t57    411.502s\n",
      "\t58    408.970s\n",
      "\t59    408.587s\n",
      "\t60    408.444s\n",
      "\t61    408.184s\n",
      "\t62    403.572s\n",
      "\t63    409.651s\n",
      "\t64    417.759s\n",
      "\t65    416.937s\n",
      "\t66    414.423s\n",
      "\t67    413.679s\n",
      "\t68    412.955s\n",
      "\t69    410.788s\n",
      "\t70    405.938s\n",
      "\t71    406.009s\n",
      "\t72    406.483s\n",
      "\t73    403.583s\n",
      "\t74    406.862s\n",
      "\t75    408.359s\n",
      "\t76    401.641s\n",
      "\t77    400.935s\n",
      "\t78    402.368s\n",
      "\t79    403.028s\n",
      "\t80    401.472s\n",
      "\t81    401.201s\n",
      "\t82    402.508s\n",
      "\t83    398.739s\n",
      "\t84    406.509s\n",
      "\t85    404.479s\n",
      "\t86    403.336s\n",
      "\t87    400.537s\n",
      "\t88    399.061s\n",
      "\t89    402.614s\n",
      "\t90    400.644s\n",
      "\t91    398.721s\n",
      "\t92    396.795s\n",
      "\t93    396.825s\n",
      "\t94    396.998s\n",
      "\t95    399.445s\n",
      "\t96    399.990s\n",
      "\t97    395.967s\n",
      "\t98    398.305s\n",
      "\t99    396.078s\n",
      "\t100   399.420s\n",
      "\t101   398.896s\n",
      "\t102   398.075s\n",
      "\t103   397.091s\n",
      "\t104   398.303s\n",
      "\t105   395.883s\n",
      "\t106   397.425s\n",
      "\t107   395.222s\n",
      "\t108   395.378s\n",
      "\t109   392.670s\n",
      "\t110   400.641s\n",
      "\t111   394.953s\n",
      "\t112   397.846s\n",
      "\t113   399.377s\n",
      "\t114   398.291s\n",
      "\t115   394.501s\n",
      "\t116   398.879s\n",
      "\t117   397.726s\n",
      "\t118   395.367s\n",
      "\t119   398.725s\n",
      "\t120   397.767s\n",
      "\t121   397.562s\n",
      "\t122   395.616s\n",
      "\t123   392.990s\n",
      "\t124   400.696s\n",
      "\t125   392.703s\n",
      "\t126   394.143s\n",
      "\t127   398.592s\n",
      "\t128   395.483s\n",
      "\t129   395.911s\n",
      "\t130   404.143s\n",
      "\t131   395.195s\n",
      "\t132   395.153s\n",
      "\t133   394.135s\n",
      "\t134   394.109s\n",
      "\t135   396.938s\n",
      "\t136   393.493s\n",
      "\t137   393.789s\n",
      "\t138   393.586s\n",
      "\t139   391.174s\n",
      "\t140   396.835s\n",
      "\t141   394.525s\n",
      "\t142   391.125s\n",
      "\t143   392.558s\n",
      "\t144   393.642s\n",
      "\t145   392.072s\n",
      "\t146   396.112s\n",
      "\t147   396.253s\n",
      "\t148   394.364s\n",
      "\t149   391.840s\n",
      "\t150   395.653s\n"
     ]
    }
   ],
   "source": [
    "train_time_seconds = train_end-train_start\n",
    "print(\"[time] Total training time: {:.3f}s = {:.3f}h\".format(train_time_seconds, train_time_seconds/(60*60)))\n",
    "print(f\"[time] Time for each epoch:\")\n",
    "for i,x in enumerate(epoch_timing):\n",
    "    print (\"\\t{:<5} {:.3f}s\".format(i+1, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testeo de la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1...\n",
      "\tProcesando lote 1/52...\n",
      "\t\tCon umbral -0.5: 28/64\n",
      "\t\tCon umbral    0: 49/64\n",
      "\t\tCon umbral  0.5: 61/64\n",
      "\t\tCon umbral 0.75: 60/64\n",
      "\tProcesando lote 2/52...\n",
      "\t\tCon umbral -0.5: 37/64\n",
      "\t\tCon umbral    0: 53/64\n",
      "\t\tCon umbral  0.5: 60/64\n",
      "\t\tCon umbral 0.75: 61/64\n",
      "\tProcesando lote 3/52...\n",
      "\t\tCon umbral -0.5: 29/64\n",
      "\t\tCon umbral    0: 54/64\n",
      "\t\tCon umbral  0.5: 61/64\n",
      "\t\tCon umbral 0.75: 60/64\n",
      "\tProcesando lote 4/52...\n",
      "\t\tCon umbral -0.5: 34/64\n",
      "\t\tCon umbral    0: 56/64\n",
      "\t\tCon umbral  0.5: 63/64\n",
      "\t\tCon umbral 0.75: 63/64\n",
      "\tProcesando lote 5/52...\n",
      "\t\tCon umbral -0.5: 30/64\n",
      "\t\tCon umbral    0: 55/64\n",
      "\t\tCon umbral  0.5: 60/64\n",
      "\t\tCon umbral 0.75: 60/64\n",
      "\tProcesando lote 6/52...\n",
      "\t\tCon umbral -0.5: 34/64\n",
      "\t\tCon umbral    0: 50/64\n",
      "\t\tCon umbral  0.5: 59/64\n",
      "\t\tCon umbral 0.75: 57/64\n",
      "\tProcesando lote 7/52...\n",
      "\t\tCon umbral -0.5: 35/64\n",
      "\t\tCon umbral    0: 51/64\n",
      "\t\tCon umbral  0.5: 60/64\n",
      "\t\tCon umbral 0.75: 60/64\n",
      "\tProcesando lote 8/52...\n",
      "\t\tCon umbral -0.5: 25/64\n",
      "\t\tCon umbral    0: 49/64\n",
      "\t\tCon umbral  0.5: 63/64\n",
      "\t\tCon umbral 0.75: 59/64\n",
      "\tProcesando lote 9/52...\n",
      "\t\tCon umbral -0.5: 33/64\n",
      "\t\tCon umbral    0: 47/64\n",
      "\t\tCon umbral  0.5: 59/64\n",
      "\t\tCon umbral 0.75: 61/64\n",
      "\tProcesando lote 10/52...\n",
      "\t\tCon umbral -0.5: 30/64\n",
      "\t\tCon umbral    0: 47/64\n",
      "\t\tCon umbral  0.5: 58/64\n",
      "\t\tCon umbral 0.75: 59/64\n",
      "\tProcesando lote 11/52...\n",
      "\t\tCon umbral -0.5: 35/64\n",
      "\t\tCon umbral    0: 51/64\n",
      "\t\tCon umbral  0.5: 63/64\n",
      "\t\tCon umbral 0.75: 62/64\n",
      "\tProcesando lote 12/52...\n",
      "\t\tCon umbral -0.5: 34/64\n",
      "\t\tCon umbral    0: 51/64\n",
      "\t\tCon umbral  0.5: 62/64\n",
      "\t\tCon umbral 0.75: 60/64\n",
      "\tProcesando lote 13/52...\n",
      "\t\tCon umbral -0.5: 38/64\n",
      "\t\tCon umbral    0: 54/64\n",
      "\t\tCon umbral  0.5: 61/64\n",
      "\t\tCon umbral 0.75: 59/64\n",
      "\tProcesando lote 14/52...\n",
      "\t\tCon umbral -0.5: 35/64\n",
      "\t\tCon umbral    0: 49/64\n",
      "\t\tCon umbral  0.5: 60/64\n",
      "\t\tCon umbral 0.75: 61/64\n",
      "\tProcesando lote 15/52...\n",
      "\t\tCon umbral -0.5: 36/64\n",
      "\t\tCon umbral    0: 56/64\n",
      "\t\tCon umbral  0.5: 61/64\n",
      "\t\tCon umbral 0.75: 59/64\n",
      "\tProcesando lote 16/52...\n",
      "\t\tCon umbral -0.5: 20/64\n",
      "\t\tCon umbral    0: 47/64\n",
      "\t\tCon umbral  0.5: 61/64\n",
      "\t\tCon umbral 0.75: 63/64\n",
      "\tProcesando lote 17/52...\n",
      "\t\tCon umbral -0.5: 37/64\n",
      "\t\tCon umbral    0: 49/64\n",
      "\t\tCon umbral  0.5: 57/64\n",
      "\t\tCon umbral 0.75: 60/64\n",
      "\tProcesando lote 18/52...\n",
      "\t\tCon umbral -0.5: 32/64\n",
      "\t\tCon umbral    0: 50/64\n",
      "\t\tCon umbral  0.5: 60/64\n",
      "\t\tCon umbral 0.75: 64/64\n",
      "\tProcesando lote 19/52...\n",
      "\t\tCon umbral -0.5: 31/64\n",
      "\t\tCon umbral    0: 48/64\n",
      "\t\tCon umbral  0.5: 62/64\n",
      "\t\tCon umbral 0.75: 63/64\n",
      "\tProcesando lote 20/52...\n",
      "\t\tCon umbral -0.5: 30/64\n",
      "\t\tCon umbral    0: 53/64\n",
      "\t\tCon umbral  0.5: 62/64\n",
      "\t\tCon umbral 0.75: 63/64\n",
      "\tProcesando lote 21/52...\n",
      "\t\tCon umbral -0.5: 41/64\n",
      "\t\tCon umbral    0: 57/64\n",
      "\t\tCon umbral  0.5: 60/64\n",
      "\t\tCon umbral 0.75: 60/64\n",
      "\tProcesando lote 22/52...\n",
      "\t\tCon umbral -0.5: 41/64\n",
      "\t\tCon umbral    0: 54/64\n",
      "\t\tCon umbral  0.5: 58/64\n",
      "\t\tCon umbral 0.75: 59/64\n",
      "\tProcesando lote 23/52...\n",
      "\t\tCon umbral -0.5: 38/64\n",
      "\t\tCon umbral    0: 56/64\n",
      "\t\tCon umbral  0.5: 62/64\n",
      "\t\tCon umbral 0.75: 63/64\n",
      "\tProcesando lote 24/52...\n",
      "\t\tCon umbral -0.5: 34/64\n",
      "\t\tCon umbral    0: 52/64\n",
      "\t\tCon umbral  0.5: 62/64\n",
      "\t\tCon umbral 0.75: 61/64\n",
      "\tProcesando lote 25/52...\n",
      "\t\tCon umbral -0.5: 33/64\n",
      "\t\tCon umbral    0: 50/64\n",
      "\t\tCon umbral  0.5: 59/64\n",
      "\t\tCon umbral 0.75: 62/64\n",
      "\tProcesando lote 26/52...\n",
      "\t\tCon umbral -0.5: 34/64\n",
      "\t\tCon umbral    0: 50/64\n",
      "\t\tCon umbral  0.5: 60/64\n",
      "\t\tCon umbral 0.75: 60/64\n",
      "\tProcesando lote 27/52...\n",
      "\t\tCon umbral -0.5: 30/64\n",
      "\t\tCon umbral    0: 48/64\n",
      "\t\tCon umbral  0.5: 60/64\n",
      "\t\tCon umbral 0.75: 63/64\n",
      "\tProcesando lote 28/52...\n",
      "\t\tCon umbral -0.5: 42/64\n",
      "\t\tCon umbral    0: 55/64\n",
      "\t\tCon umbral  0.5: 61/64\n",
      "\t\tCon umbral 0.75: 61/64\n",
      "\tProcesando lote 29/52...\n",
      "\t\tCon umbral -0.5: 31/64\n",
      "\t\tCon umbral    0: 50/64\n",
      "\t\tCon umbral  0.5: 63/64\n",
      "\t\tCon umbral 0.75: 63/64\n",
      "\tProcesando lote 30/52...\n",
      "\t\tCon umbral -0.5: 33/64\n",
      "\t\tCon umbral    0: 50/64\n",
      "\t\tCon umbral  0.5: 58/64\n",
      "\t\tCon umbral 0.75: 62/64\n",
      "\tProcesando lote 31/52...\n",
      "\t\tCon umbral -0.5: 29/64\n",
      "\t\tCon umbral    0: 52/64\n",
      "\t\tCon umbral  0.5: 63/64\n",
      "\t\tCon umbral 0.75: 61/64\n",
      "\tProcesando lote 32/52...\n",
      "\t\tCon umbral -0.5: 36/64\n",
      "\t\tCon umbral    0: 49/64\n",
      "\t\tCon umbral  0.5: 64/64\n",
      "\t\tCon umbral 0.75: 63/64\n",
      "\tProcesando lote 33/52...\n",
      "\t\tCon umbral -0.5: 28/64\n",
      "\t\tCon umbral    0: 48/64\n",
      "\t\tCon umbral  0.5: 60/64\n",
      "\t\tCon umbral 0.75: 63/64\n",
      "\tProcesando lote 34/52...\n",
      "\t\tCon umbral -0.5: 34/64\n",
      "\t\tCon umbral    0: 54/64\n",
      "\t\tCon umbral  0.5: 61/64\n",
      "\t\tCon umbral 0.75: 62/64\n",
      "\tProcesando lote 35/52...\n",
      "\t\tCon umbral -0.5: 32/64\n",
      "\t\tCon umbral    0: 49/64\n",
      "\t\tCon umbral  0.5: 61/64\n",
      "\t\tCon umbral 0.75: 61/64\n",
      "\tProcesando lote 36/52...\n",
      "\t\tCon umbral -0.5: 41/64\n",
      "\t\tCon umbral    0: 56/64\n",
      "\t\tCon umbral  0.5: 63/64\n",
      "\t\tCon umbral 0.75: 62/64\n",
      "\tProcesando lote 37/52...\n",
      "\t\tCon umbral -0.5: 39/64\n",
      "\t\tCon umbral    0: 52/64\n",
      "\t\tCon umbral  0.5: 63/64\n",
      "\t\tCon umbral 0.75: 59/64\n",
      "\tProcesando lote 38/52...\n",
      "\t\tCon umbral -0.5: 31/64\n",
      "\t\tCon umbral    0: 56/64\n",
      "\t\tCon umbral  0.5: 63/64\n",
      "\t\tCon umbral 0.75: 64/64\n",
      "\tProcesando lote 39/52...\n",
      "\t\tCon umbral -0.5: 40/64\n",
      "\t\tCon umbral    0: 55/64\n",
      "\t\tCon umbral  0.5: 60/64\n",
      "\t\tCon umbral 0.75: 61/64\n",
      "\tProcesando lote 40/52...\n",
      "\t\tCon umbral -0.5: 34/64\n",
      "\t\tCon umbral    0: 52/64\n",
      "\t\tCon umbral  0.5: 62/64\n",
      "\t\tCon umbral 0.75: 62/64\n",
      "\tProcesando lote 41/52...\n",
      "\t\tCon umbral -0.5: 41/64\n",
      "\t\tCon umbral    0: 55/64\n",
      "\t\tCon umbral  0.5: 60/64\n",
      "\t\tCon umbral 0.75: 61/64\n",
      "\tProcesando lote 42/52...\n",
      "\t\tCon umbral -0.5: 34/64\n",
      "\t\tCon umbral    0: 51/64\n",
      "\t\tCon umbral  0.5: 61/64\n",
      "\t\tCon umbral 0.75: 60/64\n",
      "\tProcesando lote 43/52...\n",
      "\t\tCon umbral -0.5: 36/64\n",
      "\t\tCon umbral    0: 51/64\n",
      "\t\tCon umbral  0.5: 62/64\n",
      "\t\tCon umbral 0.75: 62/64\n",
      "\tProcesando lote 44/52...\n",
      "\t\tCon umbral -0.5: 35/64\n",
      "\t\tCon umbral    0: 54/64\n",
      "\t\tCon umbral  0.5: 62/64\n",
      "\t\tCon umbral 0.75: 63/64\n",
      "\tProcesando lote 45/52...\n",
      "\t\tCon umbral -0.5: 28/64\n",
      "\t\tCon umbral    0: 49/64\n",
      "\t\tCon umbral  0.5: 58/64\n",
      "\t\tCon umbral 0.75: 62/64\n",
      "\tProcesando lote 46/52...\n",
      "\t\tCon umbral -0.5: 34/64\n",
      "\t\tCon umbral    0: 52/64\n",
      "\t\tCon umbral  0.5: 61/64\n",
      "\t\tCon umbral 0.75: 61/64\n",
      "\tProcesando lote 47/52...\n",
      "\t\tCon umbral -0.5: 37/64\n",
      "\t\tCon umbral    0: 50/64\n",
      "\t\tCon umbral  0.5: 62/64\n",
      "\t\tCon umbral 0.75: 61/64\n",
      "\tProcesando lote 48/52...\n",
      "\t\tCon umbral -0.5: 32/64\n",
      "\t\tCon umbral    0: 49/64\n",
      "\t\tCon umbral  0.5: 60/64\n",
      "\t\tCon umbral 0.75: 61/64\n",
      "\tProcesando lote 49/52...\n",
      "\t\tCon umbral -0.5: 32/64\n",
      "\t\tCon umbral    0: 49/64\n",
      "\t\tCon umbral  0.5: 60/64\n",
      "\t\tCon umbral 0.75: 60/64\n",
      "\tProcesando lote 50/52...\n",
      "\t\tCon umbral -0.5: 29/64\n",
      "\t\tCon umbral    0: 53/64\n",
      "\t\tCon umbral  0.5: 63/64\n",
      "\t\tCon umbral 0.75: 63/64\n",
      "\tProcesando lote 51/52...\n",
      "\t\tCon umbral -0.5: 39/64\n",
      "\t\tCon umbral    0: 52/64\n",
      "\t\tCon umbral  0.5: 60/64\n",
      "\t\tCon umbral 0.75: 57/64\n",
      "\tProcesando lote 52/52...\n",
      "\tLote de tamaño 13 incrementado en 51.\n",
      "\t\tCon umbral -0.5: 32/64\n",
      "\t\tCon umbral    0: 53/64\n",
      "\t\tCon umbral  0.5: 62/64\n",
      "\t\tCon umbral 0.75: 62/64\n"
     ]
    }
   ],
   "source": [
    "# Cargado de la RN.\n",
    "fecha = \"2023-01-28-17-37\"\n",
    "#red = RN().to(device)\n",
    "#red.load_state_dict(torch.load(DIR_models+fecha+\".pt\"))\n",
    "red.eval()\n",
    "    \n",
    "def test(epoch):\n",
    "    \"\"\"\n",
    "    Testeo de la RN.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inicio, en segundos, del epoch.\n",
    "    epoch_start = timer()\n",
    "    \n",
    "    # Imprimimos el número de epoch.\n",
    "    print(f\"Epoch {epoch}...\")\n",
    "    \n",
    "    for batch_idx, data in enumerate(birds_dl_test):\n",
    "\n",
    "        # DEBUG.\n",
    "        print(f\"\\tProcesando lote {batch_idx+1}/{len(birds_dl_test)}...\")\n",
    "        \n",
    "        # Completando lotes que no tienen tamaño batch_size.\n",
    "        incremento = 0\n",
    "        tam_original = len(data[2])\n",
    "        while len(data[2]) < batch_size:\n",
    "            x,y,l = birds_ds.__getitem__()\n",
    "            x = torch.tensor(x)[None, :]\n",
    "            y = torch.tensor(y)[None, :]\n",
    "            l = torch.unsqueeze(torch.tensor(l), 0)\n",
    "            data[0] = torch.cat((data[0], x), 0)\n",
    "            data[1] = torch.cat((data[1], y), 0)\n",
    "            data[2] = torch.cat((data[2], l), 0)\n",
    "            incremento += 1\n",
    "        if incremento != 0:\n",
    "            print(f\"\\tLote de tamaño {tam_original} incrementado en {incremento}.\")\n",
    "        assert len(data[0]) == len(data[1])\n",
    "        assert len(data[0]) == len(data[2])\n",
    "        \n",
    "        # 'data' es una lista que representa un lote:\n",
    "        # data[0] contiene los primeros cachos de audio.\n",
    "        # data[1] contiene los segundos cachos de audio.\n",
    "        # data[2] contiene las etiquetas.\n",
    "        for i,d in enumerate(data):\n",
    "            data[i] = d.to(device)\n",
    "        \n",
    "        # Metemos los datos a la red neuronal.\n",
    "        output_x, output_y = red(data[0], data[1])\n",
    "        \n",
    "        # Realizamos la diferencia con Similitud Coseno.\n",
    "        cos = nn.CosineSimilarity()\n",
    "        diff = cos(output_x, output_y)\n",
    "        \n",
    "        #print(f\"Etiquetas: {data[2]}\")\n",
    "        #print(f\"CosineSimilarity: {diff}\")\n",
    "\n",
    "        # Estadísticas del testeo del lote.\n",
    "        correctNeg50 = 0\n",
    "        correctZero = 0\n",
    "        correctPos50 = 0\n",
    "        correctUmbral = 0\n",
    "        umbral = 0.75 # Umbral entre -1 y 1.\n",
    "        \n",
    "        for i,l in enumerate(data[2]):\n",
    "            #total += 1\n",
    "            \n",
    "            if (diff[i] >= -0.5 and l == 1) or (diff[i] < -0.5 and l == -1):\n",
    "                correctNeg50 += 1\n",
    "            \n",
    "            if (diff[i] >= 0 and l == 1) or (diff[i] < 0 and l == -1):\n",
    "                correctZero += 1\n",
    "            \n",
    "            if (diff[i] >= 0.5 and l == 1) or (diff[i] < 0.5 and l == -1):\n",
    "                correctPos50 += 1\n",
    "            \n",
    "            if (diff[i] >= umbral and l == 1) or (diff[i] < umbral and l == -1):\n",
    "                correctUmbral += 1\n",
    "        \n",
    "        print(f\"\\t\\tCon umbral -0.5: {correctNeg50}/{len(data[2])}\")\n",
    "        print(f\"\\t\\tCon umbral    0: {correctZero}/{len(data[2])}\")\n",
    "        print(f\"\\t\\tCon umbral  0.5: {correctPos50}/{len(data[2])}\")\n",
    "        print(f\"\\t\\tCon umbral {umbral}: {correctUmbral}/{len(data[2])}\")\n",
    "        \n",
    "        # DEBUG: Permite el testeo de un sólo lote\n",
    "        #break\n",
    "        \n",
    "        # TO-DO: Terminar definición del testeo.\n",
    "\n",
    "# Ejecutamos el testeo definido, \"epochs\" veces.\n",
    "test_start = timer()\n",
    "for epoch in range(1, epochs+1): # Rango [a, b)\n",
    "    test(epoch)\n",
    "    break # DEBUG: Permite la ejecución de sólo un epoch.\n",
    "test_end = timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadísticas del testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[time] Total testing time: 197.523s = 3.292m = 0.055h\n"
     ]
    }
   ],
   "source": [
    "test_time_seconds = test_end-test_start\n",
    "print(\"[time] Total testing time: {:.3f}s = {:.3f}m = {:.3f}h\".format(test_time_seconds, test_time_seconds/60, test_time_seconds/(60*60)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardado de la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(red.state_dict(), DIR_models+dt_string+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG\n",
    "\n",
    "Esta celda y las siguientes son para testear. Han de ser eliminadas cuando se limpie el código de este *notebook*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado de objetos.\n",
    "with open(DIR_objects+dt_string+\"_loss-history\", \"wb\") as file:\n",
    "    pickle.dump(loss_history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargado de objetos.\n",
    "fecha = \"\"\n",
    "\n",
    "#with open(DIR_objects+fecha+\"_loss-history\", \"rb\") as file:\n",
    "    #pickle.dump(loss_history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = birds_df.iloc[5][file_col_name]\n",
    "#librosa_process(birds_path+f, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.uniform(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9\n",
      "1 2 3 4 5 6 7 8 9\n"
     ]
    }
   ],
   "source": [
    "print(*range(0,10))\n",
    "print(*range(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21-02-2023-22-57-55\n"
     ]
    }
   ],
   "source": [
    "dt_string = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "print(dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargado de modelos.\n",
    "fecha = \"\"\n",
    "\n",
    "# Definimos un modelo que alojará a la Red Neuronal.\n",
    "#modelo = RN().to(device)\n",
    "\n",
    "# Actualizamos el modelo.\n",
    "#modelo.load_state_dict(torch.load(DIR_models+fecha+\".pt\"))\n",
    "\n",
    "# modelo.eval() le indica al modelo que ha de evaluar.\n",
    "#modelo.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3277\n",
      "3277\n",
      "total_audios/batch_size = 51.203125\n"
     ]
    }
   ],
   "source": [
    "print(len(birds_df))\n",
    "print(len(birds_ds))\n",
    "print(f\"total_audios/batch_size = {len(birds_df)/batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha = \"2023-02-01-05-24\"\n",
    "#red = RN().to(device)\n",
    "#red.load_state_dict(torch.load(DIR_models+fecha+\".pt\"))\n",
    "#red.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: -1\n",
      "diff: tensor([-0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451,\n",
      "        -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451,\n",
      "        -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451,\n",
      "        -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451,\n",
      "        -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451,\n",
      "        -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451,\n",
      "        -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451,\n",
      "        -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451, -0.0451],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x,y,l = birds_ds.__getitem__()\n",
    "\n",
    "x = np.expand_dims(x, 0)\n",
    "x = np.repeat(x, batch_size, axis=0)\n",
    "x = torch.tensor(x).to(device)\n",
    "\n",
    "y = np.expand_dims(y, 0)\n",
    "y = np.repeat(y, batch_size, axis=0)\n",
    "y = torch.tensor(y).to(device)\n",
    "\n",
    "#l = np.repeat(l, batch_size)\n",
    "\n",
    "output_x, output_y = red(x, y)\n",
    "cos = nn.CosineSimilarity()\n",
    "diff = cos(output_x, output_y)\n",
    "\n",
    "print(f\"label: {l}\")\n",
    "print(f\"diff: {diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En México:\n",
      "2023-02-21 16:57:55.934758-06:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone, timedelta\n",
    "print(\"En México:\")\n",
    "print(datetime.now(timezone(timedelta(hours=-6))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
