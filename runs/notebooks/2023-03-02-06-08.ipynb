{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "Este *notebook* incluye:\n",
    "- Pequeños ejemplos de uso de *pandas*.\n",
    "- Un *DataSet* (de *PyTorch*) que almacena información de los archivos de audio con los cantos de las aves. Este *DataSet*, al solicitársele el i-ésimo *item*, devuelve un cacho del i-ésimo audio, un cacho de un j-ésimo audio, y un 0 o 1 si `i != j` o `i == j` respectivamente.\n",
    "- Un *DataLoader* (de *PyTorch*) que envuelve al *DataSet* previamente descrito.\n",
    "- Una Red Neuronal (de *PyTorch*) que toma los espectrogramas de dos audios de longitud 1s cada uno, y devuelve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importaciones\n",
    "\n",
    "Importación de las bibliotecas a utilizar, y una pequeña descripción de cada una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alamina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/alamina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/alamina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/alamina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/alamina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/alamina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# pandas is an open source data analysis and manipulation tool.\n",
    "import pandas as pd\n",
    "\n",
    "# NumPy is for scientific computing with Python\n",
    "import numpy as np\n",
    "\n",
    "# TensorFlow is a free and open-source software library\n",
    "# for machine learning and artificial intelligence.\n",
    "import tensorflow as tf\n",
    "\n",
    "# PyTorch is an open source machine learning framework.\n",
    "import torch\n",
    "\n",
    "# PyTorch provides the torch.nn module to help us\n",
    "# in creating and training of the neural network.\n",
    "import torch.nn as nn\n",
    "\n",
    "# PyTorch has two primitives to work with data:\n",
    "# torch.utils.data.Dataset stores the samples and their corresponding labels.\n",
    "# torch.utils.data.DataLoader wraps an iterable around the Dataset.\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# \"The easiest way to use deep metric learning in your application\".\n",
    "# Written in PyTorch.\n",
    "# https://github.com/KevinMusgrave/pytorch-metric-learning\n",
    "from pytorch_metric_learning import losses\n",
    "\n",
    "# librosa is for music and audio analysis; it provides\n",
    "# the building blocks necessary to create music\n",
    "# information retrieval systems.\n",
    "import librosa\n",
    "\n",
    "# Displays a spectrogram/chromagram/cqt/etc.\n",
    "from librosa.display import specshow\n",
    "\n",
    "# matplotlib.pyplot is a collection of functions that make\n",
    "# matplotlib work like MATLAB. Each pyplot function makes\n",
    "# some change to a figure: e.g., creates a figure, creates\n",
    "# a plotting area in a figure, plots some lines in a plotting\n",
    "# area, decorates the plot with labels, etc.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TensorBoard is a visualization toolkit for machine learning\n",
    "# experimentation. TensorBoard allows tracking and visualizing\n",
    "# metrics such as loss and accuracy, visualizing the model graph,\n",
    "# viewing histograms, displaying images and much more.\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Para utilizar t-SNE.\n",
    "from tensorboard.plugins import projector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Para tomar el tiempo que toman ciertos procesos de la siguiente manera:\n",
    "# start = timer()\n",
    "# (algún proceso)\n",
    "# end = timer()\n",
    "# El tiempo en segundos es end-start.\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# CUDA-accelerated PyTorch implementation of the\n",
    "# T-Stochastic Neighbor Embedding algorithm.\n",
    "#from tsne_torch import TorchTSNE as TSNE\n",
    "\n",
    "# Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Manejo de guardado y cargado de objetos mediante archivos.\n",
    "import pickle\n",
    "\n",
    "# Manejo de pseudo-aleatoriedad.\n",
    "import random\n",
    "\n",
    "# Manejo de funciones matemáticas.\n",
    "import math\n",
    "\n",
    "# Manejo de fecha y tiempo.\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables generales\n",
    "\n",
    "Variables generales/globales que se utilizarán a lo largo del *notebook*. Conviene tener este apartado para consultarlas y modificarlas fácilmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizando cuda:0 para el procesamiento de datos.\n"
     ]
    }
   ],
   "source": [
    "# Uso del GPU, si está disponible.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Utilizando {device} para el procesamiento de datos.\")\n",
    "\n",
    "# Cadena con la ubicación del archivo CSV que contiene\n",
    "# el DataFrame con datos de los audios de aves.\n",
    "birds_csv = \"/media/birds/BirdsDataFrame.csv\"\n",
    "\n",
    "# Cadena con la ubicación de los archivos WAV y XML\n",
    "# correspondientes a los audios de aves a procesar.\n",
    "birds_path = \"/media/birds/data/\"\n",
    "\n",
    "# Otras ubicaciones útiles.\n",
    "DIR_runs = \"./runs/\"\n",
    "DIR_objects = DIR_runs+\"python_objects/\"\n",
    "DIR_tensorboard = DIR_runs+\"tensorboard/\"\n",
    "DIR_notebooks = DIR_runs+\"notebooks/\"\n",
    "DIR_models = DIR_runs+\"models/\"\n",
    "\n",
    "# Nombre de la columna, dentro del DataFrame,\n",
    "# que contiene el nombre de los archivos de audio.\n",
    "file_col_name = \"FileName\"\n",
    "\n",
    "# DataFrame (de 'pandas') del archivo CSV dado.\n",
    "birds_df = pd.read_csv(birds_csv)\n",
    "\n",
    "# Los audios de aves se cortarán en cachos cuya longitud\n",
    "# varíe entre len_min segundos y len_max segundos.\n",
    "len_min = 1\n",
    "len_max = 1\n",
    "\n",
    "# Ancho y alto de cada espectrograma.\n",
    "# TO-DO: ¿Es posible calcular esto mediante una fórmula? Resulta del size()/shape de aplicar \"stft\" al audio \"y\".\n",
    "ancho,alto = 1025,87\n",
    "\n",
    "# Número de canales que tendrá cada audio.\n",
    "# Hasta ahora, si un audio tiene 1 canal, y aquí se\n",
    "# especifican 2, se copia el primer canal en un\n",
    "# segundo canal. Si un audio tiene más de 2 canales,\n",
    "# la operación no está definida.\n",
    "audio_channels = 2\n",
    "\n",
    "# Frecuencia de muestreo a la cual TODOS los audios se\n",
    "# muestrearán. Esto es necesario para que los vectores\n",
    "# que representan a los audios tengan los mismos tamaños.\n",
    "sr = 44100\n",
    "\n",
    "# Probabilidad de que dos audios de aves (o\n",
    "# cachos de audios) compartan cierta propiedad.\n",
    "p_prop = 0.5\n",
    "\n",
    "# Variables asociadas a la Red Neuronal.\n",
    "batch_size = 64 # Número de muestras que se tomarán por lote/epoch.\n",
    "epochs = 60 # Veces que se recorrerá un DataSet entero.\n",
    "lr = 6e-03 # Learning Rate.\n",
    "#momentum = 0.5 # The SGD momentum (default: 0.5) is the moving average of our gradients (helps to keep direction).\n",
    "\n",
    "# Para TensorBoard, creamos un SummaryWriter.\n",
    "# Éste escribiría al directorio ./runs/ por defecto.\n",
    "dt_string = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "writer = SummaryWriter(log_dir=DIR_tensorboard+dt_string+\"_adbekunkus\")\n",
    "\n",
    "# Función a utilizar para procesar los audios de aves.\n",
    "def librosa_process(path, cut, cut_len=None):\n",
    "    \"\"\"\n",
    "    Función que carga un audio con Librosa y devuelve el vector\n",
    "    unidimensional que representa al audio, y su frecuencia de muestreo.\n",
    "    :param str path: Ruta donde se ubica el audio.\n",
    "    :param bool cut: ¿Se cortará (y devolverá) sólo un cacho aleatorio del audio?\n",
    "    :param float cut_len: Longitud del cacho de audio (si cut==True).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Longitud del audio completo en segundos.\n",
    "    audio_len = librosa.get_duration(filename=path)\n",
    "    \n",
    "    # Si se desea el audio completo, 'librosa' lo\n",
    "    # cargará desde el inicio hasta el final.\n",
    "    start = 0\n",
    "    duracion = audio_len\n",
    "        \n",
    "    # Si se desea sólo un cacho del audio...\n",
    "    if cut:\n",
    "        \n",
    "        # Determinamos la longitud del cacho\n",
    "        # aleatorio de audio en segundos.\n",
    "        duracion = cut_len if cut_len != None else random.uniform(len_min, len_max) # Rango [a,b].\n",
    "        \n",
    "        # Aseguramos que el audio completo es más\n",
    "        # grande que el tamaño del cacho que queremos.\n",
    "        assert audio_len > duracion\n",
    "        \n",
    "        # Definimos en dónde empezará\n",
    "        # (aleatoriamente) el cacho de audio.\n",
    "        start = random.uniform(0, audio_len-duracion) # Rango [a,b].\n",
    "    \n",
    "    # Obtenemos el audio-vector y su (nueva) frecuencia de muestreo.\n",
    "    y, sampling_rate = librosa.load(path, sr=sr, offset=start, duration=duracion, mono=False)\n",
    "    \n",
    "    # Algunos audios fueron grabados en dos canales (stereo), y otros en\n",
    "    # uno (mono). Convertimos los que fueron grabados en un canal en\n",
    "    # audios de dos canales (al duplicar el único canal que tienen).\n",
    "    if y.ndim == 1:\n",
    "        y = np.repeat(y[np.newaxis, :], 2, axis=0)\n",
    "    \n",
    "    # Función no definida para audios que tienen más de dos canales.\n",
    "    # Igual se lanza un error si los vectores no tienen la longitud adecuada (sr).\n",
    "    assert(y.shape == (2, sr))\n",
    "    \n",
    "    # Short-time Fourier transform (STFT).\n",
    "    # The STFT represents a signal in the time-frequency domain by computing\n",
    "    # discrete Fourier transforms (DFT) over short overlapping windows.\n",
    "    stft = librosa.stft(y)\n",
    "    \n",
    "    # This function (stft) returns a complex-valued matrix D such that\n",
    "    # np.abs(D[..., f, t]) is the magnitude of frequency bin f at frame t.\n",
    "    magnitude = np.abs(stft)\n",
    "    \n",
    "    # Converts an amplitude spectrogram to dB-scaled spectrogram.\n",
    "    spectogram = librosa.amplitude_to_db(magnitude)\n",
    "    \n",
    "    # Devolvemos el espectrograma y su frecuencia de muestreo.\n",
    "    return spectogram, sampling_rate\n",
    "\n",
    "# Comprobaciones sobre las variables aquí definidas.\n",
    "assert len_min <= len_max # Lógicamente, min<=max.\n",
    "assert p_prop >= 0 and p_prop <= 1 # Las probabilidades se encuentran en este rango."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _pandas_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el archivo `birds_csv` cuenta con *N* columnas `columna0,columna1,...,columnaN-1`, imprimimos a continuación el nombre de cada columna, enumerándolas desde cero.\n",
    "\n",
    "**NOTA**: La primera columna no tiene nombre, por lo que *pandas*, al convertir el archivo CSV en un *DataFrame* mediante la función `read_csv()`, le asigna el nombre `Unnamed: 0`. Esta columna sirve para indexar a las entradas dentro del archivo CSV (no confundir con la columna 'index' cuyo propósito es indexar a los archivos de audio de otra manera)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Por cada columna del DataFrame, imprimimos dicha columna.\n",
    "#for i,col in enumerate(birds_df.columns):\n",
    "#    print(f\"{i}:{col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplificamos con la primera entrada del archivo al imprimir qué valor tiene asociado a cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"iloc\" permite indexar por posiciones mediante el uso de enteros.\n",
    "# Por cada columna y valor en la primera línea, imprimimos ambos.\n",
    "#for col, val in birds_df.iloc[0].iteritems():\n",
    "#    print(f\"{col}:{val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay algunas columnas tal que todas las entradas del archivo comparten un mismo valor dentro de esa columna. A continuación imprimimos los nombres de las columnas que cumplen ésto, así como el valor que todas las entradas comparten en dicha columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Por cada columna del DataFrame...\n",
    "#for col in birds_df.columns:\n",
    "    \n",
    "    # Si todas las entradas tienen el mismo valor en dicha\n",
    "    # columna, imprimimos la columna y el valor correspondiente.\n",
    "    #if (birds_df[col] == birds_df[col][0]).all():\n",
    "        #print(f\"{col}:{birds_df[col][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del *DataSet*\n",
    "\n",
    "Creamos el *DataSet* de *PyTorch* que guarda y maneja los datos de los archivos de audio (que contienen los cantos de las aves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBirdDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset de audios de aves.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, process_func, audio_path, transform=None, target_transform=None):\n",
    "        \"\"\"\n",
    "        The __init__ function is run once when instantiating the Dataset object.\n",
    "        \"\"\"\n",
    "        \n",
    "        # 'df' es el DataFrame a almacenar.\n",
    "        self.df = df\n",
    "        \n",
    "        # 'process_func' toma la ruta de un audio a procesar, y lo procesa.\n",
    "        self.process_func = process_func\n",
    "        \n",
    "        # 'audio_path' es la ruta donde se ubican los archivos de audio.\n",
    "        self.audio_path = audio_path\n",
    "        \n",
    "        # 'transform' and 'target_transform' modify the samples and labels respectively.\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        The __len__ function returns the number of samples in our dataset.\n",
    "        \"\"\"\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx=None):\n",
    "        \"\"\"\n",
    "        The __getitem__ function loads and returns a sample from the dataset at the given index 'idx'.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Si no se especifica un índice, se toma una muestra aleatoria.\n",
    "        if idx == None:\n",
    "            idx = random.randrange(0, birds_ds.__len__()) # Rango [a,b).\n",
    "        \n",
    "        # Obtenemos la idx-ésima línea del DataFrame almacenado.\n",
    "        # Y el nombre del archivo de audio a procesar.\n",
    "        item = self.df.iloc[idx]\n",
    "        filename = item[file_col_name]\n",
    "        \n",
    "        # Procesamos el primer cacho de audio.\n",
    "        x,_ = self.process_func(self.audio_path+filename, True)\n",
    "        \n",
    "        # Si se desea que ambos cachos de audio compartan la propiedad,\n",
    "        # sólo dejamos la etiqueta como \"1\", y volvemos a procesar\n",
    "        # el mismo archivo de audio de manera aleatoria (más adelante).\n",
    "        if (random.random() < p_prop):\n",
    "            target = 1\n",
    "            \n",
    "        # Si, por otro lado, se desea que los cachos no compartan la\n",
    "        # propiedad, dejamos la etiqueta como \"-1\", y buscamos otro\n",
    "        # archivo de audio para procesar.\n",
    "        else:\n",
    "            target = -1\n",
    "            \n",
    "            # Guardamos la especie del ave del primer cacho de audio.\n",
    "            primera_especie = item[\"Species\"]\n",
    "            \n",
    "            # Quitamos el primer archivo de audio (que ya fue procesado) del\n",
    "            # DataFrame (temporalmente), obtenemos algún renglón aleatorio de\n",
    "            # este nuevo DataFrame (sample() devuelve un DataFrame, por lo que\n",
    "            # es necesario tomar el primer renglón con iloc[0]), y obtenemos\n",
    "            # el nombre del nuevo archivo de audio a procesar.\n",
    "            item = self.df.drop(idx).sample().iloc[0]\n",
    "            filename = item[file_col_name]\n",
    "                  \n",
    "            # Guardamos la especie del ave del segundo cacho de audio.\n",
    "            segunda_especie = item[\"Species\"]\n",
    "            \n",
    "            # TO-DO: Si son la misma especie, ¿sigo buscando otro segundo cacho\n",
    "            # de audio, o cambio el \"target\" a 1? Por ahora sólo lo cambio a 1.\n",
    "            #print(f\"El primer cacho de audio pertenece a un ave {primera_especie}, y el segundo pertenece a un ave {segunda_especie}.\")\n",
    "            if primera_especie == segunda_especie:\n",
    "                target = 1\n",
    "\n",
    "        # Procesamos el segundo cacho de audio.\n",
    "        y,_ = self.process_func(self.audio_path+filename, True)\n",
    "            \n",
    "        # NOTA:\n",
    "        # Aún no se define el uso para 'transform' y 'target_transform'.\n",
    "        # Una propuesta es que 'transform' sustituya a 'process_func'.\n",
    "        \n",
    "        # Devolvemos el primer cacho de audio, el segundo cacho de audio,\n",
    "        # y la etiqueta que indica si ambos comparten (1) o no (0) la propiedad.\n",
    "        return x, y, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el *DataSet* al pasarle:\n",
    "- El *DataFrame* creado previamente con *pandas*.\n",
    "- La función a utilizar para procesar los audios.\n",
    "- La ruta del directorio en el cual se encuentran los archivos de audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "birds_ds = CustomBirdDataset(birds_df, librosa_process, birds_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo del *DataSet*\n",
    "\n",
    "Y obtenemos una muestra aleatoria del *DataSet* mediante su función `__getitem__()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#birds_ds.__getitem__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del *DataLoader*\n",
    "\n",
    "Creamos dos *DataLoader* de *PyTorch* que envuelven el *DataSet* previamente definido. Uno está definido para el entrenamiento, mientras que otro está definido para el testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "birds_dl_train = [\n",
    "    DataLoader(birds_ds, batch_size=batch_size, shuffle=True, drop_last=True),\n",
    "    DataLoader(birds_ds, batch_size=batch_size, shuffle=False, drop_last=True),\n",
    "    #DataLoader(birds_ds, batch_size=batch_size, shuffle=True, drop_last=True),\n",
    "    #DataLoader(birds_ds, batch_size=batch_size, shuffle=False, drop_last=True),\n",
    "    #DataLoader(birds_ds, batch_size=batch_size, shuffle=True, drop_last=True),\n",
    "]\n",
    "\n",
    "birds_dl_test = DataLoader(birds_ds, batch_size=batch_size, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo del **DataLoader**\n",
    "\n",
    "El *DataLoader* contiene listas (que regresa la función `__getitem__()` correspondiente al *DataSet*). Estas listas contienen los lotes de tamaño `batch_size` y, para abarcar todos los datos, contiene aproximadamente `tamaño_de_todos_los_datos/batch_size` listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Tamaño del DataSet (de PyTorch) = 3277 = 3277 = Tamaño del DataFrame (de pandas)\n"
     ]
    }
   ],
   "source": [
    "print(f\"- Tamaño del DataSet (de PyTorch) = {len(birds_ds)} = {len(birds_df)} = Tamaño del DataFrame (de pandas)\")\n",
    "#print(f\"- Tamaño del DataLoader (de PyTorch): {len(birds_dl)}\")\n",
    "#iterador = iter(birds_dl)\n",
    "#primer_lote = next(iterador)\n",
    "#print(f\"- Tamaño de la primera lista del DataLoader: {len(primer_lote)}\")\n",
    "#print(f\"- Tamaño de los elementos de la primera lista: {len(primer_lote[0])} {len(primer_lote[1])} {len(primer_lote[2])}\")\n",
    "#print(f\"- Tamaño del DataLoader por el tamaño de cada lote: {len(birds_dl)*batch_size} ≈ {len(birds_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos datos sobre el primer lote para ejemplificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#primeros_cachos, segundos_cachos, labels = primer_lote\n",
    "#print(f\"- Los primeros cachos de audio del primer lote tienen tamaño: {primeros_cachos.size()}\")\n",
    "#print(f\"- Los segundos cachos de audio del primer lote tienen tamaño: {segundos_cachos.size()}\")\n",
    "#print(f\"- Las etiquetas del primer lote tienen tamaño: {labels.size()}\")\n",
    "#print(f\"- Etiquetas del primer lote: {labels}\")\n",
    "#print(f\"- Primeros cachos del primer lote: {primeros_cachos}\")\n",
    "#print(f\"- Segundos cachos del primer lote: {segundos_cachos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Module is the base class for all neural network modules.\n",
    "# Our models should also subclass this class.\n",
    "# Modules can also contain other Modules, allowing to nest them in a tree structure.\n",
    "class RN(nn.Module):\n",
    "    \"\"\"\n",
    "    Red Neuronal.\n",
    "    \"\"\"\n",
    "    \n",
    "    #This defines the structure of the NN.\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inicialización de la Red Neuronal.\n",
    "        Aquí se define su estructura.\n",
    "        \"\"\"\n",
    "        \n",
    "        #\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inicio de las capas convolucionales.\n",
    "        conv_layers = []\n",
    "        \n",
    "        # Primera capa convolucional.\n",
    "        self.conv1 = nn.Conv2d(in_channels=audio_channels, out_channels=batch_size, kernel_size=(10,10), stride=(2,1))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        conv_layers += [self.conv1, self.relu1, self.mp1]\n",
    "        \n",
    "        # Segunda capa convolucional.\n",
    "        self.conv2 = nn.Conv2d(in_channels=batch_size, out_channels=(batch_size//2), kernel_size=(7,7), stride=(2,1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        conv_layers += [self.conv2, self.relu2, self.mp2]\n",
    "        \n",
    "        # Tercera capa convolucional.\n",
    "        self.conv3 = nn.Conv2d(in_channels=(batch_size//2), out_channels=(batch_size//4), kernel_size=(4,4), stride=(2,1))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.mp3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        conv_layers += [self.conv3, self.relu3, self.mp3]\n",
    "        \n",
    "        # Fin de las capas convoluciones.\n",
    "        self.conv = nn.Sequential(*conv_layers)\n",
    "        \n",
    "        # Inicio de las capas lineales (fully-connected).\n",
    "        fc_layers = []\n",
    "        \n",
    "        # Primera capa lineal.\n",
    "        # TO-DO: Determinar entrada.\n",
    "        # TO-DO: Determinar salida.\n",
    "        self.fc1 = nn.Linear(int(22.5*batch_size),512)\n",
    "        fc_layers += [self.fc1]\n",
    "        \n",
    "        # Fin de las capas lineales.\n",
    "        self.fc = nn.Sequential(*fc_layers)\n",
    "        \n",
    "        # Segunda capa lineal.\n",
    "        # TO-DO: Determinar entrada.\n",
    "        # TO-DO: Determinar salida. ¿Es 1 valor para cada entrada?\n",
    "        self.fc2 = nn.Linear(4063232, 1)\n",
    "        # Ésta no se agrega a las demás,\n",
    "        # pues no se aplica individualmente a\n",
    "        # cada entrada; primero es necesario\n",
    "        # realizar la operación de distancia\n",
    "        # sobre éstas para después aplicar\n",
    "        # esta capa lineal.\n",
    "    \n",
    "    def invididual_process(self, z):\n",
    "        \n",
    "        start = timer()\n",
    "        z = self.conv(z)\n",
    "        end = timer()\n",
    "        #print(f\"\\t\\t[time] Capas convolucionales: time={end-start}s out_size={z.size()}\") # DEBUG\n",
    "        \n",
    "        # Para que 'z' tenga sólo una dimensión...\n",
    "        #print(f\"\\t\\tz antes de z.view: {z.size()}\") # DEBUG\n",
    "        z = z.view(batch_size, -1)\n",
    "        #print(f\"\\t\\tz después de z.view: {z.size()}\") # DEBUG\n",
    "        \n",
    "        start = timer()\n",
    "        z = self.fc(z)\n",
    "        end = timer()\n",
    "        #print(f\"\\t\\t[time] Capas lineales: time={end-start}s out_size={z.size()}\") # DEBUG\n",
    "        \n",
    "        return z\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \n",
    "        # TO-DO: Analizar las múltiples dimensiones en 2 o 3 dimensiones.\n",
    "        #TSNE(n_components=2, verbose=True).fit_transform(x)\n",
    "        \n",
    "        #print(f\"\\tProcesando x: {x.size()}\") # DEBUG\n",
    "        x = self.invididual_process(x)\n",
    "        #print(f\"\\tProcesando y: {y.size()}\") # DEBUG\n",
    "        y = self.invididual_process(y)\n",
    "        \n",
    "        # Para que 'x' y 'y' tengan sólo una dimensión...\n",
    "        x = x.view(batch_size, -1)\n",
    "        #print(f\"\\t\\tDespués de aplanar x: {x.size()}\") # DEBUG\n",
    "        y = y.view(batch_size, -1)\n",
    "        #print(f\"\\t\\tDespués de aplanar y: {y.size()}\") # DEBUG\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "# Definición del modelo.\n",
    "red = RN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.5043683052062988\n",
      "\tLoss: 0.4434036612510681\n",
      "\tLoss: 0.462659627199173\n",
      "\tLoss: 0.41871529817581177\n",
      "\tLoss: 0.36249488592147827\n",
      "\tLoss: 0.25853240489959717\n",
      "\tLoss: 0.2779850959777832\n",
      "\tLoss: 0.3262324631214142\n",
      "\tLoss: 0.2728760540485382\n",
      "\tLoss: 0.35217705368995667\n",
      "\tLoss: 0.37771421670913696\n",
      "\tLoss: 0.21324948966503143\n",
      "\tLoss: 0.3001549243927002\n",
      "\tLoss: 0.3860936164855957\n",
      "\tLoss: 0.3514488637447357\n",
      "\tLoss: 0.3459138870239258\n",
      "\tLoss: 0.26687684655189514\n",
      "\tLoss: 0.27007997035980225\n",
      "\tLoss: 0.31776541471481323\n",
      "\tLoss: 0.23867212235927582\n",
      "\tLoss: 0.3155478537082672\n",
      "\tLoss: 0.31219974160194397\n",
      "\tLoss: 0.36913546919822693\n",
      "\tLoss: 0.32530832290649414\n",
      "\tLoss: 0.29030853509902954\n",
      "\tLoss: 0.3065914511680603\n",
      "\tLoss: 0.3659874200820923\n",
      "\tLoss: 0.2929210662841797\n",
      "\tLoss: 0.3051703870296478\n",
      "\tLoss: 0.22604382038116455\n",
      "\tLoss: 0.2964472472667694\n",
      "\tLoss: 0.27090802788734436\n",
      "\tLoss: 0.3107215166091919\n",
      "\tLoss: 0.2775634527206421\n",
      "\tLoss: 0.267059862613678\n",
      "\tLoss: 0.23530066013336182\n",
      "\tLoss: 0.28444910049438477\n",
      "\tLoss: 0.3321719765663147\n",
      "\tLoss: 0.15625837445259094\n",
      "\tLoss: 0.2799992263317108\n",
      "\tLoss: 0.2835642099380493\n",
      "\tLoss: 0.30511540174484253\n",
      "\tLoss: 0.28942015767097473\n",
      "\tLoss: 0.21059834957122803\n",
      "\tLoss: 0.230283722281456\n",
      "\tLoss: 0.29237884283065796\n",
      "\tLoss: 0.2233220487833023\n",
      "\tLoss: 0.16548147797584534\n",
      "\tLoss: 0.27698442339897156\n",
      "\tLoss: 0.22762563824653625\n",
      "\tLoss: 0.22809018194675446\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.31163865327835083\n",
      "\tLoss: 0.32984280586242676\n",
      "\tLoss: 0.24013561010360718\n",
      "\tLoss: 0.2553199827671051\n",
      "\tLoss: 0.24498412013053894\n",
      "\tLoss: 0.26715341210365295\n",
      "\tLoss: 0.19740870594978333\n",
      "\tLoss: 0.2570526599884033\n",
      "\tLoss: 0.22593754529953003\n",
      "\tLoss: 0.21474125981330872\n",
      "\tLoss: 0.1974189281463623\n",
      "\tLoss: 0.3038904368877411\n",
      "\tLoss: 0.15589742362499237\n",
      "\tLoss: 0.24837055802345276\n",
      "\tLoss: 0.24211278557777405\n",
      "\tLoss: 0.22813104093074799\n",
      "\tLoss: 0.1838729977607727\n",
      "\tLoss: 0.1857151836156845\n",
      "\tLoss: 0.2825813889503479\n",
      "\tLoss: 0.14443056285381317\n",
      "\tLoss: 0.21913272142410278\n",
      "\tLoss: 0.1579923927783966\n",
      "\tLoss: 0.22896888852119446\n",
      "\tLoss: 0.2619401812553406\n",
      "\tLoss: 0.2536725401878357\n",
      "\tLoss: 0.1859910488128662\n",
      "\tLoss: 0.25632143020629883\n",
      "\tLoss: 0.23838122189044952\n",
      "\tLoss: 0.26125243306159973\n",
      "\tLoss: 0.1886909008026123\n",
      "\tLoss: 0.22906585037708282\n",
      "\tLoss: 0.3034668564796448\n",
      "\tLoss: 0.24706962704658508\n",
      "\tLoss: 0.212149977684021\n",
      "\tLoss: 0.1538362354040146\n",
      "\tLoss: 0.18736353516578674\n",
      "\tLoss: 0.2255552113056183\n",
      "\tLoss: 0.238194540143013\n",
      "\tLoss: 0.2141246497631073\n",
      "\tLoss: 0.20677942037582397\n",
      "\tLoss: 0.20368003845214844\n",
      "\tLoss: 0.2026447057723999\n",
      "\tLoss: 0.22794373333454132\n",
      "\tLoss: 0.2467467486858368\n",
      "\tLoss: 0.1304370015859604\n",
      "\tLoss: 0.2399800419807434\n",
      "\tLoss: 0.2485952377319336\n",
      "\tLoss: 0.14642053842544556\n",
      "\tLoss: 0.2234637588262558\n",
      "\tLoss: 0.20146574079990387\n",
      "\tLoss: 0.17816048860549927\n",
      "[time] Epoch 1: 503.4440726842731s = 8.390734544737885m\n",
      "\n",
      "Epoch 2...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.2101684957742691\n",
      "\tLoss: 0.21210667490959167\n",
      "\tLoss: 0.16709956526756287\n",
      "\tLoss: 0.24089352786540985\n",
      "\tLoss: 0.19902847707271576\n",
      "\tLoss: 0.18366901576519012\n",
      "\tLoss: 0.18819929659366608\n",
      "\tLoss: 0.25994667410850525\n",
      "\tLoss: 0.18101395666599274\n",
      "\tLoss: 0.23659811913967133\n",
      "\tLoss: 0.17352533340454102\n",
      "\tLoss: 0.20339135825634003\n",
      "\tLoss: 0.1831488013267517\n",
      "\tLoss: 0.25052356719970703\n",
      "\tLoss: 0.2466011345386505\n",
      "\tLoss: 0.2786276638507843\n",
      "\tLoss: 0.2173360288143158\n",
      "\tLoss: 0.18863584101200104\n",
      "\tLoss: 0.18501579761505127\n",
      "\tLoss: 0.16045868396759033\n",
      "\tLoss: 0.24857600033283234\n",
      "\tLoss: 0.28174254298210144\n",
      "\tLoss: 0.19295969605445862\n",
      "\tLoss: 0.24818871915340424\n",
      "\tLoss: 0.24613071978092194\n",
      "\tLoss: 0.14576077461242676\n",
      "\tLoss: 0.21370108425617218\n",
      "\tLoss: 0.20902174711227417\n",
      "\tLoss: 0.19431638717651367\n",
      "\tLoss: 0.2318844050168991\n",
      "\tLoss: 0.12778382003307343\n",
      "\tLoss: 0.1731937974691391\n",
      "\tLoss: 0.20601090788841248\n",
      "\tLoss: 0.17613530158996582\n",
      "\tLoss: 0.22122900187969208\n",
      "\tLoss: 0.1626967191696167\n",
      "\tLoss: 0.22284039855003357\n",
      "\tLoss: 0.29374611377716064\n",
      "\tLoss: 0.23694442212581635\n",
      "\tLoss: 0.17711347341537476\n",
      "\tLoss: 0.1301942616701126\n",
      "\tLoss: 0.1859290897846222\n",
      "\tLoss: 0.18949736654758453\n",
      "\tLoss: 0.1716638058423996\n",
      "\tLoss: 0.18529197573661804\n",
      "\tLoss: 0.21313288807868958\n",
      "\tLoss: 0.22873049974441528\n",
      "\tLoss: 0.19359205663204193\n",
      "\tLoss: 0.23840509355068207\n",
      "\tLoss: 0.20358793437480927\n",
      "\tLoss: 0.16627958416938782\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.17672526836395264\n",
      "\tLoss: 0.27532193064689636\n",
      "\tLoss: 0.1914443075656891\n",
      "\tLoss: 0.11408355832099915\n",
      "\tLoss: 0.2562909722328186\n",
      "\tLoss: 0.19933471083641052\n",
      "\tLoss: 0.16895842552185059\n",
      "\tLoss: 0.19905798137187958\n",
      "\tLoss: 0.2699963450431824\n",
      "\tLoss: 0.13608019053936005\n",
      "\tLoss: 0.22589391469955444\n",
      "\tLoss: 0.19671164453029633\n",
      "\tLoss: 0.15818271040916443\n",
      "\tLoss: 0.16483011841773987\n",
      "\tLoss: 0.24780800938606262\n",
      "\tLoss: 0.2140609622001648\n",
      "\tLoss: 0.19840383529663086\n",
      "\tLoss: 0.31494343280792236\n",
      "\tLoss: 0.13198572397232056\n",
      "\tLoss: 0.3041336238384247\n",
      "\tLoss: 0.20802900195121765\n",
      "\tLoss: 0.21418675780296326\n",
      "\tLoss: 0.19747915863990784\n",
      "\tLoss: 0.17490831017494202\n",
      "\tLoss: 0.13888883590698242\n",
      "\tLoss: 0.10489536076784134\n",
      "\tLoss: 0.20723070204257965\n",
      "\tLoss: 0.19141696393489838\n",
      "\tLoss: 0.22540798783302307\n",
      "\tLoss: 0.19820675253868103\n",
      "\tLoss: 0.22457446157932281\n",
      "\tLoss: 0.18939386308193207\n",
      "\tLoss: 0.1952531337738037\n",
      "\tLoss: 0.25456079840660095\n",
      "\tLoss: 0.2322959005832672\n",
      "\tLoss: 0.2371869534254074\n",
      "\tLoss: 0.2525518238544464\n",
      "\tLoss: 0.17212873697280884\n",
      "\tLoss: 0.26565173268318176\n",
      "\tLoss: 0.23408155143260956\n",
      "\tLoss: 0.20147296786308289\n",
      "\tLoss: 0.21030327677726746\n",
      "\tLoss: 0.14282110333442688\n",
      "\tLoss: 0.21849340200424194\n",
      "\tLoss: 0.20474697649478912\n",
      "\tLoss: 0.1544661521911621\n",
      "\tLoss: 0.18161988258361816\n",
      "\tLoss: 0.23355428874492645\n",
      "\tLoss: 0.1846024990081787\n",
      "\tLoss: 0.2643391489982605\n",
      "\tLoss: 0.24986828863620758\n",
      "[time] Epoch 2: 484.2917770873755s = 8.071529618122925m\n",
      "\n",
      "Epoch 3...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.19435450434684753\n",
      "\tLoss: 0.1787620633840561\n",
      "\tLoss: 0.18086178600788116\n",
      "\tLoss: 0.2417161911725998\n",
      "\tLoss: 0.2698533833026886\n",
      "\tLoss: 0.2457503229379654\n",
      "\tLoss: 0.20221032202243805\n",
      "\tLoss: 0.19540062546730042\n",
      "\tLoss: 0.166727215051651\n",
      "\tLoss: 0.17519593238830566\n",
      "\tLoss: 0.1745980829000473\n",
      "\tLoss: 0.1872107982635498\n",
      "\tLoss: 0.2576659917831421\n",
      "\tLoss: 0.2440018355846405\n",
      "\tLoss: 0.21887601912021637\n",
      "\tLoss: 0.1640048325061798\n",
      "\tLoss: 0.13623908162117004\n",
      "\tLoss: 0.12052285671234131\n",
      "\tLoss: 0.22439122200012207\n",
      "\tLoss: 0.19128857553005219\n",
      "\tLoss: 0.18330617249011993\n",
      "\tLoss: 0.15580309927463531\n",
      "\tLoss: 0.2156500220298767\n",
      "\tLoss: 0.18515095114707947\n",
      "\tLoss: 0.20757551491260529\n",
      "\tLoss: 0.17303718626499176\n",
      "\tLoss: 0.21862046420574188\n",
      "\tLoss: 0.18911662697792053\n",
      "\tLoss: 0.17177152633666992\n",
      "\tLoss: 0.17001566290855408\n",
      "\tLoss: 0.20089609920978546\n",
      "\tLoss: 0.22496098279953003\n",
      "\tLoss: 0.13653779029846191\n",
      "\tLoss: 0.19340083003044128\n",
      "\tLoss: 0.10450504720211029\n",
      "\tLoss: 0.23206348717212677\n",
      "\tLoss: 0.17957502603530884\n",
      "\tLoss: 0.3047316074371338\n",
      "\tLoss: 0.1437349170446396\n",
      "\tLoss: 0.18651404976844788\n",
      "\tLoss: 0.17400473356246948\n",
      "\tLoss: 0.22400875389575958\n",
      "\tLoss: 0.19172190129756927\n",
      "\tLoss: 0.19472259283065796\n",
      "\tLoss: 0.14095109701156616\n",
      "\tLoss: 0.15612570941448212\n",
      "\tLoss: 0.20495864748954773\n",
      "\tLoss: 0.21805241703987122\n",
      "\tLoss: 0.2305716872215271\n",
      "\tLoss: 0.17789094150066376\n",
      "\tLoss: 0.25379443168640137\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.21631282567977905\n",
      "\tLoss: 0.1589895635843277\n",
      "\tLoss: 0.18409353494644165\n",
      "\tLoss: 0.160838782787323\n",
      "\tLoss: 0.11637221276760101\n",
      "\tLoss: 0.16554008424282074\n",
      "\tLoss: 0.17579808831214905\n",
      "\tLoss: 0.2395642101764679\n",
      "\tLoss: 0.21034769713878632\n",
      "\tLoss: 0.20816442370414734\n",
      "\tLoss: 0.15208134055137634\n",
      "\tLoss: 0.2315051108598709\n",
      "\tLoss: 0.21819111704826355\n",
      "\tLoss: 0.19650281965732574\n",
      "\tLoss: 0.2282755970954895\n",
      "\tLoss: 0.19536422193050385\n",
      "\tLoss: 0.16471949219703674\n",
      "\tLoss: 0.1926175355911255\n",
      "\tLoss: 0.15684877336025238\n",
      "\tLoss: 0.22794285416603088\n",
      "\tLoss: 0.16250668466091156\n",
      "\tLoss: 0.16216835379600525\n",
      "\tLoss: 0.15027554333209991\n",
      "\tLoss: 0.16389860212802887\n",
      "\tLoss: 0.17194092273712158\n",
      "\tLoss: 0.1555463969707489\n",
      "\tLoss: 0.21659988164901733\n",
      "\tLoss: 0.1661488562822342\n",
      "\tLoss: 0.20620256662368774\n",
      "\tLoss: 0.1588010936975479\n",
      "\tLoss: 0.1822606772184372\n",
      "\tLoss: 0.16598615050315857\n",
      "\tLoss: 0.2281908094882965\n",
      "\tLoss: 0.23213200271129608\n",
      "\tLoss: 0.2213474065065384\n",
      "\tLoss: 0.21684956550598145\n",
      "\tLoss: 0.1624271273612976\n",
      "\tLoss: 0.16140080988407135\n",
      "\tLoss: 0.24959516525268555\n",
      "\tLoss: 0.20060837268829346\n",
      "\tLoss: 0.2016262710094452\n",
      "\tLoss: 0.25448179244995117\n",
      "\tLoss: 0.13847416639328003\n",
      "\tLoss: 0.17235158383846283\n",
      "\tLoss: 0.16110816597938538\n",
      "\tLoss: 0.2267678678035736\n",
      "\tLoss: 0.15337897837162018\n",
      "\tLoss: 0.21951861679553986\n",
      "\tLoss: 0.21992939710617065\n",
      "\tLoss: 0.14001613855361938\n",
      "\tLoss: 0.2267475128173828\n",
      "[time] Epoch 3: 473.08270510844886s = 7.884711751807481m\n",
      "\n",
      "Epoch 4...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1748613715171814\n",
      "\tLoss: 0.19896559417247772\n",
      "\tLoss: 0.1437297761440277\n",
      "\tLoss: 0.2021680474281311\n",
      "\tLoss: 0.147642582654953\n",
      "\tLoss: 0.201307475566864\n",
      "\tLoss: 0.13902655243873596\n",
      "\tLoss: 0.20740950107574463\n",
      "\tLoss: 0.17497952282428741\n",
      "\tLoss: 0.20687603950500488\n",
      "\tLoss: 0.23293988406658173\n",
      "\tLoss: 0.18230292201042175\n",
      "\tLoss: 0.17138217389583588\n",
      "\tLoss: 0.12881214916706085\n",
      "\tLoss: 0.23396790027618408\n",
      "\tLoss: 0.1425912082195282\n",
      "\tLoss: 0.1483706384897232\n",
      "\tLoss: 0.1616205871105194\n",
      "\tLoss: 0.24047920107841492\n",
      "\tLoss: 0.24278217554092407\n",
      "\tLoss: 0.2270490825176239\n",
      "\tLoss: 0.18779103457927704\n",
      "\tLoss: 0.20906305313110352\n",
      "\tLoss: 0.22353142499923706\n",
      "\tLoss: 0.19620949029922485\n",
      "\tLoss: 0.13446786999702454\n",
      "\tLoss: 0.1793193519115448\n",
      "\tLoss: 0.22842413187026978\n",
      "\tLoss: 0.18057939410209656\n",
      "\tLoss: 0.1317453235387802\n",
      "\tLoss: 0.1507793664932251\n",
      "\tLoss: 0.2198236584663391\n",
      "\tLoss: 0.17780320346355438\n",
      "\tLoss: 0.17796912789344788\n",
      "\tLoss: 0.10402378439903259\n",
      "\tLoss: 0.21511489152908325\n",
      "\tLoss: 0.19121232628822327\n",
      "\tLoss: 0.20119240880012512\n",
      "\tLoss: 0.1390892118215561\n",
      "\tLoss: 0.1409071981906891\n",
      "\tLoss: 0.15733039379119873\n",
      "\tLoss: 0.21724192798137665\n",
      "\tLoss: 0.1557789444923401\n",
      "\tLoss: 0.15524327754974365\n",
      "\tLoss: 0.13464736938476562\n",
      "\tLoss: 0.1811167150735855\n",
      "\tLoss: 0.15027159452438354\n",
      "\tLoss: 0.1422189176082611\n",
      "\tLoss: 0.11553849279880524\n",
      "\tLoss: 0.180146723985672\n",
      "\tLoss: 0.18447071313858032\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.18936175107955933\n",
      "\tLoss: 0.17405763268470764\n",
      "\tLoss: 0.22318987548351288\n",
      "\tLoss: 0.15123088657855988\n",
      "\tLoss: 0.18999642133712769\n",
      "\tLoss: 0.22849535942077637\n",
      "\tLoss: 0.12855124473571777\n",
      "\tLoss: 0.1377616673707962\n",
      "\tLoss: 0.1664099395275116\n",
      "\tLoss: 0.18891164660453796\n",
      "\tLoss: 0.20558437705039978\n",
      "\tLoss: 0.16470125317573547\n",
      "\tLoss: 0.16968730092048645\n",
      "\tLoss: 0.1422431319952011\n",
      "\tLoss: 0.19903764128684998\n",
      "\tLoss: 0.22409483790397644\n",
      "\tLoss: 0.1750379204750061\n",
      "\tLoss: 0.22552409768104553\n",
      "\tLoss: 0.19938907027244568\n",
      "\tLoss: 0.16648876667022705\n",
      "\tLoss: 0.17753559350967407\n",
      "\tLoss: 0.24044963717460632\n",
      "\tLoss: 0.11990151554346085\n",
      "\tLoss: 0.16639390587806702\n",
      "\tLoss: 0.13183775544166565\n",
      "\tLoss: 0.19489675760269165\n",
      "\tLoss: 0.20734429359436035\n",
      "\tLoss: 0.20076656341552734\n",
      "\tLoss: 0.16302108764648438\n",
      "\tLoss: 0.19325372576713562\n",
      "\tLoss: 0.16715312004089355\n",
      "\tLoss: 0.22144271433353424\n",
      "\tLoss: 0.1518678069114685\n",
      "\tLoss: 0.1724473536014557\n",
      "\tLoss: 0.11724235117435455\n",
      "\tLoss: 0.19797596335411072\n",
      "\tLoss: 0.14875712990760803\n",
      "\tLoss: 0.10531963407993317\n",
      "\tLoss: 0.15281352400779724\n",
      "\tLoss: 0.18613342940807343\n",
      "\tLoss: 0.2123347967863083\n",
      "\tLoss: 0.19953995943069458\n",
      "\tLoss: 0.214491605758667\n",
      "\tLoss: 0.17513062059879303\n",
      "\tLoss: 0.17888732254505157\n",
      "\tLoss: 0.16468867659568787\n",
      "\tLoss: 0.18563340604305267\n",
      "\tLoss: 0.22363659739494324\n",
      "\tLoss: 0.11259521543979645\n",
      "\tLoss: 0.24745114147663116\n",
      "\tLoss: 0.25387465953826904\n",
      "[time] Epoch 4: 464.97249901201576s = 7.749541650200262m\n",
      "\n",
      "Epoch 5...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.21577975153923035\n",
      "\tLoss: 0.12968933582305908\n",
      "\tLoss: 0.23422712087631226\n",
      "\tLoss: 0.1878376305103302\n",
      "\tLoss: 0.17748576402664185\n",
      "\tLoss: 0.2389192134141922\n",
      "\tLoss: 0.20238862931728363\n",
      "\tLoss: 0.16532903909683228\n",
      "\tLoss: 0.17079049348831177\n",
      "\tLoss: 0.14995259046554565\n",
      "\tLoss: 0.17986688017845154\n",
      "\tLoss: 0.14143864810466766\n",
      "\tLoss: 0.18908506631851196\n",
      "\tLoss: 0.17185211181640625\n",
      "\tLoss: 0.1629025638103485\n",
      "\tLoss: 0.172652468085289\n",
      "\tLoss: 0.1867724508047104\n",
      "\tLoss: 0.1768995225429535\n",
      "\tLoss: 0.12216085195541382\n",
      "\tLoss: 0.18949075043201447\n",
      "\tLoss: 0.2457147240638733\n",
      "\tLoss: 0.17199836671352386\n",
      "\tLoss: 0.16871923208236694\n",
      "\tLoss: 0.17721505463123322\n",
      "\tLoss: 0.17742453515529633\n",
      "\tLoss: 0.1670602262020111\n",
      "\tLoss: 0.1463378220796585\n",
      "\tLoss: 0.1724342554807663\n",
      "\tLoss: 0.2695661783218384\n",
      "\tLoss: 0.20722582936286926\n",
      "\tLoss: 0.18267211318016052\n",
      "\tLoss: 0.1649795025587082\n",
      "\tLoss: 0.1894906759262085\n",
      "\tLoss: 0.132558673620224\n",
      "\tLoss: 0.12167440354824066\n",
      "\tLoss: 0.1657775342464447\n",
      "\tLoss: 0.16489844024181366\n",
      "\tLoss: 0.1958441436290741\n",
      "\tLoss: 0.12706279754638672\n",
      "\tLoss: 0.20133894681930542\n",
      "\tLoss: 0.22000768780708313\n",
      "\tLoss: 0.1664080172777176\n",
      "\tLoss: 0.16254308819770813\n",
      "\tLoss: 0.14660394191741943\n",
      "\tLoss: 0.130806103348732\n",
      "\tLoss: 0.12131129205226898\n",
      "\tLoss: 0.19502466917037964\n",
      "\tLoss: 0.14866232872009277\n",
      "\tLoss: 0.15249237418174744\n",
      "\tLoss: 0.1941029131412506\n",
      "\tLoss: 0.17546728253364563\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.185748890042305\n",
      "\tLoss: 0.15471480786800385\n",
      "\tLoss: 0.1899855136871338\n",
      "\tLoss: 0.1775493323802948\n",
      "\tLoss: 0.1440805196762085\n",
      "\tLoss: 0.1869436353445053\n",
      "\tLoss: 0.2122631072998047\n",
      "\tLoss: 0.1848108470439911\n",
      "\tLoss: 0.1778118908405304\n",
      "\tLoss: 0.19542019069194794\n",
      "\tLoss: 0.16132421791553497\n",
      "\tLoss: 0.1636231392621994\n",
      "\tLoss: 0.15919552743434906\n",
      "\tLoss: 0.1622561514377594\n",
      "\tLoss: 0.1926727592945099\n",
      "\tLoss: 0.14573074877262115\n",
      "\tLoss: 0.19228796660900116\n",
      "\tLoss: 0.16050264239311218\n",
      "\tLoss: 0.2386900782585144\n",
      "\tLoss: 0.13143011927604675\n",
      "\tLoss: 0.15812847018241882\n",
      "\tLoss: 0.2211926430463791\n",
      "\tLoss: 0.18938703835010529\n",
      "\tLoss: 0.15299640595912933\n",
      "\tLoss: 0.1552625596523285\n",
      "\tLoss: 0.12962281703948975\n",
      "\tLoss: 0.14440175890922546\n",
      "\tLoss: 0.19819438457489014\n",
      "\tLoss: 0.2278050184249878\n",
      "\tLoss: 0.2020552158355713\n",
      "\tLoss: 0.19057247042655945\n",
      "\tLoss: 0.19622060656547546\n",
      "\tLoss: 0.15856975317001343\n",
      "\tLoss: 0.13863974809646606\n",
      "\tLoss: 0.12474468350410461\n",
      "\tLoss: 0.1504780799150467\n",
      "\tLoss: 0.1256597489118576\n",
      "\tLoss: 0.12501633167266846\n",
      "\tLoss: 0.2079106867313385\n",
      "\tLoss: 0.2069365531206131\n",
      "\tLoss: 0.20509293675422668\n",
      "\tLoss: 0.16910883784294128\n",
      "\tLoss: 0.1513284146785736\n",
      "\tLoss: 0.1695680022239685\n",
      "\tLoss: 0.18927070498466492\n",
      "\tLoss: 0.16361090540885925\n",
      "\tLoss: 0.13184690475463867\n",
      "\tLoss: 0.17623141407966614\n",
      "\tLoss: 0.11116232722997665\n",
      "\tLoss: 0.20557205379009247\n",
      "\tLoss: 0.17088153958320618\n",
      "[time] Epoch 5: 461.0720184277743s = 7.684533640462905m\n",
      "\n",
      "Epoch 6...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.21449029445648193\n",
      "\tLoss: 0.2136971354484558\n",
      "\tLoss: 0.23137348890304565\n",
      "\tLoss: 0.1457141637802124\n",
      "\tLoss: 0.18367823958396912\n",
      "\tLoss: 0.1279602348804474\n",
      "\tLoss: 0.13934603333473206\n",
      "\tLoss: 0.18721207976341248\n",
      "\tLoss: 0.1947961449623108\n",
      "\tLoss: 0.18582311272621155\n",
      "\tLoss: 0.21783319115638733\n",
      "\tLoss: 0.14081019163131714\n",
      "\tLoss: 0.15854017436504364\n",
      "\tLoss: 0.13663716614246368\n",
      "\tLoss: 0.19136258959770203\n",
      "\tLoss: 0.2124922126531601\n",
      "\tLoss: 0.17910608649253845\n",
      "\tLoss: 0.15504950284957886\n",
      "\tLoss: 0.17773596942424774\n",
      "\tLoss: 0.20043237507343292\n",
      "\tLoss: 0.17176294326782227\n",
      "\tLoss: 0.19454583525657654\n",
      "\tLoss: 0.20570652186870575\n",
      "\tLoss: 0.13146424293518066\n",
      "\tLoss: 0.15158209204673767\n",
      "\tLoss: 0.13059203326702118\n",
      "\tLoss: 0.20756572484970093\n",
      "\tLoss: 0.19081471860408783\n",
      "\tLoss: 0.18495577573776245\n",
      "\tLoss: 0.18643765151500702\n",
      "\tLoss: 0.17112819850444794\n",
      "\tLoss: 0.23778361082077026\n",
      "\tLoss: 0.13721463084220886\n",
      "\tLoss: 0.1366214156150818\n",
      "\tLoss: 0.12474551796913147\n",
      "\tLoss: 0.13640178740024567\n",
      "\tLoss: 0.15810300409793854\n",
      "\tLoss: 0.18318690359592438\n",
      "\tLoss: 0.1420748382806778\n",
      "\tLoss: 0.16043472290039062\n",
      "\tLoss: 0.18939967453479767\n",
      "\tLoss: 0.1563687026500702\n",
      "\tLoss: 0.16026067733764648\n",
      "\tLoss: 0.14804187417030334\n",
      "\tLoss: 0.14725671708583832\n",
      "\tLoss: 0.2094159722328186\n",
      "\tLoss: 0.18992756307125092\n",
      "\tLoss: 0.08373983949422836\n",
      "\tLoss: 0.1580209732055664\n",
      "\tLoss: 0.18909555673599243\n",
      "\tLoss: 0.17792034149169922\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.20480504631996155\n",
      "\tLoss: 0.15307080745697021\n",
      "\tLoss: 0.16197024285793304\n",
      "\tLoss: 0.1308230608701706\n",
      "\tLoss: 0.15204612910747528\n",
      "\tLoss: 0.15578198432922363\n",
      "\tLoss: 0.1901167780160904\n",
      "\tLoss: 0.143245667219162\n",
      "\tLoss: 0.14226800203323364\n",
      "\tLoss: 0.1895667463541031\n",
      "\tLoss: 0.14961527287960052\n",
      "\tLoss: 0.16781412065029144\n",
      "\tLoss: 0.1658029705286026\n",
      "\tLoss: 0.17015910148620605\n",
      "\tLoss: 0.1665557622909546\n",
      "\tLoss: 0.1459365040063858\n",
      "\tLoss: 0.1535922884941101\n",
      "\tLoss: 0.19823941588401794\n",
      "\tLoss: 0.2662777304649353\n",
      "\tLoss: 0.1611906886100769\n",
      "\tLoss: 0.17845025658607483\n",
      "\tLoss: 0.1712876558303833\n",
      "\tLoss: 0.18243536353111267\n",
      "\tLoss: 0.16178001463413239\n",
      "\tLoss: 0.15302489697933197\n",
      "\tLoss: 0.18569612503051758\n",
      "\tLoss: 0.199000746011734\n",
      "\tLoss: 0.2451874315738678\n",
      "\tLoss: 0.18534426391124725\n",
      "\tLoss: 0.13783040642738342\n",
      "\tLoss: 0.13770455121994019\n",
      "\tLoss: 0.12399555742740631\n",
      "\tLoss: 0.19098468124866486\n",
      "\tLoss: 0.1532190442085266\n",
      "\tLoss: 0.19510047137737274\n",
      "\tLoss: 0.15605561435222626\n",
      "\tLoss: 0.19171130657196045\n",
      "\tLoss: 0.16961559653282166\n",
      "\tLoss: 0.13488540053367615\n",
      "\tLoss: 0.19650623202323914\n",
      "\tLoss: 0.14277362823486328\n",
      "\tLoss: 0.17238378524780273\n",
      "\tLoss: 0.10151688009500504\n",
      "\tLoss: 0.1495271474123001\n",
      "\tLoss: 0.15884710848331451\n",
      "\tLoss: 0.1474786251783371\n",
      "\tLoss: 0.17166265845298767\n",
      "\tLoss: 0.13924092054367065\n",
      "\tLoss: 0.15561476349830627\n",
      "\tLoss: 0.19543348252773285\n",
      "\tLoss: 0.12038510292768478\n",
      "[time] Epoch 6: 462.48026282154024s = 7.708004380359004m\n",
      "\n",
      "Epoch 7...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.12985624372959137\n",
      "\tLoss: 0.1562877595424652\n",
      "\tLoss: 0.14139680564403534\n",
      "\tLoss: 0.11615964770317078\n",
      "\tLoss: 0.14075838029384613\n",
      "\tLoss: 0.1275516152381897\n",
      "\tLoss: 0.1339384913444519\n",
      "\tLoss: 0.1606561243534088\n",
      "\tLoss: 0.168193519115448\n",
      "\tLoss: 0.1486840844154358\n",
      "\tLoss: 0.13992203772068024\n",
      "\tLoss: 0.15899120271205902\n",
      "\tLoss: 0.22537800669670105\n",
      "\tLoss: 0.17643915116786957\n",
      "\tLoss: 0.1989586055278778\n",
      "\tLoss: 0.14449122548103333\n",
      "\tLoss: 0.12893043458461761\n",
      "\tLoss: 0.19690895080566406\n",
      "\tLoss: 0.11672793328762054\n",
      "\tLoss: 0.15047317743301392\n",
      "\tLoss: 0.16742512583732605\n",
      "\tLoss: 0.15649130940437317\n",
      "\tLoss: 0.20252195000648499\n",
      "\tLoss: 0.15344853699207306\n",
      "\tLoss: 0.14701299369335175\n",
      "\tLoss: 0.13969452679157257\n",
      "\tLoss: 0.12166233360767365\n",
      "\tLoss: 0.17067836225032806\n",
      "\tLoss: 0.17045025527477264\n",
      "\tLoss: 0.15872064232826233\n",
      "\tLoss: 0.1419300138950348\n",
      "\tLoss: 0.1302616000175476\n",
      "\tLoss: 0.21524739265441895\n",
      "\tLoss: 0.17378519475460052\n",
      "\tLoss: 0.16260778903961182\n",
      "\tLoss: 0.16586202383041382\n",
      "\tLoss: 0.16689810156822205\n",
      "\tLoss: 0.13283145427703857\n",
      "\tLoss: 0.14689017832279205\n",
      "\tLoss: 0.1875603199005127\n",
      "\tLoss: 0.14634665846824646\n",
      "\tLoss: 0.18097500503063202\n",
      "\tLoss: 0.1832302212715149\n",
      "\tLoss: 0.15794001519680023\n",
      "\tLoss: 0.1616554856300354\n",
      "\tLoss: 0.19369792938232422\n",
      "\tLoss: 0.18017634749412537\n",
      "\tLoss: 0.17620472609996796\n",
      "\tLoss: 0.22132545709609985\n",
      "\tLoss: 0.17125922441482544\n",
      "\tLoss: 0.15329480171203613\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.18522784113883972\n",
      "\tLoss: 0.193505197763443\n",
      "\tLoss: 0.17426088452339172\n",
      "\tLoss: 0.14543560147285461\n",
      "\tLoss: 0.12532788515090942\n",
      "\tLoss: 0.18065044283866882\n",
      "\tLoss: 0.19051651656627655\n",
      "\tLoss: 0.1617194414138794\n",
      "\tLoss: 0.19353097677230835\n",
      "\tLoss: 0.1536446362733841\n",
      "\tLoss: 0.17157462239265442\n",
      "\tLoss: 0.13387368619441986\n",
      "\tLoss: 0.17525623738765717\n",
      "\tLoss: 0.16364452242851257\n",
      "\tLoss: 0.2030637562274933\n",
      "\tLoss: 0.16732308268547058\n",
      "\tLoss: 0.14782151579856873\n",
      "\tLoss: 0.15713855624198914\n",
      "\tLoss: 0.24356180429458618\n",
      "\tLoss: 0.16206908226013184\n",
      "\tLoss: 0.14222007989883423\n",
      "\tLoss: 0.104365773499012\n",
      "\tLoss: 0.14974577724933624\n",
      "\tLoss: 0.1539015769958496\n",
      "\tLoss: 0.1792563796043396\n",
      "\tLoss: 0.17052116990089417\n",
      "\tLoss: 0.16093093156814575\n",
      "\tLoss: 0.1732780635356903\n",
      "\tLoss: 0.14535605907440186\n",
      "\tLoss: 0.17367322742938995\n",
      "\tLoss: 0.173434317111969\n",
      "\tLoss: 0.10265485942363739\n",
      "\tLoss: 0.08696594834327698\n",
      "\tLoss: 0.11790908873081207\n",
      "\tLoss: 0.175166517496109\n",
      "\tLoss: 0.20285600423812866\n",
      "\tLoss: 0.13631343841552734\n",
      "\tLoss: 0.12061558663845062\n",
      "\tLoss: 0.2231803983449936\n",
      "\tLoss: 0.2802237570285797\n",
      "\tLoss: 0.22802922129631042\n",
      "\tLoss: 0.18115267157554626\n",
      "\tLoss: 0.13673734664916992\n",
      "\tLoss: 0.20295420289039612\n",
      "\tLoss: 0.1510097086429596\n",
      "\tLoss: 0.17503082752227783\n",
      "\tLoss: 0.1484663486480713\n",
      "\tLoss: 0.12565413117408752\n",
      "\tLoss: 0.17791476845741272\n",
      "\tLoss: 0.17267930507659912\n",
      "\tLoss: 0.16808101534843445\n",
      "[time] Epoch 7: 460.82167403772473s = 7.680361233962079m\n",
      "\n",
      "Epoch 8...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.13348951935768127\n",
      "\tLoss: 0.09304788708686829\n",
      "\tLoss: 0.1707289218902588\n",
      "\tLoss: 0.1345159411430359\n",
      "\tLoss: 0.1326439082622528\n",
      "\tLoss: 0.13657067716121674\n",
      "\tLoss: 0.1745389997959137\n",
      "\tLoss: 0.14795231819152832\n",
      "\tLoss: 0.12520962953567505\n",
      "\tLoss: 0.14148205518722534\n",
      "\tLoss: 0.16222767531871796\n",
      "\tLoss: 0.1841060072183609\n",
      "\tLoss: 0.1749955117702484\n",
      "\tLoss: 0.27962368726730347\n",
      "\tLoss: 0.1412922739982605\n",
      "\tLoss: 0.158152237534523\n",
      "\tLoss: 0.14700210094451904\n",
      "\tLoss: 0.19367679953575134\n",
      "\tLoss: 0.16436487436294556\n",
      "\tLoss: 0.13573676347732544\n",
      "\tLoss: 0.1516421139240265\n",
      "\tLoss: 0.14068706333637238\n",
      "\tLoss: 0.13546901941299438\n",
      "\tLoss: 0.2024088203907013\n",
      "\tLoss: 0.1346849501132965\n",
      "\tLoss: 0.16779911518096924\n",
      "\tLoss: 0.17207923531532288\n",
      "\tLoss: 0.14126302301883698\n",
      "\tLoss: 0.19527500867843628\n",
      "\tLoss: 0.13509032130241394\n",
      "\tLoss: 0.137465238571167\n",
      "\tLoss: 0.13490648567676544\n",
      "\tLoss: 0.15486644208431244\n",
      "\tLoss: 0.19124595820903778\n",
      "\tLoss: 0.2018027901649475\n",
      "\tLoss: 0.1651465743780136\n",
      "\tLoss: 0.17830485105514526\n",
      "\tLoss: 0.1258239895105362\n",
      "\tLoss: 0.13781964778900146\n",
      "\tLoss: 0.15441328287124634\n",
      "\tLoss: 0.16957557201385498\n",
      "\tLoss: 0.13271430134773254\n",
      "\tLoss: 0.11024575680494308\n",
      "\tLoss: 0.13344527781009674\n",
      "\tLoss: 0.15197496116161346\n",
      "\tLoss: 0.19109855592250824\n",
      "\tLoss: 0.15952080488204956\n",
      "\tLoss: 0.18562299013137817\n",
      "\tLoss: 0.15596765279769897\n",
      "\tLoss: 0.12724186480045319\n",
      "\tLoss: 0.1560073345899582\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.16318438947200775\n",
      "\tLoss: 0.15115053951740265\n",
      "\tLoss: 0.151612788438797\n",
      "\tLoss: 0.14938856661319733\n",
      "\tLoss: 0.17570337653160095\n",
      "\tLoss: 0.1551373302936554\n",
      "\tLoss: 0.1326885223388672\n",
      "\tLoss: 0.13493934273719788\n",
      "\tLoss: 0.18041592836380005\n",
      "\tLoss: 0.2276650071144104\n",
      "\tLoss: 0.19122248888015747\n",
      "\tLoss: 0.19312110543251038\n",
      "\tLoss: 0.15361227095127106\n",
      "\tLoss: 0.12019572407007217\n",
      "\tLoss: 0.17687131464481354\n",
      "\tLoss: 0.1713556945323944\n",
      "\tLoss: 0.13861298561096191\n",
      "\tLoss: 0.16910497844219208\n",
      "\tLoss: 0.1582016944885254\n",
      "\tLoss: 0.16603690385818481\n",
      "\tLoss: 0.11469961702823639\n",
      "\tLoss: 0.1633501648902893\n",
      "\tLoss: 0.1320279985666275\n",
      "\tLoss: 0.1604422926902771\n",
      "\tLoss: 0.18454408645629883\n",
      "\tLoss: 0.1625264585018158\n",
      "\tLoss: 0.1383284628391266\n",
      "\tLoss: 0.17353075742721558\n",
      "\tLoss: 0.17474761605262756\n",
      "\tLoss: 0.21604116261005402\n",
      "\tLoss: 0.18342137336730957\n",
      "\tLoss: 0.1233600452542305\n",
      "\tLoss: 0.18119728565216064\n",
      "\tLoss: 0.14710567891597748\n",
      "\tLoss: 0.12056276947259903\n",
      "\tLoss: 0.1501060426235199\n",
      "\tLoss: 0.110019750893116\n",
      "\tLoss: 0.09626943618059158\n",
      "\tLoss: 0.1450638771057129\n",
      "\tLoss: 0.19315238296985626\n",
      "\tLoss: 0.1637597382068634\n",
      "\tLoss: 0.1717875897884369\n",
      "\tLoss: 0.15815849602222443\n",
      "\tLoss: 0.15826177597045898\n",
      "\tLoss: 0.1525060534477234\n",
      "\tLoss: 0.13944724202156067\n",
      "\tLoss: 0.15249864757061005\n",
      "\tLoss: 0.11635644733905792\n",
      "\tLoss: 0.09760203957557678\n",
      "\tLoss: 0.15181317925453186\n",
      "\tLoss: 0.15965454280376434\n",
      "[time] Epoch 8: 458.8091672286391s = 7.646819453810652m\n",
      "\n",
      "Epoch 9...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1428157389163971\n",
      "\tLoss: 0.20207400619983673\n",
      "\tLoss: 0.19799578189849854\n",
      "\tLoss: 0.15914508700370789\n",
      "\tLoss: 0.1803058385848999\n",
      "\tLoss: 0.1522803008556366\n",
      "\tLoss: 0.15765726566314697\n",
      "\tLoss: 0.12943735718727112\n",
      "\tLoss: 0.17146633565425873\n",
      "\tLoss: 0.1413349211215973\n",
      "\tLoss: 0.18614883720874786\n",
      "\tLoss: 0.17678183317184448\n",
      "\tLoss: 0.1620277613401413\n",
      "\tLoss: 0.23284637928009033\n",
      "\tLoss: 0.2012619972229004\n",
      "\tLoss: 0.1641751229763031\n",
      "\tLoss: 0.13402095437049866\n",
      "\tLoss: 0.1325041651725769\n",
      "\tLoss: 0.16160109639167786\n",
      "\tLoss: 0.2031875103712082\n",
      "\tLoss: 0.21526022255420685\n",
      "\tLoss: 0.11109884083271027\n",
      "\tLoss: 0.14563991129398346\n",
      "\tLoss: 0.15192697942256927\n",
      "\tLoss: 0.16123336553573608\n",
      "\tLoss: 0.18663057684898376\n",
      "\tLoss: 0.18323446810245514\n",
      "\tLoss: 0.1622437685728073\n",
      "\tLoss: 0.16604292392730713\n",
      "\tLoss: 0.1686224639415741\n",
      "\tLoss: 0.15963289141654968\n",
      "\tLoss: 0.12220758944749832\n",
      "\tLoss: 0.15908676385879517\n",
      "\tLoss: 0.1261964738368988\n",
      "\tLoss: 0.14737200736999512\n",
      "\tLoss: 0.14874646067619324\n",
      "\tLoss: 0.15713471174240112\n",
      "\tLoss: 0.12263637036085129\n",
      "\tLoss: 0.12275108695030212\n",
      "\tLoss: 0.1720747947692871\n",
      "\tLoss: 0.1510310024023056\n",
      "\tLoss: 0.1406300961971283\n",
      "\tLoss: 0.1341090202331543\n",
      "\tLoss: 0.15178659558296204\n",
      "\tLoss: 0.20981144905090332\n",
      "\tLoss: 0.17588844895362854\n",
      "\tLoss: 0.20513485372066498\n",
      "\tLoss: 0.1260998249053955\n",
      "\tLoss: 0.10746060311794281\n",
      "\tLoss: 0.12967301905155182\n",
      "\tLoss: 0.14907985925674438\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.16481684148311615\n",
      "\tLoss: 0.15906396508216858\n",
      "\tLoss: 0.14494910836219788\n",
      "\tLoss: 0.1752963662147522\n",
      "\tLoss: 0.10827389359474182\n",
      "\tLoss: 0.2008432149887085\n",
      "\tLoss: 0.1255730390548706\n",
      "\tLoss: 0.13778480887413025\n",
      "\tLoss: 0.20827126502990723\n",
      "\tLoss: 0.15599001944065094\n",
      "\tLoss: 0.15243053436279297\n",
      "\tLoss: 0.105974942445755\n",
      "\tLoss: 0.1384732574224472\n",
      "\tLoss: 0.15193666517734528\n",
      "\tLoss: 0.1365916132926941\n",
      "\tLoss: 0.11267851293087006\n",
      "\tLoss: 0.10714608430862427\n",
      "\tLoss: 0.19363872706890106\n",
      "\tLoss: 0.1668146401643753\n",
      "\tLoss: 0.0925741121172905\n",
      "\tLoss: 0.17190688848495483\n",
      "\tLoss: 0.1363230049610138\n",
      "\tLoss: 0.1347377598285675\n",
      "\tLoss: 0.15308567881584167\n",
      "\tLoss: 0.1782366782426834\n",
      "\tLoss: 0.19154328107833862\n",
      "\tLoss: 0.13587644696235657\n",
      "\tLoss: 0.12828242778778076\n",
      "\tLoss: 0.1846545934677124\n",
      "\tLoss: 0.15217553079128265\n",
      "\tLoss: 0.1773456484079361\n",
      "\tLoss: 0.1745038628578186\n",
      "\tLoss: 0.17132657766342163\n",
      "\tLoss: 0.1432512104511261\n",
      "\tLoss: 0.15735332667827606\n",
      "\tLoss: 0.12854284048080444\n",
      "\tLoss: 0.21105043590068817\n",
      "\tLoss: 0.1467912495136261\n",
      "\tLoss: 0.13674074411392212\n",
      "\tLoss: 0.17477479577064514\n",
      "\tLoss: 0.13388650119304657\n",
      "\tLoss: 0.18812066316604614\n",
      "\tLoss: 0.1697118878364563\n",
      "\tLoss: 0.11994668841362\n",
      "\tLoss: 0.13719432055950165\n",
      "\tLoss: 0.1419387012720108\n",
      "\tLoss: 0.16895851492881775\n",
      "\tLoss: 0.16413217782974243\n",
      "\tLoss: 0.16762930154800415\n",
      "\tLoss: 0.13324810564517975\n",
      "\tLoss: 0.15481288731098175\n",
      "[time] Epoch 9: 458.3923517661169s = 7.639872529435282m\n",
      "\n",
      "Epoch 10...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1624053567647934\n",
      "\tLoss: 0.19003495573997498\n",
      "\tLoss: 0.12332853674888611\n",
      "\tLoss: 0.13348108530044556\n",
      "\tLoss: 0.15156175196170807\n",
      "\tLoss: 0.18399466574192047\n",
      "\tLoss: 0.16227588057518005\n",
      "\tLoss: 0.17598161101341248\n",
      "\tLoss: 0.15658599138259888\n",
      "\tLoss: 0.1637076735496521\n",
      "\tLoss: 0.13037116825580597\n",
      "\tLoss: 0.1290355622768402\n",
      "\tLoss: 0.10464605689048767\n",
      "\tLoss: 0.1470513492822647\n",
      "\tLoss: 0.1951412558555603\n",
      "\tLoss: 0.14128002524375916\n",
      "\tLoss: 0.12537086009979248\n",
      "\tLoss: 0.13209913671016693\n",
      "\tLoss: 0.1297660619020462\n",
      "\tLoss: 0.12794117629528046\n",
      "\tLoss: 0.12913493812084198\n",
      "\tLoss: 0.15540897846221924\n",
      "\tLoss: 0.134147047996521\n",
      "\tLoss: 0.14080049097537994\n",
      "\tLoss: 0.15135818719863892\n",
      "\tLoss: 0.15475963056087494\n",
      "\tLoss: 0.13926909863948822\n",
      "\tLoss: 0.1960512101650238\n",
      "\tLoss: 0.141592875123024\n",
      "\tLoss: 0.16517695784568787\n",
      "\tLoss: 0.1618935763835907\n",
      "\tLoss: 0.14519524574279785\n",
      "\tLoss: 0.18829122185707092\n",
      "\tLoss: 0.13446126878261566\n",
      "\tLoss: 0.18727140128612518\n",
      "\tLoss: 0.12116008996963501\n",
      "\tLoss: 0.10051432996988297\n",
      "\tLoss: 0.12451431155204773\n",
      "\tLoss: 0.10748554766178131\n",
      "\tLoss: 0.1273445039987564\n",
      "\tLoss: 0.12870240211486816\n",
      "\tLoss: 0.18334704637527466\n",
      "\tLoss: 0.16582418978214264\n",
      "\tLoss: 0.19389264285564423\n",
      "\tLoss: 0.17334750294685364\n",
      "\tLoss: 0.14996398985385895\n",
      "\tLoss: 0.11462549865245819\n",
      "\tLoss: 0.18488150835037231\n",
      "\tLoss: 0.1258426010608673\n",
      "\tLoss: 0.1348636895418167\n",
      "\tLoss: 0.16222929954528809\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.16993100941181183\n",
      "\tLoss: 0.15783938765525818\n",
      "\tLoss: 0.18075886368751526\n",
      "\tLoss: 0.16219562292099\n",
      "\tLoss: 0.1367972195148468\n",
      "\tLoss: 0.16551968455314636\n",
      "\tLoss: 0.1023547500371933\n",
      "\tLoss: 0.17483800649642944\n",
      "\tLoss: 0.14958634972572327\n",
      "\tLoss: 0.16469426453113556\n",
      "\tLoss: 0.14235076308250427\n",
      "\tLoss: 0.1751556247472763\n",
      "\tLoss: 0.11758267879486084\n",
      "\tLoss: 0.13126224279403687\n",
      "\tLoss: 0.18617194890975952\n",
      "\tLoss: 0.15640509128570557\n",
      "\tLoss: 0.1652127355337143\n",
      "\tLoss: 0.13478413224220276\n",
      "\tLoss: 0.1609896719455719\n",
      "\tLoss: 0.13923627138137817\n",
      "\tLoss: 0.15214130282402039\n",
      "\tLoss: 0.1507643759250641\n",
      "\tLoss: 0.13339489698410034\n",
      "\tLoss: 0.13371524214744568\n",
      "\tLoss: 0.17377199232578278\n",
      "\tLoss: 0.13002675771713257\n",
      "\tLoss: 0.0886538028717041\n",
      "\tLoss: 0.11375364661216736\n",
      "\tLoss: 0.16299942135810852\n",
      "\tLoss: 0.15144789218902588\n",
      "\tLoss: 0.17697718739509583\n",
      "\tLoss: 0.16623884439468384\n",
      "\tLoss: 0.1490909606218338\n",
      "\tLoss: 0.13223396241664886\n",
      "\tLoss: 0.1449456512928009\n",
      "\tLoss: 0.13030703365802765\n",
      "\tLoss: 0.10165532678365707\n",
      "\tLoss: 0.11352372169494629\n",
      "\tLoss: 0.21588408946990967\n",
      "\tLoss: 0.1815032958984375\n",
      "\tLoss: 0.17961107194423676\n",
      "\tLoss: 0.20155057311058044\n",
      "\tLoss: 0.15710832178592682\n",
      "\tLoss: 0.14561274647712708\n",
      "\tLoss: 0.1448369324207306\n",
      "\tLoss: 0.18215411901474\n",
      "\tLoss: 0.17301112413406372\n",
      "\tLoss: 0.12217330932617188\n",
      "\tLoss: 0.13270607590675354\n",
      "\tLoss: 0.1509762555360794\n",
      "\tLoss: 0.1615319848060608\n",
      "[time] Epoch 10: 455.6315638050437s = 7.593859396750728m\n",
      "\n",
      "Epoch 11...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.20697934925556183\n",
      "\tLoss: 0.15802788734436035\n",
      "\tLoss: 0.15092961490154266\n",
      "\tLoss: 0.14478260278701782\n",
      "\tLoss: 0.146277517080307\n",
      "\tLoss: 0.18514439463615417\n",
      "\tLoss: 0.14823579788208008\n",
      "\tLoss: 0.15416239202022552\n",
      "\tLoss: 0.16306374967098236\n",
      "\tLoss: 0.16213037073612213\n",
      "\tLoss: 0.142329603433609\n",
      "\tLoss: 0.14020538330078125\n",
      "\tLoss: 0.14180779457092285\n",
      "\tLoss: 0.16816619038581848\n",
      "\tLoss: 0.16118964552879333\n",
      "\tLoss: 0.1895829737186432\n",
      "\tLoss: 0.16273263096809387\n",
      "\tLoss: 0.15720105171203613\n",
      "\tLoss: 0.1589890867471695\n",
      "\tLoss: 0.1864284873008728\n",
      "\tLoss: 0.12536361813545227\n",
      "\tLoss: 0.16963249444961548\n",
      "\tLoss: 0.15739652514457703\n",
      "\tLoss: 0.14703109860420227\n",
      "\tLoss: 0.12034346163272858\n",
      "\tLoss: 0.08642405271530151\n",
      "\tLoss: 0.10774199664592743\n",
      "\tLoss: 0.15358465909957886\n",
      "\tLoss: 0.14026260375976562\n",
      "\tLoss: 0.15420332551002502\n",
      "\tLoss: 0.1506039947271347\n",
      "\tLoss: 0.14020389318466187\n",
      "\tLoss: 0.13714876770973206\n",
      "\tLoss: 0.12797963619232178\n",
      "\tLoss: 0.1915595829486847\n",
      "\tLoss: 0.14445744454860687\n",
      "\tLoss: 0.10559466481208801\n",
      "\tLoss: 0.17708536982536316\n",
      "\tLoss: 0.17295145988464355\n",
      "\tLoss: 0.13583052158355713\n",
      "\tLoss: 0.16377511620521545\n",
      "\tLoss: 0.13060012459754944\n",
      "\tLoss: 0.1387963742017746\n",
      "\tLoss: 0.11207430064678192\n",
      "\tLoss: 0.15055084228515625\n",
      "\tLoss: 0.18383046984672546\n",
      "\tLoss: 0.19855734705924988\n",
      "\tLoss: 0.10771403461694717\n",
      "\tLoss: 0.14164197444915771\n",
      "\tLoss: 0.11721108853816986\n",
      "\tLoss: 0.1334039270877838\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.1323760598897934\n",
      "\tLoss: 0.2137574851512909\n",
      "\tLoss: 0.1361771523952484\n",
      "\tLoss: 0.11974883079528809\n",
      "\tLoss: 0.12310037016868591\n",
      "\tLoss: 0.150380477309227\n",
      "\tLoss: 0.14035354554653168\n",
      "\tLoss: 0.11706150323152542\n",
      "\tLoss: 0.17418403923511505\n",
      "\tLoss: 0.1304868757724762\n",
      "\tLoss: 0.1070680320262909\n",
      "\tLoss: 0.1486956924200058\n",
      "\tLoss: 0.16974614560604095\n",
      "\tLoss: 0.1517169028520584\n",
      "\tLoss: 0.21939674019813538\n",
      "\tLoss: 0.15616190433502197\n",
      "\tLoss: 0.14634005725383759\n",
      "\tLoss: 0.1663394719362259\n",
      "\tLoss: 0.11722682416439056\n",
      "\tLoss: 0.13633617758750916\n",
      "\tLoss: 0.12735772132873535\n",
      "\tLoss: 0.13907572627067566\n",
      "\tLoss: 0.1372869610786438\n",
      "\tLoss: 0.1650255024433136\n",
      "\tLoss: 0.10583431273698807\n",
      "\tLoss: 0.16973337531089783\n",
      "\tLoss: 0.14560583233833313\n",
      "\tLoss: 0.17937737703323364\n",
      "\tLoss: 0.16447332501411438\n",
      "\tLoss: 0.09673508256673813\n",
      "\tLoss: 0.19428718090057373\n",
      "\tLoss: 0.11971096694469452\n",
      "\tLoss: 0.1326451450586319\n",
      "\tLoss: 0.14967478811740875\n",
      "\tLoss: 0.11595495045185089\n",
      "\tLoss: 0.15833725035190582\n",
      "\tLoss: 0.13038694858551025\n",
      "\tLoss: 0.16314947605133057\n",
      "\tLoss: 0.19123254716396332\n",
      "\tLoss: 0.2083486020565033\n",
      "\tLoss: 0.17385300993919373\n",
      "\tLoss: 0.16131722927093506\n",
      "\tLoss: 0.15279783308506012\n",
      "\tLoss: 0.1610129475593567\n",
      "\tLoss: 0.13964122533798218\n",
      "\tLoss: 0.14428173005580902\n",
      "\tLoss: 0.13581544160842896\n",
      "\tLoss: 0.20190095901489258\n",
      "\tLoss: 0.12539035081863403\n",
      "\tLoss: 0.1622965782880783\n",
      "\tLoss: 0.14758360385894775\n",
      "[time] Epoch 11: 449.91782491095364s = 7.498630415182561m\n",
      "\n",
      "Epoch 12...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1623871624469757\n",
      "\tLoss: 0.1851063370704651\n",
      "\tLoss: 0.1338392198085785\n",
      "\tLoss: 0.15927386283874512\n",
      "\tLoss: 0.14324963092803955\n",
      "\tLoss: 0.14837172627449036\n",
      "\tLoss: 0.1682606339454651\n",
      "\tLoss: 0.16587743163108826\n",
      "\tLoss: 0.15976528823375702\n",
      "\tLoss: 0.11515294015407562\n",
      "\tLoss: 0.1336691975593567\n",
      "\tLoss: 0.17086127400398254\n",
      "\tLoss: 0.13852199912071228\n",
      "\tLoss: 0.13996346294879913\n",
      "\tLoss: 0.16525417566299438\n",
      "\tLoss: 0.1715008020401001\n",
      "\tLoss: 0.11233080923557281\n",
      "\tLoss: 0.1938868761062622\n",
      "\tLoss: 0.2091575264930725\n",
      "\tLoss: 0.21236968040466309\n",
      "\tLoss: 0.16111764311790466\n",
      "\tLoss: 0.14996002614498138\n",
      "\tLoss: 0.13943390548229218\n",
      "\tLoss: 0.1206018328666687\n",
      "\tLoss: 0.1761009842157364\n",
      "\tLoss: 0.11706119775772095\n",
      "\tLoss: 0.16362479329109192\n",
      "\tLoss: 0.13207194209098816\n",
      "\tLoss: 0.14574673771858215\n",
      "\tLoss: 0.1548062264919281\n",
      "\tLoss: 0.1768016666173935\n",
      "\tLoss: 0.08386563509702682\n",
      "\tLoss: 0.15638577938079834\n",
      "\tLoss: 0.18143099546432495\n",
      "\tLoss: 0.115639828145504\n",
      "\tLoss: 0.16267985105514526\n",
      "\tLoss: 0.1350320279598236\n",
      "\tLoss: 0.14714321494102478\n",
      "\tLoss: 0.14002099633216858\n",
      "\tLoss: 0.14553001523017883\n",
      "\tLoss: 0.1519503891468048\n",
      "\tLoss: 0.14759764075279236\n",
      "\tLoss: 0.1785360872745514\n",
      "\tLoss: 0.08750411868095398\n",
      "\tLoss: 0.155242919921875\n",
      "\tLoss: 0.18714438378810883\n",
      "\tLoss: 0.13362039625644684\n",
      "\tLoss: 0.11082200706005096\n",
      "\tLoss: 0.17219099402427673\n",
      "\tLoss: 0.15948784351348877\n",
      "\tLoss: 0.16538812220096588\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.1594284176826477\n",
      "\tLoss: 0.15670742094516754\n",
      "\tLoss: 0.15664193034172058\n",
      "\tLoss: 0.10915693640708923\n",
      "\tLoss: 0.13503727316856384\n",
      "\tLoss: 0.19391107559204102\n",
      "\tLoss: 0.17354151606559753\n",
      "\tLoss: 0.1989852786064148\n",
      "\tLoss: 0.14407986402511597\n",
      "\tLoss: 0.19058620929718018\n",
      "\tLoss: 0.12264303863048553\n",
      "\tLoss: 0.19736284017562866\n",
      "\tLoss: 0.14119833707809448\n",
      "\tLoss: 0.1432165652513504\n",
      "\tLoss: 0.22133304178714752\n",
      "\tLoss: 0.16054773330688477\n",
      "\tLoss: 0.12426014989614487\n",
      "\tLoss: 0.1879557967185974\n",
      "\tLoss: 0.15329982340335846\n",
      "\tLoss: 0.14446261525154114\n",
      "\tLoss: 0.1663750857114792\n",
      "\tLoss: 0.1322418749332428\n",
      "\tLoss: 0.13470256328582764\n",
      "\tLoss: 0.11919654905796051\n",
      "\tLoss: 0.18971450626850128\n",
      "\tLoss: 0.1980038285255432\n",
      "\tLoss: 0.1354140043258667\n",
      "\tLoss: 0.12049843370914459\n",
      "\tLoss: 0.12357920408248901\n",
      "\tLoss: 0.16095778346061707\n",
      "\tLoss: 0.14308828115463257\n",
      "\tLoss: 0.1347508430480957\n",
      "\tLoss: 0.10219652950763702\n",
      "\tLoss: 0.12044493854045868\n",
      "\tLoss: 0.18515697121620178\n",
      "\tLoss: 0.21597744524478912\n",
      "\tLoss: 0.15612103044986725\n",
      "\tLoss: 0.11789028346538544\n",
      "\tLoss: 0.13349178433418274\n",
      "\tLoss: 0.10861340165138245\n",
      "\tLoss: 0.21513932943344116\n",
      "\tLoss: 0.13680286705493927\n",
      "\tLoss: 0.12535670399665833\n",
      "\tLoss: 0.17039863765239716\n",
      "\tLoss: 0.17215865850448608\n",
      "\tLoss: 0.09078504145145416\n",
      "\tLoss: 0.13898764550685883\n",
      "\tLoss: 0.1771133542060852\n",
      "\tLoss: 0.1420241743326187\n",
      "\tLoss: 0.12538252770900726\n",
      "\tLoss: 0.1849425882101059\n",
      "[time] Epoch 12: 454.8200614415109s = 7.580334357358515m\n",
      "\n",
      "Epoch 13...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1668027639389038\n",
      "\tLoss: 0.18983250856399536\n",
      "\tLoss: 0.14021386206150055\n",
      "\tLoss: 0.11440445482730865\n",
      "\tLoss: 0.20956572890281677\n",
      "\tLoss: 0.14476656913757324\n",
      "\tLoss: 0.13020455837249756\n",
      "\tLoss: 0.1364007592201233\n",
      "\tLoss: 0.12419144809246063\n",
      "\tLoss: 0.12455351650714874\n",
      "\tLoss: 0.13620327413082123\n",
      "\tLoss: 0.09156544506549835\n",
      "\tLoss: 0.11533167213201523\n",
      "\tLoss: 0.12153568863868713\n",
      "\tLoss: 0.13273094594478607\n",
      "\tLoss: 0.17667344212532043\n",
      "\tLoss: 0.1322164386510849\n",
      "\tLoss: 0.18418684601783752\n",
      "\tLoss: 0.1566310077905655\n",
      "\tLoss: 0.0989856868982315\n",
      "\tLoss: 0.14934158325195312\n",
      "\tLoss: 0.16339808702468872\n",
      "\tLoss: 0.17313309013843536\n",
      "\tLoss: 0.16084571182727814\n",
      "\tLoss: 0.1421499103307724\n",
      "\tLoss: 0.12235303223133087\n",
      "\tLoss: 0.15875914692878723\n",
      "\tLoss: 0.19589118659496307\n",
      "\tLoss: 0.13634416460990906\n",
      "\tLoss: 0.15286663174629211\n",
      "\tLoss: 0.11688095331192017\n",
      "\tLoss: 0.15083757042884827\n",
      "\tLoss: 0.1478160321712494\n",
      "\tLoss: 0.15134194493293762\n",
      "\tLoss: 0.16893553733825684\n",
      "\tLoss: 0.13527029752731323\n",
      "\tLoss: 0.11403323709964752\n",
      "\tLoss: 0.14761382341384888\n",
      "\tLoss: 0.1450890153646469\n",
      "\tLoss: 0.156276673078537\n",
      "\tLoss: 0.12476170063018799\n",
      "\tLoss: 0.12822702527046204\n",
      "\tLoss: 0.12455540895462036\n",
      "\tLoss: 0.16801322996616364\n",
      "\tLoss: 0.13403114676475525\n",
      "\tLoss: 0.1087438240647316\n",
      "\tLoss: 0.11057828366756439\n",
      "\tLoss: 0.09838363528251648\n",
      "\tLoss: 0.13960829377174377\n",
      "\tLoss: 0.12387552112340927\n",
      "\tLoss: 0.10916398465633392\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.1399778127670288\n",
      "\tLoss: 0.11430751532316208\n",
      "\tLoss: 0.1644439399242401\n",
      "\tLoss: 0.17939120531082153\n",
      "\tLoss: 0.09665476530790329\n",
      "\tLoss: 0.138960599899292\n",
      "\tLoss: 0.10939213633537292\n",
      "\tLoss: 0.13771812617778778\n",
      "\tLoss: 0.13846978545188904\n",
      "\tLoss: 0.1464889645576477\n",
      "\tLoss: 0.13958469033241272\n",
      "\tLoss: 0.13232220709323883\n",
      "\tLoss: 0.1208583265542984\n",
      "\tLoss: 0.08970080316066742\n",
      "\tLoss: 0.16822800040245056\n",
      "\tLoss: 0.1500059962272644\n",
      "\tLoss: 0.15909186005592346\n",
      "\tLoss: 0.14256888628005981\n",
      "\tLoss: 0.17114177346229553\n",
      "\tLoss: 0.15414725244045258\n",
      "\tLoss: 0.12170817703008652\n",
      "\tLoss: 0.1470343917608261\n",
      "\tLoss: 0.1682206243276596\n",
      "\tLoss: 0.10785456746816635\n",
      "\tLoss: 0.13300344347953796\n",
      "\tLoss: 0.11990123987197876\n",
      "\tLoss: 0.12623295187950134\n",
      "\tLoss: 0.17752940952777863\n",
      "\tLoss: 0.13233497738838196\n",
      "\tLoss: 0.1284792572259903\n",
      "\tLoss: 0.1404445320367813\n",
      "\tLoss: 0.15314072370529175\n",
      "\tLoss: 0.11224202811717987\n",
      "\tLoss: 0.146190345287323\n",
      "\tLoss: 0.17391908168792725\n",
      "\tLoss: 0.1625036895275116\n",
      "\tLoss: 0.11051642894744873\n",
      "\tLoss: 0.13833680748939514\n",
      "\tLoss: 0.20494861900806427\n",
      "\tLoss: 0.18653249740600586\n",
      "\tLoss: 0.1354767382144928\n",
      "\tLoss: 0.11532857269048691\n",
      "\tLoss: 0.14544141292572021\n",
      "\tLoss: 0.14955729246139526\n",
      "\tLoss: 0.13811714947223663\n",
      "\tLoss: 0.11211851239204407\n",
      "\tLoss: 0.12442047894001007\n",
      "\tLoss: 0.1053382158279419\n",
      "\tLoss: 0.12858323752880096\n",
      "\tLoss: 0.17055901885032654\n",
      "\tLoss: 0.1525789499282837\n",
      "[time] Epoch 13: 448.89461622480303s = 7.4815769370800504m\n",
      "\n",
      "Epoch 14...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.15115045011043549\n",
      "\tLoss: 0.11056621372699738\n",
      "\tLoss: 0.07782211154699326\n",
      "\tLoss: 0.11991523206233978\n",
      "\tLoss: 0.18480202555656433\n",
      "\tLoss: 0.14517655968666077\n",
      "\tLoss: 0.13124245405197144\n",
      "\tLoss: 0.15518485009670258\n",
      "\tLoss: 0.1488620936870575\n",
      "\tLoss: 0.19430479407310486\n",
      "\tLoss: 0.1638081669807434\n",
      "\tLoss: 0.17223325371742249\n",
      "\tLoss: 0.1588577926158905\n",
      "\tLoss: 0.1155899316072464\n",
      "\tLoss: 0.19489389657974243\n",
      "\tLoss: 0.14049747586250305\n",
      "\tLoss: 0.2154688835144043\n",
      "\tLoss: 0.14087307453155518\n",
      "\tLoss: 0.17824558913707733\n",
      "\tLoss: 0.11203701794147491\n",
      "\tLoss: 0.1376812756061554\n",
      "\tLoss: 0.13858118653297424\n",
      "\tLoss: 0.09471876174211502\n",
      "\tLoss: 0.153501495718956\n",
      "\tLoss: 0.09443552047014236\n",
      "\tLoss: 0.12476064264774323\n",
      "\tLoss: 0.1347724348306656\n",
      "\tLoss: 0.17003333568572998\n",
      "\tLoss: 0.14779844880104065\n",
      "\tLoss: 0.13415762782096863\n",
      "\tLoss: 0.16551494598388672\n",
      "\tLoss: 0.18851706385612488\n",
      "\tLoss: 0.12367002665996552\n",
      "\tLoss: 0.1367824673652649\n",
      "\tLoss: 0.13908620178699493\n",
      "\tLoss: 0.14516033232212067\n",
      "\tLoss: 0.14981883764266968\n",
      "\tLoss: 0.15553107857704163\n",
      "\tLoss: 0.1384461224079132\n",
      "\tLoss: 0.18163828551769257\n",
      "\tLoss: 0.19044579565525055\n",
      "\tLoss: 0.1174827367067337\n",
      "\tLoss: 0.13128362596035004\n",
      "\tLoss: 0.1408742368221283\n",
      "\tLoss: 0.1067725270986557\n",
      "\tLoss: 0.11904196441173553\n",
      "\tLoss: 0.1528840959072113\n",
      "\tLoss: 0.1756780743598938\n",
      "\tLoss: 0.16039173305034637\n",
      "\tLoss: 0.12457208335399628\n",
      "\tLoss: 0.1333484649658203\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.11774026602506638\n",
      "\tLoss: 0.15748682618141174\n",
      "\tLoss: 0.18179389834403992\n",
      "\tLoss: 0.1753890961408615\n",
      "\tLoss: 0.1829041987657547\n",
      "\tLoss: 0.22317633032798767\n",
      "\tLoss: 0.11960648000240326\n",
      "\tLoss: 0.10978975892066956\n",
      "\tLoss: 0.17267513275146484\n",
      "\tLoss: 0.12979663908481598\n",
      "\tLoss: 0.1856471449136734\n",
      "\tLoss: 0.18177521228790283\n",
      "\tLoss: 0.14707109332084656\n",
      "\tLoss: 0.16409271955490112\n",
      "\tLoss: 0.20444799959659576\n",
      "\tLoss: 0.14073488116264343\n",
      "\tLoss: 0.19704411923885345\n",
      "\tLoss: 0.12807747721672058\n",
      "\tLoss: 0.14329512417316437\n",
      "\tLoss: 0.1287226676940918\n",
      "\tLoss: 0.10685800015926361\n",
      "\tLoss: 0.12016797065734863\n",
      "\tLoss: 0.14186030626296997\n",
      "\tLoss: 0.19566623866558075\n",
      "\tLoss: 0.16865184903144836\n",
      "\tLoss: 0.15556706488132477\n",
      "\tLoss: 0.1314897984266281\n",
      "\tLoss: 0.18435150384902954\n",
      "\tLoss: 0.1415480077266693\n",
      "\tLoss: 0.17078238725662231\n",
      "\tLoss: 0.1420649290084839\n",
      "\tLoss: 0.13027453422546387\n",
      "\tLoss: 0.11687374860048294\n",
      "\tLoss: 0.15112967789173126\n",
      "\tLoss: 0.1259169578552246\n",
      "\tLoss: 0.16102862358093262\n",
      "\tLoss: 0.17743104696273804\n",
      "\tLoss: 0.11397756636142731\n",
      "\tLoss: 0.1797795444726944\n",
      "\tLoss: 0.149529367685318\n",
      "\tLoss: 0.09595287591218948\n",
      "\tLoss: 0.1494576632976532\n",
      "\tLoss: 0.15903866291046143\n",
      "\tLoss: 0.17097125947475433\n",
      "\tLoss: 0.14321234822273254\n",
      "\tLoss: 0.15654981136322021\n",
      "\tLoss: 0.15083545446395874\n",
      "\tLoss: 0.1914697289466858\n",
      "\tLoss: 0.13269267976284027\n",
      "\tLoss: 0.1436300128698349\n",
      "\tLoss: 0.17288769781589508\n",
      "[time] Epoch 14: 450.90063396375626s = 7.515010566062604m\n",
      "\n",
      "Epoch 15...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.14220142364501953\n",
      "\tLoss: 0.11529098451137543\n",
      "\tLoss: 0.12647676467895508\n",
      "\tLoss: 0.09379500150680542\n",
      "\tLoss: 0.12631075084209442\n",
      "\tLoss: 0.11398577690124512\n",
      "\tLoss: 0.1473207175731659\n",
      "\tLoss: 0.10443909466266632\n",
      "\tLoss: 0.13294214010238647\n",
      "\tLoss: 0.10682368278503418\n",
      "\tLoss: 0.1288432627916336\n",
      "\tLoss: 0.15031494200229645\n",
      "\tLoss: 0.1319572627544403\n",
      "\tLoss: 0.12404278665781021\n",
      "\tLoss: 0.14032766222953796\n",
      "\tLoss: 0.12886060774326324\n",
      "\tLoss: 0.14220258593559265\n",
      "\tLoss: 0.2131047248840332\n",
      "\tLoss: 0.15043219923973083\n",
      "\tLoss: 0.10816102474927902\n",
      "\tLoss: 0.09752646833658218\n",
      "\tLoss: 0.1022813469171524\n",
      "\tLoss: 0.17839112877845764\n",
      "\tLoss: 0.17006146907806396\n",
      "\tLoss: 0.15175440907478333\n",
      "\tLoss: 0.13701513409614563\n",
      "\tLoss: 0.2232363224029541\n",
      "\tLoss: 0.20156463980674744\n",
      "\tLoss: 0.1408393681049347\n",
      "\tLoss: 0.11887133121490479\n",
      "\tLoss: 0.1505691111087799\n",
      "\tLoss: 0.20522871613502502\n",
      "\tLoss: 0.1381935477256775\n",
      "\tLoss: 0.14822566509246826\n",
      "\tLoss: 0.16442102193832397\n",
      "\tLoss: 0.12827470898628235\n",
      "\tLoss: 0.13674548268318176\n",
      "\tLoss: 0.15624454617500305\n",
      "\tLoss: 0.1535399854183197\n",
      "\tLoss: 0.1742866337299347\n",
      "\tLoss: 0.1357070803642273\n",
      "\tLoss: 0.11768658459186554\n",
      "\tLoss: 0.1660897135734558\n",
      "\tLoss: 0.17438188195228577\n",
      "\tLoss: 0.09876610338687897\n",
      "\tLoss: 0.15243923664093018\n",
      "\tLoss: 0.1267397701740265\n",
      "\tLoss: 0.12139023840427399\n",
      "\tLoss: 0.11280468106269836\n",
      "\tLoss: 0.14439016580581665\n",
      "\tLoss: 0.19154536724090576\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.11623138934373856\n",
      "\tLoss: 0.1909085214138031\n",
      "\tLoss: 0.12070311605930328\n",
      "\tLoss: 0.12185423076152802\n",
      "\tLoss: 0.11269189417362213\n",
      "\tLoss: 0.16467247903347015\n",
      "\tLoss: 0.13567031919956207\n",
      "\tLoss: 0.13013368844985962\n",
      "\tLoss: 0.15916435420513153\n",
      "\tLoss: 0.10802286863327026\n",
      "\tLoss: 0.15408146381378174\n",
      "\tLoss: 0.14238695800304413\n",
      "\tLoss: 0.16679531335830688\n",
      "\tLoss: 0.13106733560562134\n",
      "\tLoss: 0.12559232115745544\n",
      "\tLoss: 0.14219340682029724\n",
      "\tLoss: 0.1287178099155426\n",
      "\tLoss: 0.1610291451215744\n",
      "\tLoss: 0.1019330769777298\n",
      "\tLoss: 0.10091876983642578\n",
      "\tLoss: 0.12303295731544495\n",
      "\tLoss: 0.13805364072322845\n",
      "\tLoss: 0.136244535446167\n",
      "\tLoss: 0.11600904166698456\n",
      "\tLoss: 0.09532134979963303\n",
      "\tLoss: 0.151011660695076\n",
      "\tLoss: 0.10470347106456757\n",
      "\tLoss: 0.11242325603961945\n",
      "\tLoss: 0.15190613269805908\n",
      "\tLoss: 0.18292507529258728\n",
      "\tLoss: 0.19403213262557983\n",
      "\tLoss: 0.1630113422870636\n",
      "\tLoss: 0.11180128157138824\n",
      "\tLoss: 0.09381408989429474\n",
      "\tLoss: 0.13471060991287231\n",
      "\tLoss: 0.09374319016933441\n",
      "\tLoss: 0.1172385886311531\n",
      "\tLoss: 0.1368616819381714\n",
      "\tLoss: 0.14912283420562744\n",
      "\tLoss: 0.13765637576580048\n",
      "\tLoss: 0.1678590625524521\n",
      "\tLoss: 0.11075112968683243\n",
      "\tLoss: 0.1387031078338623\n",
      "\tLoss: 0.1544165313243866\n",
      "\tLoss: 0.14603281021118164\n",
      "\tLoss: 0.12852469086647034\n",
      "\tLoss: 0.19758635759353638\n",
      "\tLoss: 0.13467168807983398\n",
      "\tLoss: 0.1547989696264267\n",
      "\tLoss: 0.14100569486618042\n",
      "\tLoss: 0.15186746418476105\n",
      "[time] Epoch 15: 456.56691554002464s = 7.609448592333744m\n",
      "\n",
      "Epoch 16...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.08799558132886887\n",
      "\tLoss: 0.1348051279783249\n",
      "\tLoss: 0.17521344125270844\n",
      "\tLoss: 0.0954190269112587\n",
      "\tLoss: 0.10997039079666138\n",
      "\tLoss: 0.15213510394096375\n",
      "\tLoss: 0.10745742172002792\n",
      "\tLoss: 0.11286412179470062\n",
      "\tLoss: 0.14063343405723572\n",
      "\tLoss: 0.18823693692684174\n",
      "\tLoss: 0.13727764785289764\n",
      "\tLoss: 0.11400923132896423\n",
      "\tLoss: 0.1689266711473465\n",
      "\tLoss: 0.1691647171974182\n",
      "\tLoss: 0.1622532308101654\n",
      "\tLoss: 0.1293843537569046\n",
      "\tLoss: 0.1885938048362732\n",
      "\tLoss: 0.14792907238006592\n",
      "\tLoss: 0.11410199105739594\n",
      "\tLoss: 0.10138091444969177\n",
      "\tLoss: 0.08063891530036926\n",
      "\tLoss: 0.16362005472183228\n",
      "\tLoss: 0.1564054787158966\n",
      "\tLoss: 0.1448318064212799\n",
      "\tLoss: 0.139769047498703\n",
      "\tLoss: 0.1653478443622589\n",
      "\tLoss: 0.09923239052295685\n",
      "\tLoss: 0.16284829378128052\n",
      "\tLoss: 0.13130393624305725\n",
      "\tLoss: 0.13443079590797424\n",
      "\tLoss: 0.16653788089752197\n",
      "\tLoss: 0.16382065415382385\n",
      "\tLoss: 0.2139042168855667\n",
      "\tLoss: 0.11518420279026031\n",
      "\tLoss: 0.12728451192378998\n",
      "\tLoss: 0.13855360448360443\n",
      "\tLoss: 0.1406918615102768\n",
      "\tLoss: 0.16783401370048523\n",
      "\tLoss: 0.14170867204666138\n",
      "\tLoss: 0.14955276250839233\n",
      "\tLoss: 0.07950375229120255\n",
      "\tLoss: 0.16761264204978943\n",
      "\tLoss: 0.14038753509521484\n",
      "\tLoss: 0.1978624314069748\n",
      "\tLoss: 0.08359444886445999\n",
      "\tLoss: 0.10211724787950516\n",
      "\tLoss: 0.16043831408023834\n",
      "\tLoss: 0.13269740343093872\n",
      "\tLoss: 0.17063672840595245\n",
      "\tLoss: 0.1355469822883606\n",
      "\tLoss: 0.1325000822544098\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.13511353731155396\n",
      "\tLoss: 0.12733472883701324\n",
      "\tLoss: 0.12203755974769592\n",
      "\tLoss: 0.1341799944639206\n",
      "\tLoss: 0.12841391563415527\n",
      "\tLoss: 0.15690472722053528\n",
      "\tLoss: 0.15764641761779785\n",
      "\tLoss: 0.14984101057052612\n",
      "\tLoss: 0.13556040823459625\n",
      "\tLoss: 0.12151192128658295\n",
      "\tLoss: 0.1479203701019287\n",
      "\tLoss: 0.14867684245109558\n",
      "\tLoss: 0.19841116666793823\n",
      "\tLoss: 0.1514352262020111\n",
      "\tLoss: 0.17097698152065277\n",
      "\tLoss: 0.18220508098602295\n",
      "\tLoss: 0.11357367038726807\n",
      "\tLoss: 0.12542730569839478\n",
      "\tLoss: 0.12978361546993256\n",
      "\tLoss: 0.13338391482830048\n",
      "\tLoss: 0.13856241106987\n",
      "\tLoss: 0.11771189421415329\n",
      "\tLoss: 0.14507970213890076\n",
      "\tLoss: 0.1398971527814865\n",
      "\tLoss: 0.1675790548324585\n",
      "\tLoss: 0.17563414573669434\n",
      "\tLoss: 0.12354965507984161\n",
      "\tLoss: 0.16857939958572388\n",
      "\tLoss: 0.14683715999126434\n",
      "\tLoss: 0.18160565197467804\n",
      "\tLoss: 0.15688541531562805\n",
      "\tLoss: 0.1402178704738617\n",
      "\tLoss: 0.10265356302261353\n",
      "\tLoss: 0.11128725111484528\n",
      "\tLoss: 0.1514793336391449\n",
      "\tLoss: 0.15879054367542267\n",
      "\tLoss: 0.11006863415241241\n",
      "\tLoss: 0.1024027168750763\n",
      "\tLoss: 0.13683289289474487\n",
      "\tLoss: 0.11754108965396881\n",
      "\tLoss: 0.12141536921262741\n",
      "\tLoss: 0.12835003435611725\n",
      "\tLoss: 0.18209515511989594\n",
      "\tLoss: 0.13306720554828644\n",
      "\tLoss: 0.0985899418592453\n",
      "\tLoss: 0.14805883169174194\n",
      "\tLoss: 0.15580463409423828\n",
      "\tLoss: 0.12764376401901245\n",
      "\tLoss: 0.12702114880084991\n",
      "\tLoss: 0.15502868592739105\n",
      "\tLoss: 0.12465287744998932\n",
      "[time] Epoch 16: 445.5970164742321s = 7.426616941237201m\n",
      "\n",
      "Epoch 17...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.16062019765377045\n",
      "\tLoss: 0.13643983006477356\n",
      "\tLoss: 0.10871570557355881\n",
      "\tLoss: 0.16614076495170593\n",
      "\tLoss: 0.1692594736814499\n",
      "\tLoss: 0.12645497918128967\n",
      "\tLoss: 0.16082796454429626\n",
      "\tLoss: 0.17060309648513794\n",
      "\tLoss: 0.16906072199344635\n",
      "\tLoss: 0.1563889980316162\n",
      "\tLoss: 0.10408104956150055\n",
      "\tLoss: 0.1659761667251587\n",
      "\tLoss: 0.16111695766448975\n",
      "\tLoss: 0.14572621881961823\n",
      "\tLoss: 0.12910279631614685\n",
      "\tLoss: 0.19041356444358826\n",
      "\tLoss: 0.15045666694641113\n",
      "\tLoss: 0.1611645519733429\n",
      "\tLoss: 0.0944545716047287\n",
      "\tLoss: 0.12687820196151733\n",
      "\tLoss: 0.19816872477531433\n",
      "\tLoss: 0.10113368928432465\n",
      "\tLoss: 0.1651630699634552\n",
      "\tLoss: 0.15074759721755981\n",
      "\tLoss: 0.14051461219787598\n",
      "\tLoss: 0.13447745144367218\n",
      "\tLoss: 0.11476118117570877\n",
      "\tLoss: 0.11567723006010056\n",
      "\tLoss: 0.14986278116703033\n",
      "\tLoss: 0.16436782479286194\n",
      "\tLoss: 0.13935841619968414\n",
      "\tLoss: 0.16324171423912048\n",
      "\tLoss: 0.1742432564496994\n",
      "\tLoss: 0.1260405033826828\n",
      "\tLoss: 0.12516018748283386\n",
      "\tLoss: 0.1647569239139557\n",
      "\tLoss: 0.10781165957450867\n",
      "\tLoss: 0.13832536339759827\n",
      "\tLoss: 0.1256314218044281\n",
      "\tLoss: 0.13253824412822723\n",
      "\tLoss: 0.12035151571035385\n",
      "\tLoss: 0.1307447850704193\n",
      "\tLoss: 0.15397962927818298\n",
      "\tLoss: 0.10115447640419006\n",
      "\tLoss: 0.11752885580062866\n",
      "\tLoss: 0.12002159655094147\n",
      "\tLoss: 0.16080357134342194\n",
      "\tLoss: 0.1827811896800995\n",
      "\tLoss: 0.14155104756355286\n",
      "\tLoss: 0.17554140090942383\n",
      "\tLoss: 0.1394982933998108\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.14377276599407196\n",
      "\tLoss: 0.08249281346797943\n",
      "\tLoss: 0.09023824334144592\n",
      "\tLoss: 0.11620917916297913\n",
      "\tLoss: 0.13387998938560486\n",
      "\tLoss: 0.1806647926568985\n",
      "\tLoss: 0.11681948602199554\n",
      "\tLoss: 0.09407738596200943\n",
      "\tLoss: 0.0854596421122551\n",
      "\tLoss: 0.1665879189968109\n",
      "\tLoss: 0.15169216692447662\n",
      "\tLoss: 0.1210472509264946\n",
      "\tLoss: 0.16295164823532104\n",
      "\tLoss: 0.15534833073616028\n",
      "\tLoss: 0.13839557766914368\n",
      "\tLoss: 0.15976089239120483\n",
      "\tLoss: 0.14723935723304749\n",
      "\tLoss: 0.16781491041183472\n",
      "\tLoss: 0.11488027125597\n",
      "\tLoss: 0.13292446732521057\n",
      "\tLoss: 0.1252988576889038\n",
      "\tLoss: 0.15826767683029175\n",
      "\tLoss: 0.16076523065567017\n",
      "\tLoss: 0.15013045072555542\n",
      "\tLoss: 0.12201683223247528\n",
      "\tLoss: 0.09741614758968353\n",
      "\tLoss: 0.11897425353527069\n",
      "\tLoss: 0.13743816316127777\n",
      "\tLoss: 0.14791814982891083\n",
      "\tLoss: 0.17308951914310455\n",
      "\tLoss: 0.14931008219718933\n",
      "\tLoss: 0.1361694186925888\n",
      "\tLoss: 0.10409389436244965\n",
      "\tLoss: 0.184986412525177\n",
      "\tLoss: 0.12257440388202667\n",
      "\tLoss: 0.11865964531898499\n",
      "\tLoss: 0.1102909967303276\n",
      "\tLoss: 0.13804097473621368\n",
      "\tLoss: 0.18651539087295532\n",
      "\tLoss: 0.10880640894174576\n",
      "\tLoss: 0.14646559953689575\n",
      "\tLoss: 0.12848901748657227\n",
      "\tLoss: 0.16419781744480133\n",
      "\tLoss: 0.13592740893363953\n",
      "\tLoss: 0.14938965439796448\n",
      "\tLoss: 0.13967710733413696\n",
      "\tLoss: 0.1560715138912201\n",
      "\tLoss: 0.13978660106658936\n",
      "\tLoss: 0.1201397180557251\n",
      "\tLoss: 0.17626012861728668\n",
      "\tLoss: 0.17525535821914673\n",
      "[time] Epoch 17: 441.6030661854893s = 7.360051103091489m\n",
      "\n",
      "Epoch 18...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1360795497894287\n",
      "\tLoss: 0.18341362476348877\n",
      "\tLoss: 0.12333410978317261\n",
      "\tLoss: 0.12054598331451416\n",
      "\tLoss: 0.14104238152503967\n",
      "\tLoss: 0.079332634806633\n",
      "\tLoss: 0.10224650800228119\n",
      "\tLoss: 0.10049979388713837\n",
      "\tLoss: 0.09924515336751938\n",
      "\tLoss: 0.16959014534950256\n",
      "\tLoss: 0.14968617260456085\n",
      "\tLoss: 0.16248422861099243\n",
      "\tLoss: 0.1430160105228424\n",
      "\tLoss: 0.19106218218803406\n",
      "\tLoss: 0.11960101127624512\n",
      "\tLoss: 0.11132466793060303\n",
      "\tLoss: 0.10915756225585938\n",
      "\tLoss: 0.11274490505456924\n",
      "\tLoss: 0.16747470200061798\n",
      "\tLoss: 0.1300308108329773\n",
      "\tLoss: 0.15786412358283997\n",
      "\tLoss: 0.1359580159187317\n",
      "\tLoss: 0.13480891287326813\n",
      "\tLoss: 0.11233508586883545\n",
      "\tLoss: 0.1575089991092682\n",
      "\tLoss: 0.0870627835392952\n",
      "\tLoss: 0.1520644724369049\n",
      "\tLoss: 0.1569061577320099\n",
      "\tLoss: 0.11588706821203232\n",
      "\tLoss: 0.1348915994167328\n",
      "\tLoss: 0.10440114140510559\n",
      "\tLoss: 0.11392564326524734\n",
      "\tLoss: 0.18213826417922974\n",
      "\tLoss: 0.15961043536663055\n",
      "\tLoss: 0.14167973399162292\n",
      "\tLoss: 0.1174989715218544\n",
      "\tLoss: 0.1331806778907776\n",
      "\tLoss: 0.13308385014533997\n",
      "\tLoss: 0.08532096445560455\n",
      "\tLoss: 0.10419367253780365\n",
      "\tLoss: 0.15907037258148193\n",
      "\tLoss: 0.12424476444721222\n",
      "\tLoss: 0.1784675121307373\n",
      "\tLoss: 0.12114115059375763\n",
      "\tLoss: 0.12322255969047546\n",
      "\tLoss: 0.10691455006599426\n",
      "\tLoss: 0.09797868877649307\n",
      "\tLoss: 0.20796939730644226\n",
      "\tLoss: 0.129802405834198\n",
      "\tLoss: 0.17816942930221558\n",
      "\tLoss: 0.12109187245368958\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.08514399826526642\n",
      "\tLoss: 0.1631610095500946\n",
      "\tLoss: 0.13106033205986023\n",
      "\tLoss: 0.17700889706611633\n",
      "\tLoss: 0.12210875749588013\n",
      "\tLoss: 0.13457606732845306\n",
      "\tLoss: 0.08147761225700378\n",
      "\tLoss: 0.10047288239002228\n",
      "\tLoss: 0.11192429065704346\n",
      "\tLoss: 0.13766367733478546\n",
      "\tLoss: 0.13875815272331238\n",
      "\tLoss: 0.14975708723068237\n",
      "\tLoss: 0.1352386474609375\n",
      "\tLoss: 0.1554827094078064\n",
      "\tLoss: 0.12103758007287979\n",
      "\tLoss: 0.12696309387683868\n",
      "\tLoss: 0.16519202291965485\n",
      "\tLoss: 0.14530746638774872\n",
      "\tLoss: 0.14492912590503693\n",
      "\tLoss: 0.1462448239326477\n",
      "\tLoss: 0.13418540358543396\n",
      "\tLoss: 0.13289357721805573\n",
      "\tLoss: 0.11440696567296982\n",
      "\tLoss: 0.1531103253364563\n",
      "\tLoss: 0.1405627429485321\n",
      "\tLoss: 0.11548851430416107\n",
      "\tLoss: 0.1509495973587036\n",
      "\tLoss: 0.14853323996067047\n",
      "\tLoss: 0.12442773580551147\n",
      "\tLoss: 0.147337406873703\n",
      "\tLoss: 0.1570979803800583\n",
      "\tLoss: 0.14973774552345276\n",
      "\tLoss: 0.17186835408210754\n",
      "\tLoss: 0.14706668257713318\n",
      "\tLoss: 0.13752922415733337\n",
      "\tLoss: 0.17549066245555878\n",
      "\tLoss: 0.11828718334436417\n",
      "\tLoss: 0.1497819721698761\n",
      "\tLoss: 0.11904928088188171\n",
      "\tLoss: 0.13709694147109985\n",
      "\tLoss: 0.17519772052764893\n",
      "\tLoss: 0.15573018789291382\n",
      "\tLoss: 0.12331939488649368\n",
      "\tLoss: 0.12942181527614594\n",
      "\tLoss: 0.11650595813989639\n",
      "\tLoss: 0.16511131823062897\n",
      "\tLoss: 0.1041318029165268\n",
      "\tLoss: 0.13616572320461273\n",
      "\tLoss: 0.11334611475467682\n",
      "\tLoss: 0.11556337028741837\n",
      "\tLoss: 0.1692976951599121\n",
      "[time] Epoch 18: 457.1244525164366s = 7.618740875273943m\n",
      "\n",
      "Epoch 19...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.14626985788345337\n",
      "\tLoss: 0.10557112097740173\n",
      "\tLoss: 0.16988730430603027\n",
      "\tLoss: 0.09356153756380081\n",
      "\tLoss: 0.10269895195960999\n",
      "\tLoss: 0.11889855563640594\n",
      "\tLoss: 0.10829727351665497\n",
      "\tLoss: 0.20442888140678406\n",
      "\tLoss: 0.14854022860527039\n",
      "\tLoss: 0.14370277523994446\n",
      "\tLoss: 0.1114916279911995\n",
      "\tLoss: 0.12193694710731506\n",
      "\tLoss: 0.10431864112615585\n",
      "\tLoss: 0.18780586123466492\n",
      "\tLoss: 0.1179209053516388\n",
      "\tLoss: 0.13566523790359497\n",
      "\tLoss: 0.17703187465667725\n",
      "\tLoss: 0.10839653015136719\n",
      "\tLoss: 0.15152883529663086\n",
      "\tLoss: 0.12492930889129639\n",
      "\tLoss: 0.17109940946102142\n",
      "\tLoss: 0.1244891807436943\n",
      "\tLoss: 0.17138032615184784\n",
      "\tLoss: 0.122932568192482\n",
      "\tLoss: 0.14070114493370056\n",
      "\tLoss: 0.12118455767631531\n",
      "\tLoss: 0.1646316647529602\n",
      "\tLoss: 0.14900365471839905\n",
      "\tLoss: 0.07835961878299713\n",
      "\tLoss: 0.12054740637540817\n",
      "\tLoss: 0.15723241865634918\n",
      "\tLoss: 0.15498322248458862\n",
      "\tLoss: 0.07773688435554504\n",
      "\tLoss: 0.1687660962343216\n",
      "\tLoss: 0.16739147901535034\n",
      "\tLoss: 0.11422103643417358\n",
      "\tLoss: 0.11992185562849045\n",
      "\tLoss: 0.09897275269031525\n",
      "\tLoss: 0.12140023708343506\n",
      "\tLoss: 0.10726723819971085\n",
      "\tLoss: 0.13496451079845428\n",
      "\tLoss: 0.15920212864875793\n",
      "\tLoss: 0.2199312299489975\n",
      "\tLoss: 0.12714503705501556\n",
      "\tLoss: 0.14490343630313873\n",
      "\tLoss: 0.14902503788471222\n",
      "\tLoss: 0.13119056820869446\n",
      "\tLoss: 0.19642530381679535\n",
      "\tLoss: 0.136713445186615\n",
      "\tLoss: 0.15717622637748718\n",
      "\tLoss: 0.12603521347045898\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.12876367568969727\n",
      "\tLoss: 0.15429553389549255\n",
      "\tLoss: 0.12355946749448776\n",
      "\tLoss: 0.1413455754518509\n",
      "\tLoss: 0.09977753460407257\n",
      "\tLoss: 0.1328432261943817\n",
      "\tLoss: 0.1328980028629303\n",
      "\tLoss: 0.15080922842025757\n",
      "\tLoss: 0.16070525348186493\n",
      "\tLoss: 0.15884290635585785\n",
      "\tLoss: 0.17551836371421814\n",
      "\tLoss: 0.1358506828546524\n",
      "\tLoss: 0.13441595435142517\n",
      "\tLoss: 0.07363900542259216\n",
      "\tLoss: 0.1806444674730301\n",
      "\tLoss: 0.11368538439273834\n",
      "\tLoss: 0.18718546628952026\n",
      "\tLoss: 0.14468234777450562\n",
      "\tLoss: 0.176267609000206\n",
      "\tLoss: 0.13492418825626373\n",
      "\tLoss: 0.09939631074666977\n",
      "\tLoss: 0.10857634246349335\n",
      "\tLoss: 0.09851625561714172\n",
      "\tLoss: 0.09435035288333893\n",
      "\tLoss: 0.11746948212385178\n",
      "\tLoss: 0.16167232394218445\n",
      "\tLoss: 0.11809668689966202\n",
      "\tLoss: 0.141169011592865\n",
      "\tLoss: 0.16259269416332245\n",
      "\tLoss: 0.1293218731880188\n",
      "\tLoss: 0.13235166668891907\n",
      "\tLoss: 0.12459579110145569\n",
      "\tLoss: 0.08442366123199463\n",
      "\tLoss: 0.11984655261039734\n",
      "\tLoss: 0.13765127956867218\n",
      "\tLoss: 0.1570032835006714\n",
      "\tLoss: 0.09741576761007309\n",
      "\tLoss: 0.12785592675209045\n",
      "\tLoss: 0.13197669386863708\n",
      "\tLoss: 0.13585598766803741\n",
      "\tLoss: 0.12025957554578781\n",
      "\tLoss: 0.10664276033639908\n",
      "\tLoss: 0.12575465440750122\n",
      "\tLoss: 0.12785209715366364\n",
      "\tLoss: 0.12195026874542236\n",
      "\tLoss: 0.10885515064001083\n",
      "\tLoss: 0.12676075100898743\n",
      "\tLoss: 0.11374279856681824\n",
      "\tLoss: 0.11562807112932205\n",
      "\tLoss: 0.1535569727420807\n",
      "\tLoss: 0.10053218901157379\n",
      "[time] Epoch 19: 446.3393449857831s = 7.438989083096385m\n",
      "\n",
      "Epoch 20...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.11922335624694824\n",
      "\tLoss: 0.12931981682777405\n",
      "\tLoss: 0.0983830988407135\n",
      "\tLoss: 0.12061239778995514\n",
      "\tLoss: 0.08730714023113251\n",
      "\tLoss: 0.19629646837711334\n",
      "\tLoss: 0.15622425079345703\n",
      "\tLoss: 0.11701439321041107\n",
      "\tLoss: 0.14428260922431946\n",
      "\tLoss: 0.11219170689582825\n",
      "\tLoss: 0.14194387197494507\n",
      "\tLoss: 0.12185454368591309\n",
      "\tLoss: 0.12803024053573608\n",
      "\tLoss: 0.0966326892375946\n",
      "\tLoss: 0.15724727511405945\n",
      "\tLoss: 0.14460137486457825\n",
      "\tLoss: 0.12918588519096375\n",
      "\tLoss: 0.1288508176803589\n",
      "\tLoss: 0.15715163946151733\n",
      "\tLoss: 0.12515568733215332\n",
      "\tLoss: 0.1056637391448021\n",
      "\tLoss: 0.12082049250602722\n",
      "\tLoss: 0.11906109005212784\n",
      "\tLoss: 0.12755295634269714\n",
      "\tLoss: 0.11627501994371414\n",
      "\tLoss: 0.12135542184114456\n",
      "\tLoss: 0.1526404470205307\n",
      "\tLoss: 0.16357019543647766\n",
      "\tLoss: 0.11840856820344925\n",
      "\tLoss: 0.11321084201335907\n",
      "\tLoss: 0.1262456774711609\n",
      "\tLoss: 0.11185946315526962\n",
      "\tLoss: 0.12805652618408203\n",
      "\tLoss: 0.14403626322746277\n",
      "\tLoss: 0.11251488327980042\n",
      "\tLoss: 0.11697046458721161\n",
      "\tLoss: 0.15257467329502106\n",
      "\tLoss: 0.10889731347560883\n",
      "\tLoss: 0.10490798205137253\n",
      "\tLoss: 0.15126162767410278\n",
      "\tLoss: 0.14123576879501343\n",
      "\tLoss: 0.13065138459205627\n",
      "\tLoss: 0.13849234580993652\n",
      "\tLoss: 0.1229933500289917\n",
      "\tLoss: 0.12314529716968536\n",
      "\tLoss: 0.12952899932861328\n",
      "\tLoss: 0.1135321781039238\n",
      "\tLoss: 0.11020799726247787\n",
      "\tLoss: 0.1335977464914322\n",
      "\tLoss: 0.16170474886894226\n",
      "\tLoss: 0.12083009630441666\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.10951831936836243\n",
      "\tLoss: 0.13520459830760956\n",
      "\tLoss: 0.17465390264987946\n",
      "\tLoss: 0.12858200073242188\n",
      "\tLoss: 0.09648898243904114\n",
      "\tLoss: 0.15213511884212494\n",
      "\tLoss: 0.14319224655628204\n",
      "\tLoss: 0.12437712401151657\n",
      "\tLoss: 0.16419048607349396\n",
      "\tLoss: 0.16424766182899475\n",
      "\tLoss: 0.13279786705970764\n",
      "\tLoss: 0.09949663281440735\n",
      "\tLoss: 0.16489818692207336\n",
      "\tLoss: 0.12041649222373962\n",
      "\tLoss: 0.1765259951353073\n",
      "\tLoss: 0.1600184440612793\n",
      "\tLoss: 0.13966518640518188\n",
      "\tLoss: 0.06978937983512878\n",
      "\tLoss: 0.16088473796844482\n",
      "\tLoss: 0.16588738560676575\n",
      "\tLoss: 0.14163467288017273\n",
      "\tLoss: 0.15009544789791107\n",
      "\tLoss: 0.10205653309822083\n",
      "\tLoss: 0.11549192667007446\n",
      "\tLoss: 0.16225358843803406\n",
      "\tLoss: 0.12097996473312378\n",
      "\tLoss: 0.15215617418289185\n",
      "\tLoss: 0.16815924644470215\n",
      "\tLoss: 0.15260756015777588\n",
      "\tLoss: 0.14256158471107483\n",
      "\tLoss: 0.19885572791099548\n",
      "\tLoss: 0.12300212681293488\n",
      "\tLoss: 0.13868972659111023\n",
      "\tLoss: 0.1092778742313385\n",
      "\tLoss: 0.09314123541116714\n",
      "\tLoss: 0.13372282683849335\n",
      "\tLoss: 0.1834391951560974\n",
      "\tLoss: 0.11921243369579315\n",
      "\tLoss: 0.16086027026176453\n",
      "\tLoss: 0.14144407212734222\n",
      "\tLoss: 0.1507204920053482\n",
      "\tLoss: 0.12421198189258575\n",
      "\tLoss: 0.17407824099063873\n",
      "\tLoss: 0.1320447325706482\n",
      "\tLoss: 0.1466049700975418\n",
      "\tLoss: 0.09442520141601562\n",
      "\tLoss: 0.18525244295597076\n",
      "\tLoss: 0.12593483924865723\n",
      "\tLoss: 0.12442433834075928\n",
      "\tLoss: 0.11807462573051453\n",
      "\tLoss: 0.15287506580352783\n",
      "[time] Epoch 20: 445.49496904667467s = 7.424916150777912m\n",
      "\n",
      "Epoch 21...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.18242675065994263\n",
      "\tLoss: 0.13799062371253967\n",
      "\tLoss: 0.11939244717359543\n",
      "\tLoss: 0.11508553475141525\n",
      "\tLoss: 0.12000458687543869\n",
      "\tLoss: 0.14015507698059082\n",
      "\tLoss: 0.15227319300174713\n",
      "\tLoss: 0.10733643919229507\n",
      "\tLoss: 0.1468379646539688\n",
      "\tLoss: 0.11804530024528503\n",
      "\tLoss: 0.14402079582214355\n",
      "\tLoss: 0.12303781509399414\n",
      "\tLoss: 0.12164696305990219\n",
      "\tLoss: 0.12220191210508347\n",
      "\tLoss: 0.1329270601272583\n",
      "\tLoss: 0.17811426520347595\n",
      "\tLoss: 0.10248607397079468\n",
      "\tLoss: 0.17287275195121765\n",
      "\tLoss: 0.12950345873832703\n",
      "\tLoss: 0.11297506093978882\n",
      "\tLoss: 0.1342535763978958\n",
      "\tLoss: 0.17395657300949097\n",
      "\tLoss: 0.16564016044139862\n",
      "\tLoss: 0.13291035592556\n",
      "\tLoss: 0.10243149101734161\n",
      "\tLoss: 0.09161201119422913\n",
      "\tLoss: 0.2130766361951828\n",
      "\tLoss: 0.09812401235103607\n",
      "\tLoss: 0.13580940663814545\n",
      "\tLoss: 0.16525082290172577\n",
      "\tLoss: 0.09120093286037445\n",
      "\tLoss: 0.13924258947372437\n",
      "\tLoss: 0.14691200852394104\n",
      "\tLoss: 0.10574055463075638\n",
      "\tLoss: 0.13157635927200317\n",
      "\tLoss: 0.1281990110874176\n",
      "\tLoss: 0.1412447690963745\n",
      "\tLoss: 0.16585278511047363\n",
      "\tLoss: 0.10384324193000793\n",
      "\tLoss: 0.116874098777771\n",
      "\tLoss: 0.1377861499786377\n",
      "\tLoss: 0.11463067680597305\n",
      "\tLoss: 0.18177926540374756\n",
      "\tLoss: 0.16793785989284515\n",
      "\tLoss: 0.09028194844722748\n",
      "\tLoss: 0.15233157575130463\n",
      "\tLoss: 0.09035274386405945\n",
      "\tLoss: 0.10087184607982635\n",
      "\tLoss: 0.10386266559362411\n",
      "\tLoss: 0.13922306895256042\n",
      "\tLoss: 0.11207777261734009\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.14120236039161682\n",
      "\tLoss: 0.09867696464061737\n",
      "\tLoss: 0.11685517430305481\n",
      "\tLoss: 0.09238820523023605\n",
      "\tLoss: 0.12191939353942871\n",
      "\tLoss: 0.14111970365047455\n",
      "\tLoss: 0.08266854286193848\n",
      "\tLoss: 0.10924331098794937\n",
      "\tLoss: 0.14629799127578735\n",
      "\tLoss: 0.09736476093530655\n",
      "\tLoss: 0.16772867739200592\n",
      "\tLoss: 0.10258239507675171\n",
      "\tLoss: 0.09702134132385254\n",
      "\tLoss: 0.0945286750793457\n",
      "\tLoss: 0.15660592913627625\n",
      "\tLoss: 0.1303858458995819\n",
      "\tLoss: 0.1759193241596222\n",
      "\tLoss: 0.1684883087873459\n",
      "\tLoss: 0.12327799201011658\n",
      "\tLoss: 0.10361312329769135\n",
      "\tLoss: 0.17978206276893616\n",
      "\tLoss: 0.07603009790182114\n",
      "\tLoss: 0.10875526815652847\n",
      "\tLoss: 0.1207321360707283\n",
      "\tLoss: 0.12588933110237122\n",
      "\tLoss: 0.11752322316169739\n",
      "\tLoss: 0.17245548963546753\n",
      "\tLoss: 0.09985557943582535\n",
      "\tLoss: 0.19649575650691986\n",
      "\tLoss: 0.07482638955116272\n",
      "\tLoss: 0.11693929135799408\n",
      "\tLoss: 0.09431031346321106\n",
      "\tLoss: 0.12545397877693176\n",
      "\tLoss: 0.13359099626541138\n",
      "\tLoss: 0.11940030753612518\n",
      "\tLoss: 0.11259226500988007\n",
      "\tLoss: 0.1779538094997406\n",
      "\tLoss: 0.14583975076675415\n",
      "\tLoss: 0.09860285371541977\n",
      "\tLoss: 0.121018186211586\n",
      "\tLoss: 0.12483425438404083\n",
      "\tLoss: 0.18386298418045044\n",
      "\tLoss: 0.11635526269674301\n",
      "\tLoss: 0.16367214918136597\n",
      "\tLoss: 0.16216808557510376\n",
      "\tLoss: 0.1365801990032196\n",
      "\tLoss: 0.11185842752456665\n",
      "\tLoss: 0.16661503911018372\n",
      "\tLoss: 0.08318544924259186\n",
      "\tLoss: 0.0914423018693924\n",
      "\tLoss: 0.1692417412996292\n",
      "[time] Epoch 21: 450.5754299880937s = 7.509590499801561m\n",
      "\n",
      "Epoch 22...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1258600652217865\n",
      "\tLoss: 0.10640625655651093\n",
      "\tLoss: 0.11530435085296631\n",
      "\tLoss: 0.1161717101931572\n",
      "\tLoss: 0.12867435812950134\n",
      "\tLoss: 0.12744449079036713\n",
      "\tLoss: 0.13669535517692566\n",
      "\tLoss: 0.125990629196167\n",
      "\tLoss: 0.11106906831264496\n",
      "\tLoss: 0.14354383945465088\n",
      "\tLoss: 0.13701756298542023\n",
      "\tLoss: 0.13798928260803223\n",
      "\tLoss: 0.16289953887462616\n",
      "\tLoss: 0.1839052438735962\n",
      "\tLoss: 0.11505293846130371\n",
      "\tLoss: 0.16053296625614166\n",
      "\tLoss: 0.13985809683799744\n",
      "\tLoss: 0.11267691850662231\n",
      "\tLoss: 0.15616944432258606\n",
      "\tLoss: 0.10863447189331055\n",
      "\tLoss: 0.10842318832874298\n",
      "\tLoss: 0.13238270580768585\n",
      "\tLoss: 0.11008499562740326\n",
      "\tLoss: 0.096415676176548\n",
      "\tLoss: 0.14044038951396942\n",
      "\tLoss: 0.1399739533662796\n",
      "\tLoss: 0.14303414523601532\n",
      "\tLoss: 0.13070039451122284\n",
      "\tLoss: 0.14079061150550842\n",
      "\tLoss: 0.0995640754699707\n",
      "\tLoss: 0.14362606406211853\n",
      "\tLoss: 0.07855071872472763\n",
      "\tLoss: 0.13186660408973694\n",
      "\tLoss: 0.08781883865594864\n",
      "\tLoss: 0.08388230204582214\n",
      "\tLoss: 0.16062092781066895\n",
      "\tLoss: 0.11601422727108002\n",
      "\tLoss: 0.08243697881698608\n",
      "\tLoss: 0.17537474632263184\n",
      "\tLoss: 0.14509370923042297\n",
      "\tLoss: 0.12065652757883072\n",
      "\tLoss: 0.16326358914375305\n",
      "\tLoss: 0.11263854801654816\n",
      "\tLoss: 0.12179752439260483\n",
      "\tLoss: 0.16427454352378845\n",
      "\tLoss: 0.1277715563774109\n",
      "\tLoss: 0.17760106921195984\n",
      "\tLoss: 0.1580694019794464\n",
      "\tLoss: 0.1303625851869583\n",
      "\tLoss: 0.08661562204360962\n",
      "\tLoss: 0.10275589674711227\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.11291523277759552\n",
      "\tLoss: 0.1282539814710617\n",
      "\tLoss: 0.1337791085243225\n",
      "\tLoss: 0.12752041220664978\n",
      "\tLoss: 0.12442222237586975\n",
      "\tLoss: 0.1270260214805603\n",
      "\tLoss: 0.13557499647140503\n",
      "\tLoss: 0.13938772678375244\n",
      "\tLoss: 0.14564836025238037\n",
      "\tLoss: 0.12297028303146362\n",
      "\tLoss: 0.07404974102973938\n",
      "\tLoss: 0.1324506402015686\n",
      "\tLoss: 0.09555680304765701\n",
      "\tLoss: 0.10965844243764877\n",
      "\tLoss: 0.13749894499778748\n",
      "\tLoss: 0.13777987658977509\n",
      "\tLoss: 0.15562930703163147\n",
      "\tLoss: 0.14489692449569702\n",
      "\tLoss: 0.09341886639595032\n",
      "\tLoss: 0.15849018096923828\n",
      "\tLoss: 0.15846267342567444\n",
      "\tLoss: 0.1290299892425537\n",
      "\tLoss: 0.13875922560691833\n",
      "\tLoss: 0.13453790545463562\n",
      "\tLoss: 0.13044187426567078\n",
      "\tLoss: 0.08519113063812256\n",
      "\tLoss: 0.09932690858840942\n",
      "\tLoss: 0.15582898259162903\n",
      "\tLoss: 0.11487630754709244\n",
      "\tLoss: 0.10319998115301132\n",
      "\tLoss: 0.14087384939193726\n",
      "\tLoss: 0.08661016821861267\n",
      "\tLoss: 0.11061156541109085\n",
      "\tLoss: 0.083095982670784\n",
      "\tLoss: 0.09258490055799484\n",
      "\tLoss: 0.12856784462928772\n",
      "\tLoss: 0.1572561264038086\n",
      "\tLoss: 0.18726575374603271\n",
      "\tLoss: 0.13774698972702026\n",
      "\tLoss: 0.12457272410392761\n",
      "\tLoss: 0.10579551756381989\n",
      "\tLoss: 0.1136426031589508\n",
      "\tLoss: 0.13867253065109253\n",
      "\tLoss: 0.08140943944454193\n",
      "\tLoss: 0.1209845319390297\n",
      "\tLoss: 0.13610032200813293\n",
      "\tLoss: 0.10787729173898697\n",
      "\tLoss: 0.10723089426755905\n",
      "\tLoss: 0.07862579822540283\n",
      "\tLoss: 0.13913673162460327\n",
      "\tLoss: 0.149824857711792\n",
      "[time] Epoch 22: 450.18962677475065s = 7.503160446245844m\n",
      "\n",
      "Epoch 23...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.12813901901245117\n",
      "\tLoss: 0.10416974127292633\n",
      "\tLoss: 0.11311251670122147\n",
      "\tLoss: 0.11178500950336456\n",
      "\tLoss: 0.1329815685749054\n",
      "\tLoss: 0.12002433836460114\n",
      "\tLoss: 0.09481465071439743\n",
      "\tLoss: 0.09999401867389679\n",
      "\tLoss: 0.12117806822061539\n",
      "\tLoss: 0.1065821647644043\n",
      "\tLoss: 0.09958707541227341\n",
      "\tLoss: 0.09875796735286713\n",
      "\tLoss: 0.08450858294963837\n",
      "\tLoss: 0.1298241913318634\n",
      "\tLoss: 0.11148755252361298\n",
      "\tLoss: 0.14154623448848724\n",
      "\tLoss: 0.165240079164505\n",
      "\tLoss: 0.08744195848703384\n",
      "\tLoss: 0.09898343682289124\n",
      "\tLoss: 0.1263304352760315\n",
      "\tLoss: 0.17755740880966187\n",
      "\tLoss: 0.1531766653060913\n",
      "\tLoss: 0.08933547139167786\n",
      "\tLoss: 0.11868838220834732\n",
      "\tLoss: 0.11654998362064362\n",
      "\tLoss: 0.15959957242012024\n",
      "\tLoss: 0.1365196704864502\n",
      "\tLoss: 0.1076778918504715\n",
      "\tLoss: 0.11454569548368454\n",
      "\tLoss: 0.1054229661822319\n",
      "\tLoss: 0.13891269266605377\n",
      "\tLoss: 0.11169534176588058\n",
      "\tLoss: 0.1383228898048401\n",
      "\tLoss: 0.15532004833221436\n",
      "\tLoss: 0.10929286479949951\n",
      "\tLoss: 0.1998518407344818\n",
      "\tLoss: 0.14052538573741913\n",
      "\tLoss: 0.16615864634513855\n",
      "\tLoss: 0.1014103889465332\n",
      "\tLoss: 0.10914427787065506\n",
      "\tLoss: 0.10750731825828552\n",
      "\tLoss: 0.10977683961391449\n",
      "\tLoss: 0.11652272939682007\n",
      "\tLoss: 0.10709677636623383\n",
      "\tLoss: 0.12824025750160217\n",
      "\tLoss: 0.16629129648208618\n",
      "\tLoss: 0.1588042974472046\n",
      "\tLoss: 0.1531388759613037\n",
      "\tLoss: 0.1348326951265335\n",
      "\tLoss: 0.17123185098171234\n",
      "\tLoss: 0.1298154592514038\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.12538129091262817\n",
      "\tLoss: 0.12142753601074219\n",
      "\tLoss: 0.14861077070236206\n",
      "\tLoss: 0.12002888321876526\n",
      "\tLoss: 0.10728388279676437\n",
      "\tLoss: 0.14305183291435242\n",
      "\tLoss: 0.16784968972206116\n",
      "\tLoss: 0.12963250279426575\n",
      "\tLoss: 0.12059290707111359\n",
      "\tLoss: 0.12164248526096344\n",
      "\tLoss: 0.12210513651371002\n",
      "\tLoss: 0.17161142826080322\n",
      "\tLoss: 0.1629331409931183\n",
      "\tLoss: 0.09531638026237488\n",
      "\tLoss: 0.08302652090787888\n",
      "\tLoss: 0.09531833231449127\n",
      "\tLoss: 0.10793866217136383\n",
      "\tLoss: 0.11025053262710571\n",
      "\tLoss: 0.11513973772525787\n",
      "\tLoss: 0.12565870583057404\n",
      "\tLoss: 0.15048259496688843\n",
      "\tLoss: 0.09963081032037735\n",
      "\tLoss: 0.11105059832334518\n",
      "\tLoss: 0.11182120442390442\n",
      "\tLoss: 0.11822766065597534\n",
      "\tLoss: 0.14727255702018738\n",
      "\tLoss: 0.14989712834358215\n",
      "\tLoss: 0.1195053830742836\n",
      "\tLoss: 0.11830472946166992\n",
      "\tLoss: 0.12304534018039703\n",
      "\tLoss: 0.1500866711139679\n",
      "\tLoss: 0.09013693034648895\n",
      "\tLoss: 0.1517786979675293\n",
      "\tLoss: 0.1476185917854309\n",
      "\tLoss: 0.14282956719398499\n",
      "\tLoss: 0.1123109757900238\n",
      "\tLoss: 0.12166428565979004\n",
      "\tLoss: 0.13202597200870514\n",
      "\tLoss: 0.16844868659973145\n",
      "\tLoss: 0.19112204015254974\n",
      "\tLoss: 0.1796802580356598\n",
      "\tLoss: 0.09479326009750366\n",
      "\tLoss: 0.13906791806221008\n",
      "\tLoss: 0.1182771772146225\n",
      "\tLoss: 0.14585593342781067\n",
      "\tLoss: 0.13433176279067993\n",
      "\tLoss: 0.1395847350358963\n",
      "\tLoss: 0.093733049929142\n",
      "\tLoss: 0.1082579642534256\n",
      "\tLoss: 0.09910456836223602\n",
      "\tLoss: 0.1445218026638031\n",
      "[time] Epoch 23: 440.50727944169194s = 7.341787990694866m\n",
      "\n",
      "Epoch 24...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.08273503184318542\n",
      "\tLoss: 0.11456665396690369\n",
      "\tLoss: 0.13934728503227234\n",
      "\tLoss: 0.17307701706886292\n",
      "\tLoss: 0.10079601407051086\n",
      "\tLoss: 0.14803680777549744\n",
      "\tLoss: 0.15269681811332703\n",
      "\tLoss: 0.129268616437912\n",
      "\tLoss: 0.10834942758083344\n",
      "\tLoss: 0.13129882514476776\n",
      "\tLoss: 0.13690346479415894\n",
      "\tLoss: 0.12598535418510437\n",
      "\tLoss: 0.15437836945056915\n",
      "\tLoss: 0.12217062711715698\n",
      "\tLoss: 0.1653546690940857\n",
      "\tLoss: 0.1339825987815857\n",
      "\tLoss: 0.1603369116783142\n",
      "\tLoss: 0.12171483784914017\n",
      "\tLoss: 0.09888588637113571\n",
      "\tLoss: 0.10729341208934784\n",
      "\tLoss: 0.1465393304824829\n",
      "\tLoss: 0.11080718040466309\n",
      "\tLoss: 0.1375763714313507\n",
      "\tLoss: 0.15998263657093048\n",
      "\tLoss: 0.15895196795463562\n",
      "\tLoss: 0.0909135565161705\n",
      "\tLoss: 0.13552594184875488\n",
      "\tLoss: 0.1232641413807869\n",
      "\tLoss: 0.1211225762963295\n",
      "\tLoss: 0.1069224625825882\n",
      "\tLoss: 0.1338214874267578\n",
      "\tLoss: 0.1309245526790619\n",
      "\tLoss: 0.1193118691444397\n",
      "\tLoss: 0.11985176801681519\n",
      "\tLoss: 0.14784204959869385\n",
      "\tLoss: 0.11493027210235596\n",
      "\tLoss: 0.14928412437438965\n",
      "\tLoss: 0.12910673022270203\n",
      "\tLoss: 0.12350952625274658\n",
      "\tLoss: 0.13166657090187073\n",
      "\tLoss: 0.12641145288944244\n",
      "\tLoss: 0.11036060750484467\n",
      "\tLoss: 0.1325846165418625\n",
      "\tLoss: 0.1416853964328766\n",
      "\tLoss: 0.13382588326931\n",
      "\tLoss: 0.13974042236804962\n",
      "\tLoss: 0.12591950595378876\n",
      "\tLoss: 0.13245609402656555\n",
      "\tLoss: 0.1299058347940445\n",
      "\tLoss: 0.11225252598524094\n",
      "\tLoss: 0.10739307105541229\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.1432468593120575\n",
      "\tLoss: 0.13725605607032776\n",
      "\tLoss: 0.15893377363681793\n",
      "\tLoss: 0.13705134391784668\n",
      "\tLoss: 0.13253073394298553\n",
      "\tLoss: 0.12678185105323792\n",
      "\tLoss: 0.10829876363277435\n",
      "\tLoss: 0.18452951312065125\n",
      "\tLoss: 0.09592597931623459\n",
      "\tLoss: 0.12409424781799316\n",
      "\tLoss: 0.08836179971694946\n",
      "\tLoss: 0.15805684030056\n",
      "\tLoss: 0.11819472163915634\n",
      "\tLoss: 0.13235428929328918\n",
      "\tLoss: 0.13923043012619019\n",
      "\tLoss: 0.1397620141506195\n",
      "\tLoss: 0.13569307327270508\n",
      "\tLoss: 0.12192559242248535\n",
      "\tLoss: 0.15581642091274261\n",
      "\tLoss: 0.1812935173511505\n",
      "\tLoss: 0.1000262051820755\n",
      "\tLoss: 0.093358613550663\n",
      "\tLoss: 0.08223146200180054\n",
      "\tLoss: 0.09843423962593079\n",
      "\tLoss: 0.09664003551006317\n",
      "\tLoss: 0.11340606212615967\n",
      "\tLoss: 0.08335790038108826\n",
      "\tLoss: 0.06781356036663055\n",
      "\tLoss: 0.1484302133321762\n",
      "\tLoss: 0.13530245423316956\n",
      "\tLoss: 0.12162318825721741\n",
      "\tLoss: 0.13449905812740326\n",
      "\tLoss: 0.15579603612422943\n",
      "\tLoss: 0.12221670150756836\n",
      "\tLoss: 0.10502801090478897\n",
      "\tLoss: 0.10761933028697968\n",
      "\tLoss: 0.09747108817100525\n",
      "\tLoss: 0.09086870402097702\n",
      "\tLoss: 0.12180247157812119\n",
      "\tLoss: 0.1378619372844696\n",
      "\tLoss: 0.11650259792804718\n",
      "\tLoss: 0.12243397533893585\n",
      "\tLoss: 0.14316125214099884\n",
      "\tLoss: 0.14153485000133514\n",
      "\tLoss: 0.13455946743488312\n",
      "\tLoss: 0.12074464559555054\n",
      "\tLoss: 0.12094263732433319\n",
      "\tLoss: 0.13193251192569733\n",
      "\tLoss: 0.063702791929245\n",
      "\tLoss: 0.11250045895576477\n",
      "\tLoss: 0.17731164395809174\n",
      "[time] Epoch 24: 445.5613389676437s = 7.426022316127395m\n",
      "\n",
      "Epoch 25...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.14808082580566406\n",
      "\tLoss: 0.10796621441841125\n",
      "\tLoss: 0.14133112132549286\n",
      "\tLoss: 0.07698913663625717\n",
      "\tLoss: 0.11400744318962097\n",
      "\tLoss: 0.10727337002754211\n",
      "\tLoss: 0.1497439742088318\n",
      "\tLoss: 0.14347657561302185\n",
      "\tLoss: 0.14246058464050293\n",
      "\tLoss: 0.10738254338502884\n",
      "\tLoss: 0.15639552474021912\n",
      "\tLoss: 0.07639570534229279\n",
      "\tLoss: 0.09253156185150146\n",
      "\tLoss: 0.12452162057161331\n",
      "\tLoss: 0.15355029702186584\n",
      "\tLoss: 0.11707650125026703\n",
      "\tLoss: 0.14024275541305542\n",
      "\tLoss: 0.11420838534832001\n",
      "\tLoss: 0.13178737461566925\n",
      "\tLoss: 0.1946953684091568\n",
      "\tLoss: 0.1066770926117897\n",
      "\tLoss: 0.14010769128799438\n",
      "\tLoss: 0.09998053312301636\n",
      "\tLoss: 0.1424693763256073\n",
      "\tLoss: 0.15474164485931396\n",
      "\tLoss: 0.12320282310247421\n",
      "\tLoss: 0.10473142564296722\n",
      "\tLoss: 0.11191581189632416\n",
      "\tLoss: 0.111177459359169\n",
      "\tLoss: 0.12593382596969604\n",
      "\tLoss: 0.1526130735874176\n",
      "\tLoss: 0.12354283779859543\n",
      "\tLoss: 0.1370251625776291\n",
      "\tLoss: 0.12006351351737976\n",
      "\tLoss: 0.11101255565881729\n",
      "\tLoss: 0.09611924737691879\n",
      "\tLoss: 0.10100184381008148\n",
      "\tLoss: 0.09421109408140182\n",
      "\tLoss: 0.16205239295959473\n",
      "\tLoss: 0.11835275590419769\n",
      "\tLoss: 0.11795482039451599\n",
      "\tLoss: 0.11513135582208633\n",
      "\tLoss: 0.12367002665996552\n",
      "\tLoss: 0.11661075055599213\n",
      "\tLoss: 0.12991182506084442\n",
      "\tLoss: 0.16390487551689148\n",
      "\tLoss: 0.13639137148857117\n",
      "\tLoss: 0.10127191245555878\n",
      "\tLoss: 0.1427215337753296\n",
      "\tLoss: 0.09914979338645935\n",
      "\tLoss: 0.13282571732997894\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.18623095750808716\n",
      "\tLoss: 0.11118949949741364\n",
      "\tLoss: 0.11797897517681122\n",
      "\tLoss: 0.14515402913093567\n",
      "\tLoss: 0.10222183912992477\n",
      "\tLoss: 0.1304541379213333\n",
      "\tLoss: 0.10217654705047607\n",
      "\tLoss: 0.10710372030735016\n",
      "\tLoss: 0.128043532371521\n",
      "\tLoss: 0.15300819277763367\n",
      "\tLoss: 0.1124759316444397\n",
      "\tLoss: 0.11435487866401672\n",
      "\tLoss: 0.12396608293056488\n",
      "\tLoss: 0.15636546909809113\n",
      "\tLoss: 0.1345921754837036\n",
      "\tLoss: 0.1334880292415619\n",
      "\tLoss: 0.10404594987630844\n",
      "\tLoss: 0.16876181960105896\n",
      "\tLoss: 0.10130484402179718\n",
      "\tLoss: 0.13803863525390625\n",
      "\tLoss: 0.09043770283460617\n",
      "\tLoss: 0.10765569657087326\n",
      "\tLoss: 0.14197048544883728\n",
      "\tLoss: 0.09916677325963974\n",
      "\tLoss: 0.094936802983284\n",
      "\tLoss: 0.1686113327741623\n",
      "\tLoss: 0.13076874613761902\n",
      "\tLoss: 0.12183846533298492\n",
      "\tLoss: 0.13545992970466614\n",
      "\tLoss: 0.14821648597717285\n",
      "\tLoss: 0.13834170997142792\n",
      "\tLoss: 0.1413590908050537\n",
      "\tLoss: 0.13183151185512543\n",
      "\tLoss: 0.12066646665334702\n",
      "\tLoss: 0.11352847516536713\n",
      "\tLoss: 0.15474985539913177\n",
      "\tLoss: 0.1346016377210617\n",
      "\tLoss: 0.11207662522792816\n",
      "\tLoss: 0.13692167401313782\n",
      "\tLoss: 0.1287725567817688\n",
      "\tLoss: 0.1299685835838318\n",
      "\tLoss: 0.15270355343818665\n",
      "\tLoss: 0.14918112754821777\n",
      "\tLoss: 0.12659257650375366\n",
      "\tLoss: 0.1312144696712494\n",
      "\tLoss: 0.08581291139125824\n",
      "\tLoss: 0.14364424347877502\n",
      "\tLoss: 0.13827788829803467\n",
      "\tLoss: 0.0993451252579689\n",
      "\tLoss: 0.09910315275192261\n",
      "\tLoss: 0.10786539316177368\n",
      "[time] Epoch 25: 446.6035898020491s = 7.443393163367485m\n",
      "\n",
      "Epoch 26...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.12992557883262634\n",
      "\tLoss: 0.1166292279958725\n",
      "\tLoss: 0.13307872414588928\n",
      "\tLoss: 0.09146866202354431\n",
      "\tLoss: 0.10345449298620224\n",
      "\tLoss: 0.10228439420461655\n",
      "\tLoss: 0.0770314484834671\n",
      "\tLoss: 0.1409994512796402\n",
      "\tLoss: 0.13110588490962982\n",
      "\tLoss: 0.08490443229675293\n",
      "\tLoss: 0.16368910670280457\n",
      "\tLoss: 0.13321524858474731\n",
      "\tLoss: 0.14504259824752808\n",
      "\tLoss: 0.0988047868013382\n",
      "\tLoss: 0.17377933859825134\n",
      "\tLoss: 0.09508530795574188\n",
      "\tLoss: 0.1044800728559494\n",
      "\tLoss: 0.13619765639305115\n",
      "\tLoss: 0.10829345881938934\n",
      "\tLoss: 0.14349406957626343\n",
      "\tLoss: 0.13154536485671997\n",
      "\tLoss: 0.10717014223337173\n",
      "\tLoss: 0.09311386197805405\n",
      "\tLoss: 0.1960742473602295\n",
      "\tLoss: 0.1169273629784584\n",
      "\tLoss: 0.1322544664144516\n",
      "\tLoss: 0.09074787050485611\n",
      "\tLoss: 0.18182936310768127\n",
      "\tLoss: 0.11074373126029968\n",
      "\tLoss: 0.11145572364330292\n",
      "\tLoss: 0.10569052398204803\n",
      "\tLoss: 0.12866345047950745\n",
      "\tLoss: 0.12497317790985107\n",
      "\tLoss: 0.1339326798915863\n",
      "\tLoss: 0.1301605999469757\n",
      "\tLoss: 0.15833908319473267\n",
      "\tLoss: 0.1260065734386444\n",
      "\tLoss: 0.14437709748744965\n",
      "\tLoss: 0.14750590920448303\n",
      "\tLoss: 0.14436613023281097\n",
      "\tLoss: 0.10311156511306763\n",
      "\tLoss: 0.14070090651512146\n",
      "\tLoss: 0.1261938065290451\n",
      "\tLoss: 0.12334582209587097\n",
      "\tLoss: 0.13615594804286957\n",
      "\tLoss: 0.09063952416181564\n",
      "\tLoss: 0.14935877919197083\n",
      "\tLoss: 0.15982851386070251\n",
      "\tLoss: 0.10476662218570709\n",
      "\tLoss: 0.14183595776557922\n",
      "\tLoss: 0.2151249647140503\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.17621366679668427\n",
      "\tLoss: 0.13789968192577362\n",
      "\tLoss: 0.13230454921722412\n",
      "\tLoss: 0.1108500212430954\n",
      "\tLoss: 0.1356295347213745\n",
      "\tLoss: 0.12248748540878296\n",
      "\tLoss: 0.17335450649261475\n",
      "\tLoss: 0.09346076101064682\n",
      "\tLoss: 0.1037447452545166\n",
      "\tLoss: 0.12396518886089325\n",
      "\tLoss: 0.17134222388267517\n",
      "\tLoss: 0.12739403545856476\n",
      "\tLoss: 0.15527495741844177\n",
      "\tLoss: 0.08760739862918854\n",
      "\tLoss: 0.1272730529308319\n",
      "\tLoss: 0.13940352201461792\n",
      "\tLoss: 0.10730535537004471\n",
      "\tLoss: 0.12698906660079956\n",
      "\tLoss: 0.13008534908294678\n",
      "\tLoss: 0.11678914725780487\n",
      "\tLoss: 0.09692199528217316\n",
      "\tLoss: 0.1284014880657196\n",
      "\tLoss: 0.12264588475227356\n",
      "\tLoss: 0.13807663321495056\n",
      "\tLoss: 0.10588502883911133\n",
      "\tLoss: 0.11177253723144531\n",
      "\tLoss: 0.13203787803649902\n",
      "\tLoss: 0.1934068202972412\n",
      "\tLoss: 0.1338004171848297\n",
      "\tLoss: 0.10979922115802765\n",
      "\tLoss: 0.10835197567939758\n",
      "\tLoss: 0.13289184868335724\n",
      "\tLoss: 0.1299910992383957\n",
      "\tLoss: 0.1371815800666809\n",
      "\tLoss: 0.12216238677501678\n",
      "\tLoss: 0.13021770119667053\n",
      "\tLoss: 0.16307172179222107\n",
      "\tLoss: 0.08244895935058594\n",
      "\tLoss: 0.09073877334594727\n",
      "\tLoss: 0.08928260952234268\n",
      "\tLoss: 0.13321834802627563\n",
      "\tLoss: 0.1366826295852661\n",
      "\tLoss: 0.11622805893421173\n",
      "\tLoss: 0.15754956007003784\n",
      "\tLoss: 0.09852752089500427\n",
      "\tLoss: 0.08030359447002411\n",
      "\tLoss: 0.08843827247619629\n",
      "\tLoss: 0.09123414009809494\n",
      "\tLoss: 0.10374696552753448\n",
      "\tLoss: 0.12228506803512573\n",
      "\tLoss: 0.1574842482805252\n",
      "[time] Epoch 26: 440.7732611428946s = 7.346221019048244m\n",
      "\n",
      "Epoch 27...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.16650907695293427\n",
      "\tLoss: 0.09750629961490631\n",
      "\tLoss: 0.15056651830673218\n",
      "\tLoss: 0.10051656514406204\n",
      "\tLoss: 0.19546520709991455\n",
      "\tLoss: 0.11804260313510895\n",
      "\tLoss: 0.14304696023464203\n",
      "\tLoss: 0.1480315625667572\n",
      "\tLoss: 0.12765875458717346\n",
      "\tLoss: 0.13879434764385223\n",
      "\tLoss: 0.09819380193948746\n",
      "\tLoss: 0.09165596961975098\n",
      "\tLoss: 0.1496938169002533\n",
      "\tLoss: 0.1140628457069397\n",
      "\tLoss: 0.11558248102664948\n",
      "\tLoss: 0.13528431951999664\n",
      "\tLoss: 0.16677069664001465\n",
      "\tLoss: 0.09508464485406876\n",
      "\tLoss: 0.13341796398162842\n",
      "\tLoss: 0.09179207682609558\n",
      "\tLoss: 0.1601579338312149\n",
      "\tLoss: 0.16017845273017883\n",
      "\tLoss: 0.15089085698127747\n",
      "\tLoss: 0.12563525140285492\n",
      "\tLoss: 0.13981106877326965\n",
      "\tLoss: 0.09612477570772171\n",
      "\tLoss: 0.13672539591789246\n",
      "\tLoss: 0.11611068248748779\n",
      "\tLoss: 0.09447707235813141\n",
      "\tLoss: 0.1224532350897789\n",
      "\tLoss: 0.0914987325668335\n",
      "\tLoss: 0.10162942856550217\n",
      "\tLoss: 0.09617534279823303\n",
      "\tLoss: 0.08932599425315857\n",
      "\tLoss: 0.1396721601486206\n",
      "\tLoss: 0.1307687908411026\n",
      "\tLoss: 0.11490657925605774\n",
      "\tLoss: 0.11929412186145782\n",
      "\tLoss: 0.14400944113731384\n",
      "\tLoss: 0.12368173152208328\n",
      "\tLoss: 0.1032082810997963\n",
      "\tLoss: 0.10152746737003326\n",
      "\tLoss: 0.10257501155138016\n",
      "\tLoss: 0.1319073736667633\n",
      "\tLoss: 0.1061699390411377\n",
      "\tLoss: 0.2000311315059662\n",
      "\tLoss: 0.17344535887241364\n",
      "\tLoss: 0.1597907990217209\n",
      "\tLoss: 0.1387578845024109\n",
      "\tLoss: 0.114881232380867\n",
      "\tLoss: 0.08024181425571442\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.15010395646095276\n",
      "\tLoss: 0.16524578630924225\n",
      "\tLoss: 0.2092609703540802\n",
      "\tLoss: 0.13405320048332214\n",
      "\tLoss: 0.14766046404838562\n",
      "\tLoss: 0.13758233189582825\n",
      "\tLoss: 0.11503706127405167\n",
      "\tLoss: 0.11090543121099472\n",
      "\tLoss: 0.09894679486751556\n",
      "\tLoss: 0.13238149881362915\n",
      "\tLoss: 0.10872314870357513\n",
      "\tLoss: 0.09141607582569122\n",
      "\tLoss: 0.0850362777709961\n",
      "\tLoss: 0.13011236488819122\n",
      "\tLoss: 0.10083484649658203\n",
      "\tLoss: 0.11701887100934982\n",
      "\tLoss: 0.11695432662963867\n",
      "\tLoss: 0.15132398903369904\n",
      "\tLoss: 0.16856218874454498\n",
      "\tLoss: 0.12709592282772064\n",
      "\tLoss: 0.14863529801368713\n",
      "\tLoss: 0.1223553717136383\n",
      "\tLoss: 0.09424079954624176\n",
      "\tLoss: 0.08212421089410782\n",
      "\tLoss: 0.1391310840845108\n",
      "\tLoss: 0.07622098922729492\n",
      "\tLoss: 0.09829986095428467\n",
      "\tLoss: 0.11027070879936218\n",
      "\tLoss: 0.16564860939979553\n",
      "\tLoss: 0.10365159064531326\n",
      "\tLoss: 0.08974327147006989\n",
      "\tLoss: 0.10799315571784973\n",
      "\tLoss: 0.10777289420366287\n",
      "\tLoss: 0.11454591155052185\n",
      "\tLoss: 0.139225035905838\n",
      "\tLoss: 0.10153360664844513\n",
      "\tLoss: 0.12219735980033875\n",
      "\tLoss: 0.1583610624074936\n",
      "\tLoss: 0.1164628267288208\n",
      "\tLoss: 0.13749533891677856\n",
      "\tLoss: 0.12127917259931564\n",
      "\tLoss: 0.15444903075695038\n",
      "\tLoss: 0.11849276721477509\n",
      "\tLoss: 0.11746703088283539\n",
      "\tLoss: 0.14006923139095306\n",
      "\tLoss: 0.11713068187236786\n",
      "\tLoss: 0.09931335598230362\n",
      "\tLoss: 0.11929358541965485\n",
      "\tLoss: 0.1365935057401657\n",
      "\tLoss: 0.11232604086399078\n",
      "\tLoss: 0.13032858073711395\n",
      "[time] Epoch 27: 446.4610957885161s = 7.4410182631419355m\n",
      "\n",
      "Epoch 28...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.14151538908481598\n",
      "\tLoss: 0.13153387606143951\n",
      "\tLoss: 0.15798525512218475\n",
      "\tLoss: 0.1357916295528412\n",
      "\tLoss: 0.12579652667045593\n",
      "\tLoss: 0.13069963455200195\n",
      "\tLoss: 0.12833631038665771\n",
      "\tLoss: 0.1569664180278778\n",
      "\tLoss: 0.13572458922863007\n",
      "\tLoss: 0.13370934128761292\n",
      "\tLoss: 0.09896530210971832\n",
      "\tLoss: 0.07686635106801987\n",
      "\tLoss: 0.11799470335245132\n",
      "\tLoss: 0.13260313868522644\n",
      "\tLoss: 0.12145452946424484\n",
      "\tLoss: 0.0712728351354599\n",
      "\tLoss: 0.15690118074417114\n",
      "\tLoss: 0.16262564063072205\n",
      "\tLoss: 0.12411490827798843\n",
      "\tLoss: 0.09405067563056946\n",
      "\tLoss: 0.12964417040348053\n",
      "\tLoss: 0.1262367069721222\n",
      "\tLoss: 0.13962966203689575\n",
      "\tLoss: 0.10664688795804977\n",
      "\tLoss: 0.09412522614002228\n",
      "\tLoss: 0.11889110505580902\n",
      "\tLoss: 0.143331378698349\n",
      "\tLoss: 0.10716252774000168\n",
      "\tLoss: 0.10268020629882812\n",
      "\tLoss: 0.08602674305438995\n",
      "\tLoss: 0.10753175616264343\n",
      "\tLoss: 0.13759760558605194\n",
      "\tLoss: 0.15320195257663727\n",
      "\tLoss: 0.12438464164733887\n",
      "\tLoss: 0.16789615154266357\n",
      "\tLoss: 0.12289007753133774\n",
      "\tLoss: 0.11955234408378601\n",
      "\tLoss: 0.06770212948322296\n",
      "\tLoss: 0.10930144786834717\n",
      "\tLoss: 0.1573842614889145\n",
      "\tLoss: 0.11627393960952759\n",
      "\tLoss: 0.1342964768409729\n",
      "\tLoss: 0.13439419865608215\n",
      "\tLoss: 0.15774796903133392\n",
      "\tLoss: 0.12051641941070557\n",
      "\tLoss: 0.11571309715509415\n",
      "\tLoss: 0.13996493816375732\n",
      "\tLoss: 0.11440186202526093\n",
      "\tLoss: 0.12679162621498108\n",
      "\tLoss: 0.09532946348190308\n",
      "\tLoss: 0.10334141552448273\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.09341453015804291\n",
      "\tLoss: 0.09446173161268234\n",
      "\tLoss: 0.14098873734474182\n",
      "\tLoss: 0.11295567452907562\n",
      "\tLoss: 0.1648673415184021\n",
      "\tLoss: 0.1170739009976387\n",
      "\tLoss: 0.06763246655464172\n",
      "\tLoss: 0.10762568563222885\n",
      "\tLoss: 0.09161265194416046\n",
      "\tLoss: 0.10502100735902786\n",
      "\tLoss: 0.09146757423877716\n",
      "\tLoss: 0.1351841688156128\n",
      "\tLoss: 0.10586313903331757\n",
      "\tLoss: 0.10054441541433334\n",
      "\tLoss: 0.09260794520378113\n",
      "\tLoss: 0.12570998072624207\n",
      "\tLoss: 0.1325865238904953\n",
      "\tLoss: 0.1505274921655655\n",
      "\tLoss: 0.08852271735668182\n",
      "\tLoss: 0.13463760912418365\n",
      "\tLoss: 0.08006535470485687\n",
      "\tLoss: 0.13004040718078613\n",
      "\tLoss: 0.0980776697397232\n",
      "\tLoss: 0.14813950657844543\n",
      "\tLoss: 0.14369070529937744\n",
      "\tLoss: 0.12536302208900452\n",
      "\tLoss: 0.14628708362579346\n",
      "\tLoss: 0.1887950599193573\n",
      "\tLoss: 0.13206186890602112\n",
      "\tLoss: 0.08834438771009445\n",
      "\tLoss: 0.10012000799179077\n",
      "\tLoss: 0.12256147712469101\n",
      "\tLoss: 0.11519688367843628\n",
      "\tLoss: 0.10309838503599167\n",
      "\tLoss: 0.09976226091384888\n",
      "\tLoss: 0.10192427784204483\n",
      "\tLoss: 0.12869054079055786\n",
      "\tLoss: 0.1425498127937317\n",
      "\tLoss: 0.11189577728509903\n",
      "\tLoss: 0.08959098905324936\n",
      "\tLoss: 0.12360037863254547\n",
      "\tLoss: 0.14045628905296326\n",
      "\tLoss: 0.16867810487747192\n",
      "\tLoss: 0.1237570196390152\n",
      "\tLoss: 0.12616224586963654\n",
      "\tLoss: 0.1346629559993744\n",
      "\tLoss: 0.09879396110773087\n",
      "\tLoss: 0.12561172246932983\n",
      "\tLoss: 0.13672491908073425\n",
      "\tLoss: 0.10046042501926422\n",
      "\tLoss: 0.10999681055545807\n",
      "[time] Epoch 28: 451.81075903680176s = 7.530179317280029m\n",
      "\n",
      "Epoch 29...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.07517392188310623\n",
      "\tLoss: 0.1484214812517166\n",
      "\tLoss: 0.14065112173557281\n",
      "\tLoss: 0.10872393846511841\n",
      "\tLoss: 0.14657282829284668\n",
      "\tLoss: 0.10264629125595093\n",
      "\tLoss: 0.15358252823352814\n",
      "\tLoss: 0.09341563284397125\n",
      "\tLoss: 0.08646208047866821\n",
      "\tLoss: 0.11865852773189545\n",
      "\tLoss: 0.10845019668340683\n",
      "\tLoss: 0.06000803783535957\n",
      "\tLoss: 0.10608324408531189\n",
      "\tLoss: 0.1259729564189911\n",
      "\tLoss: 0.11731196939945221\n",
      "\tLoss: 0.1436866968870163\n",
      "\tLoss: 0.12656956911087036\n",
      "\tLoss: 0.1463836431503296\n",
      "\tLoss: 0.11999231576919556\n",
      "\tLoss: 0.12427300959825516\n",
      "\tLoss: 0.13567227125167847\n",
      "\tLoss: 0.1324387937784195\n",
      "\tLoss: 0.1154460459947586\n",
      "\tLoss: 0.13074815273284912\n",
      "\tLoss: 0.12077520787715912\n",
      "\tLoss: 0.09709464013576508\n",
      "\tLoss: 0.1484326869249344\n",
      "\tLoss: 0.1622130572795868\n",
      "\tLoss: 0.11809467524290085\n",
      "\tLoss: 0.1424483358860016\n",
      "\tLoss: 0.11992782354354858\n",
      "\tLoss: 0.1182318776845932\n",
      "\tLoss: 0.13470590114593506\n",
      "\tLoss: 0.12258145958185196\n",
      "\tLoss: 0.14712469279766083\n",
      "\tLoss: 0.17898127436637878\n",
      "\tLoss: 0.0933183953166008\n",
      "\tLoss: 0.13269880414009094\n",
      "\tLoss: 0.11024852842092514\n",
      "\tLoss: 0.09687317907810211\n",
      "\tLoss: 0.12348901480436325\n",
      "\tLoss: 0.12566755712032318\n",
      "\tLoss: 0.12364855408668518\n",
      "\tLoss: 0.1685413122177124\n",
      "\tLoss: 0.17331480979919434\n",
      "\tLoss: 0.11900472640991211\n",
      "\tLoss: 0.11388995498418808\n",
      "\tLoss: 0.10214564204216003\n",
      "\tLoss: 0.10519011318683624\n",
      "\tLoss: 0.14409837126731873\n",
      "\tLoss: 0.08543752133846283\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.13473999500274658\n",
      "\tLoss: 0.15076357126235962\n",
      "\tLoss: 0.11183661967515945\n",
      "\tLoss: 0.12293802946805954\n",
      "\tLoss: 0.10956418514251709\n",
      "\tLoss: 0.1125367134809494\n",
      "\tLoss: 0.18238821625709534\n",
      "\tLoss: 0.10712149739265442\n",
      "\tLoss: 0.12146573513746262\n",
      "\tLoss: 0.1082257330417633\n",
      "\tLoss: 0.09622813761234283\n",
      "\tLoss: 0.12682484090328217\n",
      "\tLoss: 0.09571107476949692\n",
      "\tLoss: 0.13482563197612762\n",
      "\tLoss: 0.1554589867591858\n",
      "\tLoss: 0.12803784012794495\n",
      "\tLoss: 0.1500994861125946\n",
      "\tLoss: 0.08779660612344742\n",
      "\tLoss: 0.13449044525623322\n",
      "\tLoss: 0.14942854642868042\n",
      "\tLoss: 0.1150343120098114\n",
      "\tLoss: 0.08670272678136826\n",
      "\tLoss: 0.11417420208454132\n",
      "\tLoss: 0.09943415969610214\n",
      "\tLoss: 0.09969206899404526\n",
      "\tLoss: 0.1623823642730713\n",
      "\tLoss: 0.10258202254772186\n",
      "\tLoss: 0.12298190593719482\n",
      "\tLoss: 0.16029119491577148\n",
      "\tLoss: 0.08835507184267044\n",
      "\tLoss: 0.0998486876487732\n",
      "\tLoss: 0.08377613127231598\n",
      "\tLoss: 0.11320604383945465\n",
      "\tLoss: 0.09276203066110611\n",
      "\tLoss: 0.15148121118545532\n",
      "\tLoss: 0.09089867770671844\n",
      "\tLoss: 0.11804945766925812\n",
      "\tLoss: 0.06290823221206665\n",
      "\tLoss: 0.17418792843818665\n",
      "\tLoss: 0.14951691031455994\n",
      "\tLoss: 0.09275823831558228\n",
      "\tLoss: 0.15620984137058258\n",
      "\tLoss: 0.14348635077476501\n",
      "\tLoss: 0.15023218095302582\n",
      "\tLoss: 0.11082051694393158\n",
      "\tLoss: 0.10685122013092041\n",
      "\tLoss: 0.09901251643896103\n",
      "\tLoss: 0.12232278287410736\n",
      "\tLoss: 0.14331160485744476\n",
      "\tLoss: 0.09033343940973282\n",
      "\tLoss: 0.10505539923906326\n",
      "[time] Epoch 29: 439.86362294014543s = 7.331060382335758m\n",
      "\n",
      "Epoch 30...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.0829591155052185\n",
      "\tLoss: 0.11234018206596375\n",
      "\tLoss: 0.10554514825344086\n",
      "\tLoss: 0.12906025350093842\n",
      "\tLoss: 0.1436750888824463\n",
      "\tLoss: 0.09245672821998596\n",
      "\tLoss: 0.113338902592659\n",
      "\tLoss: 0.11717405915260315\n",
      "\tLoss: 0.07813619077205658\n",
      "\tLoss: 0.18154151737689972\n",
      "\tLoss: 0.1320696622133255\n",
      "\tLoss: 0.11220289021730423\n",
      "\tLoss: 0.1611638218164444\n",
      "\tLoss: 0.08900269865989685\n",
      "\tLoss: 0.11977960169315338\n",
      "\tLoss: 0.14219367504119873\n",
      "\tLoss: 0.09315457195043564\n",
      "\tLoss: 0.1203581839799881\n",
      "\tLoss: 0.11328558623790741\n",
      "\tLoss: 0.14308618009090424\n",
      "\tLoss: 0.13657233119010925\n",
      "\tLoss: 0.12206436693668365\n",
      "\tLoss: 0.1268509477376938\n",
      "\tLoss: 0.1312447488307953\n",
      "\tLoss: 0.09047974646091461\n",
      "\tLoss: 0.13538438081741333\n",
      "\tLoss: 0.13270123302936554\n",
      "\tLoss: 0.1204395741224289\n",
      "\tLoss: 0.10325179994106293\n",
      "\tLoss: 0.15062443912029266\n",
      "\tLoss: 0.13718745112419128\n",
      "\tLoss: 0.15280501544475555\n",
      "\tLoss: 0.1016312688589096\n",
      "\tLoss: 0.11798442900180817\n",
      "\tLoss: 0.17463958263397217\n",
      "\tLoss: 0.16085940599441528\n",
      "\tLoss: 0.08814118802547455\n",
      "\tLoss: 0.12591975927352905\n",
      "\tLoss: 0.23562933504581451\n",
      "\tLoss: 0.13127219676971436\n",
      "\tLoss: 0.10522852838039398\n",
      "\tLoss: 0.11714838445186615\n",
      "\tLoss: 0.1537448912858963\n",
      "\tLoss: 0.10226471722126007\n",
      "\tLoss: 0.13357165455818176\n",
      "\tLoss: 0.10395219922065735\n",
      "\tLoss: 0.11603013426065445\n",
      "\tLoss: 0.10750474035739899\n",
      "\tLoss: 0.07759551703929901\n",
      "\tLoss: 0.09591501951217651\n",
      "\tLoss: 0.12685835361480713\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.09329860657453537\n",
      "\tLoss: 0.1443907767534256\n",
      "\tLoss: 0.12418428063392639\n",
      "\tLoss: 0.1370709091424942\n",
      "\tLoss: 0.10833486914634705\n",
      "\tLoss: 0.11748000234365463\n",
      "\tLoss: 0.12752534449100494\n",
      "\tLoss: 0.09128414839506149\n",
      "\tLoss: 0.13333849608898163\n",
      "\tLoss: 0.13311950862407684\n",
      "\tLoss: 0.13931165635585785\n",
      "\tLoss: 0.1661321073770523\n",
      "\tLoss: 0.11950837075710297\n",
      "\tLoss: 0.11629782617092133\n",
      "\tLoss: 0.1075039878487587\n",
      "\tLoss: 0.14435529708862305\n",
      "\tLoss: 0.10777753591537476\n",
      "\tLoss: 0.10333912074565887\n",
      "\tLoss: 0.08643047511577606\n",
      "\tLoss: 0.12189792096614838\n",
      "\tLoss: 0.08151770383119583\n",
      "\tLoss: 0.14450977742671967\n",
      "\tLoss: 0.1142357736825943\n",
      "\tLoss: 0.1555795967578888\n",
      "\tLoss: 0.09885536134243011\n",
      "\tLoss: 0.1671721488237381\n",
      "\tLoss: 0.11803967505693436\n",
      "\tLoss: 0.14826259016990662\n",
      "\tLoss: 0.09327931702136993\n",
      "\tLoss: 0.117922343313694\n",
      "\tLoss: 0.12742280960083008\n",
      "\tLoss: 0.10014104843139648\n",
      "\tLoss: 0.16486766934394836\n",
      "\tLoss: 0.09969808161258698\n",
      "\tLoss: 0.12299780547618866\n",
      "\tLoss: 0.11400134116411209\n",
      "\tLoss: 0.10258858650922775\n",
      "\tLoss: 0.12614810466766357\n",
      "\tLoss: 0.12481123208999634\n",
      "\tLoss: 0.11103736609220505\n",
      "\tLoss: 0.14618481695652008\n",
      "\tLoss: 0.11303991824388504\n",
      "\tLoss: 0.07955996692180634\n",
      "\tLoss: 0.07860320061445236\n",
      "\tLoss: 0.16316093504428864\n",
      "\tLoss: 0.1354084312915802\n",
      "\tLoss: 0.16246341168880463\n",
      "\tLoss: 0.07052662968635559\n",
      "\tLoss: 0.11864031106233597\n",
      "\tLoss: 0.12889021635055542\n",
      "\tLoss: 0.18206754326820374\n",
      "[time] Epoch 30: 458.53213046118617s = 7.642202174353103m\n",
      "\n",
      "Epoch 31...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.10054957866668701\n",
      "\tLoss: 0.09303128719329834\n",
      "\tLoss: 0.07978639006614685\n",
      "\tLoss: 0.17686901986598969\n",
      "\tLoss: 0.10520443320274353\n",
      "\tLoss: 0.11010824888944626\n",
      "\tLoss: 0.11460705101490021\n",
      "\tLoss: 0.07483002543449402\n",
      "\tLoss: 0.1253194510936737\n",
      "\tLoss: 0.07484190165996552\n",
      "\tLoss: 0.09475473314523697\n",
      "\tLoss: 0.11567841470241547\n",
      "\tLoss: 0.10470937192440033\n",
      "\tLoss: 0.12564697861671448\n",
      "\tLoss: 0.07982464134693146\n",
      "\tLoss: 0.1483023762702942\n",
      "\tLoss: 0.13584047555923462\n",
      "\tLoss: 0.12295858561992645\n",
      "\tLoss: 0.11966549605131149\n",
      "\tLoss: 0.15568894147872925\n",
      "\tLoss: 0.09596996754407883\n",
      "\tLoss: 0.11984936892986298\n",
      "\tLoss: 0.12605953216552734\n",
      "\tLoss: 0.12332770228385925\n",
      "\tLoss: 0.11381871998310089\n",
      "\tLoss: 0.16633832454681396\n",
      "\tLoss: 0.10732270777225494\n",
      "\tLoss: 0.10838892310857773\n",
      "\tLoss: 0.08892720937728882\n",
      "\tLoss: 0.11583881080150604\n",
      "\tLoss: 0.1017126813530922\n",
      "\tLoss: 0.1005052998661995\n",
      "\tLoss: 0.14774130284786224\n",
      "\tLoss: 0.12276265025138855\n",
      "\tLoss: 0.12623777985572815\n",
      "\tLoss: 0.11898552626371384\n",
      "\tLoss: 0.1277700662612915\n",
      "\tLoss: 0.11176469922065735\n",
      "\tLoss: 0.12281914055347443\n",
      "\tLoss: 0.08058834075927734\n",
      "\tLoss: 0.11635759472846985\n",
      "\tLoss: 0.13314643502235413\n",
      "\tLoss: 0.11841947585344315\n",
      "\tLoss: 0.11311286687850952\n",
      "\tLoss: 0.1308610588312149\n",
      "\tLoss: 0.10489299893379211\n",
      "\tLoss: 0.11191138625144958\n",
      "\tLoss: 0.11869236081838608\n",
      "\tLoss: 0.11400805413722992\n",
      "\tLoss: 0.1830882728099823\n",
      "\tLoss: 0.08834926784038544\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.07640598714351654\n",
      "\tLoss: 0.11717042326927185\n",
      "\tLoss: 0.08999857306480408\n",
      "\tLoss: 0.10010319948196411\n",
      "\tLoss: 0.12190647423267365\n",
      "\tLoss: 0.14941616356372833\n",
      "\tLoss: 0.06271502375602722\n",
      "\tLoss: 0.10701561719179153\n",
      "\tLoss: 0.09673416614532471\n",
      "\tLoss: 0.10575960576534271\n",
      "\tLoss: 0.12860426306724548\n",
      "\tLoss: 0.10618703067302704\n",
      "\tLoss: 0.12980307638645172\n",
      "\tLoss: 0.11188746243715286\n",
      "\tLoss: 0.14243152737617493\n",
      "\tLoss: 0.09060947597026825\n",
      "\tLoss: 0.11476418375968933\n",
      "\tLoss: 0.10872896015644073\n",
      "\tLoss: 0.19452834129333496\n",
      "\tLoss: 0.1068800762295723\n",
      "\tLoss: 0.1276012659072876\n",
      "\tLoss: 0.12263046205043793\n",
      "\tLoss: 0.16402000188827515\n",
      "\tLoss: 0.114050954580307\n",
      "\tLoss: 0.11823517829179764\n",
      "\tLoss: 0.09528446197509766\n",
      "\tLoss: 0.13966435194015503\n",
      "\tLoss: 0.08403918147087097\n",
      "\tLoss: 0.12554685771465302\n",
      "\tLoss: 0.09597768634557724\n",
      "\tLoss: 0.13221657276153564\n",
      "\tLoss: 0.11507679522037506\n",
      "\tLoss: 0.10156261920928955\n",
      "\tLoss: 0.12805232405662537\n",
      "\tLoss: 0.06764397770166397\n",
      "\tLoss: 0.11318792402744293\n",
      "\tLoss: 0.15472155809402466\n",
      "\tLoss: 0.09751833975315094\n",
      "\tLoss: 0.09259110689163208\n",
      "\tLoss: 0.1453937441110611\n",
      "\tLoss: 0.09939651191234589\n",
      "\tLoss: 0.10179980099201202\n",
      "\tLoss: 0.10286794602870941\n",
      "\tLoss: 0.1247115358710289\n",
      "\tLoss: 0.12740732729434967\n",
      "\tLoss: 0.08966303616762161\n",
      "\tLoss: 0.1276269257068634\n",
      "\tLoss: 0.07170964777469635\n",
      "\tLoss: 0.10379935801029205\n",
      "\tLoss: 0.11612599343061447\n",
      "\tLoss: 0.15071183443069458\n",
      "[time] Epoch 31: 452.65472515672445s = 7.544245419278741m\n",
      "\n",
      "Epoch 32...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.13402210175991058\n",
      "\tLoss: 0.09014669060707092\n",
      "\tLoss: 0.10312521457672119\n",
      "\tLoss: 0.14478462934494019\n",
      "\tLoss: 0.08553299307823181\n",
      "\tLoss: 0.12358418852090836\n",
      "\tLoss: 0.12708407640457153\n",
      "\tLoss: 0.13255134224891663\n",
      "\tLoss: 0.09934316575527191\n",
      "\tLoss: 0.13859279453754425\n",
      "\tLoss: 0.14531376957893372\n",
      "\tLoss: 0.08504368364810944\n",
      "\tLoss: 0.09643901884555817\n",
      "\tLoss: 0.09081923216581345\n",
      "\tLoss: 0.11822038888931274\n",
      "\tLoss: 0.09091687202453613\n",
      "\tLoss: 0.13848721981048584\n",
      "\tLoss: 0.08509466052055359\n",
      "\tLoss: 0.118448406457901\n",
      "\tLoss: 0.1375373750925064\n",
      "\tLoss: 0.09645071625709534\n",
      "\tLoss: 0.08682432770729065\n",
      "\tLoss: 0.1269761025905609\n",
      "\tLoss: 0.08350750058889389\n",
      "\tLoss: 0.10502272844314575\n",
      "\tLoss: 0.14676356315612793\n",
      "\tLoss: 0.08914568275213242\n",
      "\tLoss: 0.1256142556667328\n",
      "\tLoss: 0.17217469215393066\n",
      "\tLoss: 0.10523878037929535\n",
      "\tLoss: 0.1205020546913147\n",
      "\tLoss: 0.09361810982227325\n",
      "\tLoss: 0.13835380971431732\n",
      "\tLoss: 0.1147623062133789\n",
      "\tLoss: 0.07251862436532974\n",
      "\tLoss: 0.07537506520748138\n",
      "\tLoss: 0.1087697222828865\n",
      "\tLoss: 0.08684049546718597\n",
      "\tLoss: 0.0839260146021843\n",
      "\tLoss: 0.12981098890304565\n",
      "\tLoss: 0.13256549835205078\n",
      "\tLoss: 0.17535892128944397\n",
      "\tLoss: 0.12092974781990051\n",
      "\tLoss: 0.17334771156311035\n",
      "\tLoss: 0.13867564499378204\n",
      "\tLoss: 0.1358981728553772\n",
      "\tLoss: 0.11370409280061722\n",
      "\tLoss: 0.18180158734321594\n",
      "\tLoss: 0.1477961391210556\n",
      "\tLoss: 0.12166411429643631\n",
      "\tLoss: 0.09869275987148285\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.10235364735126495\n",
      "\tLoss: 0.12615050375461578\n",
      "\tLoss: 0.09194183349609375\n",
      "\tLoss: 0.10709188878536224\n",
      "\tLoss: 0.12062186002731323\n",
      "\tLoss: 0.13573060929775238\n",
      "\tLoss: 0.11217308044433594\n",
      "\tLoss: 0.09050365537405014\n",
      "\tLoss: 0.11467801034450531\n",
      "\tLoss: 0.09298718720674515\n",
      "\tLoss: 0.10635146498680115\n",
      "\tLoss: 0.16144728660583496\n",
      "\tLoss: 0.10941929370164871\n",
      "\tLoss: 0.11167566478252411\n",
      "\tLoss: 0.1125933974981308\n",
      "\tLoss: 0.1313861608505249\n",
      "\tLoss: 0.13426335155963898\n",
      "\tLoss: 0.10463640093803406\n",
      "\tLoss: 0.1275598108768463\n",
      "\tLoss: 0.1257866770029068\n",
      "\tLoss: 0.13165555894374847\n",
      "\tLoss: 0.11593200266361237\n",
      "\tLoss: 0.11939030885696411\n",
      "\tLoss: 0.13024912774562836\n",
      "\tLoss: 0.08626745641231537\n",
      "\tLoss: 0.06943149864673615\n",
      "\tLoss: 0.08140541613101959\n",
      "\tLoss: 0.12351980805397034\n",
      "\tLoss: 0.0881081074476242\n",
      "\tLoss: 0.13805216550827026\n",
      "\tLoss: 0.13078206777572632\n",
      "\tLoss: 0.10758413374423981\n",
      "\tLoss: 0.1051671952009201\n",
      "\tLoss: 0.14206624031066895\n",
      "\tLoss: 0.09719058871269226\n",
      "\tLoss: 0.12066902965307236\n",
      "\tLoss: 0.12051969021558762\n",
      "\tLoss: 0.13300852477550507\n",
      "\tLoss: 0.10336779803037643\n",
      "\tLoss: 0.06629323959350586\n",
      "\tLoss: 0.10026736557483673\n",
      "\tLoss: 0.10127753764390945\n",
      "\tLoss: 0.15017807483673096\n",
      "\tLoss: 0.10345036536455154\n",
      "\tLoss: 0.13071519136428833\n",
      "\tLoss: 0.11469349265098572\n",
      "\tLoss: 0.1412142664194107\n",
      "\tLoss: 0.11952175199985504\n",
      "\tLoss: 0.08890719711780548\n",
      "\tLoss: 0.10608260333538055\n",
      "\tLoss: 0.10571177303791046\n",
      "[time] Epoch 32: 440.13616391830146s = 7.335602731971691m\n",
      "\n",
      "Epoch 33...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1082276701927185\n",
      "\tLoss: 0.09103826433420181\n",
      "\tLoss: 0.11796550452709198\n",
      "\tLoss: 0.09413935244083405\n",
      "\tLoss: 0.12399020791053772\n",
      "\tLoss: 0.08166152238845825\n",
      "\tLoss: 0.12435023486614227\n",
      "\tLoss: 0.10871239751577377\n",
      "\tLoss: 0.096381276845932\n",
      "\tLoss: 0.1253475397825241\n",
      "\tLoss: 0.16339263319969177\n",
      "\tLoss: 0.09520450234413147\n",
      "\tLoss: 0.13677170872688293\n",
      "\tLoss: 0.10014556348323822\n",
      "\tLoss: 0.14423933625221252\n",
      "\tLoss: 0.1598074734210968\n",
      "\tLoss: 0.11928548663854599\n",
      "\tLoss: 0.10277903825044632\n",
      "\tLoss: 0.10582950711250305\n",
      "\tLoss: 0.18315738439559937\n",
      "\tLoss: 0.1582806408405304\n",
      "\tLoss: 0.0777943804860115\n",
      "\tLoss: 0.09742644429206848\n",
      "\tLoss: 0.08146779239177704\n",
      "\tLoss: 0.10103173553943634\n",
      "\tLoss: 0.10151037573814392\n",
      "\tLoss: 0.12367787957191467\n",
      "\tLoss: 0.15446917712688446\n",
      "\tLoss: 0.11313694715499878\n",
      "\tLoss: 0.14422518014907837\n",
      "\tLoss: 0.1327604204416275\n",
      "\tLoss: 0.10774406045675278\n",
      "\tLoss: 0.11457580327987671\n",
      "\tLoss: 0.12630334496498108\n",
      "\tLoss: 0.13293783366680145\n",
      "\tLoss: 0.1492035984992981\n",
      "\tLoss: 0.12175247073173523\n",
      "\tLoss: 0.08014537394046783\n",
      "\tLoss: 0.111079141497612\n",
      "\tLoss: 0.10679131746292114\n",
      "\tLoss: 0.08636050671339035\n",
      "\tLoss: 0.13939344882965088\n",
      "\tLoss: 0.12629294395446777\n",
      "\tLoss: 0.11735458672046661\n",
      "\tLoss: 0.12600502371788025\n",
      "\tLoss: 0.10892684757709503\n",
      "\tLoss: 0.16960187256336212\n",
      "\tLoss: 0.15904571115970612\n",
      "\tLoss: 0.0980503037571907\n",
      "\tLoss: 0.09702007472515106\n",
      "\tLoss: 0.11891216039657593\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.10142706334590912\n",
      "\tLoss: 0.08910708129405975\n",
      "\tLoss: 0.15782928466796875\n",
      "\tLoss: 0.10637772083282471\n",
      "\tLoss: 0.11664418876171112\n",
      "\tLoss: 0.08154827356338501\n",
      "\tLoss: 0.10099401324987411\n",
      "\tLoss: 0.15580177307128906\n",
      "\tLoss: 0.09752634167671204\n",
      "\tLoss: 0.1692299246788025\n",
      "\tLoss: 0.1278792917728424\n",
      "\tLoss: 0.13722248375415802\n",
      "\tLoss: 0.13697227835655212\n",
      "\tLoss: 0.15806302428245544\n",
      "\tLoss: 0.15579400956630707\n",
      "\tLoss: 0.1544959545135498\n",
      "\tLoss: 0.09143105149269104\n",
      "\tLoss: 0.05973633751273155\n",
      "\tLoss: 0.148969829082489\n",
      "\tLoss: 0.1304212212562561\n",
      "\tLoss: 0.10059255361557007\n",
      "\tLoss: 0.14807751774787903\n",
      "\tLoss: 0.09935098886489868\n",
      "\tLoss: 0.08910580724477768\n",
      "\tLoss: 0.05334898456931114\n",
      "\tLoss: 0.1183621734380722\n",
      "\tLoss: 0.12136318534612656\n",
      "\tLoss: 0.11215074360370636\n",
      "\tLoss: 0.10984674096107483\n",
      "\tLoss: 0.14182215929031372\n",
      "\tLoss: 0.15047180652618408\n",
      "\tLoss: 0.15650534629821777\n",
      "\tLoss: 0.14482584595680237\n",
      "\tLoss: 0.11071674525737762\n",
      "\tLoss: 0.14121270179748535\n",
      "\tLoss: 0.10727480798959732\n",
      "\tLoss: 0.09153557568788528\n",
      "\tLoss: 0.11731794476509094\n",
      "\tLoss: 0.1585596352815628\n",
      "\tLoss: 0.1073937714099884\n",
      "\tLoss: 0.11752951890230179\n",
      "\tLoss: 0.158408522605896\n",
      "\tLoss: 0.15437009930610657\n",
      "\tLoss: 0.13815006613731384\n",
      "\tLoss: 0.09615194797515869\n",
      "\tLoss: 0.12167921662330627\n",
      "\tLoss: 0.14246866106987\n",
      "\tLoss: 0.1234285905957222\n",
      "\tLoss: 0.09528738260269165\n",
      "\tLoss: 0.14637908339500427\n",
      "\tLoss: 0.11953693628311157\n",
      "[time] Epoch 33: 446.4947462482378s = 7.441579104137296m\n",
      "\n",
      "Epoch 34...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.12557807564735413\n",
      "\tLoss: 0.11832255125045776\n",
      "\tLoss: 0.11887429654598236\n",
      "\tLoss: 0.14391060173511505\n",
      "\tLoss: 0.1282881498336792\n",
      "\tLoss: 0.11733684688806534\n",
      "\tLoss: 0.1101611778140068\n",
      "\tLoss: 0.1309596747159958\n",
      "\tLoss: 0.10535536706447601\n",
      "\tLoss: 0.09767419099807739\n",
      "\tLoss: 0.11506377905607224\n",
      "\tLoss: 0.11717355251312256\n",
      "\tLoss: 0.1438390612602234\n",
      "\tLoss: 0.1405174732208252\n",
      "\tLoss: 0.12059598416090012\n",
      "\tLoss: 0.10729088634252548\n",
      "\tLoss: 0.13708804547786713\n",
      "\tLoss: 0.11794459074735641\n",
      "\tLoss: 0.16052128374576569\n",
      "\tLoss: 0.1229337751865387\n",
      "\tLoss: 0.09937653690576553\n",
      "\tLoss: 0.08100616931915283\n",
      "\tLoss: 0.1718265265226364\n",
      "\tLoss: 0.1116814911365509\n",
      "\tLoss: 0.1043255478143692\n",
      "\tLoss: 0.14365392923355103\n",
      "\tLoss: 0.09549733996391296\n",
      "\tLoss: 0.08364338427782059\n",
      "\tLoss: 0.08101772516965866\n",
      "\tLoss: 0.1004483625292778\n",
      "\tLoss: 0.1624385565519333\n",
      "\tLoss: 0.19431829452514648\n",
      "\tLoss: 0.0750865563750267\n",
      "\tLoss: 0.15181629359722137\n",
      "\tLoss: 0.0810825526714325\n",
      "\tLoss: 0.10648186504840851\n",
      "\tLoss: 0.15000981092453003\n",
      "\tLoss: 0.14337067306041718\n",
      "\tLoss: 0.1278698742389679\n",
      "\tLoss: 0.10918193310499191\n",
      "\tLoss: 0.1270238310098648\n",
      "\tLoss: 0.12295837700366974\n",
      "\tLoss: 0.08970411121845245\n",
      "\tLoss: 0.19249215722084045\n",
      "\tLoss: 0.1239534541964531\n",
      "\tLoss: 0.10566665232181549\n",
      "\tLoss: 0.15389001369476318\n",
      "\tLoss: 0.12300482392311096\n",
      "\tLoss: 0.12206337600946426\n",
      "\tLoss: 0.1007474809885025\n",
      "\tLoss: 0.08019326627254486\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.0877109169960022\n",
      "\tLoss: 0.1226668655872345\n",
      "\tLoss: 0.13674715161323547\n",
      "\tLoss: 0.11884142458438873\n",
      "\tLoss: 0.13145805895328522\n",
      "\tLoss: 0.09180597960948944\n",
      "\tLoss: 0.08161312341690063\n",
      "\tLoss: 0.11695283651351929\n",
      "\tLoss: 0.08154875040054321\n",
      "\tLoss: 0.09713813662528992\n",
      "\tLoss: 0.08613128215074539\n",
      "\tLoss: 0.1211153119802475\n",
      "\tLoss: 0.16121500730514526\n",
      "\tLoss: 0.11058633774518967\n",
      "\tLoss: 0.14554345607757568\n",
      "\tLoss: 0.10879690945148468\n",
      "\tLoss: 0.08121441304683685\n",
      "\tLoss: 0.12659341096878052\n",
      "\tLoss: 0.09450745582580566\n",
      "\tLoss: 0.10769250988960266\n",
      "\tLoss: 0.11281877756118774\n",
      "\tLoss: 0.15241780877113342\n",
      "\tLoss: 0.11355075240135193\n",
      "\tLoss: 0.1672302484512329\n",
      "\tLoss: 0.11663245409727097\n",
      "\tLoss: 0.10680942237377167\n",
      "\tLoss: 0.10193558782339096\n",
      "\tLoss: 0.08914899080991745\n",
      "\tLoss: 0.0653456449508667\n",
      "\tLoss: 0.1303904950618744\n",
      "\tLoss: 0.10867036879062653\n",
      "\tLoss: 0.07488645613193512\n",
      "\tLoss: 0.10104449838399887\n",
      "\tLoss: 0.06182538717985153\n",
      "\tLoss: 0.07137875258922577\n",
      "\tLoss: 0.19731934368610382\n",
      "\tLoss: 0.10214957594871521\n",
      "\tLoss: 0.12043164670467377\n",
      "\tLoss: 0.13185857236385345\n",
      "\tLoss: 0.13678476214408875\n",
      "\tLoss: 0.14021170139312744\n",
      "\tLoss: 0.08908124268054962\n",
      "\tLoss: 0.16529975831508636\n",
      "\tLoss: 0.09677189588546753\n",
      "\tLoss: 0.1482136994600296\n",
      "\tLoss: 0.1484028398990631\n",
      "\tLoss: 0.15626303851604462\n",
      "\tLoss: 0.1053323969244957\n",
      "\tLoss: 0.11165714263916016\n",
      "\tLoss: 0.1101546436548233\n",
      "\tLoss: 0.1516781896352768\n",
      "[time] Epoch 34: 442.68240575212985s = 7.378040095868831m\n",
      "\n",
      "Epoch 35...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.12361432611942291\n",
      "\tLoss: 0.13991081714630127\n",
      "\tLoss: 0.10199086368083954\n",
      "\tLoss: 0.11470581591129303\n",
      "\tLoss: 0.10610692948102951\n",
      "\tLoss: 0.11936456710100174\n",
      "\tLoss: 0.10384373366832733\n",
      "\tLoss: 0.14347907900810242\n",
      "\tLoss: 0.1679210066795349\n",
      "\tLoss: 0.12351952493190765\n",
      "\tLoss: 0.10782172530889511\n",
      "\tLoss: 0.15261198580265045\n",
      "\tLoss: 0.08688844740390778\n",
      "\tLoss: 0.1112278550863266\n",
      "\tLoss: 0.14201942086219788\n",
      "\tLoss: 0.13322106003761292\n",
      "\tLoss: 0.10316881537437439\n",
      "\tLoss: 0.13526399433612823\n",
      "\tLoss: 0.06912197917699814\n",
      "\tLoss: 0.09331678599119186\n",
      "\tLoss: 0.08688725531101227\n",
      "\tLoss: 0.11120519042015076\n",
      "\tLoss: 0.08627191931009293\n",
      "\tLoss: 0.1122932955622673\n",
      "\tLoss: 0.12403565645217896\n",
      "\tLoss: 0.10747784376144409\n",
      "\tLoss: 0.07559377700090408\n",
      "\tLoss: 0.11522124707698822\n",
      "\tLoss: 0.10212025046348572\n",
      "\tLoss: 0.12139704823493958\n",
      "\tLoss: 0.09954480826854706\n",
      "\tLoss: 0.10796326398849487\n",
      "\tLoss: 0.07692677527666092\n",
      "\tLoss: 0.1037534847855568\n",
      "\tLoss: 0.1297776699066162\n",
      "\tLoss: 0.14782457053661346\n",
      "\tLoss: 0.13297030329704285\n",
      "\tLoss: 0.11838366091251373\n",
      "\tLoss: 0.138722226023674\n",
      "\tLoss: 0.11853285878896713\n",
      "\tLoss: 0.1549825668334961\n",
      "\tLoss: 0.08545795828104019\n",
      "\tLoss: 0.11093190312385559\n",
      "\tLoss: 0.1422363519668579\n",
      "\tLoss: 0.14056538045406342\n",
      "\tLoss: 0.09464430809020996\n",
      "\tLoss: 0.10203872621059418\n",
      "\tLoss: 0.09992511570453644\n",
      "\tLoss: 0.14614197611808777\n",
      "\tLoss: 0.10773050785064697\n",
      "\tLoss: 0.11943665146827698\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.0860060602426529\n",
      "\tLoss: 0.11159369349479675\n",
      "\tLoss: 0.13127264380455017\n",
      "\tLoss: 0.09675078839063644\n",
      "\tLoss: 0.09184825420379639\n",
      "\tLoss: 0.11754561960697174\n",
      "\tLoss: 0.11718614399433136\n",
      "\tLoss: 0.1129002720117569\n",
      "\tLoss: 0.12621921300888062\n",
      "\tLoss: 0.14164355397224426\n",
      "\tLoss: 0.12547795474529266\n",
      "\tLoss: 0.10321372002363205\n",
      "\tLoss: 0.10190382599830627\n",
      "\tLoss: 0.06388067454099655\n",
      "\tLoss: 0.11938941478729248\n",
      "\tLoss: 0.10153257846832275\n",
      "\tLoss: 0.13696661591529846\n",
      "\tLoss: 0.09186087548732758\n",
      "\tLoss: 0.12361999601125717\n",
      "\tLoss: 0.14024782180786133\n",
      "\tLoss: 0.16796809434890747\n",
      "\tLoss: 0.09915785491466522\n",
      "\tLoss: 0.10589293390512466\n",
      "\tLoss: 0.11232680082321167\n",
      "\tLoss: 0.09810763597488403\n",
      "\tLoss: 0.14402318000793457\n",
      "\tLoss: 0.08713840693235397\n",
      "\tLoss: 0.15184587240219116\n",
      "\tLoss: 0.0928189754486084\n",
      "\tLoss: 0.12020261585712433\n",
      "\tLoss: 0.07780250906944275\n",
      "\tLoss: 0.08813820779323578\n",
      "\tLoss: 0.13415782153606415\n",
      "\tLoss: 0.11816012859344482\n",
      "\tLoss: 0.1280619353055954\n",
      "\tLoss: 0.11647817492485046\n",
      "\tLoss: 0.09470409154891968\n",
      "\tLoss: 0.10639476031064987\n",
      "\tLoss: 0.10815989971160889\n",
      "\tLoss: 0.12968963384628296\n",
      "\tLoss: 0.11909723281860352\n",
      "\tLoss: 0.13138514757156372\n",
      "\tLoss: 0.13314282894134521\n",
      "\tLoss: 0.10467417538166046\n",
      "\tLoss: 0.17484959959983826\n",
      "\tLoss: 0.14405354857444763\n",
      "\tLoss: 0.11870649456977844\n",
      "\tLoss: 0.1449388861656189\n",
      "\tLoss: 0.126137837767601\n",
      "\tLoss: 0.1127643808722496\n",
      "\tLoss: 0.10725340247154236\n",
      "[time] Epoch 35: 444.8401504838839s = 7.414002508064732m\n",
      "\n",
      "Epoch 36...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.19713082909584045\n",
      "\tLoss: 0.11692016571760178\n",
      "\tLoss: 0.10385187715291977\n",
      "\tLoss: 0.1332058310508728\n",
      "\tLoss: 0.1075965017080307\n",
      "\tLoss: 0.15569600462913513\n",
      "\tLoss: 0.09870786964893341\n",
      "\tLoss: 0.10152275860309601\n",
      "\tLoss: 0.09344759583473206\n",
      "\tLoss: 0.1346379816532135\n",
      "\tLoss: 0.12151803076267242\n",
      "\tLoss: 0.15466716885566711\n",
      "\tLoss: 0.09291961044073105\n",
      "\tLoss: 0.10889647156000137\n",
      "\tLoss: 0.13523496687412262\n",
      "\tLoss: 0.13010382652282715\n",
      "\tLoss: 0.11742043495178223\n",
      "\tLoss: 0.12139704823493958\n",
      "\tLoss: 0.12873423099517822\n",
      "\tLoss: 0.09396440535783768\n",
      "\tLoss: 0.11750410497188568\n",
      "\tLoss: 0.10169485211372375\n",
      "\tLoss: 0.1349080353975296\n",
      "\tLoss: 0.04414486512541771\n",
      "\tLoss: 0.08645352721214294\n",
      "\tLoss: 0.08733248710632324\n",
      "\tLoss: 0.13770847022533417\n",
      "\tLoss: 0.09736989438533783\n",
      "\tLoss: 0.1166311502456665\n",
      "\tLoss: 0.15820854902267456\n",
      "\tLoss: 0.14256465435028076\n",
      "\tLoss: 0.10765061527490616\n",
      "\tLoss: 0.11986957490444183\n",
      "\tLoss: 0.08365615457296371\n",
      "\tLoss: 0.12983131408691406\n",
      "\tLoss: 0.09137821197509766\n",
      "\tLoss: 0.14101776480674744\n",
      "\tLoss: 0.15830476582050323\n",
      "\tLoss: 0.12329825758934021\n",
      "\tLoss: 0.14887996017932892\n",
      "\tLoss: 0.128798708319664\n",
      "\tLoss: 0.09652848541736603\n",
      "\tLoss: 0.10398995876312256\n",
      "\tLoss: 0.08431890606880188\n",
      "\tLoss: 0.10556778311729431\n",
      "\tLoss: 0.14126260578632355\n",
      "\tLoss: 0.10952028632164001\n",
      "\tLoss: 0.13500382006168365\n",
      "\tLoss: 0.1542361080646515\n",
      "\tLoss: 0.08795487135648727\n",
      "\tLoss: 0.1266036033630371\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.09223215281963348\n",
      "\tLoss: 0.12397579848766327\n",
      "\tLoss: 0.11907047033309937\n",
      "\tLoss: 0.12012290954589844\n",
      "\tLoss: 0.10545609146356583\n",
      "\tLoss: 0.15718483924865723\n",
      "\tLoss: 0.1466277837753296\n",
      "\tLoss: 0.1307857632637024\n",
      "\tLoss: 0.11762326955795288\n",
      "\tLoss: 0.13447712361812592\n",
      "\tLoss: 0.15611566603183746\n",
      "\tLoss: 0.08842405676841736\n",
      "\tLoss: 0.08085744082927704\n",
      "\tLoss: 0.12460877746343613\n",
      "\tLoss: 0.12702402472496033\n",
      "\tLoss: 0.14155055582523346\n",
      "\tLoss: 0.11605045944452286\n",
      "\tLoss: 0.13014821708202362\n",
      "\tLoss: 0.12610457837581635\n",
      "\tLoss: 0.11503647267818451\n",
      "\tLoss: 0.08864118158817291\n",
      "\tLoss: 0.10890069603919983\n",
      "\tLoss: 0.11154249310493469\n",
      "\tLoss: 0.13169889152050018\n",
      "\tLoss: 0.0909171923995018\n",
      "\tLoss: 0.10005781799554825\n",
      "\tLoss: 0.06628608703613281\n",
      "\tLoss: 0.10212242603302002\n",
      "\tLoss: 0.19341611862182617\n",
      "\tLoss: 0.118367999792099\n",
      "\tLoss: 0.17314201593399048\n",
      "\tLoss: 0.08675649762153625\n",
      "\tLoss: 0.10742545872926712\n",
      "\tLoss: 0.09385758638381958\n",
      "\tLoss: 0.1155368983745575\n",
      "\tLoss: 0.1067880392074585\n",
      "\tLoss: 0.136154904961586\n",
      "\tLoss: 0.08667230606079102\n",
      "\tLoss: 0.13242454826831818\n",
      "\tLoss: 0.09796935319900513\n",
      "\tLoss: 0.10319715738296509\n",
      "\tLoss: 0.13068655133247375\n",
      "\tLoss: 0.12852156162261963\n",
      "\tLoss: 0.09186030924320221\n",
      "\tLoss: 0.08765047043561935\n",
      "\tLoss: 0.10555341094732285\n",
      "\tLoss: 0.12411566078662872\n",
      "\tLoss: 0.12178841978311539\n",
      "\tLoss: 0.10804501920938492\n",
      "\tLoss: 0.12404461205005646\n",
      "\tLoss: 0.13042446970939636\n",
      "[time] Epoch 36: 443.33853747323155s = 7.38897562455386m\n",
      "\n",
      "Epoch 37...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.09387557208538055\n",
      "\tLoss: 0.09429546445608139\n",
      "\tLoss: 0.09069420397281647\n",
      "\tLoss: 0.11390072852373123\n",
      "\tLoss: 0.07274129986763\n",
      "\tLoss: 0.09773276746273041\n",
      "\tLoss: 0.07942508161067963\n",
      "\tLoss: 0.15136098861694336\n",
      "\tLoss: 0.17304928600788116\n",
      "\tLoss: 0.09502288699150085\n",
      "\tLoss: 0.15609964728355408\n",
      "\tLoss: 0.06601274758577347\n",
      "\tLoss: 0.12387420982122421\n",
      "\tLoss: 0.09802018105983734\n",
      "\tLoss: 0.13110114634037018\n",
      "\tLoss: 0.09330275654792786\n",
      "\tLoss: 0.08510643988847733\n",
      "\tLoss: 0.09547999501228333\n",
      "\tLoss: 0.15274375677108765\n",
      "\tLoss: 0.1527988165616989\n",
      "\tLoss: 0.08627909421920776\n",
      "\tLoss: 0.10763411223888397\n",
      "\tLoss: 0.07059380412101746\n",
      "\tLoss: 0.09899327903985977\n",
      "\tLoss: 0.11496740579605103\n",
      "\tLoss: 0.09087972342967987\n",
      "\tLoss: 0.10216255486011505\n",
      "\tLoss: 0.10649276524782181\n",
      "\tLoss: 0.11569580435752869\n",
      "\tLoss: 0.10290631651878357\n",
      "\tLoss: 0.06638699769973755\n",
      "\tLoss: 0.10283856838941574\n",
      "\tLoss: 0.13862508535385132\n",
      "\tLoss: 0.10703977942466736\n",
      "\tLoss: 0.11073367297649384\n",
      "\tLoss: 0.09203736484050751\n",
      "\tLoss: 0.11039459705352783\n",
      "\tLoss: 0.09571294486522675\n",
      "\tLoss: 0.10155104100704193\n",
      "\tLoss: 0.13843248784542084\n",
      "\tLoss: 0.12232276052236557\n",
      "\tLoss: 0.10131613165140152\n",
      "\tLoss: 0.11734601110219955\n",
      "\tLoss: 0.08703231066465378\n",
      "\tLoss: 0.10289725661277771\n",
      "\tLoss: 0.12224787473678589\n",
      "\tLoss: 0.10894176363945007\n",
      "\tLoss: 0.12107335776090622\n",
      "\tLoss: 0.131978839635849\n",
      "\tLoss: 0.12437006086111069\n",
      "\tLoss: 0.1303633749485016\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.10815325379371643\n",
      "\tLoss: 0.10453328490257263\n",
      "\tLoss: 0.16372069716453552\n",
      "\tLoss: 0.1516769826412201\n",
      "\tLoss: 0.09710394591093063\n",
      "\tLoss: 0.12318400293588638\n",
      "\tLoss: 0.09548214823007584\n",
      "\tLoss: 0.12896853685379028\n",
      "\tLoss: 0.07773631811141968\n",
      "\tLoss: 0.0774679034948349\n",
      "\tLoss: 0.10058308392763138\n",
      "\tLoss: 0.09637545794248581\n",
      "\tLoss: 0.12514227628707886\n",
      "\tLoss: 0.1407257318496704\n",
      "\tLoss: 0.12240742892026901\n",
      "\tLoss: 0.06527331471443176\n",
      "\tLoss: 0.10060860961675644\n",
      "\tLoss: 0.13069242238998413\n",
      "\tLoss: 0.09198614209890366\n",
      "\tLoss: 0.13582703471183777\n",
      "\tLoss: 0.09410184621810913\n",
      "\tLoss: 0.11814603209495544\n",
      "\tLoss: 0.14835503697395325\n",
      "\tLoss: 0.12960413098335266\n",
      "\tLoss: 0.10459272563457489\n",
      "\tLoss: 0.1282164305448532\n",
      "\tLoss: 0.09675359725952148\n",
      "\tLoss: 0.11009129136800766\n",
      "\tLoss: 0.09724944829940796\n",
      "\tLoss: 0.15643736720085144\n",
      "\tLoss: 0.09571225941181183\n",
      "\tLoss: 0.09195549041032791\n",
      "\tLoss: 0.10356882214546204\n",
      "\tLoss: 0.07460907846689224\n",
      "\tLoss: 0.06858183443546295\n",
      "\tLoss: 0.09284256398677826\n",
      "\tLoss: 0.1349123865365982\n",
      "\tLoss: 0.14896602928638458\n",
      "\tLoss: 0.08255995810031891\n",
      "\tLoss: 0.11964184045791626\n",
      "\tLoss: 0.09812486171722412\n",
      "\tLoss: 0.1476060152053833\n",
      "\tLoss: 0.08780745416879654\n",
      "\tLoss: 0.09121717512607574\n",
      "\tLoss: 0.18646493554115295\n",
      "\tLoss: 0.14320620894432068\n",
      "\tLoss: 0.12982973456382751\n",
      "\tLoss: 0.0861486941576004\n",
      "\tLoss: 0.1329035460948944\n",
      "\tLoss: 0.09151433408260345\n",
      "\tLoss: 0.12899911403656006\n",
      "[time] Epoch 37: 440.76310937386006s = 7.3460518228976674m\n",
      "\n",
      "Epoch 38...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.10965275019407272\n",
      "\tLoss: 0.11611944437026978\n",
      "\tLoss: 0.09360841661691666\n",
      "\tLoss: 0.1304895579814911\n",
      "\tLoss: 0.10132493078708649\n",
      "\tLoss: 0.10937398672103882\n",
      "\tLoss: 0.08393917977809906\n",
      "\tLoss: 0.11568999290466309\n",
      "\tLoss: 0.0940055251121521\n",
      "\tLoss: 0.1456417739391327\n",
      "\tLoss: 0.09799401462078094\n",
      "\tLoss: 0.11801257729530334\n",
      "\tLoss: 0.1377110332250595\n",
      "\tLoss: 0.17621161043643951\n",
      "\tLoss: 0.09064339846372604\n",
      "\tLoss: 0.09063133597373962\n",
      "\tLoss: 0.12470714747905731\n",
      "\tLoss: 0.12631310522556305\n",
      "\tLoss: 0.14053940773010254\n",
      "\tLoss: 0.13541093468666077\n",
      "\tLoss: 0.10339562594890594\n",
      "\tLoss: 0.10898425430059433\n",
      "\tLoss: 0.12882983684539795\n",
      "\tLoss: 0.11248603463172913\n",
      "\tLoss: 0.09053604304790497\n",
      "\tLoss: 0.13688965141773224\n",
      "\tLoss: 0.11230210959911346\n",
      "\tLoss: 0.12254462391138077\n",
      "\tLoss: 0.1698986142873764\n",
      "\tLoss: 0.13356560468673706\n",
      "\tLoss: 0.11775846034288406\n",
      "\tLoss: 0.13789813220500946\n",
      "\tLoss: 0.165202796459198\n",
      "\tLoss: 0.13292196393013\n",
      "\tLoss: 0.09443974494934082\n",
      "\tLoss: 0.145309180021286\n",
      "\tLoss: 0.09717783331871033\n",
      "\tLoss: 0.14461083710193634\n",
      "\tLoss: 0.12873788177967072\n",
      "\tLoss: 0.09055235981941223\n",
      "\tLoss: 0.08919364213943481\n",
      "\tLoss: 0.08142454922199249\n",
      "\tLoss: 0.12910106778144836\n",
      "\tLoss: 0.05284593254327774\n",
      "\tLoss: 0.12266108393669128\n",
      "\tLoss: 0.1270895004272461\n",
      "\tLoss: 0.11045785248279572\n",
      "\tLoss: 0.13779595494270325\n",
      "\tLoss: 0.12580448389053345\n",
      "\tLoss: 0.13600435853004456\n",
      "\tLoss: 0.11850359290838242\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.11716321855783463\n",
      "\tLoss: 0.10136817395687103\n",
      "\tLoss: 0.11139381676912308\n",
      "\tLoss: 0.1111084595322609\n",
      "\tLoss: 0.07742901146411896\n",
      "\tLoss: 0.07024022936820984\n",
      "\tLoss: 0.16227547824382782\n",
      "\tLoss: 0.1096939966082573\n",
      "\tLoss: 0.07775118201971054\n",
      "\tLoss: 0.1039062887430191\n",
      "\tLoss: 0.10099630057811737\n",
      "\tLoss: 0.08115976303815842\n",
      "\tLoss: 0.08663593977689743\n",
      "\tLoss: 0.15377506613731384\n",
      "\tLoss: 0.122543103992939\n",
      "\tLoss: 0.14089477062225342\n",
      "\tLoss: 0.07976436614990234\n",
      "\tLoss: 0.09037278592586517\n",
      "\tLoss: 0.1281193196773529\n",
      "\tLoss: 0.124916672706604\n",
      "\tLoss: 0.09234669804573059\n",
      "\tLoss: 0.1212444081902504\n",
      "\tLoss: 0.07030439376831055\n",
      "\tLoss: 0.06197419762611389\n",
      "\tLoss: 0.0996566116809845\n",
      "\tLoss: 0.14035898447036743\n",
      "\tLoss: 0.06975318491458893\n",
      "\tLoss: 0.11622308194637299\n",
      "\tLoss: 0.10877325385808945\n",
      "\tLoss: 0.08212920278310776\n",
      "\tLoss: 0.0919225662946701\n",
      "\tLoss: 0.06771642714738846\n",
      "\tLoss: 0.10061143338680267\n",
      "\tLoss: 0.07705625891685486\n",
      "\tLoss: 0.10103157162666321\n",
      "\tLoss: 0.15473075211048126\n",
      "\tLoss: 0.09550032019615173\n",
      "\tLoss: 0.10779812932014465\n",
      "\tLoss: 0.10743878781795502\n",
      "\tLoss: 0.11489982903003693\n",
      "\tLoss: 0.06804848462343216\n",
      "\tLoss: 0.1558418720960617\n",
      "\tLoss: 0.14085692167282104\n",
      "\tLoss: 0.09885042905807495\n",
      "\tLoss: 0.09630614519119263\n",
      "\tLoss: 0.13102737069129944\n",
      "\tLoss: 0.09422532469034195\n",
      "\tLoss: 0.0966336727142334\n",
      "\tLoss: 0.08426745235919952\n",
      "\tLoss: 0.09830671548843384\n",
      "\tLoss: 0.08644774556159973\n",
      "[time] Epoch 38: 437.2358230194077s = 7.287263716990128m\n",
      "\n",
      "Epoch 39...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.12838324904441833\n",
      "\tLoss: 0.08528371155261993\n",
      "\tLoss: 0.168412983417511\n",
      "\tLoss: 0.10754068195819855\n",
      "\tLoss: 0.12413691729307175\n",
      "\tLoss: 0.11284652352333069\n",
      "\tLoss: 0.07100217789411545\n",
      "\tLoss: 0.10367153584957123\n",
      "\tLoss: 0.09620600938796997\n",
      "\tLoss: 0.11203533411026001\n",
      "\tLoss: 0.11547864973545074\n",
      "\tLoss: 0.12757879495620728\n",
      "\tLoss: 0.14483782649040222\n",
      "\tLoss: 0.09495367109775543\n",
      "\tLoss: 0.11582838743925095\n",
      "\tLoss: 0.09701376408338547\n",
      "\tLoss: 0.12990033626556396\n",
      "\tLoss: 0.13596507906913757\n",
      "\tLoss: 0.14569926261901855\n",
      "\tLoss: 0.10746584087610245\n",
      "\tLoss: 0.11758051812648773\n",
      "\tLoss: 0.11187142133712769\n",
      "\tLoss: 0.11372797191143036\n",
      "\tLoss: 0.1748233437538147\n",
      "\tLoss: 0.11874961107969284\n",
      "\tLoss: 0.11413689702749252\n",
      "\tLoss: 0.13864311575889587\n",
      "\tLoss: 0.09887208044528961\n",
      "\tLoss: 0.12283827364444733\n",
      "\tLoss: 0.12511716783046722\n",
      "\tLoss: 0.07601767778396606\n",
      "\tLoss: 0.09447062015533447\n",
      "\tLoss: 0.11333177983760834\n",
      "\tLoss: 0.09141477197408676\n",
      "\tLoss: 0.06601032614707947\n",
      "\tLoss: 0.1352251172065735\n",
      "\tLoss: 0.12213970720767975\n",
      "\tLoss: 0.1051076203584671\n",
      "\tLoss: 0.1347593069076538\n",
      "\tLoss: 0.12603801488876343\n",
      "\tLoss: 0.11426907777786255\n",
      "\tLoss: 0.13931939005851746\n",
      "\tLoss: 0.0980299860239029\n",
      "\tLoss: 0.1295800507068634\n",
      "\tLoss: 0.09329798817634583\n",
      "\tLoss: 0.10279323160648346\n",
      "\tLoss: 0.12314491719007492\n",
      "\tLoss: 0.12531475722789764\n",
      "\tLoss: 0.13177171349525452\n",
      "\tLoss: 0.10577436536550522\n",
      "\tLoss: 0.18030765652656555\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.14000040292739868\n",
      "\tLoss: 0.09842891991138458\n",
      "\tLoss: 0.08646634221076965\n",
      "\tLoss: 0.09571152925491333\n",
      "\tLoss: 0.10768422484397888\n",
      "\tLoss: 0.07980309426784515\n",
      "\tLoss: 0.07779249548912048\n",
      "\tLoss: 0.12187105417251587\n",
      "\tLoss: 0.14338043332099915\n",
      "\tLoss: 0.11516499519348145\n",
      "\tLoss: 0.09199757874011993\n",
      "\tLoss: 0.12407003343105316\n",
      "\tLoss: 0.1061771884560585\n",
      "\tLoss: 0.08595575392246246\n",
      "\tLoss: 0.13864950835704803\n",
      "\tLoss: 0.1044125109910965\n",
      "\tLoss: 0.08949756622314453\n",
      "\tLoss: 0.13057734072208405\n",
      "\tLoss: 0.14906957745552063\n",
      "\tLoss: 0.10153828561306\n",
      "\tLoss: 0.09381033480167389\n",
      "\tLoss: 0.09404788166284561\n",
      "\tLoss: 0.0873086228966713\n",
      "\tLoss: 0.15806904435157776\n",
      "\tLoss: 0.12223026901483536\n",
      "\tLoss: 0.12931528687477112\n",
      "\tLoss: 0.10633252561092377\n",
      "\tLoss: 0.1018664687871933\n",
      "\tLoss: 0.13190709054470062\n",
      "\tLoss: 0.1247064396739006\n",
      "\tLoss: 0.12153930217027664\n",
      "\tLoss: 0.08205969631671906\n",
      "\tLoss: 0.08187741786241531\n",
      "\tLoss: 0.12907491624355316\n",
      "\tLoss: 0.10129550099372864\n",
      "\tLoss: 0.10091857612133026\n",
      "\tLoss: 0.13480199873447418\n",
      "\tLoss: 0.11243761330842972\n",
      "\tLoss: 0.08885402232408524\n",
      "\tLoss: 0.11136296391487122\n",
      "\tLoss: 0.11087234318256378\n",
      "\tLoss: 0.13386189937591553\n",
      "\tLoss: 0.1311151385307312\n",
      "\tLoss: 0.1593593955039978\n",
      "\tLoss: 0.1390230357646942\n",
      "\tLoss: 0.08517901599407196\n",
      "\tLoss: 0.1608942449092865\n",
      "\tLoss: 0.0971769392490387\n",
      "\tLoss: 0.11477405577898026\n",
      "\tLoss: 0.1138564869761467\n",
      "\tLoss: 0.13105100393295288\n",
      "[time] Epoch 39: 435.4977745357901s = 7.258296242263168m\n",
      "\n",
      "Epoch 40...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.13051363825798035\n",
      "\tLoss: 0.14949330687522888\n",
      "\tLoss: 0.1402992159128189\n",
      "\tLoss: 0.12463001161813736\n",
      "\tLoss: 0.1544029712677002\n",
      "\tLoss: 0.08789937198162079\n",
      "\tLoss: 0.11450918018817902\n",
      "\tLoss: 0.16679294407367706\n",
      "\tLoss: 0.1315079629421234\n",
      "\tLoss: 0.08513864874839783\n",
      "\tLoss: 0.11392616480588913\n",
      "\tLoss: 0.09084063023328781\n",
      "\tLoss: 0.09123988449573517\n",
      "\tLoss: 0.08729320019483566\n",
      "\tLoss: 0.11458688974380493\n",
      "\tLoss: 0.08389516174793243\n",
      "\tLoss: 0.1386857032775879\n",
      "\tLoss: 0.11745405942201614\n",
      "\tLoss: 0.15431182086467743\n",
      "\tLoss: 0.08417768776416779\n",
      "\tLoss: 0.10752871632575989\n",
      "\tLoss: 0.112280935049057\n",
      "\tLoss: 0.06826995313167572\n",
      "\tLoss: 0.06839974224567413\n",
      "\tLoss: 0.08475160598754883\n",
      "\tLoss: 0.1168113499879837\n",
      "\tLoss: 0.048337869346141815\n",
      "\tLoss: 0.1480436623096466\n",
      "\tLoss: 0.13777096569538116\n",
      "\tLoss: 0.12745514512062073\n",
      "\tLoss: 0.10127944499254227\n",
      "\tLoss: 0.15785883367061615\n",
      "\tLoss: 0.09323765337467194\n",
      "\tLoss: 0.07514403760433197\n",
      "\tLoss: 0.10839325189590454\n",
      "\tLoss: 0.11259286105632782\n",
      "\tLoss: 0.11553261429071426\n",
      "\tLoss: 0.08937114477157593\n",
      "\tLoss: 0.12404129654169083\n",
      "\tLoss: 0.12031872570514679\n",
      "\tLoss: 0.12479980289936066\n",
      "\tLoss: 0.12026673555374146\n",
      "\tLoss: 0.08890187740325928\n",
      "\tLoss: 0.14306098222732544\n",
      "\tLoss: 0.08787654340267181\n",
      "\tLoss: 0.10792194306850433\n",
      "\tLoss: 0.11121319234371185\n",
      "\tLoss: 0.08652065694332123\n",
      "\tLoss: 0.0995812714099884\n",
      "\tLoss: 0.128806471824646\n",
      "\tLoss: 0.10494653880596161\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.10716360062360764\n",
      "\tLoss: 0.13614550232887268\n",
      "\tLoss: 0.1069163978099823\n",
      "\tLoss: 0.11628351360559464\n",
      "\tLoss: 0.0837555006146431\n",
      "\tLoss: 0.11658942699432373\n",
      "\tLoss: 0.08887232095003128\n",
      "\tLoss: 0.1476937085390091\n",
      "\tLoss: 0.11790652573108673\n",
      "\tLoss: 0.11948353052139282\n",
      "\tLoss: 0.09900093823671341\n",
      "\tLoss: 0.1178600937128067\n",
      "\tLoss: 0.1168411523103714\n",
      "\tLoss: 0.1171913594007492\n",
      "\tLoss: 0.1041853278875351\n",
      "\tLoss: 0.12133365869522095\n",
      "\tLoss: 0.11491531133651733\n",
      "\tLoss: 0.06411496549844742\n",
      "\tLoss: 0.11861362308263779\n",
      "\tLoss: 0.1395942121744156\n",
      "\tLoss: 0.12499099224805832\n",
      "\tLoss: 0.135591521859169\n",
      "\tLoss: 0.08057679235935211\n",
      "\tLoss: 0.10130635648965836\n",
      "\tLoss: 0.10807529091835022\n",
      "\tLoss: 0.11830251663923264\n",
      "\tLoss: 0.11883556842803955\n",
      "\tLoss: 0.11347948759794235\n",
      "\tLoss: 0.08164772391319275\n",
      "\tLoss: 0.0954420417547226\n",
      "\tLoss: 0.1373852640390396\n",
      "\tLoss: 0.09112316370010376\n",
      "\tLoss: 0.11509962379932404\n",
      "\tLoss: 0.10491567850112915\n",
      "\tLoss: 0.09516259282827377\n",
      "\tLoss: 0.09973839670419693\n",
      "\tLoss: 0.1520429104566574\n",
      "\tLoss: 0.1453690528869629\n",
      "\tLoss: 0.0761568546295166\n",
      "\tLoss: 0.13702544569969177\n",
      "\tLoss: 0.0918622612953186\n",
      "\tLoss: 0.12327798455953598\n",
      "\tLoss: 0.15017373859882355\n",
      "\tLoss: 0.12153352051973343\n",
      "\tLoss: 0.10481911897659302\n",
      "\tLoss: 0.10311071574687958\n",
      "\tLoss: 0.0912775918841362\n",
      "\tLoss: 0.0880255252122879\n",
      "\tLoss: 0.11886070668697357\n",
      "\tLoss: 0.07230491936206818\n",
      "\tLoss: 0.06966514140367508\n",
      "[time] Epoch 40: 442.65254449658096s = 7.37754240827635m\n",
      "\n",
      "Epoch 41...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.14638742804527283\n",
      "\tLoss: 0.1021822988986969\n",
      "\tLoss: 0.1161995381116867\n",
      "\tLoss: 0.07329760491847992\n",
      "\tLoss: 0.12390017509460449\n",
      "\tLoss: 0.13698147237300873\n",
      "\tLoss: 0.15371069312095642\n",
      "\tLoss: 0.12839031219482422\n",
      "\tLoss: 0.14932474493980408\n",
      "\tLoss: 0.15301772952079773\n",
      "\tLoss: 0.09745887666940689\n",
      "\tLoss: 0.06404685974121094\n",
      "\tLoss: 0.10673683881759644\n",
      "\tLoss: 0.06187766045331955\n",
      "\tLoss: 0.1314389407634735\n",
      "\tLoss: 0.09633168578147888\n",
      "\tLoss: 0.09596439450979233\n",
      "\tLoss: 0.08608566969633102\n",
      "\tLoss: 0.12157300114631653\n",
      "\tLoss: 0.10364682227373123\n",
      "\tLoss: 0.09807050228118896\n",
      "\tLoss: 0.06998895108699799\n",
      "\tLoss: 0.07651146501302719\n",
      "\tLoss: 0.08615860342979431\n",
      "\tLoss: 0.12029501795768738\n",
      "\tLoss: 0.12021145224571228\n",
      "\tLoss: 0.10760417580604553\n",
      "\tLoss: 0.08188126981258392\n",
      "\tLoss: 0.14196054637432098\n",
      "\tLoss: 0.0777309238910675\n",
      "\tLoss: 0.14137956500053406\n",
      "\tLoss: 0.12110843509435654\n",
      "\tLoss: 0.07823432981967926\n",
      "\tLoss: 0.08179458975791931\n",
      "\tLoss: 0.14733392000198364\n",
      "\tLoss: 0.10959525406360626\n",
      "\tLoss: 0.11324020475149155\n",
      "\tLoss: 0.13385602831840515\n",
      "\tLoss: 0.1345973163843155\n",
      "\tLoss: 0.10674208402633667\n",
      "\tLoss: 0.08696399629116058\n",
      "\tLoss: 0.14361770451068878\n",
      "\tLoss: 0.0828089490532875\n",
      "\tLoss: 0.09972299635410309\n",
      "\tLoss: 0.11278232932090759\n",
      "\tLoss: 0.0993591919541359\n",
      "\tLoss: 0.1260630339384079\n",
      "\tLoss: 0.1516479253768921\n",
      "\tLoss: 0.06276747584342957\n",
      "\tLoss: 0.14255473017692566\n",
      "\tLoss: 0.10406665503978729\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.10401690006256104\n",
      "\tLoss: 0.10239595174789429\n",
      "\tLoss: 0.14191709458827972\n",
      "\tLoss: 0.13400611281394958\n",
      "\tLoss: 0.12583929300308228\n",
      "\tLoss: 0.0949646532535553\n",
      "\tLoss: 0.08567364513874054\n",
      "\tLoss: 0.14051848649978638\n",
      "\tLoss: 0.1395706832408905\n",
      "\tLoss: 0.09814390540122986\n",
      "\tLoss: 0.10328133404254913\n",
      "\tLoss: 0.11235316097736359\n",
      "\tLoss: 0.11102963984012604\n",
      "\tLoss: 0.09194866567850113\n",
      "\tLoss: 0.16426220536231995\n",
      "\tLoss: 0.15873734652996063\n",
      "\tLoss: 0.12800860404968262\n",
      "\tLoss: 0.07903996109962463\n",
      "\tLoss: 0.12881451845169067\n",
      "\tLoss: 0.10620193183422089\n",
      "\tLoss: 0.11254364997148514\n",
      "\tLoss: 0.08875370025634766\n",
      "\tLoss: 0.12920723855495453\n",
      "\tLoss: 0.07244624197483063\n",
      "\tLoss: 0.10849878191947937\n",
      "\tLoss: 0.07900837063789368\n",
      "\tLoss: 0.15793582797050476\n",
      "\tLoss: 0.15074168145656586\n",
      "\tLoss: 0.1547473669052124\n",
      "\tLoss: 0.07515443861484528\n",
      "\tLoss: 0.0933661162853241\n",
      "\tLoss: 0.08246360719203949\n",
      "\tLoss: 0.08789897710084915\n",
      "\tLoss: 0.11052629351615906\n",
      "\tLoss: 0.12254704535007477\n",
      "\tLoss: 0.110658198595047\n",
      "\tLoss: 0.09646350890398026\n",
      "\tLoss: 0.11623166501522064\n",
      "\tLoss: 0.09176842868328094\n",
      "\tLoss: 0.08986687660217285\n",
      "\tLoss: 0.12230624258518219\n",
      "\tLoss: 0.11787162721157074\n",
      "\tLoss: 0.09019805490970612\n",
      "\tLoss: 0.18596285581588745\n",
      "\tLoss: 0.12366800010204315\n",
      "\tLoss: 0.09281512349843979\n",
      "\tLoss: 0.10712042450904846\n",
      "\tLoss: 0.1029021143913269\n",
      "\tLoss: 0.08920552581548691\n",
      "\tLoss: 0.12089353799819946\n",
      "\tLoss: 0.1302221715450287\n",
      "[time] Epoch 41: 439.29718890972435s = 7.321619815162072m\n",
      "\n",
      "Epoch 42...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.12047840654850006\n",
      "\tLoss: 0.12238530069589615\n",
      "\tLoss: 0.11126943677663803\n",
      "\tLoss: 0.14000797271728516\n",
      "\tLoss: 0.0784892737865448\n",
      "\tLoss: 0.08252477645874023\n",
      "\tLoss: 0.09868045151233673\n",
      "\tLoss: 0.08518053591251373\n",
      "\tLoss: 0.1452309489250183\n",
      "\tLoss: 0.08463713526725769\n",
      "\tLoss: 0.1020190492272377\n",
      "\tLoss: 0.06674154847860336\n",
      "\tLoss: 0.13505104184150696\n",
      "\tLoss: 0.1193297877907753\n",
      "\tLoss: 0.11478570103645325\n",
      "\tLoss: 0.09772324562072754\n",
      "\tLoss: 0.0853743776679039\n",
      "\tLoss: 0.1371396780014038\n",
      "\tLoss: 0.1507217288017273\n",
      "\tLoss: 0.13721248507499695\n",
      "\tLoss: 0.11464866995811462\n",
      "\tLoss: 0.08950667083263397\n",
      "\tLoss: 0.13619592785835266\n",
      "\tLoss: 0.0904410257935524\n",
      "\tLoss: 0.1126556247472763\n",
      "\tLoss: 0.12312909960746765\n",
      "\tLoss: 0.13450123369693756\n",
      "\tLoss: 0.07659244537353516\n",
      "\tLoss: 0.10828666388988495\n",
      "\tLoss: 0.14067915081977844\n",
      "\tLoss: 0.18808028101921082\n",
      "\tLoss: 0.13012723624706268\n",
      "\tLoss: 0.1253243386745453\n",
      "\tLoss: 0.1014142632484436\n",
      "\tLoss: 0.1118168830871582\n",
      "\tLoss: 0.10701459646224976\n",
      "\tLoss: 0.15804502367973328\n",
      "\tLoss: 0.09768553078174591\n",
      "\tLoss: 0.10034061223268509\n",
      "\tLoss: 0.14149892330169678\n",
      "\tLoss: 0.13965871930122375\n",
      "\tLoss: 0.1402556598186493\n",
      "\tLoss: 0.08173055946826935\n",
      "\tLoss: 0.12346478551626205\n",
      "\tLoss: 0.10267199575901031\n",
      "\tLoss: 0.1385268270969391\n",
      "\tLoss: 0.11283303797245026\n",
      "\tLoss: 0.12782615423202515\n",
      "\tLoss: 0.09889904409646988\n",
      "\tLoss: 0.140981525182724\n",
      "\tLoss: 0.12536385655403137\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.12841615080833435\n",
      "\tLoss: 0.16928055882453918\n",
      "\tLoss: 0.12371979653835297\n",
      "\tLoss: 0.12530827522277832\n",
      "\tLoss: 0.1255023330450058\n",
      "\tLoss: 0.09393291175365448\n",
      "\tLoss: 0.0653030052781105\n",
      "\tLoss: 0.12869888544082642\n",
      "\tLoss: 0.07473274320363998\n",
      "\tLoss: 0.1098414808511734\n",
      "\tLoss: 0.12760601937770844\n",
      "\tLoss: 0.1207544282078743\n",
      "\tLoss: 0.11857974529266357\n",
      "\tLoss: 0.08697184175252914\n",
      "\tLoss: 0.15014103055000305\n",
      "\tLoss: 0.1270042508840561\n",
      "\tLoss: 0.07578781247138977\n",
      "\tLoss: 0.06489653140306473\n",
      "\tLoss: 0.10456670820713043\n",
      "\tLoss: 0.13295826315879822\n",
      "\tLoss: 0.11639164388179779\n",
      "\tLoss: 0.0772983729839325\n",
      "\tLoss: 0.10443424433469772\n",
      "\tLoss: 0.0824505090713501\n",
      "\tLoss: 0.10227514803409576\n",
      "\tLoss: 0.10545191913843155\n",
      "\tLoss: 0.13238130509853363\n",
      "\tLoss: 0.11658597737550735\n",
      "\tLoss: 0.08031298965215683\n",
      "\tLoss: 0.08216410130262375\n",
      "\tLoss: 0.08514757454395294\n",
      "\tLoss: 0.07191982865333557\n",
      "\tLoss: 0.07972276210784912\n",
      "\tLoss: 0.08828394114971161\n",
      "\tLoss: 0.09817828238010406\n",
      "\tLoss: 0.12138228118419647\n",
      "\tLoss: 0.12521743774414062\n",
      "\tLoss: 0.09458114206790924\n",
      "\tLoss: 0.11416012048721313\n",
      "\tLoss: 0.1408728063106537\n",
      "\tLoss: 0.11576662212610245\n",
      "\tLoss: 0.09720286726951599\n",
      "\tLoss: 0.08972786366939545\n",
      "\tLoss: 0.09011688083410263\n",
      "\tLoss: 0.09403935074806213\n",
      "\tLoss: 0.08466421812772751\n",
      "\tLoss: 0.10108673572540283\n",
      "\tLoss: 0.1189921498298645\n",
      "\tLoss: 0.09446495026350021\n",
      "\tLoss: 0.0808352679014206\n",
      "\tLoss: 0.1305404007434845\n",
      "[time] Epoch 42: 438.37776998616755s = 7.306296166436126m\n",
      "\n",
      "Epoch 43...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.07417194545269012\n",
      "\tLoss: 0.11575353145599365\n",
      "\tLoss: 0.0644715428352356\n",
      "\tLoss: 0.12359721958637238\n",
      "\tLoss: 0.06888853758573532\n",
      "\tLoss: 0.06987316906452179\n",
      "\tLoss: 0.06041726842522621\n",
      "\tLoss: 0.12176856398582458\n",
      "\tLoss: 0.14111557602882385\n",
      "\tLoss: 0.1358671933412552\n",
      "\tLoss: 0.09374938905239105\n",
      "\tLoss: 0.1465071439743042\n",
      "\tLoss: 0.09118841588497162\n",
      "\tLoss: 0.10927309095859528\n",
      "\tLoss: 0.13773976266384125\n",
      "\tLoss: 0.17051884531974792\n",
      "\tLoss: 0.08226560056209564\n",
      "\tLoss: 0.0872674211859703\n",
      "\tLoss: 0.10210992395877838\n",
      "\tLoss: 0.10258036106824875\n",
      "\tLoss: 0.09860999882221222\n",
      "\tLoss: 0.06027888134121895\n",
      "\tLoss: 0.11665304005146027\n",
      "\tLoss: 0.10878066718578339\n",
      "\tLoss: 0.0856022983789444\n",
      "\tLoss: 0.11686401814222336\n",
      "\tLoss: 0.08758678287267685\n",
      "\tLoss: 0.09919308125972748\n",
      "\tLoss: 0.10483242571353912\n",
      "\tLoss: 0.09785972535610199\n",
      "\tLoss: 0.12374676018953323\n",
      "\tLoss: 0.07558596134185791\n",
      "\tLoss: 0.1301184892654419\n",
      "\tLoss: 0.14222723245620728\n",
      "\tLoss: 0.13459937274456024\n",
      "\tLoss: 0.08517935872077942\n",
      "\tLoss: 0.1258086860179901\n",
      "\tLoss: 0.09748919308185577\n",
      "\tLoss: 0.11972065269947052\n",
      "\tLoss: 0.08282558619976044\n",
      "\tLoss: 0.08803276717662811\n",
      "\tLoss: 0.09884418547153473\n",
      "\tLoss: 0.13027629256248474\n",
      "\tLoss: 0.09984389692544937\n",
      "\tLoss: 0.11789266765117645\n",
      "\tLoss: 0.11903052031993866\n",
      "\tLoss: 0.17956310510635376\n",
      "\tLoss: 0.10491588711738586\n",
      "\tLoss: 0.0658191442489624\n",
      "\tLoss: 0.1017950251698494\n",
      "\tLoss: 0.08481374382972717\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.13956479728221893\n",
      "\tLoss: 0.10115890949964523\n",
      "\tLoss: 0.13860757648944855\n",
      "\tLoss: 0.12189579010009766\n",
      "\tLoss: 0.12035199999809265\n",
      "\tLoss: 0.10947715491056442\n",
      "\tLoss: 0.09324777871370316\n",
      "\tLoss: 0.11488374322652817\n",
      "\tLoss: 0.10939401388168335\n",
      "\tLoss: 0.09616390615701675\n",
      "\tLoss: 0.10596700012683868\n",
      "\tLoss: 0.11691584438085556\n",
      "\tLoss: 0.11862330138683319\n",
      "\tLoss: 0.14494407176971436\n",
      "\tLoss: 0.11131156980991364\n",
      "\tLoss: 0.14706946909427643\n",
      "\tLoss: 0.15724577009677887\n",
      "\tLoss: 0.145694300532341\n",
      "\tLoss: 0.11999210715293884\n",
      "\tLoss: 0.12762892246246338\n",
      "\tLoss: 0.16107934713363647\n",
      "\tLoss: 0.13804754614830017\n",
      "\tLoss: 0.07049348205327988\n",
      "\tLoss: 0.14727775752544403\n",
      "\tLoss: 0.1203826442360878\n",
      "\tLoss: 0.12898750603199005\n",
      "\tLoss: 0.10409390181303024\n",
      "\tLoss: 0.08691852539777756\n",
      "\tLoss: 0.13473379611968994\n",
      "\tLoss: 0.12359806895256042\n",
      "\tLoss: 0.13124880194664001\n",
      "\tLoss: 0.09243780374526978\n",
      "\tLoss: 0.09588472545146942\n",
      "\tLoss: 0.11618533730506897\n",
      "\tLoss: 0.12938067317008972\n",
      "\tLoss: 0.08814176172018051\n",
      "\tLoss: 0.09692467749118805\n",
      "\tLoss: 0.1518414318561554\n",
      "\tLoss: 0.17872382700443268\n",
      "\tLoss: 0.132967010140419\n",
      "\tLoss: 0.0883970707654953\n",
      "\tLoss: 0.14656183123588562\n",
      "\tLoss: 0.1538497507572174\n",
      "\tLoss: 0.10356950759887695\n",
      "\tLoss: 0.13397328555583954\n",
      "\tLoss: 0.1382087916135788\n",
      "\tLoss: 0.10475735366344452\n",
      "\tLoss: 0.113139308989048\n",
      "\tLoss: 0.09383527934551239\n",
      "\tLoss: 0.10193555802106857\n",
      "\tLoss: 0.11212041229009628\n",
      "[time] Epoch 43: 437.16148316208273s = 7.286024719368045m\n",
      "\n",
      "Epoch 44...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.09932664036750793\n",
      "\tLoss: 0.1119317039847374\n",
      "\tLoss: 0.12594342231750488\n",
      "\tLoss: 0.11785932630300522\n",
      "\tLoss: 0.10888680070638657\n",
      "\tLoss: 0.08715282380580902\n",
      "\tLoss: 0.07982536405324936\n",
      "\tLoss: 0.10490533709526062\n",
      "\tLoss: 0.1078554093837738\n",
      "\tLoss: 0.09130916744470596\n",
      "\tLoss: 0.09043385088443756\n",
      "\tLoss: 0.08251754939556122\n",
      "\tLoss: 0.10033658146858215\n",
      "\tLoss: 0.1416274607181549\n",
      "\tLoss: 0.12055137753486633\n",
      "\tLoss: 0.10359321534633636\n",
      "\tLoss: 0.07756273448467255\n",
      "\tLoss: 0.10256662219762802\n",
      "\tLoss: 0.14153534173965454\n",
      "\tLoss: 0.07760800421237946\n",
      "\tLoss: 0.08441296219825745\n",
      "\tLoss: 0.10757040977478027\n",
      "\tLoss: 0.10591605305671692\n",
      "\tLoss: 0.12207093089818954\n",
      "\tLoss: 0.107437863945961\n",
      "\tLoss: 0.1151173785328865\n",
      "\tLoss: 0.07216796278953552\n",
      "\tLoss: 0.11231080442667007\n",
      "\tLoss: 0.11512020230293274\n",
      "\tLoss: 0.09947866201400757\n",
      "\tLoss: 0.1416431963443756\n",
      "\tLoss: 0.09751996397972107\n",
      "\tLoss: 0.10583306103944778\n",
      "\tLoss: 0.09987702965736389\n",
      "\tLoss: 0.11384470760822296\n",
      "\tLoss: 0.07343222200870514\n",
      "\tLoss: 0.130051851272583\n",
      "\tLoss: 0.14144845306873322\n",
      "\tLoss: 0.10830719023942947\n",
      "\tLoss: 0.10056603699922562\n",
      "\tLoss: 0.06124673783779144\n",
      "\tLoss: 0.1016884595155716\n",
      "\tLoss: 0.13209696114063263\n",
      "\tLoss: 0.10781952738761902\n",
      "\tLoss: 0.12959782779216766\n",
      "\tLoss: 0.07497341930866241\n",
      "\tLoss: 0.0782850831747055\n",
      "\tLoss: 0.10779151320457458\n",
      "\tLoss: 0.1587371528148651\n",
      "\tLoss: 0.10531233251094818\n",
      "\tLoss: 0.16370904445648193\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.10391740500926971\n",
      "\tLoss: 0.10121375322341919\n",
      "\tLoss: 0.12733235955238342\n",
      "\tLoss: 0.1516382396221161\n",
      "\tLoss: 0.11888688057661057\n",
      "\tLoss: 0.12639740109443665\n",
      "\tLoss: 0.07831397652626038\n",
      "\tLoss: 0.10076708346605301\n",
      "\tLoss: 0.11364629119634628\n",
      "\tLoss: 0.10571003705263138\n",
      "\tLoss: 0.11397965997457504\n",
      "\tLoss: 0.12071284651756287\n",
      "\tLoss: 0.12017503380775452\n",
      "\tLoss: 0.08083699643611908\n",
      "\tLoss: 0.09197588264942169\n",
      "\tLoss: 0.08434665203094482\n",
      "\tLoss: 0.1265539675951004\n",
      "\tLoss: 0.110012948513031\n",
      "\tLoss: 0.09845595806837082\n",
      "\tLoss: 0.08941073715686798\n",
      "\tLoss: 0.11989150941371918\n",
      "\tLoss: 0.08164504170417786\n",
      "\tLoss: 0.14790838956832886\n",
      "\tLoss: 0.11083327978849411\n",
      "\tLoss: 0.09158438444137573\n",
      "\tLoss: 0.13082081079483032\n",
      "\tLoss: 0.10570521652698517\n",
      "\tLoss: 0.15571552515029907\n",
      "\tLoss: 0.12463274598121643\n",
      "\tLoss: 0.07562976330518723\n",
      "\tLoss: 0.09487476944923401\n",
      "\tLoss: 0.07999913394451141\n",
      "\tLoss: 0.09835025668144226\n",
      "\tLoss: 0.14479029178619385\n",
      "\tLoss: 0.11573287844657898\n",
      "\tLoss: 0.16017946600914001\n",
      "\tLoss: 0.14120420813560486\n",
      "\tLoss: 0.10619746148586273\n",
      "\tLoss: 0.10671821236610413\n",
      "\tLoss: 0.14984960854053497\n",
      "\tLoss: 0.17257361114025116\n",
      "\tLoss: 0.16693158447742462\n",
      "\tLoss: 0.06375560164451599\n",
      "\tLoss: 0.10372284054756165\n",
      "\tLoss: 0.11336728185415268\n",
      "\tLoss: 0.09829326719045639\n",
      "\tLoss: 0.11603435128927231\n",
      "\tLoss: 0.10099814832210541\n",
      "\tLoss: 0.07101598381996155\n",
      "\tLoss: 0.08649343997240067\n",
      "\tLoss: 0.17405478656291962\n",
      "[time] Epoch 44: 431.51342287193984s = 7.191890381198998m\n",
      "\n",
      "Epoch 45...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.11436355859041214\n",
      "\tLoss: 0.12151554226875305\n",
      "\tLoss: 0.11607351899147034\n",
      "\tLoss: 0.09378215670585632\n",
      "\tLoss: 0.1335669457912445\n",
      "\tLoss: 0.12788864970207214\n",
      "\tLoss: 0.12869523465633392\n",
      "\tLoss: 0.06940478086471558\n",
      "\tLoss: 0.13561981916427612\n",
      "\tLoss: 0.13832983374595642\n",
      "\tLoss: 0.12292162328958511\n",
      "\tLoss: 0.14477571845054626\n",
      "\tLoss: 0.1184772178530693\n",
      "\tLoss: 0.14987049996852875\n",
      "\tLoss: 0.13082683086395264\n",
      "\tLoss: 0.1048281267285347\n",
      "\tLoss: 0.10807930678129196\n",
      "\tLoss: 0.10150828212499619\n",
      "\tLoss: 0.06821005046367645\n",
      "\tLoss: 0.12170197069644928\n",
      "\tLoss: 0.06718597561120987\n",
      "\tLoss: 0.09656953811645508\n",
      "\tLoss: 0.1318955421447754\n",
      "\tLoss: 0.11679578572511673\n",
      "\tLoss: 0.11200267821550369\n",
      "\tLoss: 0.07178597152233124\n",
      "\tLoss: 0.09713224321603775\n",
      "\tLoss: 0.10525408387184143\n",
      "\tLoss: 0.1316540390253067\n",
      "\tLoss: 0.08603700995445251\n",
      "\tLoss: 0.15205253660678864\n",
      "\tLoss: 0.09925349056720734\n",
      "\tLoss: 0.109296515583992\n",
      "\tLoss: 0.11531330645084381\n",
      "\tLoss: 0.11970880627632141\n",
      "\tLoss: 0.13485047221183777\n",
      "\tLoss: 0.1334448754787445\n",
      "\tLoss: 0.1285194456577301\n",
      "\tLoss: 0.15290941298007965\n",
      "\tLoss: 0.07495780289173126\n",
      "\tLoss: 0.06250422447919846\n",
      "\tLoss: 0.12918618321418762\n",
      "\tLoss: 0.14674201607704163\n",
      "\tLoss: 0.15684333443641663\n",
      "\tLoss: 0.08596601337194443\n",
      "\tLoss: 0.10934256762266159\n",
      "\tLoss: 0.1107354462146759\n",
      "\tLoss: 0.11066269874572754\n",
      "\tLoss: 0.1423155814409256\n",
      "\tLoss: 0.09764464944601059\n",
      "\tLoss: 0.10191909968852997\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.08792734146118164\n",
      "\tLoss: 0.08231841027736664\n",
      "\tLoss: 0.10513471066951752\n",
      "\tLoss: 0.1069442629814148\n",
      "\tLoss: 0.0767320767045021\n",
      "\tLoss: 0.08079826831817627\n",
      "\tLoss: 0.08194328844547272\n",
      "\tLoss: 0.06807490438222885\n",
      "\tLoss: 0.19293266534805298\n",
      "\tLoss: 0.17769357562065125\n",
      "\tLoss: 0.0730258896946907\n",
      "\tLoss: 0.11950480192899704\n",
      "\tLoss: 0.07324467599391937\n",
      "\tLoss: 0.1056348979473114\n",
      "\tLoss: 0.08267011493444443\n",
      "\tLoss: 0.10366719216108322\n",
      "\tLoss: 0.11242196708917618\n",
      "\tLoss: 0.11937880516052246\n",
      "\tLoss: 0.10477182269096375\n",
      "\tLoss: 0.1400839388370514\n",
      "\tLoss: 0.11023613810539246\n",
      "\tLoss: 0.16020739078521729\n",
      "\tLoss: 0.127241849899292\n",
      "\tLoss: 0.09244654327630997\n",
      "\tLoss: 0.08112698793411255\n",
      "\tLoss: 0.1055285707116127\n",
      "\tLoss: 0.08718973398208618\n",
      "\tLoss: 0.1012837290763855\n",
      "\tLoss: 0.10864923894405365\n",
      "\tLoss: 0.12022112309932709\n",
      "\tLoss: 0.12496519088745117\n",
      "\tLoss: 0.09362728148698807\n",
      "\tLoss: 0.11887852847576141\n",
      "\tLoss: 0.11605080217123032\n",
      "\tLoss: 0.13412046432495117\n",
      "\tLoss: 0.07336769998073578\n",
      "\tLoss: 0.10553329437971115\n",
      "\tLoss: 0.07098840922117233\n",
      "\tLoss: 0.11908157169818878\n",
      "\tLoss: 0.0733376294374466\n",
      "\tLoss: 0.08989869803190231\n",
      "\tLoss: 0.1185251846909523\n",
      "\tLoss: 0.1407695859670639\n",
      "\tLoss: 0.09066477417945862\n",
      "\tLoss: 0.14330479502677917\n",
      "\tLoss: 0.08344469219446182\n",
      "\tLoss: 0.09552864730358124\n",
      "\tLoss: 0.0714433565735817\n",
      "\tLoss: 0.11281365156173706\n",
      "\tLoss: 0.1311066746711731\n",
      "\tLoss: 0.10887626558542252\n",
      "[time] Epoch 45: 439.1676380271092s = 7.3194606337851535m\n",
      "\n",
      "Epoch 46...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.07916589081287384\n",
      "\tLoss: 0.11719957739114761\n",
      "\tLoss: 0.10406269878149033\n",
      "\tLoss: 0.09209701418876648\n",
      "\tLoss: 0.1500488668680191\n",
      "\tLoss: 0.12273768335580826\n",
      "\tLoss: 0.1086704209446907\n",
      "\tLoss: 0.16342273354530334\n",
      "\tLoss: 0.0968792587518692\n",
      "\tLoss: 0.13757775723934174\n",
      "\tLoss: 0.11574763059616089\n",
      "\tLoss: 0.11897462606430054\n",
      "\tLoss: 0.12623971700668335\n",
      "\tLoss: 0.0875101312994957\n",
      "\tLoss: 0.06544110178947449\n",
      "\tLoss: 0.13628943264484406\n",
      "\tLoss: 0.11996246874332428\n",
      "\tLoss: 0.09098995476961136\n",
      "\tLoss: 0.12194731086492538\n",
      "\tLoss: 0.11231386661529541\n",
      "\tLoss: 0.11295169591903687\n",
      "\tLoss: 0.07706230878829956\n",
      "\tLoss: 0.14037171006202698\n",
      "\tLoss: 0.09117132425308228\n",
      "\tLoss: 0.10832393169403076\n",
      "\tLoss: 0.12002813071012497\n",
      "\tLoss: 0.10319075733423233\n",
      "\tLoss: 0.11648254841566086\n",
      "\tLoss: 0.10358912497758865\n",
      "\tLoss: 0.08427092432975769\n",
      "\tLoss: 0.13455471396446228\n",
      "\tLoss: 0.13234826922416687\n",
      "\tLoss: 0.117113396525383\n",
      "\tLoss: 0.10001711547374725\n",
      "\tLoss: 0.10554911196231842\n",
      "\tLoss: 0.12224500626325607\n",
      "\tLoss: 0.09077522903680801\n",
      "\tLoss: 0.12313250452280045\n",
      "\tLoss: 0.08069606870412827\n",
      "\tLoss: 0.1366710662841797\n",
      "\tLoss: 0.12880873680114746\n",
      "\tLoss: 0.09721337258815765\n",
      "\tLoss: 0.11203809082508087\n",
      "\tLoss: 0.11337026208639145\n",
      "\tLoss: 0.10794387757778168\n",
      "\tLoss: 0.1151813492178917\n",
      "\tLoss: 0.10573191940784454\n",
      "\tLoss: 0.15273693203926086\n",
      "\tLoss: 0.07886266708374023\n",
      "\tLoss: 0.1124684140086174\n",
      "\tLoss: 0.11254613101482391\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.1055959016084671\n",
      "\tLoss: 0.13251854479312897\n",
      "\tLoss: 0.11065208166837692\n",
      "\tLoss: 0.11004450917243958\n",
      "\tLoss: 0.11706921458244324\n",
      "\tLoss: 0.16486212611198425\n",
      "\tLoss: 0.10111619532108307\n",
      "\tLoss: 0.09957678616046906\n",
      "\tLoss: 0.09153048694133759\n",
      "\tLoss: 0.13625457882881165\n",
      "\tLoss: 0.08127416670322418\n",
      "\tLoss: 0.09617461264133453\n",
      "\tLoss: 0.1272837519645691\n",
      "\tLoss: 0.10255207866430283\n",
      "\tLoss: 0.11952895671129227\n",
      "\tLoss: 0.12835054099559784\n",
      "\tLoss: 0.15093842148780823\n",
      "\tLoss: 0.15421253442764282\n",
      "\tLoss: 0.12947024405002594\n",
      "\tLoss: 0.09751135110855103\n",
      "\tLoss: 0.07697146385908127\n",
      "\tLoss: 0.10051251947879791\n",
      "\tLoss: 0.10363681614398956\n",
      "\tLoss: 0.10428342968225479\n",
      "\tLoss: 0.09283660352230072\n",
      "\tLoss: 0.13615790009498596\n",
      "\tLoss: 0.11114956438541412\n",
      "\tLoss: 0.09086954593658447\n",
      "\tLoss: 0.13554424047470093\n",
      "\tLoss: 0.1600351482629776\n",
      "\tLoss: 0.10293352603912354\n",
      "\tLoss: 0.12339074909687042\n",
      "\tLoss: 0.11331886798143387\n",
      "\tLoss: 0.15856367349624634\n",
      "\tLoss: 0.13650844991207123\n",
      "\tLoss: 0.12148736417293549\n",
      "\tLoss: 0.10250973701477051\n",
      "\tLoss: 0.12191681563854218\n",
      "\tLoss: 0.13650354743003845\n",
      "\tLoss: 0.08885404467582703\n",
      "\tLoss: 0.0976775735616684\n",
      "\tLoss: 0.09070168435573578\n",
      "\tLoss: 0.10767710208892822\n",
      "\tLoss: 0.12378513067960739\n",
      "\tLoss: 0.10245166718959808\n",
      "\tLoss: 0.0892428383231163\n",
      "\tLoss: 0.11600901931524277\n",
      "\tLoss: 0.10085839778184891\n",
      "\tLoss: 0.11176715791225433\n",
      "\tLoss: 0.2378450632095337\n",
      "\tLoss: 0.09709721803665161\n",
      "[time] Epoch 46: 437.224591486156s = 7.287076524769266m\n",
      "\n",
      "Epoch 47...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.13250699639320374\n",
      "\tLoss: 0.11669346690177917\n",
      "\tLoss: 0.16214385628700256\n",
      "\tLoss: 0.14550577104091644\n",
      "\tLoss: 0.10397084057331085\n",
      "\tLoss: 0.11240527033805847\n",
      "\tLoss: 0.11447691917419434\n",
      "\tLoss: 0.10522167384624481\n",
      "\tLoss: 0.11120297014713287\n",
      "\tLoss: 0.15520024299621582\n",
      "\tLoss: 0.07740522921085358\n",
      "\tLoss: 0.0890873521566391\n",
      "\tLoss: 0.1026727482676506\n",
      "\tLoss: 0.10364788770675659\n",
      "\tLoss: 0.09970119595527649\n",
      "\tLoss: 0.07598145306110382\n",
      "\tLoss: 0.10049035400152206\n",
      "\tLoss: 0.10644645988941193\n",
      "\tLoss: 0.09448865801095963\n",
      "\tLoss: 0.13079598546028137\n",
      "\tLoss: 0.094207763671875\n",
      "\tLoss: 0.14785268902778625\n",
      "\tLoss: 0.07707203179597855\n",
      "\tLoss: 0.09996965527534485\n",
      "\tLoss: 0.12886092066764832\n",
      "\tLoss: 0.07767164707183838\n",
      "\tLoss: 0.07735508680343628\n",
      "\tLoss: 0.09116964042186737\n",
      "\tLoss: 0.07461021095514297\n",
      "\tLoss: 0.06303144246339798\n",
      "\tLoss: 0.07776477187871933\n",
      "\tLoss: 0.11639832705259323\n",
      "\tLoss: 0.11169570684432983\n",
      "\tLoss: 0.08174705505371094\n",
      "\tLoss: 0.13170868158340454\n",
      "\tLoss: 0.10422289371490479\n",
      "\tLoss: 0.10277118533849716\n",
      "\tLoss: 0.11411979794502258\n",
      "\tLoss: 0.09543538093566895\n",
      "\tLoss: 0.11302768439054489\n",
      "\tLoss: 0.1110144704580307\n",
      "\tLoss: 0.11697617173194885\n",
      "\tLoss: 0.09480611234903336\n",
      "\tLoss: 0.13248032331466675\n",
      "\tLoss: 0.1040118932723999\n",
      "\tLoss: 0.12367644160985947\n",
      "\tLoss: 0.09520354866981506\n",
      "\tLoss: 0.10254637151956558\n",
      "\tLoss: 0.0948483794927597\n",
      "\tLoss: 0.08893519639968872\n",
      "\tLoss: 0.12966963648796082\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.09958449751138687\n",
      "\tLoss: 0.09596283733844757\n",
      "\tLoss: 0.07437027245759964\n",
      "\tLoss: 0.11592528969049454\n",
      "\tLoss: 0.09190593659877777\n",
      "\tLoss: 0.11936923861503601\n",
      "\tLoss: 0.09550260007381439\n",
      "\tLoss: 0.08681847900152206\n",
      "\tLoss: 0.0941280722618103\n",
      "\tLoss: 0.13927105069160461\n",
      "\tLoss: 0.10965792834758759\n",
      "\tLoss: 0.13000789284706116\n",
      "\tLoss: 0.08116188645362854\n",
      "\tLoss: 0.081867516040802\n",
      "\tLoss: 0.13406825065612793\n",
      "\tLoss: 0.12492980062961578\n",
      "\tLoss: 0.13000597059726715\n",
      "\tLoss: 0.10246849060058594\n",
      "\tLoss: 0.107307069003582\n",
      "\tLoss: 0.13657376170158386\n",
      "\tLoss: 0.07396115362644196\n",
      "\tLoss: 0.09465861320495605\n",
      "\tLoss: 0.10354821383953094\n",
      "\tLoss: 0.09962212294340134\n",
      "\tLoss: 0.12459761649370193\n",
      "\tLoss: 0.11386274546384811\n",
      "\tLoss: 0.07987098395824432\n",
      "\tLoss: 0.1285281777381897\n",
      "\tLoss: 0.12809357047080994\n",
      "\tLoss: 0.1432092785835266\n",
      "\tLoss: 0.10796233266592026\n",
      "\tLoss: 0.10138160735368729\n",
      "\tLoss: 0.08911067247390747\n",
      "\tLoss: 0.0723683312535286\n",
      "\tLoss: 0.09704867005348206\n",
      "\tLoss: 0.14168617129325867\n",
      "\tLoss: 0.09734123200178146\n",
      "\tLoss: 0.06993716955184937\n",
      "\tLoss: 0.1069585457444191\n",
      "\tLoss: 0.129214346408844\n",
      "\tLoss: 0.0905459076166153\n",
      "\tLoss: 0.13442641496658325\n",
      "\tLoss: 0.08746885508298874\n",
      "\tLoss: 0.12201853841543198\n",
      "\tLoss: 0.13717898726463318\n",
      "\tLoss: 0.11435538530349731\n",
      "\tLoss: 0.07453452050685883\n",
      "\tLoss: 0.12385864555835724\n",
      "\tLoss: 0.07246335595846176\n",
      "\tLoss: 0.201300710439682\n",
      "\tLoss: 0.09192461520433426\n",
      "[time] Epoch 47: 431.8304960690439s = 7.197174934484065m\n",
      "\n",
      "Epoch 48...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.11423993110656738\n",
      "\tLoss: 0.16535624861717224\n",
      "\tLoss: 0.143326073884964\n",
      "\tLoss: 0.12355118989944458\n",
      "\tLoss: 0.11056685447692871\n",
      "\tLoss: 0.1099286824464798\n",
      "\tLoss: 0.10027207434177399\n",
      "\tLoss: 0.1237274557352066\n",
      "\tLoss: 0.07842971384525299\n",
      "\tLoss: 0.10034690797328949\n",
      "\tLoss: 0.15137946605682373\n",
      "\tLoss: 0.09403471648693085\n",
      "\tLoss: 0.16502296924591064\n",
      "\tLoss: 0.0933128148317337\n",
      "\tLoss: 0.08733991533517838\n",
      "\tLoss: 0.0732206478714943\n",
      "\tLoss: 0.12280400842428207\n",
      "\tLoss: 0.09461949020624161\n",
      "\tLoss: 0.09198412299156189\n",
      "\tLoss: 0.09565652161836624\n",
      "\tLoss: 0.12082702666521072\n",
      "\tLoss: 0.06452541798353195\n",
      "\tLoss: 0.09930199384689331\n",
      "\tLoss: 0.15157273411750793\n",
      "\tLoss: 0.12366724759340286\n",
      "\tLoss: 0.09751565754413605\n",
      "\tLoss: 0.10819894820451736\n",
      "\tLoss: 0.11387044191360474\n",
      "\tLoss: 0.08838967978954315\n",
      "\tLoss: 0.14167526364326477\n",
      "\tLoss: 0.10556004196405411\n",
      "\tLoss: 0.0967520922422409\n",
      "\tLoss: 0.14619779586791992\n",
      "\tLoss: 0.07852911949157715\n",
      "\tLoss: 0.10756660997867584\n",
      "\tLoss: 0.12763093411922455\n",
      "\tLoss: 0.09811465442180634\n",
      "\tLoss: 0.09386108815670013\n",
      "\tLoss: 0.15672260522842407\n",
      "\tLoss: 0.1309237778186798\n",
      "\tLoss: 0.09106922894716263\n",
      "\tLoss: 0.1004505306482315\n",
      "\tLoss: 0.09605790674686432\n",
      "\tLoss: 0.11042089015245438\n",
      "\tLoss: 0.12475506216287613\n",
      "\tLoss: 0.09920509159564972\n",
      "\tLoss: 0.07734362781047821\n",
      "\tLoss: 0.134199321269989\n",
      "\tLoss: 0.0422055758535862\n",
      "\tLoss: 0.13754253089427948\n",
      "\tLoss: 0.14991992712020874\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.115968719124794\n",
      "\tLoss: 0.14207462966442108\n",
      "\tLoss: 0.1148703545331955\n",
      "\tLoss: 0.05980304256081581\n",
      "\tLoss: 0.15719740092754364\n",
      "\tLoss: 0.1016264408826828\n",
      "\tLoss: 0.08612930774688721\n",
      "\tLoss: 0.06949977576732635\n",
      "\tLoss: 0.15260401368141174\n",
      "\tLoss: 0.12833498418331146\n",
      "\tLoss: 0.13068555295467377\n",
      "\tLoss: 0.0755738914012909\n",
      "\tLoss: 0.11673255264759064\n",
      "\tLoss: 0.11925014853477478\n",
      "\tLoss: 0.11013589054346085\n",
      "\tLoss: 0.09487122297286987\n",
      "\tLoss: 0.10060295462608337\n",
      "\tLoss: 0.07878389954566956\n",
      "\tLoss: 0.10181138664484024\n",
      "\tLoss: 0.1027183085680008\n",
      "\tLoss: 0.09078353643417358\n",
      "\tLoss: 0.09882168471813202\n",
      "\tLoss: 0.07612261176109314\n",
      "\tLoss: 0.12382173538208008\n",
      "\tLoss: 0.08174819499254227\n",
      "\tLoss: 0.10599398612976074\n",
      "\tLoss: 0.13993504643440247\n",
      "\tLoss: 0.15762335062026978\n",
      "\tLoss: 0.07223109900951385\n",
      "\tLoss: 0.12213025987148285\n",
      "\tLoss: 0.10742112249135971\n",
      "\tLoss: 0.08581358194351196\n",
      "\tLoss: 0.1248771995306015\n",
      "\tLoss: 0.11847322434186935\n",
      "\tLoss: 0.11872595548629761\n",
      "\tLoss: 0.09551607072353363\n",
      "\tLoss: 0.0938161090016365\n",
      "\tLoss: 0.09804877638816833\n",
      "\tLoss: 0.1077822595834732\n",
      "\tLoss: 0.14071929454803467\n",
      "\tLoss: 0.12018586695194244\n",
      "\tLoss: 0.15680991113185883\n",
      "\tLoss: 0.09067514538764954\n",
      "\tLoss: 0.12859804928302765\n",
      "\tLoss: 0.12210316210985184\n",
      "\tLoss: 0.15429745614528656\n",
      "\tLoss: 0.17821446061134338\n",
      "\tLoss: 0.08192548155784607\n",
      "\tLoss: 0.0725221186876297\n",
      "\tLoss: 0.12455935031175613\n",
      "\tLoss: 0.12043493986129761\n",
      "[time] Epoch 48: 442.0358391748741s = 7.367263986247902m\n",
      "\n",
      "Epoch 49...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.13093556463718414\n",
      "\tLoss: 0.0990397036075592\n",
      "\tLoss: 0.15830671787261963\n",
      "\tLoss: 0.08608199656009674\n",
      "\tLoss: 0.14759184420108795\n",
      "\tLoss: 0.09740573167800903\n",
      "\tLoss: 0.12765540182590485\n",
      "\tLoss: 0.18279094994068146\n",
      "\tLoss: 0.09413854032754898\n",
      "\tLoss: 0.10100474953651428\n",
      "\tLoss: 0.09548778831958771\n",
      "\tLoss: 0.06778129935264587\n",
      "\tLoss: 0.13381712138652802\n",
      "\tLoss: 0.09341739118099213\n",
      "\tLoss: 0.11987636238336563\n",
      "\tLoss: 0.13955235481262207\n",
      "\tLoss: 0.12696415185928345\n",
      "\tLoss: 0.12722976505756378\n",
      "\tLoss: 0.09166516363620758\n",
      "\tLoss: 0.1413169801235199\n",
      "\tLoss: 0.08661240339279175\n",
      "\tLoss: 0.11162988096475601\n",
      "\tLoss: 0.08325028419494629\n",
      "\tLoss: 0.0763034000992775\n",
      "\tLoss: 0.11518298089504242\n",
      "\tLoss: 0.09509220719337463\n",
      "\tLoss: 0.1305810809135437\n",
      "\tLoss: 0.12520861625671387\n",
      "\tLoss: 0.0760253369808197\n",
      "\tLoss: 0.06157652661204338\n",
      "\tLoss: 0.0971120223402977\n",
      "\tLoss: 0.10736113041639328\n",
      "\tLoss: 0.07217690348625183\n",
      "\tLoss: 0.12855130434036255\n",
      "\tLoss: 0.08485731482505798\n",
      "\tLoss: 0.08007550239562988\n",
      "\tLoss: 0.1344243288040161\n",
      "\tLoss: 0.10841161012649536\n",
      "\tLoss: 0.09729006886482239\n",
      "\tLoss: 0.07659412175416946\n",
      "\tLoss: 0.1452055275440216\n",
      "\tLoss: 0.05761164054274559\n",
      "\tLoss: 0.07651641964912415\n",
      "\tLoss: 0.09100732207298279\n",
      "\tLoss: 0.11681948602199554\n",
      "\tLoss: 0.09566156566143036\n",
      "\tLoss: 0.08821579813957214\n",
      "\tLoss: 0.055831555277109146\n",
      "\tLoss: 0.11712696403265\n",
      "\tLoss: 0.13144166767597198\n",
      "\tLoss: 0.08177441358566284\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.08615152537822723\n",
      "\tLoss: 0.09370604157447815\n",
      "\tLoss: 0.10742504149675369\n",
      "\tLoss: 0.11826913803815842\n",
      "\tLoss: 0.07961516082286835\n",
      "\tLoss: 0.13817819952964783\n",
      "\tLoss: 0.11702798306941986\n",
      "\tLoss: 0.1341245025396347\n",
      "\tLoss: 0.16516277194023132\n",
      "\tLoss: 0.10362154245376587\n",
      "\tLoss: 0.09379716217517853\n",
      "\tLoss: 0.100108303129673\n",
      "\tLoss: 0.10407338291406631\n",
      "\tLoss: 0.07942920178174973\n",
      "\tLoss: 0.11589578539133072\n",
      "\tLoss: 0.07891755551099777\n",
      "\tLoss: 0.09983634948730469\n",
      "\tLoss: 0.1125401109457016\n",
      "\tLoss: 0.12140344083309174\n",
      "\tLoss: 0.08093047887086868\n",
      "\tLoss: 0.10475163161754608\n",
      "\tLoss: 0.13267731666564941\n",
      "\tLoss: 0.07874201238155365\n",
      "\tLoss: 0.11382579803466797\n",
      "\tLoss: 0.17704877257347107\n",
      "\tLoss: 0.13320934772491455\n",
      "\tLoss: 0.10713617503643036\n",
      "\tLoss: 0.09813741594552994\n",
      "\tLoss: 0.1255074143409729\n",
      "\tLoss: 0.15547671914100647\n",
      "\tLoss: 0.16297920048236847\n",
      "\tLoss: 0.10594643652439117\n",
      "\tLoss: 0.10277555137872696\n",
      "\tLoss: 0.06694558262825012\n",
      "\tLoss: 0.09682616591453552\n",
      "\tLoss: 0.10170723497867584\n",
      "\tLoss: 0.10889393091201782\n",
      "\tLoss: 0.10015610605478287\n",
      "\tLoss: 0.11695337295532227\n",
      "\tLoss: 0.08931583166122437\n",
      "\tLoss: 0.1992282122373581\n",
      "\tLoss: 0.10439364612102509\n",
      "\tLoss: 0.10163576155900955\n",
      "\tLoss: 0.1508641541004181\n",
      "\tLoss: 0.13852578401565552\n",
      "\tLoss: 0.09664765000343323\n",
      "\tLoss: 0.12776705622673035\n",
      "\tLoss: 0.1718035191297531\n",
      "\tLoss: 0.13460682332515717\n",
      "\tLoss: 0.11684327572584152\n",
      "\tLoss: 0.13440537452697754\n",
      "[time] Epoch 49: 440.66379055939615s = 7.3443965093232695m\n",
      "\n",
      "Epoch 50...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.13664396107196808\n",
      "\tLoss: 0.1181909441947937\n",
      "\tLoss: 0.12816011905670166\n",
      "\tLoss: 0.08943474292755127\n",
      "\tLoss: 0.1097913458943367\n",
      "\tLoss: 0.12363772839307785\n",
      "\tLoss: 0.16225817799568176\n",
      "\tLoss: 0.09342066943645477\n",
      "\tLoss: 0.16778883337974548\n",
      "\tLoss: 0.0672905296087265\n",
      "\tLoss: 0.10203169286251068\n",
      "\tLoss: 0.10621090233325958\n",
      "\tLoss: 0.07602159678936005\n",
      "\tLoss: 0.1297832876443863\n",
      "\tLoss: 0.1699017584323883\n",
      "\tLoss: 0.07934050261974335\n",
      "\tLoss: 0.0943603664636612\n",
      "\tLoss: 0.1540564000606537\n",
      "\tLoss: 0.1197969987988472\n",
      "\tLoss: 0.10149706900119781\n",
      "\tLoss: 0.09391871094703674\n",
      "\tLoss: 0.11281666159629822\n",
      "\tLoss: 0.10102054476737976\n",
      "\tLoss: 0.08188396692276001\n",
      "\tLoss: 0.10582207888364792\n",
      "\tLoss: 0.10747236013412476\n",
      "\tLoss: 0.11556820571422577\n",
      "\tLoss: 0.11920436471700668\n",
      "\tLoss: 0.13323363661766052\n",
      "\tLoss: 0.09772101044654846\n",
      "\tLoss: 0.12107230722904205\n",
      "\tLoss: 0.12911450862884521\n",
      "\tLoss: 0.09513747692108154\n",
      "\tLoss: 0.11063264310359955\n",
      "\tLoss: 0.19168420135974884\n",
      "\tLoss: 0.090740866959095\n",
      "\tLoss: 0.14231151342391968\n",
      "\tLoss: 0.08608068525791168\n",
      "\tLoss: 0.12985116243362427\n",
      "\tLoss: 0.11065000295639038\n",
      "\tLoss: 0.09726813435554504\n",
      "\tLoss: 0.08117426931858063\n",
      "\tLoss: 0.09638018906116486\n",
      "\tLoss: 0.10174596309661865\n",
      "\tLoss: 0.15242545306682587\n",
      "\tLoss: 0.13790374994277954\n",
      "\tLoss: 0.1363217532634735\n",
      "\tLoss: 0.07653165608644485\n",
      "\tLoss: 0.11957225203514099\n",
      "\tLoss: 0.13665112853050232\n",
      "\tLoss: 0.14432813227176666\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.08077596127986908\n",
      "\tLoss: 0.10864673554897308\n",
      "\tLoss: 0.10423461347818375\n",
      "\tLoss: 0.14175689220428467\n",
      "\tLoss: 0.11189556866884232\n",
      "\tLoss: 0.11272841691970825\n",
      "\tLoss: 0.09555406868457794\n",
      "\tLoss: 0.10193655639886856\n",
      "\tLoss: 0.11869754642248154\n",
      "\tLoss: 0.15689891576766968\n",
      "\tLoss: 0.1353813260793686\n",
      "\tLoss: 0.11307313293218613\n",
      "\tLoss: 0.12465841323137283\n",
      "\tLoss: 0.10003618150949478\n",
      "\tLoss: 0.1182330846786499\n",
      "\tLoss: 0.15162119269371033\n",
      "\tLoss: 0.12646400928497314\n",
      "\tLoss: 0.09209642559289932\n",
      "\tLoss: 0.11538934707641602\n",
      "\tLoss: 0.10935790091753006\n",
      "\tLoss: 0.13417498767375946\n",
      "\tLoss: 0.13321073353290558\n",
      "\tLoss: 0.09098446369171143\n",
      "\tLoss: 0.1457625776529312\n",
      "\tLoss: 0.11197955161333084\n",
      "\tLoss: 0.1110234186053276\n",
      "\tLoss: 0.1138342097401619\n",
      "\tLoss: 0.146998792886734\n",
      "\tLoss: 0.06262262165546417\n",
      "\tLoss: 0.0917254313826561\n",
      "\tLoss: 0.07222722470760345\n",
      "\tLoss: 0.09016065299510956\n",
      "\tLoss: 0.1266811490058899\n",
      "\tLoss: 0.07597934454679489\n",
      "\tLoss: 0.09869653731584549\n",
      "\tLoss: 0.1857772171497345\n",
      "\tLoss: 0.13777785003185272\n",
      "\tLoss: 0.11186583340167999\n",
      "\tLoss: 0.13415932655334473\n",
      "\tLoss: 0.11628074198961258\n",
      "\tLoss: 0.07378987222909927\n",
      "\tLoss: 0.10766779631376266\n",
      "\tLoss: 0.11535914987325668\n",
      "\tLoss: 0.09509827196598053\n",
      "\tLoss: 0.14720098674297333\n",
      "\tLoss: 0.09651502966880798\n",
      "\tLoss: 0.08118249475955963\n",
      "\tLoss: 0.09213341027498245\n",
      "\tLoss: 0.13519880175590515\n",
      "\tLoss: 0.11980964243412018\n",
      "\tLoss: 0.1279270350933075\n",
      "[time] Epoch 50: 446.4053565924987s = 7.440089276541645m\n",
      "\n",
      "Epoch 51...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.11057481169700623\n",
      "\tLoss: 0.07711171358823776\n",
      "\tLoss: 0.136674165725708\n",
      "\tLoss: 0.13221639394760132\n",
      "\tLoss: 0.1259555220603943\n",
      "\tLoss: 0.11371144652366638\n",
      "\tLoss: 0.07599379122257233\n",
      "\tLoss: 0.1037135124206543\n",
      "\tLoss: 0.13864341378211975\n",
      "\tLoss: 0.12980127334594727\n",
      "\tLoss: 0.1167495995759964\n",
      "\tLoss: 0.07234220951795578\n",
      "\tLoss: 0.12138427793979645\n",
      "\tLoss: 0.1100236177444458\n",
      "\tLoss: 0.09490298479795456\n",
      "\tLoss: 0.12656854093074799\n",
      "\tLoss: 0.09530553221702576\n",
      "\tLoss: 0.08974293619394302\n",
      "\tLoss: 0.07881861925125122\n",
      "\tLoss: 0.06941204518079758\n",
      "\tLoss: 0.14002439379692078\n",
      "\tLoss: 0.10233640670776367\n",
      "\tLoss: 0.09855235368013382\n",
      "\tLoss: 0.07798909395933151\n",
      "\tLoss: 0.13949087262153625\n",
      "\tLoss: 0.06287116557359695\n",
      "\tLoss: 0.1103099137544632\n",
      "\tLoss: 0.11557918787002563\n",
      "\tLoss: 0.0871816948056221\n",
      "\tLoss: 0.09446363151073456\n",
      "\tLoss: 0.12525247037410736\n",
      "\tLoss: 0.11089855432510376\n",
      "\tLoss: 0.07982777059078217\n",
      "\tLoss: 0.12284216284751892\n",
      "\tLoss: 0.12146248668432236\n",
      "\tLoss: 0.09168143570423126\n",
      "\tLoss: 0.11516596376895905\n",
      "\tLoss: 0.09813444316387177\n",
      "\tLoss: 0.07376173138618469\n",
      "\tLoss: 0.11371011286973953\n",
      "\tLoss: 0.12850463390350342\n",
      "\tLoss: 0.08993342518806458\n",
      "\tLoss: 0.09622730314731598\n",
      "\tLoss: 0.13294248282909393\n",
      "\tLoss: 0.13331247866153717\n",
      "\tLoss: 0.07873883843421936\n",
      "\tLoss: 0.09500716626644135\n",
      "\tLoss: 0.10616522282361984\n",
      "\tLoss: 0.08216553181409836\n",
      "\tLoss: 0.13620808720588684\n",
      "\tLoss: 0.1317218542098999\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.07716736942529678\n",
      "\tLoss: 0.15458878874778748\n",
      "\tLoss: 0.09281433373689651\n",
      "\tLoss: 0.12193100899457932\n",
      "\tLoss: 0.09446325898170471\n",
      "\tLoss: 0.10415584594011307\n",
      "\tLoss: 0.09806959331035614\n",
      "\tLoss: 0.077121302485466\n",
      "\tLoss: 0.08315087854862213\n",
      "\tLoss: 0.11416491866111755\n",
      "\tLoss: 0.09293597936630249\n",
      "\tLoss: 0.11869239807128906\n",
      "\tLoss: 0.11918755620718002\n",
      "\tLoss: 0.056392863392829895\n",
      "\tLoss: 0.07137814164161682\n",
      "\tLoss: 0.14492204785346985\n",
      "\tLoss: 0.09552183747291565\n",
      "\tLoss: 0.10677528381347656\n",
      "\tLoss: 0.15456217527389526\n",
      "\tLoss: 0.07598434388637543\n",
      "\tLoss: 0.0893329381942749\n",
      "\tLoss: 0.07626248151063919\n",
      "\tLoss: 0.1290455460548401\n",
      "\tLoss: 0.13127495348453522\n",
      "\tLoss: 0.11324727535247803\n",
      "\tLoss: 0.0748143419623375\n",
      "\tLoss: 0.11881981045007706\n",
      "\tLoss: 0.09282967448234558\n",
      "\tLoss: 0.08891463279724121\n",
      "\tLoss: 0.16919457912445068\n",
      "\tLoss: 0.06981591880321503\n",
      "\tLoss: 0.08266149461269379\n",
      "\tLoss: 0.08688277006149292\n",
      "\tLoss: 0.07363278418779373\n",
      "\tLoss: 0.09436678141355515\n",
      "\tLoss: 0.08215837180614471\n",
      "\tLoss: 0.10660815238952637\n",
      "\tLoss: 0.08756252378225327\n",
      "\tLoss: 0.0858476385474205\n",
      "\tLoss: 0.11597881466150284\n",
      "\tLoss: 0.06989777088165283\n",
      "\tLoss: 0.12229800224304199\n",
      "\tLoss: 0.10621975362300873\n",
      "\tLoss: 0.12299567461013794\n",
      "\tLoss: 0.13817352056503296\n",
      "\tLoss: 0.13235044479370117\n",
      "\tLoss: 0.12639692425727844\n",
      "\tLoss: 0.11248710006475449\n",
      "\tLoss: 0.09974323213100433\n",
      "\tLoss: 0.08086387068033218\n",
      "\tLoss: 0.13765433430671692\n",
      "[time] Epoch 51: 433.28167086001486s = 7.221361181000248m\n",
      "\n",
      "Epoch 52...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.09701572358608246\n",
      "\tLoss: 0.1426043063402176\n",
      "\tLoss: 0.09620427340269089\n",
      "\tLoss: 0.10196006298065186\n",
      "\tLoss: 0.09043434262275696\n",
      "\tLoss: 0.09647729247808456\n",
      "\tLoss: 0.1359167993068695\n",
      "\tLoss: 0.08165676146745682\n",
      "\tLoss: 0.10674488544464111\n",
      "\tLoss: 0.0844799280166626\n",
      "\tLoss: 0.10528712719678879\n",
      "\tLoss: 0.1478278934955597\n",
      "\tLoss: 0.10131081938743591\n",
      "\tLoss: 0.0981174111366272\n",
      "\tLoss: 0.12044697254896164\n",
      "\tLoss: 0.13371914625167847\n",
      "\tLoss: 0.11764555424451828\n",
      "\tLoss: 0.13270524144172668\n",
      "\tLoss: 0.09520429372787476\n",
      "\tLoss: 0.08667703717947006\n",
      "\tLoss: 0.08331973850727081\n",
      "\tLoss: 0.08828920125961304\n",
      "\tLoss: 0.09587053954601288\n",
      "\tLoss: 0.10959302634000778\n",
      "\tLoss: 0.13141335546970367\n",
      "\tLoss: 0.09501606225967407\n",
      "\tLoss: 0.09265276789665222\n",
      "\tLoss: 0.10126519203186035\n",
      "\tLoss: 0.11769329011440277\n",
      "\tLoss: 0.0830458253622055\n",
      "\tLoss: 0.08819295465946198\n",
      "\tLoss: 0.11131942272186279\n",
      "\tLoss: 0.1234060674905777\n",
      "\tLoss: 0.1014208048582077\n",
      "\tLoss: 0.11037196218967438\n",
      "\tLoss: 0.1049591675400734\n",
      "\tLoss: 0.08941461145877838\n",
      "\tLoss: 0.08255922794342041\n",
      "\tLoss: 0.09760943800210953\n",
      "\tLoss: 0.1281937062740326\n",
      "\tLoss: 0.15788094699382782\n",
      "\tLoss: 0.1339290887117386\n",
      "\tLoss: 0.10437534749507904\n",
      "\tLoss: 0.08972975611686707\n",
      "\tLoss: 0.1509607434272766\n",
      "\tLoss: 0.04609512537717819\n",
      "\tLoss: 0.0898478701710701\n",
      "\tLoss: 0.10339927673339844\n",
      "\tLoss: 0.10139426589012146\n",
      "\tLoss: 0.14484702050685883\n",
      "\tLoss: 0.10581931471824646\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.09698187559843063\n",
      "\tLoss: 0.12069079279899597\n",
      "\tLoss: 0.10230827331542969\n",
      "\tLoss: 0.0965426042675972\n",
      "\tLoss: 0.053535208106040955\n",
      "\tLoss: 0.1087675541639328\n",
      "\tLoss: 0.11181879043579102\n",
      "\tLoss: 0.060839392244815826\n",
      "\tLoss: 0.0741177424788475\n",
      "\tLoss: 0.11242352426052094\n",
      "\tLoss: 0.08254048228263855\n",
      "\tLoss: 0.1553468257188797\n",
      "\tLoss: 0.12567077577114105\n",
      "\tLoss: 0.08833974599838257\n",
      "\tLoss: 0.09340105950832367\n",
      "\tLoss: 0.09181265532970428\n",
      "\tLoss: 0.10668519139289856\n",
      "\tLoss: 0.08752128481864929\n",
      "\tLoss: 0.11047212779521942\n",
      "\tLoss: 0.13219250738620758\n",
      "\tLoss: 0.07802081108093262\n",
      "\tLoss: 0.13909496366977692\n",
      "\tLoss: 0.09389680624008179\n",
      "\tLoss: 0.12701991200447083\n",
      "\tLoss: 0.14742380380630493\n",
      "\tLoss: 0.14124856889247894\n",
      "\tLoss: 0.08298826217651367\n",
      "\tLoss: 0.14104361832141876\n",
      "\tLoss: 0.11119160056114197\n",
      "\tLoss: 0.10309012234210968\n",
      "\tLoss: 0.09357894212007523\n",
      "\tLoss: 0.0855104923248291\n",
      "\tLoss: 0.1361289620399475\n",
      "\tLoss: 0.10216449201107025\n",
      "\tLoss: 0.147131085395813\n",
      "\tLoss: 0.14143909513950348\n",
      "\tLoss: 0.07547204941511154\n",
      "\tLoss: 0.07735046744346619\n",
      "\tLoss: 0.13807794451713562\n",
      "\tLoss: 0.10323700308799744\n",
      "\tLoss: 0.1148991584777832\n",
      "\tLoss: 0.12373411655426025\n",
      "\tLoss: 0.112070232629776\n",
      "\tLoss: 0.1069984883069992\n",
      "\tLoss: 0.13266536593437195\n",
      "\tLoss: 0.1175156980752945\n",
      "\tLoss: 0.12982594966888428\n",
      "\tLoss: 0.1105472519993782\n",
      "\tLoss: 0.12256758660078049\n",
      "\tLoss: 0.06704111397266388\n",
      "\tLoss: 0.15551355481147766\n",
      "[time] Epoch 52: 441.09573507495224s = 7.351595584582538m\n",
      "\n",
      "Epoch 53...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.07972069829702377\n",
      "\tLoss: 0.08543635159730911\n",
      "\tLoss: 0.11842313408851624\n",
      "\tLoss: 0.09859038144350052\n",
      "\tLoss: 0.11778367310762405\n",
      "\tLoss: 0.12935321033000946\n",
      "\tLoss: 0.07617230713367462\n",
      "\tLoss: 0.11584453284740448\n",
      "\tLoss: 0.08164212852716446\n",
      "\tLoss: 0.10068489611148834\n",
      "\tLoss: 0.12540769577026367\n",
      "\tLoss: 0.10993266850709915\n",
      "\tLoss: 0.11107536405324936\n",
      "\tLoss: 0.1071334034204483\n",
      "\tLoss: 0.10055098682641983\n",
      "\tLoss: 0.06035977602005005\n",
      "\tLoss: 0.10656777024269104\n",
      "\tLoss: 0.11416055262088776\n",
      "\tLoss: 0.10645854473114014\n",
      "\tLoss: 0.07200738787651062\n",
      "\tLoss: 0.11532872170209885\n",
      "\tLoss: 0.13505280017852783\n",
      "\tLoss: 0.16029010713100433\n",
      "\tLoss: 0.09914694726467133\n",
      "\tLoss: 0.17051000893115997\n",
      "\tLoss: 0.119171142578125\n",
      "\tLoss: 0.12247315794229507\n",
      "\tLoss: 0.17305022478103638\n",
      "\tLoss: 0.08473356068134308\n",
      "\tLoss: 0.1307922899723053\n",
      "\tLoss: 0.08155828714370728\n",
      "\tLoss: 0.085354745388031\n",
      "\tLoss: 0.1163095086812973\n",
      "\tLoss: 0.1018538624048233\n",
      "\tLoss: 0.14434799551963806\n",
      "\tLoss: 0.06782401353120804\n",
      "\tLoss: 0.08884447813034058\n",
      "\tLoss: 0.12435438483953476\n",
      "\tLoss: 0.1209598258137703\n",
      "\tLoss: 0.08619292080402374\n",
      "\tLoss: 0.0978582575917244\n",
      "\tLoss: 0.061099592596292496\n",
      "\tLoss: 0.09041397273540497\n",
      "\tLoss: 0.1207057535648346\n",
      "\tLoss: 0.14979912340641022\n",
      "\tLoss: 0.08525972813367844\n",
      "\tLoss: 0.11870652437210083\n",
      "\tLoss: 0.14576417207717896\n",
      "\tLoss: 0.13621601462364197\n",
      "\tLoss: 0.05728032439947128\n",
      "\tLoss: 0.11019821465015411\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.10073231160640717\n",
      "\tLoss: 0.1483190804719925\n",
      "\tLoss: 0.11260196566581726\n",
      "\tLoss: 0.162817120552063\n",
      "\tLoss: 0.07534997165203094\n",
      "\tLoss: 0.12489403039216995\n",
      "\tLoss: 0.0780165046453476\n",
      "\tLoss: 0.10876556485891342\n",
      "\tLoss: 0.0706607848405838\n",
      "\tLoss: 0.08313260227441788\n",
      "\tLoss: 0.1294102966785431\n",
      "\tLoss: 0.07257698476314545\n",
      "\tLoss: 0.09246411919593811\n",
      "\tLoss: 0.12056899070739746\n",
      "\tLoss: 0.12430624663829803\n",
      "\tLoss: 0.11925357580184937\n",
      "\tLoss: 0.11066953837871552\n",
      "\tLoss: 0.11709348857402802\n",
      "\tLoss: 0.09545253962278366\n",
      "\tLoss: 0.16491565108299255\n",
      "\tLoss: 0.09106071293354034\n",
      "\tLoss: 0.10001429915428162\n",
      "\tLoss: 0.10256607830524445\n",
      "\tLoss: 0.08754624426364899\n",
      "\tLoss: 0.08656984567642212\n",
      "\tLoss: 0.108260378241539\n",
      "\tLoss: 0.11013449728488922\n",
      "\tLoss: 0.10513670742511749\n",
      "\tLoss: 0.08544334769248962\n",
      "\tLoss: 0.0973118394613266\n",
      "\tLoss: 0.11288098990917206\n",
      "\tLoss: 0.06968627870082855\n",
      "\tLoss: 0.11486434936523438\n",
      "\tLoss: 0.08218003809452057\n",
      "\tLoss: 0.09705525636672974\n",
      "\tLoss: 0.09976924955844879\n",
      "\tLoss: 0.09982000291347504\n",
      "\tLoss: 0.11706459522247314\n",
      "\tLoss: 0.06288157403469086\n",
      "\tLoss: 0.10991405695676804\n",
      "\tLoss: 0.10913674533367157\n",
      "\tLoss: 0.10750126838684082\n",
      "\tLoss: 0.13646040856838226\n",
      "\tLoss: 0.12401394546031952\n",
      "\tLoss: 0.1218012273311615\n",
      "\tLoss: 0.10897726565599442\n",
      "\tLoss: 0.1344197392463684\n",
      "\tLoss: 0.11536787450313568\n",
      "\tLoss: 0.13986213505268097\n",
      "\tLoss: 0.15320202708244324\n",
      "\tLoss: 0.13603860139846802\n",
      "[time] Epoch 53: 436.17858303617686s = 7.269643050602948m\n",
      "\n",
      "Epoch 54...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.14362527430057526\n",
      "\tLoss: 0.12685620784759521\n",
      "\tLoss: 0.12368553876876831\n",
      "\tLoss: 0.07603686302900314\n",
      "\tLoss: 0.11495301872491837\n",
      "\tLoss: 0.117827408015728\n",
      "\tLoss: 0.12355849891901016\n",
      "\tLoss: 0.11071403324604034\n",
      "\tLoss: 0.06576306372880936\n",
      "\tLoss: 0.09828896075487137\n",
      "\tLoss: 0.08959132432937622\n",
      "\tLoss: 0.08458448946475983\n",
      "\tLoss: 0.10722468793392181\n",
      "\tLoss: 0.10144448280334473\n",
      "\tLoss: 0.08286838233470917\n",
      "\tLoss: 0.12749910354614258\n",
      "\tLoss: 0.10632190108299255\n",
      "\tLoss: 0.10370536148548126\n",
      "\tLoss: 0.11217392981052399\n",
      "\tLoss: 0.12568694353103638\n",
      "\tLoss: 0.10418082028627396\n",
      "\tLoss: 0.12794415652751923\n",
      "\tLoss: 0.10258025676012039\n",
      "\tLoss: 0.10530399531126022\n",
      "\tLoss: 0.1234111487865448\n",
      "\tLoss: 0.1372271627187729\n",
      "\tLoss: 0.10943742096424103\n",
      "\tLoss: 0.08309309929609299\n",
      "\tLoss: 0.11294050514698029\n",
      "\tLoss: 0.13544143736362457\n",
      "\tLoss: 0.08717125654220581\n",
      "\tLoss: 0.07702983915805817\n",
      "\tLoss: 0.10455705225467682\n",
      "\tLoss: 0.10366175323724747\n",
      "\tLoss: 0.1050620824098587\n",
      "\tLoss: 0.11503048986196518\n",
      "\tLoss: 0.07374195754528046\n",
      "\tLoss: 0.12825745344161987\n",
      "\tLoss: 0.12004999816417694\n",
      "\tLoss: 0.08992884308099747\n",
      "\tLoss: 0.15511447191238403\n",
      "\tLoss: 0.07595716416835785\n",
      "\tLoss: 0.08416187018156052\n",
      "\tLoss: 0.09446287155151367\n",
      "\tLoss: 0.09608657658100128\n",
      "\tLoss: 0.14485648274421692\n",
      "\tLoss: 0.1255812644958496\n",
      "\tLoss: 0.09802137315273285\n",
      "\tLoss: 0.08549967408180237\n",
      "\tLoss: 0.06324462592601776\n",
      "\tLoss: 0.13147017359733582\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.1127069741487503\n",
      "\tLoss: 0.10405659675598145\n",
      "\tLoss: 0.1358868032693863\n",
      "\tLoss: 0.08457311987876892\n",
      "\tLoss: 0.08833612501621246\n",
      "\tLoss: 0.08518814295530319\n",
      "\tLoss: 0.09555644541978836\n",
      "\tLoss: 0.06954057514667511\n",
      "\tLoss: 0.07396543025970459\n",
      "\tLoss: 0.10494446754455566\n",
      "\tLoss: 0.08974187821149826\n",
      "\tLoss: 0.09215960651636124\n",
      "\tLoss: 0.08011666685342789\n",
      "\tLoss: 0.0987396240234375\n",
      "\tLoss: 0.12905295193195343\n",
      "\tLoss: 0.13836011290550232\n",
      "\tLoss: 0.07926617562770844\n",
      "\tLoss: 0.11046221852302551\n",
      "\tLoss: 0.12177127599716187\n",
      "\tLoss: 0.11520718783140182\n",
      "\tLoss: 0.09834779053926468\n",
      "\tLoss: 0.07352812588214874\n",
      "\tLoss: 0.07749443501234055\n",
      "\tLoss: 0.091458760201931\n",
      "\tLoss: 0.09761415421962738\n",
      "\tLoss: 0.08956187963485718\n",
      "\tLoss: 0.10165120661258698\n",
      "\tLoss: 0.14145499467849731\n",
      "\tLoss: 0.06183807551860809\n",
      "\tLoss: 0.1507655680179596\n",
      "\tLoss: 0.1462503969669342\n",
      "\tLoss: 0.11926253139972687\n",
      "\tLoss: 0.07658381015062332\n",
      "\tLoss: 0.09835001081228256\n",
      "\tLoss: 0.08051355183124542\n",
      "\tLoss: 0.10364770889282227\n",
      "\tLoss: 0.10059108585119247\n",
      "\tLoss: 0.0861017256975174\n",
      "\tLoss: 0.1005629450082779\n",
      "\tLoss: 0.06195998936891556\n",
      "\tLoss: 0.10587634146213531\n",
      "\tLoss: 0.12659788131713867\n",
      "\tLoss: 0.13802309334278107\n",
      "\tLoss: 0.15153588354587555\n",
      "\tLoss: 0.12894463539123535\n",
      "\tLoss: 0.09638485312461853\n",
      "\tLoss: 0.10991880297660828\n",
      "\tLoss: 0.07976552844047546\n",
      "\tLoss: 0.09018021821975708\n",
      "\tLoss: 0.148130863904953\n",
      "\tLoss: 0.10331405699253082\n",
      "[time] Epoch 54: 428.7711601406336s = 7.146186002343893m\n",
      "\n",
      "Epoch 55...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1119658499956131\n",
      "\tLoss: 0.14535248279571533\n",
      "\tLoss: 0.1056922972202301\n",
      "\tLoss: 0.09773097932338715\n",
      "\tLoss: 0.11516863107681274\n",
      "\tLoss: 0.10756620019674301\n",
      "\tLoss: 0.10676110535860062\n",
      "\tLoss: 0.09948980063199997\n",
      "\tLoss: 0.06815040111541748\n",
      "\tLoss: 0.08785159885883331\n",
      "\tLoss: 0.09422970563173294\n",
      "\tLoss: 0.10674586147069931\n",
      "\tLoss: 0.11373324692249298\n",
      "\tLoss: 0.10496047139167786\n",
      "\tLoss: 0.13588649034500122\n",
      "\tLoss: 0.08286818861961365\n",
      "\tLoss: 0.15712299942970276\n",
      "\tLoss: 0.08901818096637726\n",
      "\tLoss: 0.08580924570560455\n",
      "\tLoss: 0.08937354385852814\n",
      "\tLoss: 0.10229186713695526\n",
      "\tLoss: 0.1358773112297058\n",
      "\tLoss: 0.11551327258348465\n",
      "\tLoss: 0.14297756552696228\n",
      "\tLoss: 0.10900259763002396\n",
      "\tLoss: 0.1005980595946312\n",
      "\tLoss: 0.12052746117115021\n",
      "\tLoss: 0.1024966612458229\n",
      "\tLoss: 0.16545569896697998\n",
      "\tLoss: 0.13080227375030518\n",
      "\tLoss: 0.13496559858322144\n",
      "\tLoss: 0.12263359874486923\n",
      "\tLoss: 0.12525621056556702\n",
      "\tLoss: 0.061162661761045456\n",
      "\tLoss: 0.08850039541721344\n",
      "\tLoss: 0.0808798149228096\n",
      "\tLoss: 0.07837004959583282\n",
      "\tLoss: 0.11369246244430542\n",
      "\tLoss: 0.11211985349655151\n",
      "\tLoss: 0.07706789672374725\n",
      "\tLoss: 0.10817462205886841\n",
      "\tLoss: 0.10008427500724792\n",
      "\tLoss: 0.13905231654644012\n",
      "\tLoss: 0.13608530163764954\n",
      "\tLoss: 0.11453131586313248\n",
      "\tLoss: 0.07464690506458282\n",
      "\tLoss: 0.08860518783330917\n",
      "\tLoss: 0.08508658409118652\n",
      "\tLoss: 0.10656128078699112\n",
      "\tLoss: 0.10725032538175583\n",
      "\tLoss: 0.13965103030204773\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.0868404284119606\n",
      "\tLoss: 0.13146093487739563\n",
      "\tLoss: 0.15848690271377563\n",
      "\tLoss: 0.09359999746084213\n",
      "\tLoss: 0.16410407423973083\n",
      "\tLoss: 0.12999475002288818\n",
      "\tLoss: 0.08862187713384628\n",
      "\tLoss: 0.11877921223640442\n",
      "\tLoss: 0.12228650599718094\n",
      "\tLoss: 0.12099996209144592\n",
      "\tLoss: 0.15318435430526733\n",
      "\tLoss: 0.1045096144080162\n",
      "\tLoss: 0.1211479902267456\n",
      "\tLoss: 0.10263119637966156\n",
      "\tLoss: 0.14682595431804657\n",
      "\tLoss: 0.12133079767227173\n",
      "\tLoss: 0.1440264880657196\n",
      "\tLoss: 0.09164797514677048\n",
      "\tLoss: 0.13763567805290222\n",
      "\tLoss: 0.15448446571826935\n",
      "\tLoss: 0.13979268074035645\n",
      "\tLoss: 0.10933341085910797\n",
      "\tLoss: 0.08611596375703812\n",
      "\tLoss: 0.12915320694446564\n",
      "\tLoss: 0.11518283933401108\n",
      "\tLoss: 0.1385076940059662\n",
      "\tLoss: 0.1314733922481537\n",
      "\tLoss: 0.09613941609859467\n",
      "\tLoss: 0.11805033683776855\n",
      "\tLoss: 0.090995192527771\n",
      "\tLoss: 0.13605645298957825\n",
      "\tLoss: 0.08726943284273148\n",
      "\tLoss: 0.1251351535320282\n",
      "\tLoss: 0.09127968549728394\n",
      "\tLoss: 0.12147625535726547\n",
      "\tLoss: 0.0777004212141037\n",
      "\tLoss: 0.1015225425362587\n",
      "\tLoss: 0.09657374769449234\n",
      "\tLoss: 0.04114004597067833\n",
      "\tLoss: 0.10353967547416687\n",
      "\tLoss: 0.10894719511270523\n",
      "\tLoss: 0.11452797055244446\n",
      "\tLoss: 0.13321934640407562\n",
      "\tLoss: 0.12912261486053467\n",
      "\tLoss: 0.11691848188638687\n",
      "\tLoss: 0.08642494678497314\n",
      "\tLoss: 0.13187217712402344\n",
      "\tLoss: 0.10357347130775452\n",
      "\tLoss: 0.08927886188030243\n",
      "\tLoss: 0.1045665442943573\n",
      "\tLoss: 0.06610894948244095\n",
      "[time] Epoch 55: 427.9823821671307s = 7.133039702785512m\n",
      "\n",
      "Epoch 56...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.07212258875370026\n",
      "\tLoss: 0.0666535347700119\n",
      "\tLoss: 0.08019664883613586\n",
      "\tLoss: 0.09318044781684875\n",
      "\tLoss: 0.08636408299207687\n",
      "\tLoss: 0.0595933198928833\n",
      "\tLoss: 0.09990440309047699\n",
      "\tLoss: 0.08682757616043091\n",
      "\tLoss: 0.08862078189849854\n",
      "\tLoss: 0.09959660470485687\n",
      "\tLoss: 0.10293325036764145\n",
      "\tLoss: 0.08987519890069962\n",
      "\tLoss: 0.0891716331243515\n",
      "\tLoss: 0.09537872672080994\n",
      "\tLoss: 0.10570769757032394\n",
      "\tLoss: 0.08691219985485077\n",
      "\tLoss: 0.10768827795982361\n",
      "\tLoss: 0.13581515848636627\n",
      "\tLoss: 0.11306488513946533\n",
      "\tLoss: 0.09833265841007233\n",
      "\tLoss: 0.0936412513256073\n",
      "\tLoss: 0.11508793383836746\n",
      "\tLoss: 0.07565969228744507\n",
      "\tLoss: 0.08708076179027557\n",
      "\tLoss: 0.12387321889400482\n",
      "\tLoss: 0.10845975577831268\n",
      "\tLoss: 0.06780380010604858\n",
      "\tLoss: 0.07054688036441803\n",
      "\tLoss: 0.12011467665433884\n",
      "\tLoss: 0.1152212917804718\n",
      "\tLoss: 0.11819849163293839\n",
      "\tLoss: 0.10563091933727264\n",
      "\tLoss: 0.12082315981388092\n",
      "\tLoss: 0.10656753182411194\n",
      "\tLoss: 0.09539519250392914\n",
      "\tLoss: 0.11841467022895813\n",
      "\tLoss: 0.09328223764896393\n",
      "\tLoss: 0.09932677447795868\n",
      "\tLoss: 0.12461597472429276\n",
      "\tLoss: 0.13303148746490479\n",
      "\tLoss: 0.11982619017362595\n",
      "\tLoss: 0.11850133538246155\n",
      "\tLoss: 0.07672441750764847\n",
      "\tLoss: 0.10141302645206451\n",
      "\tLoss: 0.09757936745882034\n",
      "\tLoss: 0.06735144555568695\n",
      "\tLoss: 0.10547924786806107\n",
      "\tLoss: 0.10297724604606628\n",
      "\tLoss: 0.11906613409519196\n",
      "\tLoss: 0.11666680872440338\n",
      "\tLoss: 0.122779980301857\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.10558100044727325\n",
      "\tLoss: 0.10342012345790863\n",
      "\tLoss: 0.12319448590278625\n",
      "\tLoss: 0.09760291874408722\n",
      "\tLoss: 0.1018371731042862\n",
      "\tLoss: 0.12538032233715057\n",
      "\tLoss: 0.11547207832336426\n",
      "\tLoss: 0.07658563554286957\n",
      "\tLoss: 0.07911287248134613\n",
      "\tLoss: 0.1007184386253357\n",
      "\tLoss: 0.09210208803415298\n",
      "\tLoss: 0.10196874290704727\n",
      "\tLoss: 0.11058409512042999\n",
      "\tLoss: 0.1346847116947174\n",
      "\tLoss: 0.12415926903486252\n",
      "\tLoss: 0.11090908944606781\n",
      "\tLoss: 0.11488408595323563\n",
      "\tLoss: 0.07553794234991074\n",
      "\tLoss: 0.08962631970643997\n",
      "\tLoss: 0.08911062031984329\n",
      "\tLoss: 0.1038493812084198\n",
      "\tLoss: 0.13532644510269165\n",
      "\tLoss: 0.10317713767290115\n",
      "\tLoss: 0.06706023216247559\n",
      "\tLoss: 0.1273641735315323\n",
      "\tLoss: 0.11040462553501129\n",
      "\tLoss: 0.08583883941173553\n",
      "\tLoss: 0.10998553037643433\n",
      "\tLoss: 0.12691017985343933\n",
      "\tLoss: 0.12556429207324982\n",
      "\tLoss: 0.11510749161243439\n",
      "\tLoss: 0.13426822423934937\n",
      "\tLoss: 0.12806282937526703\n",
      "\tLoss: 0.08839660882949829\n",
      "\tLoss: 0.11605048924684525\n",
      "\tLoss: 0.0854719877243042\n",
      "\tLoss: 0.12656816840171814\n",
      "\tLoss: 0.12635327875614166\n",
      "\tLoss: 0.11931817978620529\n",
      "\tLoss: 0.12262901663780212\n",
      "\tLoss: 0.09676354378461838\n",
      "\tLoss: 0.08562979102134705\n",
      "\tLoss: 0.1434844434261322\n",
      "\tLoss: 0.08690088987350464\n",
      "\tLoss: 0.15413635969161987\n",
      "\tLoss: 0.17332389950752258\n",
      "\tLoss: 0.10886069387197495\n",
      "\tLoss: 0.09191283583641052\n",
      "\tLoss: 0.11203926801681519\n",
      "\tLoss: 0.10628195106983185\n",
      "\tLoss: 0.0984356477856636\n",
      "[time] Epoch 56: 436.56850920058787s = 7.276141820009798m\n",
      "\n",
      "Epoch 57...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.07049664855003357\n",
      "\tLoss: 0.16911892592906952\n",
      "\tLoss: 0.12713390588760376\n",
      "\tLoss: 0.08899221569299698\n",
      "\tLoss: 0.12025997042655945\n",
      "\tLoss: 0.11983269453048706\n",
      "\tLoss: 0.1024414449930191\n",
      "\tLoss: 0.08521382510662079\n",
      "\tLoss: 0.12826287746429443\n",
      "\tLoss: 0.1373615562915802\n",
      "\tLoss: 0.13747096061706543\n",
      "\tLoss: 0.1536867320537567\n",
      "\tLoss: 0.10655904561281204\n",
      "\tLoss: 0.1590387523174286\n",
      "\tLoss: 0.08722230792045593\n",
      "\tLoss: 0.12885110080242157\n",
      "\tLoss: 0.09417745471000671\n",
      "\tLoss: 0.07204412668943405\n",
      "\tLoss: 0.10875268280506134\n",
      "\tLoss: 0.08144807815551758\n",
      "\tLoss: 0.10984610766172409\n",
      "\tLoss: 0.08534133434295654\n",
      "\tLoss: 0.10155007243156433\n",
      "\tLoss: 0.12255419045686722\n",
      "\tLoss: 0.13596713542938232\n",
      "\tLoss: 0.09238719940185547\n",
      "\tLoss: 0.07351280748844147\n",
      "\tLoss: 0.11654345691204071\n",
      "\tLoss: 0.0946647897362709\n",
      "\tLoss: 0.09288434684276581\n",
      "\tLoss: 0.07915568351745605\n",
      "\tLoss: 0.1528792828321457\n",
      "\tLoss: 0.10751070082187653\n",
      "\tLoss: 0.07050751894712448\n",
      "\tLoss: 0.11943115293979645\n",
      "\tLoss: 0.1310124695301056\n",
      "\tLoss: 0.10626578330993652\n",
      "\tLoss: 0.11142072826623917\n",
      "\tLoss: 0.10758641362190247\n",
      "\tLoss: 0.15916535258293152\n",
      "\tLoss: 0.11717817187309265\n",
      "\tLoss: 0.11468842625617981\n",
      "\tLoss: 0.07725824415683746\n",
      "\tLoss: 0.1440296769142151\n",
      "\tLoss: 0.1155092641711235\n",
      "\tLoss: 0.08821915090084076\n",
      "\tLoss: 0.13527166843414307\n",
      "\tLoss: 0.1301601380109787\n",
      "\tLoss: 0.12962986528873444\n",
      "\tLoss: 0.11043982207775116\n",
      "\tLoss: 0.07159224152565002\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.12765160202980042\n",
      "\tLoss: 0.105725958943367\n",
      "\tLoss: 0.12836161255836487\n",
      "\tLoss: 0.11391930282115936\n",
      "\tLoss: 0.10317742824554443\n",
      "\tLoss: 0.0762956365942955\n",
      "\tLoss: 0.09441259503364563\n",
      "\tLoss: 0.06731706857681274\n",
      "\tLoss: 0.10491196066141129\n",
      "\tLoss: 0.10156168788671494\n",
      "\tLoss: 0.12334340810775757\n",
      "\tLoss: 0.150858074426651\n",
      "\tLoss: 0.13494707643985748\n",
      "\tLoss: 0.11441721767187119\n",
      "\tLoss: 0.12848056852817535\n",
      "\tLoss: 0.10579799860715866\n",
      "\tLoss: 0.13270094990730286\n",
      "\tLoss: 0.08400356769561768\n",
      "\tLoss: 0.0738421306014061\n",
      "\tLoss: 0.1614016592502594\n",
      "\tLoss: 0.11825546622276306\n",
      "\tLoss: 0.1030631735920906\n",
      "\tLoss: 0.14246734976768494\n",
      "\tLoss: 0.1415329873561859\n",
      "\tLoss: 0.08576010912656784\n",
      "\tLoss: 0.14386630058288574\n",
      "\tLoss: 0.14865905046463013\n",
      "\tLoss: 0.08892974257469177\n",
      "\tLoss: 0.09157723188400269\n",
      "\tLoss: 0.06041325256228447\n",
      "\tLoss: 0.09149935841560364\n",
      "\tLoss: 0.09190525114536285\n",
      "\tLoss: 0.10623431205749512\n",
      "\tLoss: 0.08758535981178284\n",
      "\tLoss: 0.09740234166383743\n",
      "\tLoss: 0.061871595680713654\n",
      "\tLoss: 0.14137205481529236\n",
      "\tLoss: 0.10297266393899918\n",
      "\tLoss: 0.08740837126970291\n",
      "\tLoss: 0.11252569407224655\n",
      "\tLoss: 0.07792001962661743\n",
      "\tLoss: 0.10017168521881104\n",
      "\tLoss: 0.11189906299114227\n",
      "\tLoss: 0.07138799130916595\n",
      "\tLoss: 0.1024649441242218\n",
      "\tLoss: 0.10690560191869736\n",
      "\tLoss: 0.10273979604244232\n",
      "\tLoss: 0.13316752016544342\n",
      "\tLoss: 0.09189530462026596\n",
      "\tLoss: 0.07995577901601791\n",
      "\tLoss: 0.10797041654586792\n",
      "[time] Epoch 57: 433.4739918000996s = 7.224566530001661m\n",
      "\n",
      "Epoch 58...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.11011949926614761\n",
      "\tLoss: 0.16063255071640015\n",
      "\tLoss: 0.1306772530078888\n",
      "\tLoss: 0.10796114057302475\n",
      "\tLoss: 0.09998273104429245\n",
      "\tLoss: 0.09780938923358917\n",
      "\tLoss: 0.0683044046163559\n",
      "\tLoss: 0.11965809017419815\n",
      "\tLoss: 0.08923229575157166\n",
      "\tLoss: 0.0917130634188652\n",
      "\tLoss: 0.11322076618671417\n",
      "\tLoss: 0.07832793146371841\n",
      "\tLoss: 0.09570588171482086\n",
      "\tLoss: 0.12801815569400787\n",
      "\tLoss: 0.11997878551483154\n",
      "\tLoss: 0.13462330400943756\n",
      "\tLoss: 0.11112263053655624\n",
      "\tLoss: 0.08804982155561447\n",
      "\tLoss: 0.08608822524547577\n",
      "\tLoss: 0.10213547199964523\n",
      "\tLoss: 0.10036870837211609\n",
      "\tLoss: 0.12990272045135498\n",
      "\tLoss: 0.08107246458530426\n",
      "\tLoss: 0.06331610679626465\n",
      "\tLoss: 0.13861674070358276\n",
      "\tLoss: 0.08859844505786896\n",
      "\tLoss: 0.12093432247638702\n",
      "\tLoss: 0.09852960705757141\n",
      "\tLoss: 0.10475412011146545\n",
      "\tLoss: 0.11124124377965927\n",
      "\tLoss: 0.09448330849409103\n",
      "\tLoss: 0.09451407194137573\n",
      "\tLoss: 0.12132228165864944\n",
      "\tLoss: 0.11970919370651245\n",
      "\tLoss: 0.10661733895540237\n",
      "\tLoss: 0.10754654556512833\n",
      "\tLoss: 0.1414368748664856\n",
      "\tLoss: 0.059844810515642166\n",
      "\tLoss: 0.10786209255456924\n",
      "\tLoss: 0.1317950189113617\n",
      "\tLoss: 0.12911221385002136\n",
      "\tLoss: 0.1017133891582489\n",
      "\tLoss: 0.08970826864242554\n",
      "\tLoss: 0.09570925682783127\n",
      "\tLoss: 0.12906277179718018\n",
      "\tLoss: 0.06763827800750732\n",
      "\tLoss: 0.12313982844352722\n",
      "\tLoss: 0.1100471168756485\n",
      "\tLoss: 0.13625375926494598\n",
      "\tLoss: 0.07910006493330002\n",
      "\tLoss: 0.09633415937423706\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.1393333077430725\n",
      "\tLoss: 0.08837646245956421\n",
      "\tLoss: 0.110902801156044\n",
      "\tLoss: 0.13183201849460602\n",
      "\tLoss: 0.09456664323806763\n",
      "\tLoss: 0.09588763862848282\n",
      "\tLoss: 0.0606052502989769\n",
      "\tLoss: 0.10283783078193665\n",
      "\tLoss: 0.1292937695980072\n",
      "\tLoss: 0.12996944785118103\n",
      "\tLoss: 0.11355388909578323\n",
      "\tLoss: 0.1176171749830246\n",
      "\tLoss: 0.08491046726703644\n",
      "\tLoss: 0.10574719309806824\n",
      "\tLoss: 0.1143709197640419\n",
      "\tLoss: 0.13462454080581665\n",
      "\tLoss: 0.08162546902894974\n",
      "\tLoss: 0.1286226511001587\n",
      "\tLoss: 0.08553820848464966\n",
      "\tLoss: 0.1086992472410202\n",
      "\tLoss: 0.0702505111694336\n",
      "\tLoss: 0.10229627788066864\n",
      "\tLoss: 0.06389030069112778\n",
      "\tLoss: 0.1096654087305069\n",
      "\tLoss: 0.07091136276721954\n",
      "\tLoss: 0.08354103565216064\n",
      "\tLoss: 0.06031971797347069\n",
      "\tLoss: 0.09490367025136948\n",
      "\tLoss: 0.10865987837314606\n",
      "\tLoss: 0.08981932699680328\n",
      "\tLoss: 0.1106141209602356\n",
      "\tLoss: 0.07711432874202728\n",
      "\tLoss: 0.11768622696399689\n",
      "\tLoss: 0.08210927248001099\n",
      "\tLoss: 0.11205576360225677\n",
      "\tLoss: 0.09412546455860138\n",
      "\tLoss: 0.12240997701883316\n",
      "\tLoss: 0.11501127481460571\n",
      "\tLoss: 0.07549615204334259\n",
      "\tLoss: 0.11275207996368408\n",
      "\tLoss: 0.08349918574094772\n",
      "\tLoss: 0.10631325840950012\n",
      "\tLoss: 0.09523757547140121\n",
      "\tLoss: 0.13968947529792786\n",
      "\tLoss: 0.11690875142812729\n",
      "\tLoss: 0.11382988840341568\n",
      "\tLoss: 0.09661909937858582\n",
      "\tLoss: 0.08653348684310913\n",
      "\tLoss: 0.07475746423006058\n",
      "\tLoss: 0.08614392578601837\n",
      "\tLoss: 0.10946852713823318\n",
      "[time] Epoch 58: 433.929341125302s = 7.2321556854217m\n",
      "\n",
      "Epoch 59...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.11485137045383453\n",
      "\tLoss: 0.1513899266719818\n",
      "\tLoss: 0.11258416622877121\n",
      "\tLoss: 0.10032476484775543\n",
      "\tLoss: 0.11325712502002716\n",
      "\tLoss: 0.10242428630590439\n",
      "\tLoss: 0.10420316457748413\n",
      "\tLoss: 0.12716513872146606\n",
      "\tLoss: 0.11264406889677048\n",
      "\tLoss: 0.12642762064933777\n",
      "\tLoss: 0.11041364073753357\n",
      "\tLoss: 0.12856273353099823\n",
      "\tLoss: 0.09101906418800354\n",
      "\tLoss: 0.1343221515417099\n",
      "\tLoss: 0.10864672809839249\n",
      "\tLoss: 0.09867323189973831\n",
      "\tLoss: 0.11506606638431549\n",
      "\tLoss: 0.1279999017715454\n",
      "\tLoss: 0.0889420211315155\n",
      "\tLoss: 0.1269758641719818\n",
      "\tLoss: 0.09986023604869843\n",
      "\tLoss: 0.08914876729249954\n",
      "\tLoss: 0.08182880282402039\n",
      "\tLoss: 0.1116141527891159\n",
      "\tLoss: 0.10076534748077393\n",
      "\tLoss: 0.14731574058532715\n",
      "\tLoss: 0.08876863121986389\n",
      "\tLoss: 0.13023582100868225\n",
      "\tLoss: 0.10690183192491531\n",
      "\tLoss: 0.09261639416217804\n",
      "\tLoss: 0.1149209588766098\n",
      "\tLoss: 0.09552212059497833\n",
      "\tLoss: 0.12412253022193909\n",
      "\tLoss: 0.1130150556564331\n",
      "\tLoss: 0.13718295097351074\n",
      "\tLoss: 0.10594788938760757\n",
      "\tLoss: 0.10379502177238464\n",
      "\tLoss: 0.07171885669231415\n",
      "\tLoss: 0.11659373342990875\n",
      "\tLoss: 0.06737285852432251\n",
      "\tLoss: 0.09691130369901657\n",
      "\tLoss: 0.0756269171833992\n",
      "\tLoss: 0.10893671959638596\n",
      "\tLoss: 0.13169533014297485\n",
      "\tLoss: 0.17987218499183655\n",
      "\tLoss: 0.08443993330001831\n",
      "\tLoss: 0.13906098902225494\n",
      "\tLoss: 0.11742034554481506\n",
      "\tLoss: 0.07335130125284195\n",
      "\tLoss: 0.1290930062532425\n",
      "\tLoss: 0.10254313051700592\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.09837041795253754\n",
      "\tLoss: 0.123650461435318\n",
      "\tLoss: 0.1256057173013687\n",
      "\tLoss: 0.12422563880681992\n",
      "\tLoss: 0.11146670579910278\n",
      "\tLoss: 0.11169231683015823\n",
      "\tLoss: 0.09048467874526978\n",
      "\tLoss: 0.11459296196699142\n",
      "\tLoss: 0.09170597791671753\n",
      "\tLoss: 0.10326157510280609\n",
      "\tLoss: 0.10203980654478073\n",
      "\tLoss: 0.10676071047782898\n",
      "\tLoss: 0.095527783036232\n",
      "\tLoss: 0.13682806491851807\n",
      "\tLoss: 0.13639065623283386\n",
      "\tLoss: 0.10188382863998413\n",
      "\tLoss: 0.09437918663024902\n",
      "\tLoss: 0.1126568540930748\n",
      "\tLoss: 0.13246499001979828\n",
      "\tLoss: 0.1054808646440506\n",
      "\tLoss: 0.10871384292840958\n",
      "\tLoss: 0.08833339810371399\n",
      "\tLoss: 0.07255873084068298\n",
      "\tLoss: 0.0905766710639\n",
      "\tLoss: 0.05419445037841797\n",
      "\tLoss: 0.12211547791957855\n",
      "\tLoss: 0.09193514287471771\n",
      "\tLoss: 0.10243010520935059\n",
      "\tLoss: 0.08239302039146423\n",
      "\tLoss: 0.07138717174530029\n",
      "\tLoss: 0.08446209132671356\n",
      "\tLoss: 0.09795530140399933\n",
      "\tLoss: 0.1249445378780365\n",
      "\tLoss: 0.07981821149587631\n",
      "\tLoss: 0.11659715324640274\n",
      "\tLoss: 0.12071472406387329\n",
      "\tLoss: 0.07791651040315628\n",
      "\tLoss: 0.1335250437259674\n",
      "\tLoss: 0.09528079628944397\n",
      "\tLoss: 0.12216696888208389\n",
      "\tLoss: 0.13279268145561218\n",
      "\tLoss: 0.1256832331418991\n",
      "\tLoss: 0.11478139460086823\n",
      "\tLoss: 0.07611720263957977\n",
      "\tLoss: 0.13447774946689606\n",
      "\tLoss: 0.09007580578327179\n",
      "\tLoss: 0.10088642686605453\n",
      "\tLoss: 0.10958372056484222\n",
      "\tLoss: 0.09916754066944122\n",
      "\tLoss: 0.06883521378040314\n",
      "\tLoss: 0.09062225371599197\n",
      "[time] Epoch 59: 431.1049709264189s = 7.185082848773648m\n",
      "\n",
      "Epoch 60...\n",
      "\tTrabajando con el 0-ésimo DataLoader:\n",
      "\tLoss: 0.1315755546092987\n",
      "\tLoss: 0.10530587285757065\n",
      "\tLoss: 0.08694836497306824\n",
      "\tLoss: 0.09588125348091125\n",
      "\tLoss: 0.07476447522640228\n",
      "\tLoss: 0.09946306049823761\n",
      "\tLoss: 0.10667148977518082\n",
      "\tLoss: 0.08541908860206604\n",
      "\tLoss: 0.1211414635181427\n",
      "\tLoss: 0.11904216557741165\n",
      "\tLoss: 0.09877748787403107\n",
      "\tLoss: 0.08674533665180206\n",
      "\tLoss: 0.11931860446929932\n",
      "\tLoss: 0.10805764049291611\n",
      "\tLoss: 0.09613287448883057\n",
      "\tLoss: 0.11863544583320618\n",
      "\tLoss: 0.13163816928863525\n",
      "\tLoss: 0.10118653625249863\n",
      "\tLoss: 0.13221655786037445\n",
      "\tLoss: 0.12835188210010529\n",
      "\tLoss: 0.13266125321388245\n",
      "\tLoss: 0.1048579066991806\n",
      "\tLoss: 0.08781345188617706\n",
      "\tLoss: 0.1575169563293457\n",
      "\tLoss: 0.08726769685745239\n",
      "\tLoss: 0.14410777390003204\n",
      "\tLoss: 0.10923724621534348\n",
      "\tLoss: 0.08163128793239594\n",
      "\tLoss: 0.08147769421339035\n",
      "\tLoss: 0.10154426842927933\n",
      "\tLoss: 0.13392028212547302\n",
      "\tLoss: 0.09810563921928406\n",
      "\tLoss: 0.09599946439266205\n",
      "\tLoss: 0.11295381188392639\n",
      "\tLoss: 0.15995848178863525\n",
      "\tLoss: 0.10379531979560852\n",
      "\tLoss: 0.15821987390518188\n",
      "\tLoss: 0.05202672630548477\n",
      "\tLoss: 0.10486860573291779\n",
      "\tLoss: 0.12056952714920044\n",
      "\tLoss: 0.12451107800006866\n",
      "\tLoss: 0.08871719241142273\n",
      "\tLoss: 0.11950035393238068\n",
      "\tLoss: 0.13277040421962738\n",
      "\tLoss: 0.11120464652776718\n",
      "\tLoss: 0.11880990862846375\n",
      "\tLoss: 0.11100342869758606\n",
      "\tLoss: 0.1044202372431755\n",
      "\tLoss: 0.09429153054952621\n",
      "\tLoss: 0.13756965100765228\n",
      "\tLoss: 0.14749591052532196\n",
      "\tTrabajando con el 1-ésimo DataLoader:\n",
      "\tLoss: 0.08657295256853104\n",
      "\tLoss: 0.1391429305076599\n",
      "\tLoss: 0.13619911670684814\n",
      "\tLoss: 0.08444267511367798\n",
      "\tLoss: 0.07673183083534241\n",
      "\tLoss: 0.08105167746543884\n",
      "\tLoss: 0.10733088850975037\n",
      "\tLoss: 0.09183626621961594\n",
      "\tLoss: 0.11171559989452362\n",
      "\tLoss: 0.10786347091197968\n",
      "\tLoss: 0.1185002326965332\n",
      "\tLoss: 0.13845978677272797\n",
      "\tLoss: 0.08215247839689255\n",
      "\tLoss: 0.07053837180137634\n",
      "\tLoss: 0.1350717544555664\n",
      "\tLoss: 0.10476236045360565\n",
      "\tLoss: 0.08487096428871155\n",
      "\tLoss: 0.12417012453079224\n",
      "\tLoss: 0.09037221968173981\n",
      "\tLoss: 0.10531199723482132\n",
      "\tLoss: 0.08411645889282227\n",
      "\tLoss: 0.11979413032531738\n",
      "\tLoss: 0.11558981239795685\n",
      "\tLoss: 0.09440688788890839\n",
      "\tLoss: 0.10102874785661697\n",
      "\tLoss: 0.1408652365207672\n",
      "\tLoss: 0.05889209359884262\n",
      "\tLoss: 0.10634976625442505\n",
      "\tLoss: 0.0905095785856247\n",
      "\tLoss: 0.07483559846878052\n",
      "\tLoss: 0.11472292244434357\n",
      "\tLoss: 0.0747704803943634\n",
      "\tLoss: 0.11718425154685974\n",
      "\tLoss: 0.12137682735919952\n",
      "\tLoss: 0.1096043586730957\n",
      "\tLoss: 0.13482464849948883\n",
      "\tLoss: 0.10230684280395508\n",
      "\tLoss: 0.14168009161949158\n",
      "\tLoss: 0.0944175124168396\n",
      "\tLoss: 0.09245799481868744\n",
      "\tLoss: 0.12219053506851196\n",
      "\tLoss: 0.12139071524143219\n",
      "\tLoss: 0.1439867615699768\n",
      "\tLoss: 0.09709706902503967\n",
      "\tLoss: 0.08966603130102158\n",
      "\tLoss: 0.12508298456668854\n",
      "\tLoss: 0.10232803225517273\n",
      "\tLoss: 0.07723640650510788\n",
      "\tLoss: 0.10003374516963959\n",
      "\tLoss: 0.10761216282844543\n",
      "\tLoss: 0.128197580575943\n",
      "[time] Epoch 60: 432.2279159678146s = 7.203798599463577m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The loss function is the quantity that will be\n",
    "# minimized during training.\n",
    "# TO-DO: Escoger 'loss' adecuado.\n",
    "#loss_func = losses.ContrastiveLoss().to(device)\n",
    "loss_func = nn.CosineEmbeddingLoss().to(device)\n",
    "\n",
    "# The optimizer determines how the network will be\n",
    "# updated based on the loss function.\n",
    "# TO-DO: Escoger 'optimizer' adecuado.\n",
    "#optimizer = torch.optim.SGD(red.parameters(), lr=lr, momentum=momentum) # Usado por MNIST Colab.\n",
    "optimizer = torch.optim.Adam(red.parameters(), lr = lr) # Usado por AlexNet (TMLoss y MSELoss).\n",
    "\n",
    "# Para obtener estadísticas del entrenamiento.\n",
    "loss_history = []\n",
    "epoch_timing = []\n",
    "\n",
    "def train(epoch):\n",
    "    \"\"\"\n",
    "    Entrenamiento de la RN.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inicio, en segundos, del epoch.\n",
    "    epoch_start = timer()\n",
    "    \n",
    "    # Imprimimos el número de epoch.\n",
    "    print(f\"Epoch {epoch}...\")\n",
    "    \n",
    "    # Recorremos cada DataLoader.\n",
    "    for dl_idx, dl in enumerate(birds_dl_train):\n",
    "        \n",
    "        # DEBUG.\n",
    "        print(f\"\\tTrabajando con el {dl_idx}-ésimo DataLoader:\")\n",
    "        \n",
    "        for batch_idx, data in enumerate(dl):\n",
    "\n",
    "            # DEBUG.\n",
    "            relative_batch_str = f\"{batch_idx+1}/{len(dl)}\"\n",
    "            #print(f\"\\tProcesando lote {relative_batch_str}...\")\n",
    "        \n",
    "            # Completando lotes que no tienen tamaño batch_size.\n",
    "            incremento = 0\n",
    "            tam_original = len(data[2])\n",
    "            while len(data[2]) < batch_size:\n",
    "                x,y,l = birds_ds.__getitem__()\n",
    "                x = torch.tensor(x)[None, :]\n",
    "                y = torch.tensor(y)[None, :]\n",
    "                l = torch.unsqueeze(torch.tensor(l), 0)\n",
    "                data[0] = torch.cat((data[0], x), 0)\n",
    "                data[1] = torch.cat((data[1], y), 0)\n",
    "                data[2] = torch.cat((data[2], l), 0)\n",
    "                incremento += 1\n",
    "            if incremento != 0:\n",
    "                print(f\"\\tLote {relative_batch_str} de tamaño {tam_original} incrementado en {incremento}.\")\n",
    "            assert len(data[0]) == len(data[1])\n",
    "            assert len(data[0]) == len(data[2])\n",
    "\n",
    "            # 'data' es una lista que representa un lote:\n",
    "            # data[0] contiene los primeros cachos de audio.\n",
    "            # data[1] contiene los segundos cachos de audio.\n",
    "            # data[2] contiene las etiquetas.\n",
    "            for i,d in enumerate(data):\n",
    "                data[i] = d.to(device)\n",
    "\n",
    "            # Convertimos las etiquetas a tipo flotante.\n",
    "            # Necesario para la función de pérdida BCE.\n",
    "            #data[2] = data[2].to(torch.float32)\n",
    "            # TO-DO: ¿Ya no se usará BCE?\n",
    "\n",
    "            # Vaciamos los gradientes para este lote.\n",
    "            optimizer.zero_grad()\n",
    "            # In PyTorch, for every mini-batch during the training phase,\n",
    "            # we typically want to explicitly set the gradients to zero\n",
    "            # before starting to do backpropragation (i.e., updating the\n",
    "            # Weights and biases) because PyTorch accumulates the gradients\n",
    "            # on subsequent backward passes.\n",
    "\n",
    "            # Metemos los datos a la red neuronal.\n",
    "            output_x, output_y = red(data[0], data[1])\n",
    "\n",
    "            # TO-DO: Describir.\n",
    "\n",
    "            start = timer()\n",
    "            loss = loss_func(output_x, output_y, data[2])\n",
    "            end = timer()\n",
    "            #print(f\"\\t[time] Loss function: {end-start}s\") # DEBUG\n",
    "\n",
    "            start = timer()\n",
    "            loss.backward() #dloss/dx for every variable\n",
    "            end = timer()\n",
    "            #print(f\"\\t[time] Loss backward: {end-start}s\") # DEBUG\n",
    "\n",
    "            # TensorBoard.\n",
    "            writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "\n",
    "            start = timer()\n",
    "            optimizer.step() #to do a one-step update on our parameter.\n",
    "            end = timer()\n",
    "            #print(f\"\\t[time] Optimizer step: {end-start}s\") # DEBUG\n",
    "\n",
    "            # Guardamos estadísticas del entrenamiento.\n",
    "            loss_history.append(loss.item())\n",
    "\n",
    "\n",
    "            # DEBUG:\n",
    "            print(f\"\\tLoss: {loss}\")\n",
    "            #print(f\"\\tEtiquetas: {data[2]}\")\n",
    "            #print(f\"\\tOutput: {output}\")\n",
    "            #print()\n",
    "\n",
    "            #break # DEBUG: Permite el entrenamiento de sólo un lote.\n",
    "    \n",
    "    # Fin, en segundos, del epoch.\n",
    "    epoch_end = timer()\n",
    "    \n",
    "    # Tiempo total, en segundos, del epoch.\n",
    "    epoch_time_seconds = epoch_end-epoch_start\n",
    "    epoch_timing.append(epoch_time_seconds)\n",
    "    \n",
    "    # DEBUG:\n",
    "    print(f\"[time] Epoch {epoch}: {epoch_time_seconds}s = {epoch_time_seconds/(60)}m\")\n",
    "    print()\n",
    "    \n",
    "# red.train() le indica al modelo que está siendo entrenado.\n",
    "# Esto ayuda con capas como Dropout y BatchNorm, que están\n",
    "# diseñadas para comporsarse distinto durante entrenamiento\n",
    "# y evaluación.\n",
    "red.train()\n",
    "    \n",
    "# Ejecutamos el entrenamiento definido, \"epochs\" veces.\n",
    "train_start = timer()\n",
    "for epoch in range(1, epochs+1): # Rango [a, b)\n",
    "    train(epoch)\n",
    "    #break # DEBUG: Permite la ejecución de sólo un epoch.\n",
    "train_end = timer()\n",
    "\n",
    "# Call flush() method to make sure that all pending events have been written to disk.\n",
    "# If you do not need the summary writer anymore, call close() method.\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadísticas del entrenamiendo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (20, 10))\n",
    "plt.plot(range(0,len(loss_history)), loss_history, 'r')\n",
    "plt.title('loss_history')\n",
    "plt.xlabel('Lote')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[time] Total training time: 26795.729s = 7.443h\n",
      "[time] Time for each epoch:\n",
      "\t1     503.444s\n",
      "\t2     484.292s\n",
      "\t3     473.083s\n",
      "\t4     464.972s\n",
      "\t5     461.072s\n",
      "\t6     462.480s\n",
      "\t7     460.822s\n",
      "\t8     458.809s\n",
      "\t9     458.392s\n",
      "\t10    455.632s\n",
      "\t11    449.918s\n",
      "\t12    454.820s\n",
      "\t13    448.895s\n",
      "\t14    450.901s\n",
      "\t15    456.567s\n",
      "\t16    445.597s\n",
      "\t17    441.603s\n",
      "\t18    457.124s\n",
      "\t19    446.339s\n",
      "\t20    445.495s\n",
      "\t21    450.575s\n",
      "\t22    450.190s\n",
      "\t23    440.507s\n",
      "\t24    445.561s\n",
      "\t25    446.604s\n",
      "\t26    440.773s\n",
      "\t27    446.461s\n",
      "\t28    451.811s\n",
      "\t29    439.864s\n",
      "\t30    458.532s\n",
      "\t31    452.655s\n",
      "\t32    440.136s\n",
      "\t33    446.495s\n",
      "\t34    442.682s\n",
      "\t35    444.840s\n",
      "\t36    443.339s\n",
      "\t37    440.763s\n",
      "\t38    437.236s\n",
      "\t39    435.498s\n",
      "\t40    442.653s\n",
      "\t41    439.297s\n",
      "\t42    438.378s\n",
      "\t43    437.161s\n",
      "\t44    431.513s\n",
      "\t45    439.168s\n",
      "\t46    437.225s\n",
      "\t47    431.830s\n",
      "\t48    442.036s\n",
      "\t49    440.664s\n",
      "\t50    446.405s\n",
      "\t51    433.282s\n",
      "\t52    441.096s\n",
      "\t53    436.179s\n",
      "\t54    428.771s\n",
      "\t55    427.982s\n",
      "\t56    436.569s\n",
      "\t57    433.474s\n",
      "\t58    433.929s\n",
      "\t59    431.105s\n",
      "\t60    432.228s\n"
     ]
    }
   ],
   "source": [
    "train_time_seconds = train_end-train_start\n",
    "print(\"[time] Total training time: {:.3f}s = {:.3f}h\".format(train_time_seconds, train_time_seconds/(60*60)))\n",
    "print(f\"[time] Time for each epoch:\")\n",
    "for i,x in enumerate(epoch_timing):\n",
    "    print (\"\\t{:<5} {:.3f}s\".format(i+1, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testeo de la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9755620723362658\n",
      "Epoch 2...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.979757085020243\n",
      "Epoch 3...\n",
      "\tProcesando lote 1/52...\n",
      "\t1.0\n",
      "Epoch 4...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9941176470588236\n",
      "Epoch 5...\n",
      "\tProcesando lote 1/52...\n",
      "\t1.0\n",
      "Epoch 6...\n",
      "\tProcesando lote 1/52...\n",
      "\t1.0\n",
      "Epoch 7...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9950980392156863\n",
      "Epoch 8...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9930555555555556\n",
      "Epoch 9...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9970674486803519\n",
      "Epoch 10...\n",
      "\tProcesando lote 1/52...\n",
      "\t1.0\n",
      "Epoch 11...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9930555555555556\n",
      "Epoch 12...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.967741935483871\n",
      "Epoch 13...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9989743589743589\n",
      "Epoch 14...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9765395894428152\n",
      "Epoch 15...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9770833333333332\n",
      "Epoch 16...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.996078431372549\n",
      "Epoch 17...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9941348973607038\n",
      "Epoch 18...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9960899315738025\n",
      "Epoch 19...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9831349206349207\n",
      "Epoch 20...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9784946236559139\n",
      "Epoch 21...\n",
      "\tProcesando lote 1/52...\n",
      "\t1.0\n",
      "Epoch 22...\n",
      "\tProcesando lote 1/52...\n",
      "\t1.0\n",
      "Epoch 23...\n",
      "\tProcesando lote 1/52...\n",
      "\t1.0\n",
      "Epoch 24...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9990147783251231\n",
      "Epoch 25...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9809809809809811\n",
      "Epoch 26...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9853372434017595\n",
      "Epoch 27...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9615384615384616\n",
      "Epoch 28...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9970674486803519\n",
      "Epoch 29...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9667644183773215\n",
      "Epoch 30...\n",
      "\tProcesando lote 1/52...\n",
      "\t1.0\n",
      "Epoch 31...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.953125\n",
      "Epoch 32...\n",
      "\tProcesando lote 1/52...\n",
      "\t1.0\n",
      "Epoch 33...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9824046920821115\n",
      "Epoch 34...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9655172413793103\n",
      "Epoch 35...\n",
      "\tProcesando lote 1/52...\n",
      "\t1.0\n",
      "Epoch 36...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9827935222672065\n",
      "Epoch 37...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.943359375\n",
      "Epoch 38...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9861111111111112\n",
      "Epoch 39...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9980449657869013\n",
      "Epoch 40...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.946946946946947\n",
      "Epoch 41...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9861111111111112\n",
      "Epoch 42...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9911330049261083\n",
      "Epoch 43...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9684729064039409\n",
      "Epoch 44...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9950396825396826\n",
      "Epoch 45...\n",
      "\tProcesando lote 1/52...\n",
      "\t1.0\n",
      "Epoch 46...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9853372434017595\n",
      "Epoch 47...\n",
      "\tProcesando lote 1/52...\n",
      "\t1.0\n",
      "Epoch 48...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.995897435897436\n",
      "Epoch 49...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9852941176470589\n",
      "Epoch 50...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9826839826839826\n",
      "Epoch 51...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9912023460410557\n",
      "Epoch 52...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9970443349753695\n",
      "Epoch 53...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9667644183773216\n",
      "Epoch 54...\n",
      "\tProcesando lote 1/52...\n",
      "\t1.0\n",
      "Epoch 55...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9853515625\n",
      "Epoch 56...\n",
      "\tProcesando lote 1/52...\n",
      "\t1.0\n",
      "Epoch 57...\n",
      "\tProcesando lote 1/52...\n",
      "\t1.0\n",
      "Epoch 58...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9714285714285714\n",
      "Epoch 59...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.984313725490196\n",
      "Epoch 60...\n",
      "\tProcesando lote 1/52...\n",
      "\t0.9803921568627451\n"
     ]
    }
   ],
   "source": [
    "# Cargado de la RN.\n",
    "#fecha = \"2023-01-28-17-37\"\n",
    "#red = RN().to(device)\n",
    "#red.load_state_dict(torch.load(DIR_models+fecha+\".pt\"))\n",
    "red.eval()\n",
    "\n",
    "def test(epoch):\n",
    "    \"\"\"\n",
    "    Testeo de la RN.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Estadísticas del testeo.\n",
    "    VP, FP, VN, FN = [0]*4\n",
    "    \n",
    "    # Inicio, en segundos, del epoch.\n",
    "    epoch_start = timer()\n",
    "    \n",
    "    # Imprimimos el número de epoch.\n",
    "    print(f\"Epoch {epoch}...\")\n",
    "    \n",
    "    for batch_idx, data in enumerate(birds_dl_test):\n",
    "\n",
    "        # DEBUG.\n",
    "        print(f\"\\tProcesando lote {batch_idx+1}/{len(birds_dl_test)}...\")\n",
    "        \n",
    "        # Completando lotes que no tienen tamaño batch_size.\n",
    "        incremento = 0\n",
    "        tam_original = len(data[2])\n",
    "        while len(data[2]) < batch_size:\n",
    "            x,y,l = birds_ds.__getitem__()\n",
    "            x = torch.tensor(x)[None, :]\n",
    "            y = torch.tensor(y)[None, :]\n",
    "            l = torch.unsqueeze(torch.tensor(l), 0)\n",
    "            data[0] = torch.cat((data[0], x), 0)\n",
    "            data[1] = torch.cat((data[1], y), 0)\n",
    "            data[2] = torch.cat((data[2], l), 0)\n",
    "            incremento += 1\n",
    "        if incremento != 0:\n",
    "            print(f\"\\tLote de tamaño {tam_original} incrementado en {incremento}.\")\n",
    "        assert len(data[0]) == len(data[1])\n",
    "        assert len(data[0]) == len(data[2])\n",
    "        \n",
    "        # 'data' es una lista que representa un lote:\n",
    "        # data[0] contiene los primeros cachos de audio.\n",
    "        # data[1] contiene los segundos cachos de audio.\n",
    "        # data[2] contiene las etiquetas.\n",
    "        for i,d in enumerate(data):\n",
    "            data[i] = d.to(device)\n",
    "        \n",
    "        # Metemos los datos a la red neuronal.\n",
    "        output_x, output_y = red(data[0], data[1])\n",
    "        \n",
    "        # Realizamos la diferencia con Similitud Coseno.\n",
    "        cos = nn.CosineSimilarity()\n",
    "        diff = cos(output_x, output_y)\n",
    "        \n",
    "        #print(f\"Etiquetas: {data[2]}\")\n",
    "        #print(f\"CosineSimilarity: {diff}\")\n",
    "\n",
    "        # Estadísticas del testeo del lote.\n",
    "        correctNeg50 = 0\n",
    "        correctZero = 0\n",
    "        correctPos50 = 0\n",
    "        correctUmbral = 0\n",
    "        umbral = 0.75 # Umbral entre -1 y 1.\n",
    "        \n",
    "        for i,l in enumerate(data[2]):\n",
    "            #total += 1\n",
    "            \n",
    "            if (diff[i] >= -0.5 and l == 1) or (diff[i] < -0.5 and l == -1):\n",
    "                correctNeg50 += 1\n",
    "            \n",
    "            if (diff[i] >= 0 and l == 1) or (diff[i] < 0 and l == -1):\n",
    "                correctZero += 1\n",
    "            \n",
    "            if (diff[i] >= 0.5 and l == 1) or (diff[i] < 0.5 and l == -1):\n",
    "                correctPos50 += 1\n",
    "            \n",
    "            if (diff[i] >= umbral and l == 1) or (diff[i] < umbral and l == -1):\n",
    "                correctUmbral += 1\n",
    "        \n",
    "        #print(f\"\\t\\tCon umbral -0.5: {correctNeg50}/{len(data[2])}\")\n",
    "        #print(f\"\\t\\tCon umbral    0: {correctZero}/{len(data[2])}\")\n",
    "        #print(f\"\\t\\tCon umbral  0.5: {correctPos50}/{len(data[2])}\")\n",
    "        #print(f\"\\t\\tCon umbral {umbral}: {correctUmbral}/{len(data[2])}\")\n",
    "        \n",
    "        # ROC_AUC\n",
    "        y_pred = diff.cpu().detach().numpy()\n",
    "        y_true = data[2].cpu().detach().numpy()\n",
    "        print(f\"\\t{roc_auc_score(y_true, y_pred)}\")\n",
    "        \n",
    "        # DEBUG: Permite el testeo de un sólo lote\n",
    "        break\n",
    "        \n",
    "        # TO-DO: Terminar definición del testeo.\n",
    "\n",
    "# Ejecutamos el testeo definido, \"epochs\" veces.\n",
    "test_start = timer()\n",
    "for epoch in range(1, epochs+1): # Rango [a, b)\n",
    "    test(epoch)\n",
    "    #break # DEBUG: Permite la ejecución de sólo un epoch.\n",
    "test_end = timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadísticas del testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[time] Total testing time: 257.009s = 4.283m = 0.071h\n"
     ]
    }
   ],
   "source": [
    "test_time_seconds = test_end-test_start\n",
    "print(\"[time] Total testing time: {:.3f}s = {:.3f}m = {:.3f}h\".format(test_time_seconds, test_time_seconds/60, test_time_seconds/(60*60)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardado de la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(red.state_dict(), DIR_models+dt_string+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG\n",
    "\n",
    "Esta celda y las siguientes son para testear. Han de ser eliminadas cuando se limpie el código de este *notebook*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado de objetos.\n",
    "with open(DIR_objects+dt_string+\"_loss-history\", \"wb\") as file:\n",
    "    pickle.dump(loss_history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargado de objetos.\n",
    "fecha = \"\"\n",
    "\n",
    "#with open(DIR_objects+fecha+\"_loss-history\", \"rb\") as file:\n",
    "    #pickle.dump(loss_history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = birds_df.iloc[5][file_col_name]\n",
    "#librosa_process(birds_path+f, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.uniform(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9\n",
      "1 2 3 4 5 6 7 8 9\n"
     ]
    }
   ],
   "source": [
    "print(*range(0,10))\n",
    "print(*range(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-03-2023-13-39-48\n"
     ]
    }
   ],
   "source": [
    "dt_string = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "print(dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargado de modelos.\n",
    "fecha = \"\"\n",
    "\n",
    "# Definimos un modelo que alojará a la Red Neuronal.\n",
    "#modelo = RN().to(device)\n",
    "\n",
    "# Actualizamos el modelo.\n",
    "#modelo.load_state_dict(torch.load(DIR_models+fecha+\".pt\"))\n",
    "\n",
    "# modelo.eval() le indica al modelo que ha de evaluar.\n",
    "#modelo.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3277\n",
      "3277\n",
      "total_audios/batch_size = 51.203125\n"
     ]
    }
   ],
   "source": [
    "print(len(birds_df))\n",
    "print(len(birds_ds))\n",
    "print(f\"total_audios/batch_size = {len(birds_df)/batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha = \"2023-02-01-05-24\"\n",
    "#red = RN().to(device)\n",
    "#red.load_state_dict(torch.load(DIR_models+fecha+\".pt\"))\n",
    "#red.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 1\n",
      "diff: tensor([0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736,\n",
      "        0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736,\n",
      "        0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736,\n",
      "        0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736,\n",
      "        0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736,\n",
      "        0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736,\n",
      "        0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736, 0.9736,\n",
      "        0.9736], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x,y,l = birds_ds.__getitem__()\n",
    "\n",
    "x = np.expand_dims(x, 0)\n",
    "x = np.repeat(x, batch_size, axis=0)\n",
    "x = torch.tensor(x).to(device)\n",
    "\n",
    "y = np.expand_dims(y, 0)\n",
    "y = np.repeat(y, batch_size, axis=0)\n",
    "y = torch.tensor(y).to(device)\n",
    "\n",
    "#l = np.repeat(l, batch_size)\n",
    "\n",
    "output_x, output_y = red(x, y)\n",
    "cos = nn.CosineSimilarity()\n",
    "diff = cos(output_x, output_y)\n",
    "\n",
    "print(f\"label: {l}\")\n",
    "print(f\"diff: {diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En México:\n",
      "2023-03-02 07:39:48.480944-06:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone, timedelta\n",
    "print(\"En México:\")\n",
    "print(datetime.now(timezone(timedelta(hours=-6))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
